
SCRAPE AND WRITE NOTES FOR FOLLOWING: https://www.geeksforgeeks.org/number-theory-competitive-programming/#basics
SCRAPE AND WRITE NOTES FOR FOLLOWING: https://medium.com/algorithms-and-leetcode/math-related-problems-on-leetcode-9537df481fbe

REVIEW MATHEMATICS/GEOMETRY ALGORITHMS FROM CP ALGORITHMS:
https://cp-algorithms.com/

Convex hull: Given a set of points, find the smallest convex polyhedron/polygon containing all the points.
Line segment intersection: Find the intersections between a given set of line segments.
Delaunay triangulation
Voronoi diagram: Given a set of points, partition the space according to which points are closest to the given points.
Linear programming
Closest pair of points: Given a set of points, find the two with the smallest distance from each other.
Largest empty circle: Given a set of points, find a largest circle with its center inside of their convex hull and enclosing none of them.
Euclidean shortest path: Connect two points in a Euclidean space (with polyhedral obstacles) by a shortest path.
Polygon triangulation: Given a polygon, partition its interior into triangles
Mesh generation
Boolean operations on polygons
The computational complexity for this class of problems is estimated by the time and space (computer memory) required to solve a given problem instance.

Geometric query problems
In geometric query problems, commonly known as geometric search problems, the input consists of two parts: the search space part and the query part, which varies over the problem instances. The search space typically needs to be preprocessed, in a way that multiple queries can be answered efficiently.

Some fundamental geometric query problems are:

Range searching: Preprocess a set of points, in order to efficiently count the number of points inside a query region.
Point location: Given a partitioning of the space into cells, produce a data structure that efficiently tells in which cell a query point is located.
Nearest neighbor: Preprocess a set of points, in order to efficiently find which point is closest to a query point.
Ray tracing: Given a set of objects in space, produce a data structure that efficiently tells which object a query ray intersects first.


0.1) Put the soln for converitng numberst to base -2 from leetcode. 




1. Basics of Array, String, Greedy, and Bit Manipulation:

Counting frequencies of array elements
Float and Precision
Prefix sum, 2D Prefix Sum, Difference Array
Coordinate Compression
Kadane Algorithm
Activity Selection Problem
Job Sequencing Problem
Sliding Window
Logical Operators
Bit Manipulation
2. Number Theory and Combinatorics:

Prime Number and Sieve Algorithms
Number Factorization and GCD/LCM
Linear Diophantine Equations
Euclidean algorithms
Euler’s Totient Function and Euler’s Totient function
Inclusion-Exclusion Principle and Pigeon Hole Principle
Modular Operations and Modular Inverse
Chinese Remainder Theorem
Permutation and Combination
Catalan numbers
3. Searching, Sorting, and Basic Data Structures:

Linear Search and Binary Search
Sorting Algorithms
Stack, Queue, Deque, Priority Queue
Tree and Graph Traversal
Shortest Path Algorithms
Minimum Spanning Tree Algorithms
Topological Sorting
Bipartite Graphs
Strongly Connected Components
Flow Algorithms
4. Recursion and Dynamic Programming:

Recursion and Backtracking
Dynamic Programming Introduction and Practice Problems
Additional DP Problems and DP on Trees
DP on Bit Masking and Digit DP
5. String Algorithms:

Suffix Tree and Z Algorithm
Pattern Searching Algorithms
String Matching Algorithms
6. Geometry and Game Theory:

Closest Pair of Points and Convex Hull
Intersecting Line Segments and Point Polygon Testing
Combinatorial Game Theory and Minimax Algorithm
Nim Game Strategy and Game Theory
7. Advanced Data Structures:

Trie and Fenwick Tree
Segment Tree and Sparse Table
Sqrt Decomposition and Heavy Light Decomposition
Meet in the Middle and MO’s Algorithm
Hope this guide proves helpful in your learning journey! Feel free to share any suggestions or additional tips you may have, as we're all constantly learning and growing in this field. Please upvote it help 😉



WRITE NOTES ON COMPUTATIONAL GEOMETRY IN NOTES SECTION HERE.

-7) Review permutations, combinations, pascals triangle. 
    pascals triangle and the combination term 
    Review bionmial theorem:
    https://www.cuemath.com/algebra/binomial-theorem/

    And expansion of terms. 

    Combinatorics
    Generating Functions 
    Solving recurrences using generating functions 

    Counting principle, 
    Bijjection principle, 
    Double counting 
    Combinations and subsets
    Multinomial coefficents

    Binomial coefficients
    https://www.math.kit.edu/iag6/lehre/co2015s/media/script.pdf


    Permuations in a circle
    


-6) GCD of multiple numbers follows following rule: 
    The GCD of three or more numbers equals the product of the prime factors 
    common to all the numbers, but it can also be calculated by repeatedly 
    taking the GCDs of pairs of numbers.

    gcd(a, b, c) = gcd(a, gcd(b, c)) 
                = gcd(gcd(a, b), c) 
                = gcd(gcd(a, c), b)

    For an array of elements, we do the following. We will also 
    check for the result if the result at any step becomes 
    1 we will just return the 1 as gcd(1,x)=1.
    





-5) Write about binomial coefficients:
    https://cp-algorithms.com/combinatorics/binomial-coefficients.html

-4) Stars and Bars Combinatorics
    (https://cp-algorithms.com/combinatorics/stars_and_bars.html)

    The number of ways to put n identical objects into k labelled boxes is 
    (n + k - 1) choose n


    The proof involves turning the objects into stars and separating the 
    boxes using bars (therefore the name). E.g. we can represent with ★|★★| |★★ 
    the following situation: in the first box is one object, in the second box 
    are two objects, the third one is empty and in the last box are two objects. 
    This is one way of dividing 5 objects into 4 boxes.

    It should be pretty obvious, that every partition can be represented using 
    n stars and k−1 bars and every stars and bars permutation using 
    n stars and k−1 bars represents one partition. Therefore the number of 
    ways to divide n identical objects into k labeled boxes is the same number 
    as there are permutations of n stars and k−1 bars. 
    The Binomial Coefficient gives us the desired formula.

    Number of non-negative integer sums
    This problem is a direct application of the theorem.

    You want to count the number of solution of the equation
    x1+x2+⋯+xk=n
    with xi≥0.

    Again we can represent a solution using stars and bars. E.g. 
    the solution 1+3+0=4 for n=4, k=3 can be represented using ★|★★★|.
    It is easy to see, that this is exactly the stars an bars theorem. 
    Therefore the solution is (n+k−1 choose n).

    Number of lower-bound integer sums
    This can easily be extended to integer sums with different 
    lower bounds. I.e. we want to count the number of solutions for the equation
    x1+x2+⋯+xk=n
    with xi≥ai.

    After substituting x′i:=xi−ai we receive the modified equation
    (x′1 + ai) + (x′2 + ai) +⋯+ (x′k+ak) = n
    ⇔  x′1 + x′2 +⋯+ x′k =(n−a1−a2−⋯−ak)
    with x′i≥0. So we have reduced the problem to the 
    simpler case with x′i≥0 and again can apply the stars and bars theorem.







-3) Integration by Simpson's formula
    WRITE NOTES FROM HERE -> https://cp-algorithms.com/num_methods/simpson-integration.html






-2) NUMERICAL Computation -> Newtons method for finding roots: 
    (https://cp-algorithms.com/num_methods/roots_newton.html)
    Find roots of f(x) = 0

    We want to solve the equation. More precisely, we want to find one of its roots 
    (it is assumed that the root exists). It is assumed that f(x) is 
    continuous and differentiable on an interval [a,b].

    Algorithm
    The input parameters of the algorithm consist of not only the function f(x) 
    but also the initial approximation - some x0, with which the algorithm starts.

    Suppose we have already calculated xi, calculate xi+1 as follows. 
    Draw the tangent to the graph of the function f(x) at the point x=xi, 
    and find the point of intersection of this tangent with the x-axis. xi+1 is set equal to 
    the x-coordinate of the point found, and we repeat the whole process from the beginning.

    It is not difficult to obtain the following formula:

    x(i+1) = xi − f(xi)/f′(xi)

    It is intuitively clear that if the function f(x) is "good" (smooth), and xi is 
    close enough to the root, then xi+1 will be even closer to the desired root.
    The rate of convergence is quadratic, which, conditionally speaking, means 
    that the number of exact digits in the approximate value xi doubles with each iteration.

    Let's use the calculation of square root as an example of Newton's method.

    If we substitute f(x)=x^2−n, then after simplifying the expression, we get:

    x(i+1)= (xi + n/xi) / 2
    
    The first typical variant of the problem is when a rational number n is 
    given, and its root must be calculated with some accuracy eps:

    double sqrt_newton(double n) {
        const double eps = 1E-15;
        double x = 1;
        for (;;) {
            double nx = (x + n / x) / 2;
            if (abs(x - nx) < eps)
                break;
            x = nx;
        }
        return x;
    }

    Another common variant of the problem is when we need to calculate the 
    integer root (for the given n find the largest x such that x^2≤n). 
    
    Here it is necessary to slightly change the termination condition of the algorithm, 
    since it may happen that x will start to "jump" near the answer. 
    Therefore, we add a condition that if the value x has decreased 
    in the previous step, and it tries to increase at the current step, 
    then the algorithm must be stopped.

    int isqrt_newton(int n) {
        int x = 1;
        bool decreased = false;
        for (;;) {
            int nx = (x + n / x) >> 1;
            if (x == nx || nx > x && decreased)
                break;
            decreased = nx < x;
            x = nx;
        }
        return x;
    }

    Finally, we are given the third variant - for the case of bignum arithmetic. 
    Since the number n can be large enough, it makes sense to 
    pay attention to the initial approximation. 
    
    Obviously, the closer it is to the root, the faster 
    the result will be achieved. It is simple enough 
    and effective to take the initial approximation as 
    the number 2^(bits/2), where bits is the number of bits in the number n. 
    
    Here is the Java code that demonstrates this variant:


    public static BigInteger isqrtNewton(BigInteger n) {
        BigInteger a = BigInteger.ONE.shiftLeft(n.bitLength() / 2);
        boolean p_dec = false;
        for (;;) {
            BigInteger b = n.divide(a).add(a).shiftRight(1);
            if (a.compareTo(b) == 0 || a.compareTo(b) < 0 && p_dec)
                break;
            p_dec = a.compareTo(b) > 0;
            a = b;
        }
        return a;
    }

    For example, this code is executed in 60 milliseconds for n=101000, 
    and if we remove the improved selection of the initial 
    approximation (just starting with 1), then it will be 
    executed in about 120 milliseconds.

    Try problem: UVa 10428 - The Roots


-1) -> LOOK AT QUESTION: Consecutive Numbers Hard in important problems to see how to do hard 
     math programming leets, with factors, primes, and creating equations from theories!
      
    Also learn to write out sums as arithmetic and geometric sequences to create useful formulas, 
    or figure out that once something is factorized, one side has to be odd, and the other has to be 
    even.

    Take advatange of all the different tricks is what you see in that problem. 


-0.5) Counting the number of  divisors of a number -> O(sqrt(N))

    If number n is of the form k2, then the symmetric divisor of k is also k. 
    This divisor should be counted just once.

    1 def divisors(n):
    2   i = 1
    3   result = 0
    4   while (i * i < n):
    5       if (n % i == 0):
    6           result += 2
    7       i += 1
    8   if (i * i == n):
    9       result += 1
    10  return result

-0.6) Primality Test:
    We assume that 1 is neither a prime nor a composite number, so the below algorithm works
    only for n >= 2.
    
    1 def primality(n):
    2   i = 2
    3   while (i * i <= n):
    4       if (n % i == 0):
    5           return False
    6       i += 1
    7   return True

-0.65) Reversing Coins problem:
    Problem: Consider n coins aligned in a row. 
    Each coin is showing heads at the beginning. 
    1 2 3 4 5 6 7 8 9 10
    Then, n people turn over corresponding coins as follows. 
    Person i reverses coins with numbers
    that are multiples of i. That is, person i flips coins i, 2 · i, 3 · i, . . . 
    until no more appropriate coins remain. 
    The goal is to count the number of coins showing tails

    Solution O(log n): Notice that each coin will be turned over exactly as many times as the
    number of its divisors. The coins that are reversed an odd number of times show tails, meaning
    that it is sufficient to find the coins with an odd number of divisors.
    We know that almost every number has a symmetric divisor (apart from divisors of the
    form √n). Thus, every number of the form k^2 has an odd number of divisors. There are
    exactly √n such numbers between 1 and n. Finding the value of √n takes logarithmic
    time (or constant time if we use operations on floating point numbers).


-0.70) Fibonnaci and using input limits to your advantage. 
    Problem: For all the given numbers x0, x1, . . . , xn−1, such that 1 <= xi <= m <= 1 000 000,
    check whether they may be presented as the sum of two Fibonacci numbers.
    Solution: Notice that only a few tens of Fibonacci numbers are smaller than the maximal
    m (exactly 31). We consider all the pairs. If some of them sum to k <= m, then we mark
    index k in the array to denote that the value k can be presented as the sum of two Fibonacci
    numbers.
    In summary, for each number xi we can answer whether it is the sum of two Fibonacci
    numbers in constant time. The total time complexity is O(n + m).

-0.75) Fast Fib:

    Phi = (sqrt(5) + 1)/2
    Fib(n) = [Phi^n - (-Phi)^(-n)]/sqrt(5) 

-0.80) Sequences and Series: 

    Arithmetic: a, a+d, a+2d, ...
    kth term: a + (k-1)*d
    Sum of n terms = (n/2) * (2a + (n-1)*d) 

    Sum of first n ints -> (n/2)*(n+1)

    Sum of the squares of the first n integers: 
    1^2 + 2^2 + ... n^2
    -> (1/6)*n*(n+1)*(2n+1)

    Geometric progression: a, ar, ar^2
    r-> common ratio, a-> first term
    kth term: ar^(k-1)

    Sum of n terms:   S = a*(1-r^n)/(1-r), r!= 1
    
    Sum of infinite geometric series:   S = a/(1-r), -1<r<1







0) Counting number of binary digits that are 1 in number:
    class Solution:
        #Slow way
        def hammingWeightSlow(self, n: int) -> int:
            # count it up!
            
            count = 0
            while n != 0: 
                count += (n & 1)
                n = n >> 1
            return count
        
        '''
        We can make the previous algorithm simpler and a little faster. 
        Instead of checking every bit of the number, we repeatedly flip 
        the least-significant 1-bit of the number to 0, and add 1 to the sum. 
        As soon as the number becomes 00, we know that it does 
        not have any more 11-bits, and we return the sum.

        The key idea here is to realize that for any number n, 
        doing a bit-wise AND of nn and n - 1 flips the least-significant 
        1-bit in n to 0.
        '''
        def hammingWeight(self, n: int) -> int:
            # count it up!
            
            count = 0
            while n != 0: 
                count += 1
                n = n & (n-1)
            return count

0.5) Catalan numbers: 

     Catalan numbers is a number sequence, which is found useful 
     in a number of combinatorial problems, often involving 
     recursively-defined objects.
     The first few numbers Catalan numbers, Cn (starting from zero):

     1,1,2,5,14,42,132,429,1430,…

    Application in some combinatorial problems
    The Catalan number Cn is the solution for

    Number of correct bracket sequence consisting of n opening and n closing brackets.
    The number of valid parenthesis expressions that consist of n 
    right parentheses and n left parethensis. N = 3 -> C = 5

    ( ) ( ) ( )
    ( ( ) ) ( )
    ( ) ( ( ) )
    ( ( ( ) ) )
    ( ( ) ( ) )
    
    The number of rooted full binary trees with n+1 leaves (vertices are not numbered). 
    A rooted binary tree is full if every vertex has either two children or no children.

    The number of ways to completely parenthesize n+1 factors.
    
    the number of ways a polygon with n+2 sides can be cut into n triangles
    The number of triangulations of a convex polygon with n+2 sides 
    (i.e. the number of partitions of polygon into disjoint triangles by using the diagonals).

    The number of ways to connect the 2n points on a circle to form n disjoint chords.
    
    the number of planar binary trees with n+1 leaves
    
    the number of paths of length 2n through an n-by-n grid that do not rise above the main diagonal

    The number of non-isomorphic full binary trees with n internal nodes (i.e. 
    nodes having at least one son).
    
    The number of monotonic lattice paths from point (0,0) to point (n,n) 
    in a square lattice of size n×n, which do not pass above the main 
    diagonal (i.e. connecting (0,0) to (n,n)).
    
    Number of permutations of length n that can be stack sorted 
    (i.e. it can be shown that the rearrangement is stack 
    sorted if and only if there is no such index i<j<k, such that ak<ai<aj ).
    
    The number of non-crossing partitions of a set of n elements.
    
    The number of ways to cover the ladder 1…n using n rectangles 
    (The ladder consists of n columns, where ith column has a height i).


0.75) Catalan numbers ANALYSIS: 
    There are two formulas for the Catalan numbers: Recursive and Analytical. 
    Since, we believe that all the mentioned above problems are equivalent 
    (have the same solution), for the proof of the formulas below we will
    choose the task which it is easiest to do.
    C0 = C1 = 1
    For n >= 2
        C_n = sum(from k = 0 to n-1) C_k * C_{n-1-k} 
    
    The recurrence formula can be easily 
    deduced from the problem of the correct 
    bracket sequence.

    Analytical Formula:
    Cn = (2n choose n) / (n+1)




0.80) Simplify a rational number 

        For numerator = 3 and denominator = 6, the output should be
        simplifyRational(numerator, denominator) = [1, 2].


        def gcdWorksOnlyWithPositives(a, b):
            if a == 0:
                return b
            if b == 0:
                return a
            
            if a == b:
                return a
            elif a < b:
                return gcd(b-a, a)
            else:
                return gcd(b, a-b)
            
        def gcd(a, b):
            while b != 0:
                t = b
                b = a % b
                a = t
            return a

        def simplifyRational(numerator, denominator):
            
            # FIND GCD Of numerator, and denominator,
            # THEN divide it from both!
            # yeah
            
            if numerator < 0 and denominator < 0:
                numerator *= -1
                denominator *= -1
            elif denominator <0:
                numerator *= -1
                denominator *= -1
                
            gcda = gcd(numerator, denominator)
            return [numerator/gcda, denominator/gcda]





0.90) What is the fastest integer factorization algorithm?

    In your algo -> 
    Don't forget to check whether the number is a true square. If it is, and you don't 
    take it into account, you'll be adding the square root to the sum twice 
    (as both i AND n/i). Take a look at Project Euler - there's all 
    sorts of things on there covering this type of optimisation.

    Less than 2^16 or so: Lookup table.
    Less than 2^70 or so: Richard Brent's modification of Pollard's rho algorithm.
    Less than 10^50: Lenstra elliptic curve factorization
    Less than 10^100: Quadratic Sieve
    More than 10^100: General Number Field Sieve

0.91) Trial Division technique: 

    We divide by each possible divisor d. We can notice, 
    that it is impossible that all prime factors of a composite 
    number n are bigger than sqrt(n). Therefore, we only need to test 
    the divisors 2≤ d ≤ sqrt(n) , which gives us the prime factorization in O(√n).

    The smallest divisor has to be a prime number. We remove the factor 
    from the number, and repeat the process. If we cannot find any divisor 
    in the range [2;√n], then the number itself has to be prime.


    vector<long long> trial_division1(long long n) {
        vector<long long> factorization;
        for (long long d = 2; d * d <= n; d++) {
            while (n % d == 0) {
                factorization.push_back(d);
                n /= d;
            }
        }
        if (n > 1)
            factorization.push_back(n);
        return factorization;
    }

0.92) Wheel factorization

        This is an optimization of the trial division. 
        The idea is the following. Once we know that the number is not 
        divisible by 2, we don't need to check every other even number. 
        This leaves us with only 50% of the numbers to check. After 
        checking 2, we can simply start with 3 and skip every other number.

        vector<long long> trial_division2(long long n) {
            vector<long long> factorization;
            while (n % 2 == 0) {
                factorization.push_back(2);
                n /= 2;
            }
            for (long long d = 3; d * d <= n; d += 2) {
                while (n % d == 0) {
                    factorization.push_back(d);
                    n /= d;
                }
            }
            if (n > 1)
                factorization.push_back(n);
            return factorization;
        }

        This method can be extended. If the number is not divisible by 3, 
        we can also ignore all other multiples of 3 in the future 
        computations. So we only need to check the numbers 5,7,11,13,17,19,23,…. 
        
        We can observe a pattern of these remaining numbers. We need to check 
        all numbers with dmod6=1 and dmod6=5. So this leaves us with 
        only 33.3% percent of the numbers to check. We can implement 
        this by checking the primes 2 and 3 first, and then start 
        checking with 5 and alternatively skip 1 or 3 numbers.

        We can extend this even further. Here is an implementation 
        for the prime number 2, 3 and 5. It's convenient to use an 
        array to store how much we have to skip.


        vector<long long> trial_division3(long long n) {
            vector<long long> factorization;
            for (int d : {2, 3, 5}) {
                while (n % d == 0) {
                    factorization.push_back(d);
                    n /= d;
                }
            }
            static array<int, 8> increments = {4, 2, 4, 2, 4, 6, 2, 6};
            int i = 0;
            for (long long d = 7; d * d <= n; d += increments[i++]) {
                while (n % d == 0) {
                    factorization.push_back(d);
                    n /= d;
                }
                if (i == 8)
                    i = 0;
            }
            if (n > 1)
                factorization.push_back(n);
            return factorization;
        }

        If we extend this further with more primes, we can even 
        reach better percentages. However, also the skip lists will get a lot bigger.

0.93) Precomputed primes
      Extending the wheel factorization with more and more primes will 
      leave exactly the primes to check. So a good way of checking is just to 
      precompute all prime numbers with the Sieve of Eratosthenes 
      until √n and test them individually.

    vector<long long> primes;

    vector<long long> trial_division4(long long n) {
        vector<long long> factorization;
        for (long long d : primes) {
            if (d * d > n)
                break;
            while (n % d == 0) {
                factorization.push_back(d);
                n /= d;
            }
        }
        if (n > 1)
            factorization.push_back(n);
        return factorization;
    }

0.94) CONTINUE WRITING INTEGER FACTORIZATION NOTES FROM: 
      https://cp-algorithms.com/algebra/factorization.html

      


0.95) Read up on https://en.wikipedia.org/wiki/Centered_polygonal_number

    You're having a big party and you're serving a pizza as a main dish. 
    You got really tired of cutting the pizza, so you decided to do it as 
    efficiently as possible by using no more than n cuts.

    Each cut is required to be a straight line, and there is no 
    requirement that the pizza pieces be the same size.

    Given n, the number of straight cuts you're willing to make, 
    find the maximum number of pieces you can cut the pizza into.

    def lazyCutter(n):
    #PATTERN: 2, 4, 7, 11, 16 
    #N INPUT: 1  2  3   4,  5
    if n == 0:
        return 1
        
    count = 2
    diff = 2
    for i in range(n-1):
        count += diff 
        diff += 1
        
    
    return count 
    
    Central polygonal numbers (the Lazy Caterer's sequence): n(n+1)/2 + 1; 
    or, maximal number of pieces formed when slicing a pancake with n cuts.
    (Formerly M1041 N0391)		366
    1, 2, 4, 7, 11, 16, 22, 29, 37, 46, 56, 67, 79, 92, 106, 121, 137, 154, 
    172, 191, 211, 232, 254, 277, 301, 326, 352, 379, 407, 436, 466, 497, 
    529, 562, 596, 631, 667, 704, 742, 781, 821, 862, 904, 947, 991, 1036, 
    1082, 1129, 1177, 1226, 1276, 1327, 1379 (list; graph; refs; listen; history; text; internal format)
    OFFSET	
    0,2

    COMMENTS	
    These are Hogben's central polygonal numbers with the (two-dimensional) symbol
    The first line cuts the pancake into 2 pieces. For n > 1, the n-th line crosses every 
    earlier line (avoids parallelism) and also avoids every previous line intersection, 
    thus increasing the number of pieces by n. For 16 lines, for example, the number of 
    pieces is 2 + 2 + 3 + 4 + 5 + ... + 16 = 137. These are the triangular numbers plus 1 (cf. A000217).


1) Crack the coding interview 2' Complement:

    Twos complement of a N-bit number is the complement of the number with respect to 2^N

    Create -3 in a 4 bit system. Have 1 bit for the sign. and 3 bits for the value. 
    We want complement wrt to 2^3 which is 8 -> that is 5. 5 is 101 in binary. 
    Therefore -3 as a 4bit number is 1101. 

    In other words the binary rep of -K as a N-bit number is concat(1, 2^(N-1) - K)
    OR, we invert the bits in the positive number, and then add 1. 

    7 and -1 look the same aka: 0111, 1111
    6 and -2 look the same aka: 0110, 1110
    5 and -3 look the same aka: 0101, 1101
    4 and -4 look the same aka: 0100, 1100
    3 and -5 look the same aka: 0011, 1011
    2 and -6 look the same aka: 0010, 1010
    1 and -7 look the same: 0001, 1001
    0 -> 0000
    Observe above the values that look the same, and that the abs(left) + abs(right) sum to 2^8
    They are identical except for sign bit. Why is tht?

    Arithmetic vs Logical Shift. 

    In a logical shift to riight -> we shift the bits and put a 0 as the most sig bit. 
    -75 >>= 1  -> will become 90
    in arithmetic right shfit, we shift the values to the right but fill in the new bits
    with the value of the sign bit (so its division by 2 rather than a force in of a 0 as MSB)

    Bit ops:

    Get bit easy to write

    set bit: num | (1 << i);

    Clear bit -> need mask. 
    int clearBit(int num, int i) {
        int mask = ~(1 << i);
        return num & mask. 
    }

    Clear bits MSB through I (inclusive):
    int clearBitsMSTThroughI(int num, int i) {
        // create mask with a 1 bit at the ith bit. 
        // then subtract 1 giving us a sequence of 0s
        int mask = (1 << i) - 1;
        return num & mask;
    }

    Clear bits from i through 0(inclusive). We take a sequence of 1s,
    and shift it left by i + 1 bits
    int clearBitsIthrough0(int num, int i) {
        int mask = (-1 << (i+1));
        return num & mask;
    }

    Update bit: to set ith bit to a value v, clear bit at position i, 
    then apply shifted value:

    int updateBit(int num, int i, bool bitIs1){
        int value = bitIs1 ? 1 : 0
        int mask = ~(1 <<i);
        return (num & mask) | (value << i);
    }    

    



1.2) Balanced Ternary and coming up with CONVERSION ALGORITHMS: 
    (https://cp-algorithms.com/algebra/balanced-ternary.html)

    This is a non-standard but still positional numeral system. 
    Its feature is that digits can have one of the values -1, 0 and 1. 
    Nevertheless, its base is still 3 (because there are three possible values). 
    Since it is not convenient to write -1 as a digit, we'll 
    use letter Z further for this purpose. 

    Here are the first few numbers from balanced ternary.
    0    0
    1    1
    2    1Z
    3    10
    4    11
    5    1ZZ
    6    1Z0
    7    1Z1
    8    10Z
    9    100
    
    This system allows you to write negative values without leading minus sign: 
    you can simply invert digits in any positive number.
    -1   Z
    -2   Z1
    -3   Z0
    -4   ZZ
    -5   Z11

    Example 1: Let us convert 64 to balanced ternary. 
            At first we use normal ternary to rewrite the number:

        64 = 02101

    Let us process it from the least significant (rightmost) digit:

    1, 0 and 1 are skipped as it is.( Because 0 and 1 are allowed in balanced ternary )

    2 is turned into Z increasing the digit to its left, so we get 1Z101.
    The final result is 1Z101.

    Let us convert it back to the decimal system by adding the weighted positional values:

    1Z101 = 81⋅1+27⋅(−1)+9⋅1+3⋅0+1⋅1=64

    Example 2: Let us convert 237 to balanced ternary. 
        At first we use normal ternary to rewrite the number:

    237 = 22210
    Let us process it from the least significant (rightmost) digit:

    0 and 1 are skipped as it is.( Because 0 and 1 are allowed in balanced ternary )
    2 is turned into Z increasing the digit to its left, so we get 23Z10.
    3 is turned into 0 increasing the digit to its left, so we get 30Z10.
    3 is turned into 0 increasing the digit to its left( which is by default 0 ), and so we get 100Z10.
    The final result is 100Z10.

    Let us convert it back to the decimal system by adding the weighted positional values:
    100Z10=243⋅1+81⋅0+27⋅0+9⋅(−1)+3⋅1+1⋅0=237


1.25) Gray Codes (Used for N choose K for instance)

      Gray code is a binary numeral system where two successive values differ in only one bit.
  
      For example, the sequence of Gray codes for 3-bit numbers is: 
          000, 001, 011, 010, 110, 111, 101, 100, so G(4)=6.
  
      This code was invented by Frank Gray in 1953.

      Finding Gray code
      Let's look at the bits of number n and the bits of number G(n). 
      Notice that i-th bit of G(n) equals 1 only when i-th bit of 
      n equals 1 and i+1-th bit equals 0 or the other way 
      around (i-th bit equals 0 and i+1-th bit equals 1). Thus, G(n)=n⊕(n>>1):
  
      int g (int n) {
          return n ^ (n >> 1);
      }

      Finding inverse Gray code
      Given Gray code g, restore the original number n.
  
      We will move from the most significant bits to the least significant 
      ones (the least significant bit has index 1 and the most significant 
      bit has index k). The relation between the bits ni of number n and 
      the bits gi of number g:
  
      nknk−1nk−2nk−3⋮=gk,=gk−1⊕nk=gk⊕gk−1,=gk−2⊕nk−1=gk⊕gk−1⊕gk−2,=gk−3⊕nk−2=gk⊕gk−1⊕gk−2⊕gk−3,
      The easiest way to write it in code is:
  
      int rev_g (int g) {
        int n = 0;
        for (; g; g >>= 1)
            n ^= g;
        return n;
      }

      Practical applications
      Gray codes have some useful applications, sometimes quite unexpected:
  
      Gray code of n bits forms a Hamiltonian cycle on a hypercube, 
      where each bit corresponds to one dimension.
  
      Gray codes are used to minimize the errors in digital-to-analog 
      signals conversion (for example, in sensors).
  
      Gray code can be used to solve the Towers of Hanoi problem. Let n denote 
      number of disks. Start with Gray code of length n which consists 
      of all zeroes (G(0)) and move between consecutive Gray codes (from 
      G(i) to G(i+1)). Let i-th bit of current Gray code represent n-th disk 
      (the least significant bit corresponds to the smallest disk and the 
      most significant bit to the biggest disk). Since exactly one bit 
      changes on each step, we can treat changing i-th bit as moving i-th disk. 
      Notice that there is exactly one move option for each disk (except the 
      smallest one) on each step (except start and finish positions). There 
      are always two move options for the smallest disk but there is a strategy 
      which will always lead to answer: if n is odd then sequence of the smallest 
      disk moves looks like f→t→r→f→t→r→... where f is the initial rod, t is the 
      terminal rod and r is the remaining rod), and if n is even: f→r→t→f→r→t→....
  
      Gray codes are also used in genetic algorithms theory.





1.3)  PLEASE IMPROVE THESE NOTES WITH PRACTICAL USE CASE OF 2'S COMPLIMENT IN PYTHON. 

        Decimal	Signed Magnitude	Signed One’s Complement	Signed Two’s Complement
        +7	    0111	            0111	                0111
        +6	    0110	            0110	                0110
        +5	    0101	            0101	                0101
        +4	    0100	            0100	                0100
        +3	    0011	            0011	                0011
        +2	    0010	            0010	                0010
        +1	    0001	            0001	                0001
        +0	    0000	            0000	                0000
        -0	    1000	            1111	                –
        -1	    1001	            1110	                1111
        -2	    1010	            1101	                1110
        -3	    1011	            1100	                1101
        -4	    1100	            1011	                1100
        -5	    1101	            1010	                1011
        -6	    1110	            1001	                1010
        -7	    1111	            1000	                1001

        The internal representation of numbers on most computers is now informally 
        standardized on two's complement integers based on 8-bit bytes and real 
        numbers based on the "IEEE Standard for Floating Point Arithmetic", ANAI/IEEE std 754-1985, 
        IEEE, NY 1985. However, many other internal representations have been used in the based, 
        and some of them are still supported on various computers.


    Two's Complement Signed Integers

    The most commonly used representation of signed integers on modern computers 
    is as two' complement numbers. The high order bit is reserved for a sign bit. 
    If a negative number is desired, each bit is "complemented", i.e. each 0 is 
    changed to a 1 and each 1 in change to a 0. Finally, 1 is added to the result.
    This is the same result we would have obtained if we had subtracted 
    the magnitude of the number from a number one larger than the range.

    Surprisingly, the negation operation is symmetric. It is not quite as simple 
    as the negation of the one's complement representation, 
    but addition is simpler, using an end-off carry.





1.35) GCD by dividing 

1 def gcd(a, b):
2   if a % b == 0:
3       return b
4   else:
5       return gcd(b, a % b)


1.37) Binary Euclidean Algorithm:

    The following function calculate gcd(a, b, res) = gcd(a, b, 1) · res. 
    So to calculate gcd(a, b) it suffices to call gcd(a, b, 1) = gcd(a, b).

    1 def gcd(a, b, res):
    2   if a == b:
    3       return res * a
    4   elif (a % 2 == 0) and (b % 2 == 0):
    5       return gcd(a // 2, b // 2, 2 * res)
    6   elif (a % 2 == 0):
    7       return gcd(a // 2, b, res)
    8   elif (b % 2 == 0):
    9       return gcd(a, b // 2, res)
    10  elif a > b:
    11      return gcd(a - b, b, res)
    12  else:
    13      return gcd(a, b - a, res)

    This algorithm is superior to the previous one for very large integers when it cannot be
    assumed that all the arithmetic operations used here can be done in a constant time. Due
    to the binary representation, operations are performed in linear time based on the length of
    the binary representation, even for very big integers. On the other hand, modulo applied in
    algorithm 10.2 has worse time complexity. It exceeds O(log n · log log n), where n = a + b.
    Denote by (ai, bi) pairs of values a and b, for which the above algorithm performs i steps.
    We have ai+1 >= ai, bi+1 >= bi, b1 = a1 > 0. 
    In the first three cases, ai+1 · bi+1 >= 2 · ai · bi. In the
    fourth case, ai+1 · bi+1 >= 2 · ai−1 · bi−1, because a difference of two odd numbers is an even
    number. By induction we get:
    ai · bi >= 2^((i−1)/2) (12.2)
    Thus, the time complexity is O(log(a · b)) = O(log a + b) = O(log n). And for very large
    integers, O((log n)2), since each arithmetic operation can be done in O(log n) time.



1.37) LCM: 
    The least common multiple (lcm) of two integers a and b is the 
    smallest positive integer that
    is divisible by both a and b. There is the following relation:
    lcm(a, b) = a·b/gcd(a,b)


    Problem: Michael, Mark and Matthew collect coins of consecutive face values a, b and c
    (each boy has only one kind of coins). The boys have to find the minimum amount of money
    that each of them may spend by using only their own coins.
    Solution: It is easy to note that we want to find the least common multiple of the three
    integers, i.e. lcm(a, b, c). The problem can be generalized for the lcm of exactly n integers.
    There is the following relation:
    lcm(a1, a2, . . . , an) = lcm(a1, lcm(a2, a3, . . . , an))
    We simply find the lcm n times, and each step works in logarithmic time.


1.4) Greatest Common Divisor and Least Common Multiple

        The GCD (Greatest Common Divisor) of two numbers is defined 
        as the largest integers 
        that divides both the numbers. For example, 2 is the GCD of 4 and 6. 
        From this concept, 
        follows something called co-primes. Two numbers are said to be 
        co-primes if their GCD is 1. 
        For example, 3 and 5 are co-primes because their GCD is 1.

        Coming to LCM (Least Common Multiple), it is defined as the 
        smallest integer that is divisible by both the numbers. 
        For example, 10 is the LCM of 2 and 5.

        Given any two numbers a and b,
        gcd(a, b) = a*b / lcm(a, b)

        Facts:
        gcd(a, b) = gcd(a, b - a)
        gcd(a, 0) = a
        gcd(a, b) is the smallest positive number in {ax + by | x, y in integers}


1.5) GCD IMPLEMENTATION: 


    Implementations of the algorithm may be expressed in pseudocode. 
    For example, the division-based version may be programmed as[19]

    BELOW VERSION WORKS FOR BOTH POSIOTIVE INTEGERS AND NEGATIVE INTEGERS!!
    BUT TO USE OTHER VERSIONS, JUST TAKE GCD OF THE ABSOLUTE VALUE VERSIONS. 

    function gcd(a, b)
        while b ≠ 0
            t := b
            b := a mod b
            a := t
        return a

    At the beginning of the kth iteration, the variable b holds the latest 
    remainder rk−1, whereas the variable a holds its predecessor, rk−2. The 
    step b := a mod b is equivalent to the above recursion formula rk ≡ rk−2 mod rk−1. 

    The temporary variable t holds the value of rk−1 while the next remainder rk is 
    being calculated. At the end of the loop iteration, the variable b holds the 
    remainder rk, whereas the variable a holds its predecessor, rk−1.

    In the subtraction-based version which was Euclid's original version, the 
    remainder calculation (b := a mod b) is replaced by repeated subtraction.[20] 
    Contrary to the division-based version, which works with arbitrary integers 
    as input, the subtraction-based version supposes that the input consists of 
    positive integers and stops when a = b:

    function gcd(a, b)
        while a ≠ b 
            if a > b
                a := a − b
            else
                b := b − a
        return a

    The variables a and b alternate holding the previous remainders rk−1 and rk−2. 
    Assume that a is larger than b at the beginning of an iteration; then a equals rk−2, 
    since rk−2 > rk−1. During the loop iteration, a is reduced by multiples of the previous 
    remainder b until a is smaller than b. Then a is the next remainder rk. Then b is reduced 
    by multiples of a until it is again smaller than a, giving the next remainder rk+1, and so on.

    The recursive version[21] is based on the equality of the GCDs of successive 
    remainders and the stopping condition gcd(rN−1, 0) = rN−1.

    function gcd(a, b)
        if b = 0
            return a
        else
            return gcd(b, a mod b)

    For illustration, the gcd(1071, 462) is calculated from the 
    equivalent gcd(462, 1071 mod 462) = gcd(462, 147). The latter GCD is 
    calculated from the gcd(147, 462 mod 147) = gcd(147, 21), which in turn 
    is calculated from the gcd(21, 147 mod 21) = gcd(21, 0) = 21.





2) Euclids algo to get GCD and LCM
    A simple implementation of Euclid's GCD algorithm in C++ would be,

        int gcd(int a,int b)
        {
            return b==0?a:gcd(b,a%b);
        }
        Once we calculate the GCD of two numbers, we can calculate the LCM very easily.

        int lcm(int a,int b)
        {
            return (a*b)/gcd(a,b);
        }

        If a is smaller than b, the first step of the algorithm swaps the numbers. 
        For example, if a < b, the initial quotient is zero and the remainder is a. 
        Thus, rk is smaller than it's predecessor rk-1.
        Since the remainders decrease with every iteration, a remainder rN must eventually equal 0, 
        at which point this algorithm stops. The final non-zero remainder rN-1 
        is the greatest common divisor for a and b.

        g = gcd(a, b) = gcd(b, r0) = gcd(r0, r1) = … = gcd(rN−2, rN−1) = rN−1.


3) Prime Number Detection:
        we can reduce the loop even further to check until sqrt(n) for any possible divisors. The implementation would be,

        bool isPrime(int x)
        {
            for(int i=0;i*i<=x;i++)
            {
                if(x%i == 0)
                    return false;
            }
            return true;
        }

        Notice that in this implementation, we hit only half the number of proper divisors.
        There are many more algorithms for primality test like 
        Fermat's little theorem, Miller-Rabin test, Solovay-Strassen 

3.5) Lemma 1: The sum of the digits of any number N to base 10 is equal to N minus some multiple of 9.
            N = Σi=0 ai*10i
            M = Σi=0 ai*10i − Σi=0 ai
            M = Σi=0 ai*(10i−1)
            M = Σi=0 ai*(99…9)
            M = Σi=0 ai*9(11…1)
            N − S(N) = 9K1
            and hence
            S(N) = N − 9K1
    Lemma 2: The digit sum (the iterative sum of the digits) of any N to base 10 is 
    equal to N minus the highest multiple of 9 that leaves a single digit.

    N − 9K1 − 9K2 = S(S(N))
    The procedure can be continued until the sum of digits is a single digit.
    N − 9Σj=1Kj = S(…S(N)) = D(N)


    The righthand side (RHS) is a single digit. The lefthand side (LHS) must 
    also be a single digit. The definition of a remainder upon division by p 
    is the single digit less than p in value. The LHS of the above expression 
    is not quite the remainder of N divided by 9. It could be equal to 9. But 9 
    may be considered equivalent to zero as a remainder upon division by 9. 
    (A digit sum of zero occurs only for the number zero.)

    A Generalization
    The previous material generalizes for numbers expressed to any integral base 
    k. The digit sum of any number base k is equivalent to its remainder upon 
    division by (k-1). For binary numbers, number expressed to base 2, the 
    proposition is true but rather bizarre. The digit sum of any binary number 
    except zero is one and the remainder of any number upon division by one is 
    zero. However as a remainder one is equivalent to zero for division by one.

3.7) Sieve of Eeraosthenes Part 1
    Initially, we have the set of all the numbers {2, 3, . . . , n}. At each step we choose the
    smallest number in the set and remove all its multiples

    Notice that every composite number
    has a divisor of at most √n. In particular, it has a divisor which is a prime number. It
    is sufficient to remove only multiples of prime numbers not exceeding √n

    1 def sieve(n):
    2   sieve = [True] * (n + 1)
    3   sieve[0] = sieve[1] = False
    4   i = 2
    5   while (i * i <= n):
    6       if (sieve[i]):
    7           k = i * i
    8           while (k <= n):
    9               sieve[k] = False
    10              k += i
    11      i += 1
    12 return sieve

    Time complexity -> O(nloglogn)

3.8) Factorization: 
    Factorization is the process of decomposition into prime factors. More precisely, for a given
    number x we want to find primes p1, p2, . . . , pk whose product equals x.
    Use of the sieve enables fast factorization. Let’s modify the sieve algorithm slightly. For
    every crossed number we will remember the smallest prime that divides this number.

    1 def arrayF(n):
    2   F = [0] * (n + 1)
    3   i = 2
    4   while (i * i <= n):
    5       if (F[i] == 0):
    6           k = i * i
    7           while (k <= n):
    8               if (F[k] == 0):
    9                   F[k] = i;
    10              k += i
    11      i += 1
    12  return F


    0 0 2 0 2 0 2 3 2  0   2  0  2  3  2  0  2  0  2
    2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20


    With this approach we can factorize numbers very quickly. If we know that one of the prime
    factors of x is p, then all the prime factors of x are p plus the decomposition of x/p 

    11.3: Factorization of x — O(log x).
    1   def factorization(x, F):
    2       primeFactors = []
    3       while (F[x] > 0):
    4           primeFactors += [F[x]]
    5           x /= F[x]
    6       primeFactors += [x]
    7       return primeFactors    

    Number x cannot have more than log x prime factors, because every prime factor is � 2.
    Factorization by the above method works in O(log x) time complexity. Note that consecutive
    factors will be presented in non-decreasing order.






4) Sieve of Eratosthenes Part 2

        In mathematics, the Sieve of Eratosthenes is a very 
        simple algorithm of finding all prime numbers upto a given limit.

        In this algorithm, we start from the number 2 and keep marking the 
        composites which are the multiples of a prime. For example, if we were trying 
        to find the primes below 11. Let the flag array be initialized to zero. The 
        flag array signifies the compositeness of each number. 
        It is set to 1 if it is a composite number, otherwise zero.

        As you can notice that after iteration 1, all numbers which are the multiples of 2 
        have been set to 1, implying that they are composite numbers. When we move to iteration 2, 
        all multiples of 3 have been marked composite. Notice that we do not change the mark of 2 
        and 3, since they weren't multiples of any smaller number, thus implying that they are primes. 
        Once all the numbers have been visited once, we loop through the flag array and filter 
        out the numbers with flag value set to 0. This gives us all the primes in the range.

        //Finding all primes within the range [1,n)
        void sieve(int n)
        {
            vector<int> flag(n,0);
            flag[0] = flag[1] = 1;              //Setting 0 and 1 as composites.
            //Finding the primes.
            for(int i=2;i<n;i++)                //Running a loop from 2 to n-1.
            {
                if(flag[i]==0)                  //Found a prime.
                {
                    for(int j=2*i;j<n;j+=i)     //looping through the multiples of the prime.
                        flag[j] = 1;            //Setting flag to composite.
                }
            }
            //Printing the primes.
            for(int i=0;i<n;i++)
            {
                if(flag[i]==0)
                    cout << i << " ";
            }
            cout << endl;
        }


4.5) Sieve of Eratosthenes Having Linear Time Complexity
    (https://cp-algorithms.com/algebra/prime-sieve-linear.html)

    Given a number n, find all prime numbers in a segment [2;n].

    The standard way of solving a task is to use the sieve of Eratosthenes. 
    This algorithm is very simple, but it has runtime O(nloglogn).

    Although there are a lot of known algorithms with sublinear runtime (i.e. o(n)), 
    the algorithm described below is interesting by its simplicity: 
    it isn't any more complex than the classic sieve of Eratosthenes.

    Besides, the algorithm given here calculates factorizations of all numbers in the 
    segment [2;n] as a side effect, and that can be helpful in many practical applications.

    The weakness of the given algorithm is in using more memory than the classic sieve of 
    Eratosthenes': it requires an array of n numbers, while for the classic 
    sieve of Eratosthenes it is enough to have n bits of memory (which is 32 times less).

    Thus, it makes sense to use the described algorithm only until for numbers of order 107 and not greater.

    Algorithm
    Manipulated Sieve of Eratosthenes algorithm works as following:

    For every number i where i varies from 2 to N-1:
        Check if the number is prime. If the number
        is prime, store it in prime array.

    For every prime numbers j less than or equal to the smallest  
    prime factor p of i:
        Mark all numbers j*p as non_prime.
        Mark smallest prime factor of j*p as j

    Implementation
    const int N = 10000000;
    int lp[N+1];
    vector<int> pr;

    for (int i=2; i<=N; ++i) {
        if (lp[i] == 0) {
            lp[i] = i;
            pr.push_back(i);
        }

        for (int j=0; j<(int)pr.size() && pr[j]<=lp[i] && i*pr[j]<=N; ++j)
            lp[i * pr[j]] = pr[j];
    }

    We can speed it up a bit by replacing vector pr with a simple array and a counter, 
    and by getting rid of the second multiplication in the nested for 
    loop (for that we just need to remember the product in a variable).

    Correctness Proof
    We need to prove that the algorithm sets all values lp[] correctly, 
    and that every value will be set exactly once. Hence, the algorithm will 
    have linear runtime, since all the remaining actions of the algorithm, obviously, work for O(n).

    Notice that every number i has exactly one representation in form:

    i=lp[i]⋅x ,

    where lp[i] is the minimal prime factor of i, and the number x doesn't have any prime factors less than lp[i], i.e.

    lp[i]≤lp[x].

    Now, let's compare this with the actions of our algorithm: in fact, for every x it goes 
    through all prime numbers it could be multiplied by, i.e. all prime numbers up to lp[x] inclusive, 
    in order to get the numbers in the form given above.

    Hence, the algorithm will go through every composite number exactly once, 
    setting the correct values lp[] there. Q.E.D.

    Runtime and Memory
    Although the running time of O(n) is better than O(nloglogn) of the classic sieve of Eratosthenes, 
    the difference between them is not so big. In practice that means just double 
    difference in speed, and the optimized versions of the sieve run as fast as the algorithm given here.

    Considering the memory requirements of this algorithm - an array lp[] of length n, 
    and an array of pr[] of length n/lnn, this algorithm 
    seems to worse that the classic sieve in every way.

    However, its redeeming quality is that this algorithm calculates an array lp[], 
    which allows us to find factorization of any number in the segment [2;n] in the time 
    of the size order of this factorization. Moreover, using just one extra 
    array will allow us to avoid divisions when looking for factorization.

    Knowing the factorizations of all numbers is very useful for some tasks, 
    and this algorithm is one of the few which allow to find them in linear time.






5)  Congruence and Modulu Operation:
    x = y (mod n) means x and y have the same 
    remainder when divided by n
    
5.1) Modulo Multiplicative inverse:

    x^-1 is the inverse of x mod n if x*(x^-1)  = 1 (mod n)

    (5^-1) = 3 ( mod 7) because 5*3 = 15 = 1 (mod 7)
    May not exist => inverse of 2 mod 4
    Exists iff gcd(x, n) = 1

    All intermediate nums calcualted by Euclidean algo are 
    integer combinations of a and b:
    - Therefore, gcd(a, b) = ax + by for some integers x,y 
    - If gcd(a, n) = 1 then ax + ny = 1 for some x, y
    - Taking modulo n gives ax = 1 (mod n)
    -> We are done finding multiplicative inverse if we can find
        such x and y


5.15) Extended Euclidean Algorithm:     
    (https://cp-algorithms.com/algebra/extended-euclid-algorithm.html)

    While the Euclidean algorithm calculates only the greatest common divisor (GCD) 
    of two integers a and b, the extended version also finds a way to 
    represent GCD in terms of a and b, i.e. coefficients x and y for which:

    a⋅x + b⋅y = gcd(a,b)

    It's important to note, that we can always find such a representation, 
    for instance gcd(55,80)=5 therefore we can represent 5 as a 
    linear combination with the terms 55 and 80: 55⋅3 + 80⋅(−2)=5
    A more general form of that problem is discussed in the article 
    about Linear Diophantine Equations. It will build upon this algorithm.

    Algorithm: 

    We will denote the GCD of a and b with g in this section.

    The changes to the original algorithm are very simple. 
    If we recall the algorithm, we can see that the algorithm 
    ends with b=0 and a=g. For these parameters 
    we can easily find coefficients, namely g⋅1+0⋅0=g.

    Starting from these coefficients (x,y)=(1,0), we can go 
    backwards up the recursive calls. All we need to do 
    is to figure out how the coefficients x and y 
    change during the transition from (a,b) to (b,a mod b).

    Let us assume we found the coefficients (x1, y1) for (b, amodb):

    b⋅x1 + (amodb)⋅y1 = g
    and we want to find the pair (x,y) for (a,b):

    a⋅x+b⋅y=g

    We can represent a mod b as:
    amodb=a−⌊a/b⌋⋅b

    Substituting this expression in the coefficient equation of (x1,y1) gives:

    g= b⋅x1 + (amodb)⋅y1 = b⋅x1 + (a−⌊a/b⌋⋅b)⋅y1
    and after rearranging the terms:

    g=a⋅y1+b⋅(x1−y1⋅⌊a/b⌋)
    We found the values of x and y:

    {
     x=y1   
     y=x1−y1⋅⌊a/b⌋
    }

    int gcd(int a, int b, int& x, int& y) {
        if (b == 0) {
            x = 1;
            y = 0;
            return a;
        }
        int x1, y1;
        int d = gcd(b, a % b, x1, y1);
        x = y1;
        y = x1 - y1 * (a / b);
        return d;
    }

    The recursive function above returns the GCD and the values of 
    coefficients to x and y (which are passed by reference to the function).

    This implementation of extended Euclidean algorithm produces 
    correct results for negative integers as well.

    Iterative version

    It's also possible to write the Extended Euclidean algorithm in an 
    iterative way. Because it avoids recursion, the code will run a 
    little bit faster than the recursive one.

    int gcd(int a, int b, int& x, int& y) {
        x = 1, y = 0;
        int x1 = 0, y1 = 1, a1 = a, b1 = b;
        while (b1) {
            int q = a1 / b1;
            tie(x, x1) = make_tuple(x1, x - q * x1);
            tie(y, y1) = make_tuple(y1, y - q * y1);
            tie(a1, b1) = make_tuple(b1, a1 - q * b1);
        }
        return a1;
    }

    If you look closely at the variable a1 and b1, you can notice 
    that they taking exactly the same values as in the iterative 
    version of the normal Euclidean algorithm. 
    So the algorithm will at least compute the correct GCD.

    To see why the algorithm also computes the correct coefficients, 
    you can check that the following invariants will hold at any time 
    (before the while loop, and at the end of each iteration): x⋅a+y⋅b=a1 
    and x1⋅a+y1⋅b=b1. It's trivial to see, that these two equations are 
    satisfied at the beginning. And you can check that the update in the 
    loop iteration will still keep those equalities valid.

    At the end we know that a1 contains the GCD, so x⋅a+y⋅b=g. Which means 
    that we have found the required coefficients.

    You can even optimize the code more, and remove the variable a1 and b1 
    from the code, and just reuse a and b. However if you do so, you loose 
    the ability to argue about the invariants.



5.17) Write about Linear diophantine equations (https://cp-algorithms.com/algebra/linear-diophantine-equation.html)

5.18) Write  about fib numbers (https://cp-algorithms.com/algebra/fibonacci-numbers.html)

5.19) Write about multiplicative inverses (Theire is a cp algorithms link to this)



5.2) Extended Euclidean Algorithm:
    ax + by = gcd(a, b) => Bezout's identity
    Keep the original algo but write all the intermediate numbers
    as integer combinations of a and b
    
    function extended_gcd(a, b)
        s := 0;    old_s := 1
        t := 1;    old_t := 0
        r := b;    old_r := a
        
        while r ≠ 0
            quotient := old_r div r
            (old_r, r) := (r, old_r - quotient * r) # this is gcd
            (old_s, s) := (s, old_s - quotient * s) # this is a
            (old_t, t) := (t, old_t - quotient * t) # this is b
        
        output "Bézout coefficients:", (old_s, old_t)
        output "greatest common divisor:", old_r
        output "quotients by the gcd:", (t, s)

5.21) Solving a Linear Congruence Equation:

    This equation is of the form:

    a⋅x = b(modn),
    where a, b and n are given integers and x is an unknown integer.

    It is required to find the value x from the interval [0,n−1] 
    (clearly, on the entire number line there can be infinitely many 
    solutions that will differ from each other in n⋅k , where k is any integer). 
    If the solution is not unique, then we will consider how to get all the solutions.


    Solution by finding the inverse element
    Let us first consider a simpler case where a and n are coprime (gcd(a,n)=1). 
    Then one can find the inverse of a, and multiplying both sides of 
    the equation with the inverse, and we can get a unique solution.

    x= b⋅a^−1 (modn)
    
    Now consider the case where a and n are not coprime (gcd(a,n)≠1). 
    Then the solution will not always exist (for example 2⋅x=1(mod4) has no solution).

    Let g=gcd(a,n), i.e. the greatest common divisor of a and n (which in this case is greater than one).

    Then, if b is not divisible by g, there is no solution. 
    In fact, for any x the left side of the equation a⋅x(modn) , 
    is always divisible by g, while the right-hand side is not divisible by it, 
    hence it follows that there are no solutions.

    If g divides b, then by dividing both sides of the equation by g 
    (i.e. dividing a, b and n by g), we receive a new equation:

    a′⋅x=b′(modn′)

    in which a′ and n′ are already relatively prime, 
    and we have already learned how to handle such an equation. 
    We get x′ as solution for x.

    It is clear that this x′ will also be a solution of the original equation. 
    However it will not be the only solution. It can be shown that 
    the original equation has exactly g solutions, and they will look like this:

    xi=(x′+i⋅n′)(modn)for i=0…g−1
    Summarizing, we can say that the number of solutions of 
    the linear congruence equation is equal to either g=gcd(a,n) or to zero.

    Solution with the Extended Euclidean Algorithm
    We can rewrite the linear congruence to the following Diophantine equation:

    a⋅x+n⋅k=b,
    where x and k are unknown integers.

    The method of solving this equation is described in the corresponding article 
    Linear Diophantine equations and it consists of applying the Extended Euclidean Algorithm.

    It also describes the method of obtaining all solutions of this equation from 
    one found solution, and incidentally this method, when carefully considered, 
    is absolutely equivalent to the method described in the previous section.


5.22) Write notes on Chinese remainder theorem(https://cp-algorithms.com/algebra/chinese-remainder-theorem.html)



5.3) Chinese remainder thrm:
        Given a, b, m, n with gcd(m, n) = 1
        Find x with x = a (mod m) and x = b (mod n)

        Soln: 
            - Let n^-1 be the inverse of n mod m
            - Let m^-1 be the inverse of m mod n
            - Set x = a*n*n^-1 + b*m*m^-1
        Extension: solve for simultaneous equations

5.4) n choose k. 
     Same as the coefficient of 
     (x^k)*(y^n-k) in the expansion of (x + y)^n
    -> Use pascals triangle


5.45) MATRIX MULTIPLCATION IS ROW OF FIRST MAT * COL OF SECOND MAT

5.5) Fibonnaci closed form: (Any linear recurrence closed form)
    [Fn+1, Fn] = [1 1, 1 0]* [Fn, Fn-1] = [1 1, 1 0]^n * [F1, F0]
    -> Comma means row split for matrix!
    -> USE FAST EXPONENTIAION to compute matrix power
    -> Can be extended to support any linear recurrence with 
    cosntant coefficents. 

5.6) Gemometry problems: DONT USE FLOATING POINT. 
     AVOID DIVISION WHENEVER POSSIBLE
    Have vector <x, y>

     Norm of vector is sqrt(x^2 + y^2)
     Counter clockwise rotation by x:
     [cos x  -sin x, sin x  cos x]*[x, y]
    Normal vectors are: (y, -x) and (-y, x)


5.7) Line Line intersection: 
    Have two lines:
    ax + by + c = 0 and dx + ey + f = 0
    Write in mat form:
    [a b, 
    d e] [x, y] = -[c, f]
    Left multiply by matrix inverse:

    => 1/(ae - bd) * [e -b, -d a] 

    -> When ae = bd -> the lines coincide or are parallel: 
            EDGE CASE CHECK FOR THIS

5.8) Circumcircle of a Triangle:
    Have three points A, B, C:
    want to compute P that is equidistant from A, B, C
    Dont solve system of quadratic equations
    Do following:
        - Find the equations of the bisectors of AB and BC
        - Compute their intersection!!!

5.9) Have three points A, B, C. 
    Want to compute the area S of trangle ABC
    Use cross product: 2S = |(B-A) x (C-A)|

 

6.0) CROSS PRODUCT COMPUTATION!

    (x1, y1) x (x2, y2) = |x1 x2, y1 y2| = x1y2 - x2y1
    -> Very important

6.1) AREA OF A SIMPLE POLYGON:

    Given vertices P1, P2, ..., Pn of polygon P
    Want to compute the area S of P
    If P is convex, we can decomponse P into triangles: 

    2S = |Sum_from_i=2_to_n-1[(P_i+1 - P_1) x (P_i - P_1)]|

    -> turns out, this formula works for non-convex polygons too
        - area is the absolute value of the sum of the "signed" area
    -> Alternative formulat (xn+1 = x1, yn+1 = y1):

        2S = |Sum_from_i=1_to_n[xi*yi+1 - xi+1*yi]



6.5) Add computational geometry notes from hackerearth here

7) Go to notes folder and add number theory notes here

8) Read uni lecture slides for math add here

9) MEMORIZE ITERTOOLS FOR PYTHON!


10) is Prime in python:
    remove all prime numbers from a linked list. 
    (no mention of how large numbers could be)

    def isprime(n):
        return all(n%i !=0 for i in xrange(2, math.sqrt(n)+1) ) if n > 0 else False

    def remove(head):
        if not head: return None
        head.next = remove(head.next)
        return head.next if isprime(head.val) else head

10.5) Rotation matrices. To rotate a vector: 
    R = [cos(x), -sin(x)
          sin(x),  cos(x)]

    v = [a, b]
    Rv  = [acos(x) - bsin(x),  asin(x) + bcos(x)]



11) SUM OF POWERS TECHNIQUE

    Sum of numbers from 1 to n -> (1/2) * n * (n+1)
    Sum of squares from 1 to n inclusive -> (1/6) * n * (n+1) * (2n + 1)
    Sum of cubes from 1 to n inclusive -> 
        (Sum of numbers from 1 to N) ^ 2 == ( (1/2)* n * (n+1)) ^ 2


11.5) Binary Exponentiation: (https://cp-algorithms.com/algebra/binary-exp.html)

    Binary exponentiation (also known as exponentiation by squaring) 
    is a trick which allows to calculate an using only O(logn) multiplications 
    (instead of O(n) multiplications required by the naive approach).

    It also has important applications in many tasks unrelated to arithmetic, 
    since it can be used with any operations that have the property of associativity:

    (X⋅Y)⋅Z=X⋅(Y⋅Z)
    Most obviously this applies to modular multiplication, to multiplication of
    matrices and to other problems which we will discuss below.

    Algorithm
    Raising a to the power of n is expressed naively as multiplication by a 
    done n−1 times: an=a⋅a⋅…⋅a. However, this approach is not practical for large a or n.

    a^(b+c)=a^b⋅a^c and a^(2b)=a^b⋅a^b=(a^b)^2.

    The idea of binary exponentiation is, that we split the work 
    using the binary representation of the exponent.

    Let's write n in base 2, for example:
    3^(13)=3^(1101)= 3^8⋅3^4⋅3^1
    Since the number n has exactly ⌊log2n⌋+1 digits in base 2, 
    we only need to perform O(logn) multiplications, 
    if we know the powers a^1,a^2,a^4,a^8,…,a^⌊logn⌋.

    So we only need to know a fast way to compute those. Luckily this 
    is very easy, since an element in the sequence is 
    just the square of the previous element.

    3^1 = 3
    3^2 = 9
    3^4 = 81
    3^8=6561
    So to get the final answer for 3^13, we only need to multiply three of 
    them (skipping 32 because the corresponding bit in n is not set): 
    3^(13)=6561⋅81⋅3=1594323

    The final complexity of this algorithm is O(logn): 
    we have to compute logn powers of a, and then have to 
    do at most logn multiplications to get the final answer from them.

    The following recursive approach expresses the same idea:

    long long binpow(long long a, long long b) {
        if (b == 0)
            return 1;
        long long res = binpow(a, b / 2);
        if (b % 2)
            return res * res * a;
        else
            return res * res;
    }

    The second approach accomplishes the same task without recursion. 
    It computes all the powers in a loop, and multiplies the ones with the 
    corresponding set bit in n. Although the complexity of both approaches 
    is identical, this approach will be faster in practice since we 
    have the overhead of the recursive calls.

    long long binpow(long long a, long long b) {
        long long res = 1;
        while (b > 0) {
            if (b & 1)
                res = res * a;
            a = a * a;
            b >>= 1;
        }
        return res;
    }

11.6) Binary Exponentiation Applications:
    (https://cp-algorithms.com/algebra/binary-exp.html)

    Applications
    Effective computation of large exponents modulo a number
    Problem: Compute x^n mod m. This is a very common operation. 
    For instance it is used in computing the modular multiplicative inverse.

    Solution: Since we know that the module operator doesn't 
    interfere with multiplications (a⋅b≡(a mod m)⋅(b mod m) (modm) ) , 
    we can directly use the same code, and just replace 
    every multiplication with a modular multiplication:

    long long binpow(long long a, long long b, long long m) {
        a %= m;
        long long res = 1;
        while (b > 0) {
            if (b & 1)
                res = res * a % m;
            a = a * a % m;
            b >>= 1;
        }
        return res;
    }

    Note: If m is a prime number we can speed up a bit this algorithm 
    by calculating x^(n mod(m−1)) instead of x^n. 
    This follows directly from Fermat's little theorem.


    Effective computation of Fibonacci numbers
    Problem: Compute n-th Fibonacci number Fn.

    Solution: For more details, see the Fibonacci Number article. 
    We will only go through an overview of the algorithm. 
    To compute the next Fibonacci number, only the two 
    previous ones are needed, as Fn=Fn−1+Fn−2. We can 
    build a 2×2 matrix that describes this transformation: 
    the transition from Fi and Fi+1 to Fi+1 and Fi+2. 
    For example, applying this transformation to the pair F0 and F1 
    would change it into F1 and F2. Therefore, we can raise this 
    transformation matrix to the n-th power to find 
    Fn in time complexity O(logn).

    Applying a permutation k times
    Problem: You are given a sequence of length n. 
    Apply to it a given permutation k times.

    Solution: Simply raise the permutation to k-th power 
    using binary exponentiation, and then apply it to the sequence. 
    This will give you a time complexity of O(nlogk).

    Note: This task can be solved more efficiently in linear 
    time by building the permutation graph and considering each 
    cycle independently. You could then compute k modulo the size of 
    the cycle and find the final position for 
    each number which is part of this cycle.

    Number of paths of length k in a graph
    Problem: Given a directed unweighted graph of n vertices, 
    find the number of paths of length k from any vertex u to any other vertex v.

    Solution: This problem is considered in more detail in a separate article. 
    The algorithm consists of raising the adjacency matrix M 
    of the graph (a matrix where mij=1 if there is an edge from i to j, or 
    0 otherwise) to the k-th power. Now mij will be the number of paths 
    of length k from i to j. The time complexity of this solution is O(n^3(logk)).

    Note: In that same article, another variation of this problem is considered: 
    when the edges are weighted and it is required to find the minimum 
    weight path containing exactly k edges. As shown in that article, 
    this problem is also solved by exponentiation of the adjacency matrix. 
    The matrix would have the weight of the edge from i to j, or ∞ if there 
    is no such edge. Instead of the usual operation of multiplying two matrices, 
    a modified one should be used: instead of multiplication, 
    both values are added, and instead of a summation, 
    a minimum is taken. That is: result(ij) = min1 ≤ k ≤ n(a(ik)+b(kj)).

    Variation of binary exponentiation: multiplying two numbers modulo m
    Problem: Multiply two numbers a and b modulo m. 
    a and b fit in the built-in data types, but their product 
    is too big to fit in a 64-bit integer. 
    The idea is to compute a⋅b(modm) without using bignum arithmetics.

    Solution: We simply apply the binary construction 
    algorithm described above, only performing 
    additions instead of multiplications. 
    In other words, we have "expanded" the multiplication 
    of two numbers to O(logm) operations of addition 
    and multiplication by two (which, in essence, is an addition).

    a⋅b= 0                  if a = 0
    a⋅b= 2⋅(a/2)⋅b          if a > 0 and a even
    a⋅b= 2⋅(a-1)⋅b/2  + b   if a > 0 and a odd
    
    Note: You can solve this task in a different way by using 
    floating-point operations. First compute the expression (a⋅b)/m using 
    floating-point numbers and cast it to an unsigned integer q. 
    Subtract q⋅m from a⋅b using unsigned integer arithmetics 
    and take it modulo m to find the answer. This s
    olution looks rather unreliable, but it is very fast, 
    and very easy to implement. See here for more information.

    Practice Problems
    UVa 1230 - MODEX
    UVa 374 - Big Mod
    UVa 11029 - Leading and Trailing
    Codeforces - Parking Lot
    SPOJ - The last digit
    SPOJ - Locker
    LA - 3722 Jewel-eating Monsters
    SPOJ - Just add it





    





12) FAST EXPONENTIATION TECHNIQUE:

    a^n = 1 if n == 0
    a^n = a if n == 1
    a^n = (a^(n/2))^2 is n is even
    a^n = a*(a^((n-1)/2) )^2 if n is odd
    => recursive implementation is O(log n)

13) Linear algebra:
    -> Solve system, invert a matrix, find the rank of matrix, compute determinant,
    -> all the above can be done with gaussian elimination



14) Cross Product Use Cases:

    - Determining the (signed) area of a triangle
    - Test if three points are collinear
    - Determining the orientation of three points
    - Testing if two line segments intersect

    Define ccw(A, B, C) = (B-A) X (C-A) = (bx - ax)(cy - ay) - (by - ay)(cx - ax)
    ccw(A, B, C) > 0 implies A->B->C is a left turn
    ccw(A, B, C) < 0 implies A->B->C is a right turn

    Segment - Segment Intersection Test:
    Given 2 segments AB and CD, determine if they intersect property, 2 segments
    meet at a signle point that are strictly inside both segments

    Assume they intersect: 
    - From A's point of view, looking straight to B, C, D must lie on different sides
    - Holds true for the other segment as well. 
    Intersection exists and is proper if:
    - ccw(A, B, C) X ccw(A, B, D) < 0 and ccw(C, D, A) X ccw(C, D, B) < 0

    Also:
    if ccw(A, B, C), ccw(A, B, D), ccw(C, D, A), and ccw(C, D, B) are all zeros, then two 
    segments are collinear


14.5) Convex Hull Grahams 
    (https://cp-algorithms.com/geometry/grahams-scan-convex-hull.html)


    The algorithm used here is Graham's scan (proposed in 1972 by Graham) with improvements by Andrew (1979). 
    The algorithm allows for the construction of a convex hull in O(NlogN) using only comparison, 
    addition and multiplication operations. The algorithm is asymptotically optimal 
    (as it is proven that there is no algorithm asymptotically better), with the exception of a 
    few problems where parallel or online processing is involved.

    Description
    The algorithm first finds the leftmost and rightmost points A and B. In the event multiple such 
    points exist, the lowest among the left (lowest Y-coordinate) is taken as A, and the highest among 
    the right (highest Y-coordinate) is taken as B. Clearly, A and B must both belong to the convex hull 
    as they are the farthest away and they cannot be contained by any line formed by a pair among the given points.

    Now, draw a line through AB. This divides all the other points into two sets, S1 and S2, 
    where S1 contains all the points above the line connecting A and B, and S2 contains all the points 
    below the line joining A and B. The points that lie on the line joining A and B may belong to either set. 
    The points A and B belong to both sets. Now the algorithm constructs the upper set S1 and the lower set S2 
    and then combines them to obtain the answer.

    To get the upper set, we sort all points by the x-coordinate. For each point we check if either - the current point 
    is the last point, (which we defined as B), or if the orientation between the line between A and the current point and the 
    line between the current point and B is clockwise. In those cases the current point belongs 
    to the upper set S1. Checking for clockwise or anticlockwise nature can 
    be done by checking the orientation.

    If the given point belongs to the upper set, we check the angle made by the line connecting the 
    second last point and the last point in the upper convex hull, with the line connecting the last point in 
    the upper convex hull and the current point. If the angle is not clockwise, we remove the most recent 
    point added to the upper convex hull as the current point will be able to 
    contain the previous point once it is added to the convex hull.

    The same logic applies for the lower set S2. If either - the current point is B, or the orientation 
    of the lines, formed by A and the current point and the current point and B, 
    is counterclockwise - then it belongs to S2.

    If the given point belongs to the lower set, we act similarly as for a point on the upper set 
    except we check for a counterclockwise orientation instead of a clockwise orientation. 
    Thus, if the angle made by the line connecting the second last point and the last point in the lower 
    convex hull, with the line connecting the last point in the lower convex hull and the current point is 
    not counterclockwise, we remove the most recent point added to the lower convex hull as the 
    current point will be able to contain the previous point once added to the hull.

    The final convex hull is obtained from the union of the upper and lower 
    convex hull, and the implementation is as follows.

    Implementation
    struct pt {
        double x, y;
    };

    bool cmp(pt a, pt b) {
        return a.x < b.x || (a.x == b.x && a.y < b.y);
    }

    bool cw(pt a, pt b, pt c) {
        return a.x*(b.y-c.y)+b.x*(c.y-a.y)+c.x*(a.y-b.y) < 0;
    }

    bool ccw(pt a, pt b, pt c) {
        return a.x*(b.y-c.y)+b.x*(c.y-a.y)+c.x*(a.y-b.y) > 0;
    }

    void convex_hull(vector<pt>& a) {
        if (a.size() == 1)
            return;

        sort(a.begin(), a.end(), &cmp);
        pt p1 = a[0], p2 = a.back();
        vector<pt> up, down;
        up.push_back(p1);
        down.push_back(p1);
        for (int i = 1; i < (int)a.size(); i++) {
            if (i == a.size() - 1 || cw(p1, a[i], p2)) {
                while (up.size() >= 2 && !cw(up[up.size()-2], up[up.size()-1], a[i]))
                    up.pop_back();
                up.push_back(a[i]);
            }
            if (i == a.size() - 1 || ccw(p1, a[i], p2)) {
                while(down.size() >= 2 && !ccw(down[down.size()-2], down[down.size()-1], a[i]))
                    down.pop_back();
                down.push_back(a[i]);
            }
        }

        a.clear();
        for (int i = 0; i < (int)up.size(); i++)
            a.push_back(up[i]);
        for (int i = down.size() - 2; i > 0; i--)
            a.push_back(down[i]);
    }
   
    Practice Problems
    Kattis - Convex Hull
    Kattis - Keep the Parade Safe
    Timus 1185: Wall
    Usaco 2014 January Contest, Gold - Cow Curling




15) Convex Hull 
    Given n points on the plane, fill the smallest convex polygon that contains all the given 
    points. 
    - FOr simplicity, assume that no 3 points are collinear

    Simple Algo:
    AB is an edge of the convex hull iff ccw(A, B, C) have the same sign for all other points C
    - This gives us a simple algo
    For each A and B: 
        - If ccw(A, B, C) > 0 for all C != A, B:
            - Record the edge A->B 

    -> Walk along the recorded edges to recover the convex hull
    
    -> Faster algo: Graham Scan
    We know that the leftmost given point has to be in the convex hull
    - assume unique leftmost point
    make the leftmost point the origin, so that all other points have positive x coords
    sort the points in increasing order of y/x
        -> increasing order of angle, whatever you like to call it
    incrementally construct the convex hull usign a stack

    We maintain a convex chain of the given points
    for each i, do the following: (i's are processed in order of increasing angle)
        - Append point i to the current chain
        - If the new point causes a concave corner, remove the bad vertex fromt the chain
            that causes it (pop from chain, until its convex again)
        - repeat until the new chain becomes convex
    
    Pseudocode:
    Set the leftmost point as (0,0), and sort the rest of the points in increasing order of y/x
    Initialize the stack s
    For i = 1, .., n
        - Let A be the second topmost element of S, B be the topmost element of S, and C be the 
          ith point
        - If ccw(A, B, C) < 0, pop S and go back
        - push C to S

    -> Points in S form the convex hull
    
16) SWEEP LINE ALGORITHM: (Mix this algorithm with interval scheduling, and 2 pointer techniques!)
    A problem solving strat for geometry problems.
    main idea: maintain a line (with some auxilary data structure) that sweeps through the entire
    plane and solves the problem locally
    -> We cant simulate a continuous process (e.g. sweeping a line) so we define events that cause
    certain changes in our data structure
        - And process the events in the order of occurence
    
    Example Problem: given n axis-aligned rectangesl, find the area of the union of the them.
    We weill sweep the plane from left to right
    Events: left and right edges of the rectangles
    THe main idea is to maintain the set of "active" rectanges in order
        -It suffices to store the y-coords of the rectangles. 
    
    Psuedo-pseudo code

    If the sweep line hits the left edges of a rectangle
        - Insert it to a data structure
    Right edge?
        - Remove it
    -> Move to the next event, and add the area(s) of the green rectangle(s)
        - Finding the length of the union of the blue segments is the hardest step
        - THere is an easy O(n) method for this step (blue edges represent current active parts)

    Sweep algo notes:
    Generic concept. Come up with the right set of events and data structures for each problem
    Exercise problems:
    - Finding the perimeter of the union of rectangles
    - Finding all k intersections of n line segments in O( (n+k)lgn ) time



17) Intersecting Half Planes:
    Representing a half-plane: ax + by + c <= 0
    The intersection of half-places is a convex area
        - if the intersection is bounded, it gives a convex polygon
    
    Give n half-planes, how do we compute the intersection of them?
        - i.e. Find the vertices of the convex area
    -> Easy O(n^3) algo and hard O(nlgn) one

    Easy way:
    For each half plane aix + biy +ci <= 0, define a straight line ei = aix+biy + ci = 0
    For each pair ei and ej:
        - Compute the intersection p = (px, py)
        - Check if akpx + bkpy + ck <= 0 for all half planes
            -> if so, store p in some array P
            -> otherwise discard p

    Find convex hull of the points in P
    
    -> Interesction of half-planes can be unbounded
        - But usually, we are given limits on the min/max vals of the coordinates
        - Add four half planes:
            x>= -M, x<= M, y>= -M, y<= M to ensure intersection is bounded
    Time complex: O(n^3)

18) BINARY SEARCH: use it to find the largest circle that fits into a given polygon
        -Dont try to find a closed form soln or anything like that!

19) Ternary search:
    Can use to:
        Find the minimum point of a "convex" function f
            - Not exactly convex but lets use this word anyway
        
        Initialize search interval [s, e]
        Until "e-s" becomes small enough:

            - m1 = s + (e-s)/3, m2 = e - (e-s)/3
            - If f(m1) <= f(m2), set e = m2
            - otherwise: set s = m1

20) Oriented Area of Triangle 
    (https://cp-algorithms.com/geometry/oriented-triangle-area.html)

    Given three points p1, p2 and p3, calculate an oriented (signed) area of a 
    triangle formed by them. The sign of the area is determined in the following
    way: imagine you are standing in the plane at point p1 and are facing p2. 
    You go to p2 and if p3 is to your right (then we say the three vectors turn "clockwise"), 
    the sign of the area is positive, otherwise it is negative. 
    If the three points are collinear, the area is zero.

    Using this signed area, we can both get the regular unsigned area 
    (as the absolute value of the signed area) and determine 
    if the points lie clockwise or counterclockwise in their 
    specified order (which is useful, for example, 
    in convex hull algorithms).

    Calculation
    We can use the fact that a determinant of a 2×2 matrix is 
    equal to the signed area of a parallelogram spanned by column 
    (or row) vectors of the matrix. This is analog to the definition 
    of the cross product in 2D (see Basic Geometry). By dividing 
    this area by two we get the area of a triangle that we are 
    interested in. We will use segment p1p2 and segment p2p3 as the column 
    vectors and calculate a 2×2 determinant:  (, breaks colums, and ; breaks rows)
     
    2S=∣∣∣x2−x1, x3-x2 ; y2−y1, y3−y2∣∣∣=(x2−x1)(y3−y2)−(x3−x2)(y2−y1)

    int signed_area_parallelogram(point2d p1, point2d p2, point2d p3) {
        return cross(p2 - p1, p3 - p2);
    }

    double triangle_area(point2d p1, point2d p2, point2d p3) {
        return abs(signed_area_parallelogram(p1, p2, p3)) / 2.0;
    }

    bool clockwise(point2d p1, point2d p2, point2d p3) {
        return signed_area_parallelogram(p1, p2, p3) < 0;
    }

    bool counter_clockwise(point2d p1, point2d p2, point2d p3) {
        return signed_area_parallelogram(p1, p2, p3) > 0;
    }


#################################################
#################################################
Cool Notes Part 0: Trigonometry formulas and identies put here!





#################################################
#################################################
[PLEASE FINISH WRITING THESE NOTES!!!! -> STOPPED AT CROSS PRODUCT]




COOL NOTES PART 1: BASIC GEOMETRY:
(https://cp-algorithms.com/geometry/basic-geometry.html)

In this article we will consider basic operations on points in 
Euclidean space which maintains the foundation of the whole analytical geometry. 
We will consider for each point r the vector r⃗  directed from 0 to r. Later we will 
not distinguish between r and r⃗  and use the term point as a synonym for vector.


    DOT PRODUCT:

        The dot (or scalar) product a⋅b for vectors a and b can be defined in two 
        identical ways. Geometrically it is product of the length of the first 
        vector by the length of the projection of the second vector onto the first one. 
        As you may see from the image below this projection is nothing but |a|cosθ 
        where θ is the angle between a and b. Thus a⋅b=|a|cosθ⋅|b|.

        The dot product holds some notable properties:

        a⋅b=b⋅a
        (α⋅a)⋅b=α⋅(a⋅b)
        (a+b)⋅c=a⋅c+b⋅c

        I.e. it is a commutative function which is linear with respect to both arguments. 
        
        Let's denote the unit vectors as
        ex=[1,0,0],ey=[0,1,0],ez=[0,0,1].

        With this notation we can write the vector r=(x;y;z) as r=x⋅ex+y⋅ey+z⋅ez. And since for unit vectors
        ex⋅ex=ey⋅ey=ez⋅ez=1,
        ex⋅ey=ey⋅ez=ez⋅ex=0

        we can see that in terms of coordinates for a=(x1;y1;z1) and b=(x2;y2;z2) holds
        a⋅b=(x1⋅ex + y1⋅ey + z1⋅ez)⋅(x2⋅ex + y2⋅ey + z2⋅ez)= x1x2 + y1y2 + z1z2

        That is also the algebraic definition of the dot product. 
        From this we can write functions which calculate it.

        ftype dot(point2d a, point2d b) {
        return a.x * b.x + a.y * b.y;
        }

        ftype dot(point3d a, point3d b) {
            return a.x * b.x + a.y * b.y + a.z * b.z;
        }
        
        When solving problems one should use algebraic definition to calculate dot products, 
        but keep in mind geometric definition and properties to use it.

        ftype dot(point2d a, point2d b) {
        return a.x * b.x + a.y * b.y;
        }

        ftype dot(point3d a, point3d b) {
            return a.x * b.x + a.y * b.y + a.z * b.z;
        }

        Properties
        We can define many geometrical properties via the dot product. For example

        Norm of a (squared length): |a|^2=a⋅a
        Length of a: |a|=√(a⋅a)
        Projection of a onto b: (a⋅b)/|b|
        Angle between vectors: arccos((a⋅b)/(|a|⋅|b|))

        From the previous point we may see that the dot product is positive 
        if the angle between them is acute, negative if it is obtuse and it 
        equals zero if they are orthogonal, i.e. they form a right angle.
        
        Note that all these functions do not depend on the number of dimensions, 
        hence they will be the same for the 2D and 3D case:

        ftype norm(point2d a) {
            return dot(a, a);
        }
        double abs(point2d a) {
            return sqrt(norm(a));
        }
        double proj(point2d a, point2d b) {
            return dot(a, b) / abs(b);
        }
        double angle(point2d a, point2d b) {
            return acos(dot(a, b) / abs(a) / abs(b));
        }
        
        To see the next important property we should take a look at the set of 
        points r for which r⋅a=C for some fixed constant C. You can see that 
        this set of points is exactly the set of points for which the 
        projection onto a is the point C⋅a/|a| and they form a hyperplane 
        orthogonal to a. You can see the vector a alongside with 
        several such vectors having same dot product with it in 2D on the picture below:

        Vectors having same dot product with a
        In 2D these vectors will form a line, in 3D they will form a plane. 
        Note that this result allows us to define a line in 2D as r⋅n=C or (r−r0)⋅n=0 
        where n is vector orthogonal to the line and r0 is any vector already present 
        on the line and C=r0⋅n. In the same manner a plane can be defined in 3D.    








    Points C++:

    struct point2d {
        ftype x, y;
        point2d() {}
        point2d(ftype x, ftype y): x(x), y(y) {}
        point2d& operator+=(const point2d &t) {
            x += t.x;
            y += t.y;
            return *this;
        }
        point2d& operator-=(const point2d &t) {
            x -= t.x;
            y -= t.y;
            return *this;
        }
        point2d& operator*=(ftype t) {
            x *= t;
            y *= t;
            return *this;
        }
        point2d& operator/=(ftype t) {
            x /= t;
            y /= t;
            return *this;
        }
        point2d operator+(const point2d &t) const {
            return point2d(*this) += t;
        }
        point2d operator-(const point2d &t) const {
            return point2d(*this) -= t;
        }
        point2d operator*(ftype t) const {
            return point2d(*this) *= t;
        }
        point2d operator/(ftype t) const {
            return point2d(*this) /= t;
        }
    };
    point2d operator*(ftype a, point2d b) {
        return b * a;
    }
    And 3D points:

    struct point3d {
        ftype x, y, z;
        point3d() {}
        point3d(ftype x, ftype y, ftype z): x(x), y(y), z(z) {}
        point3d& operator+=(const point3d &t) {
            x += t.x;
            y += t.y;
            z += t.z;
            return *this;
        }
        point3d& operator-=(const point3d &t) {
            x -= t.x;
            y -= t.y;
            z -= t.z;
            return *this;
        }
        point3d& operator*=(ftype t) {
            x *= t;
            y *= t;
            z *= t;
            return *this;
        }
        point3d& operator/=(ftype t) {
            x /= t;
            y /= t;
            z /= t;
            return *this;
        }
        point3d operator+(const point3d &t) const {
            return point3d(*this) += t;
        }
        point3d operator-(const point3d &t) const {
            return point3d(*this) -= t;
        }
        point3d operator*(ftype t) const {
            return point3d(*this) *= t;
        }
        point3d operator/(ftype t) const {
            return point3d(*this) /= t;
        }
    };
    point3d operator*(ftype a, point3d b) {
        return b * a;
    }
    Here ftype is some type used for coordinates, usually int, double or long long.










###################################################
####################################################

COOL Notes PART 2: Bit Magic

0.1) How to set a bit in a number:
        void set(int & num,int pos) 
    { 
         // First step is shift '1', second 
         // step is bitwise OR 
         num |= (1 << pos); 
    }     

0.2) How to unset/clear a bit at nth position in the number:
        // First step is to get a number that  has all 1's except the given position. 
        void unset(int &num,int pos) 
        { 
            //Second step is to bitwise and this  number with given number 
            num &= (~(1 << pos)); 
        } 

0.3) Toggle bit an nth position (use xor for toggling)
        // First step is to shift 1,Second step is to XOR with given number 
        void toggle(int &num,int pos) 
        { 
            num ^= (1 << pos); 
        } 


0.4) Checking if bit at nth position is set or unset: It is quite easily doable using ‘AND’ operator. 
        Left shift ‘1’ to given position and then ‘AND'(‘&’).

        bool at_position(int num,int pos) 
        { 
            bool bit = num & (1<<pos); 
            return bit; 
        } 

0.5) Inverting every bit of a number/1’s complement (this is how to get 1s complement):
        If we want to invert every bit of a number i.e change bit ‘0’ to ‘1’ and bit ‘1’ to ‘0’.
        We can do this with the help of ‘~’ operator. 
        For example : if number is num=00101100 (binary representation) 
        so ‘~num’ will be ‘11010011’.

0.6) Get twos complement: complement of a number is 1’s complement + 1.
    So formally we can have 2’s complement by finding 1s complement and adding 1 
    to the result i.e (~num+1) or what else we can do is using ‘-‘ operator.
        int main() 
        { 
            int num = 4; 
            int twos_complement = -num; 
            cout << "This is two's complement " << twos_complement << endl; 
            cout << "This is also two's complement " << (~num+1) << endl; 
            return 0; 
        } 
    
    This is because negative numbers are represented as 2's complement rite!




0.7) Stripping off the lowest set bit: 

        In many situations we want to strip off the lowest set bit for example in 
        Binary Indexed tree data structure, counting number of set bit in a number.

        We do something like this:

        X = X & (X-1)

        Let us see this by taking an example, let X = 1100.

        (X-1)  inverts all the bits till it encounter lowest set ‘1’ 
        and it also invert that lowest set ‘1’.

        X-1 becomes 1011. After ‘ANDing’ X with X-1 we get lowest set bit stripped.

0.8) Getting lowest set bit of a number:
        This is done by using expression ‘X &(-X)’
        Let us see this by taking an example:Let X = 00101100. 
        So ~X(1’s complement) will be ‘11010011’ and 2’s complement will 
        be (~X+1 or -X) i.e  ‘11010100’.
        So if we ‘AND’ original number ‘X’ with its 
        two’s complement which is ‘-X’, we get lowest set bit.
        
        int lowest_set_bit(int num) 
        { 
            int ret = num & (-num); 
            return ret; 
        } 

0.9) We have considered below facts in this article –

        0 based indexing of bits from left to right.
        Setting i-th bit means, turning i-th bit to 1
        Clearing i-th bit means, turning i-th bit to 0

1.0) Clear all bits from LSB to ith bit
        mask = ~((1 << i+1 ) - 1);
        x &= mask;

        Logic: To clear all bits from LSB to i-th bit, we have to AND x with mask having LSB to i-th bit 0. 
                To obtain such mask, first left shift 1 i times. Now if we minus 1 from that, 
                all the bits from 0 to i-1 become 1 and remaining bits become 0. Now we can 
                simply take complement of mask to get all first i bits to 0 and remaining to 1.
                
                x = 29 (00011101) and we want to clear LSB to 3rd bit, total 4 bits
                mask -> 1 << 4 -> 16(00010000)
                mask -> 16 – 1 -> 15(00001111)
                mask -> ~mask -> 11110000
                x & mask -> 16 (00010000)

1.1) Clearing all bits from MSB to i-th bit

        mask = (1 << i) - 1;
        x &= mask;
       
        x = 215 (11010111) and we want to clear MSB to 4th bit, total 4 bits
        mask -> 1 << 4 -> 16(00010000)
        mask -> 16 – 1 -> 15(00001111)
        x & mask -> 7(00000111)
1.2) Divide by 2
     x >>= 1;
    Multiply by 2
    x <<= 1;

1.3) Upper case English alphabet to lower case

        ch |= ' ';

1.4) Lower case English alphabet to upper case
    
        ch &= '_’ ;

1.5) 7) Count set bits in integer

        int countSetBits(int x) 
        { 
            int count = 0; 
            while (x) 
            { 
                x &= (x-1); 
                count++; 
            } 
            return count; 
        } 

1.6) Find log base 2 of 32 bit integer

        int log2(int x) 
        { 
            int res = 0; 
            while (x >>= 1) 
                res++; 
            return res; 
        } 

1.7) Checking if given 32 bit integer is power of 2

        int isPowerof2(int x) 
        { 
            return (x && !(x & x-1)); 
        } 
        Logic: All the power of 2 have only single bit set e.g. 16 (00010000). 
        If we minus 1 from this, all the bits from LSB to set bit get toggled, 
        i.e., 16-1 = 15 (00001111). Now if we AND x with (x-1) and the result 
        is 0 then we can say that x is power of 2 otherwise not. 
        We have to take extra care when x = 0.

        Example
        x = 16(000100000)
        x – 1 = 15(00001111)
        x & (x-1) = 0
        so 16 is power of 2



1.9) The left shift and right shift operators should not be used for negative numbers 
If any of the operands is a negative number, it results in undefined behaviour. 
For example results of both -1 << 1 and 1 << -1 is undefined. Also, if the number 
is shifted more than the size of integer, the behaviour is undefined. For example, 
1 << 33 is undefined if integers are stored using 32 bits. See this for more details.



2) [Leetcode A-summary:-how-to-use-bit-manipulation-to-solve-problems-easily-and-efficiently ]
    Set union A | B
    Set intersection A & B
    Set subtraction A & ~B
    Set negation ALL_BITS ^ A or ~A
    Set bit A |= 1 << bit
    Clear bit A &= ~(1 << bit)
    Test bit (A & 1 << bit) != 0
    Extract last bit A&-A or A&~(A-1) or x^(x&(x-1))
    Remove last bit A&(A-1)
    Get all 1-bits ~0

2.1) Is power of 4:

        bool isPowerOfFour(int n) {
            return !(n&(n-1)) && (n&0x55555555);
            //check the 1-bit location;
        }

2.2) ^ tricks
Use ^ to remove even exactly same numbers and save the odd, 
or save the distinct bits and remove the same.

2.3) Sum of Two Integers
        Use ^ and & to add two integers

        int getSum(int a, int b) {
            return b==0? a:getSum(a^b, (a&b)<<1); //be careful about the terminating condition;
        }

2.4) | tricks
        Keep as many 1-bits as possible

        Find the largest power of 2 (most significant bit in binary form), 
        which is less than or equal to the given number N.

        long largest_power(long N) {
            //changing all right side bits to 1.
            N = N | (N>>1);
            N = N | (N>>2);
            N = N | (N>>4);
            N = N | (N>>8);
            N = N | (N>>16);
            return (N+1)>>1;
        }

2.5) Reverse bits of a given 32 bits unsigned integer.

        uint32_t reverseBits(uint32_t n) {
            unsigned int mask = 1<<31, res = 0;
            for(int i = 0; i < 32; ++i) {
                if(n & 1) res |= mask;
                mask >>= 1;
                n >>= 1;
            }
            return res;
        }

        uint32_t reverseBits(uint32_t n) {
            uint32_t mask = 1, ret = 0;
            for(int i = 0; i < 32; ++i){
                ret <<= 1;
                if(mask & n) ret |= 1;
                mask <<= 1;
            }
            return ret;
        }

2.6) & tricks. Just selecting certain bits

        Reversing the bits in integer

        x = ((x & 0xaaaaaaaa) >> 1) | ((x & 0x55555555) << 1);
        x = ((x & 0xcccccccc) >> 2) | ((x & 0x33333333) << 2);
        x = ((x & 0xf0f0f0f0) >> 4) | ((x & 0x0f0f0f0f) << 4);
        x = ((x & 0xff00ff00) >> 8) | ((x & 0x00ff00ff) << 8);
        x = ((x & 0xffff0000) >> 16) | ((x & 0x0000ffff) << 16);


2.7) Bitwise AND of Numbers Range
Given a range [m, n] where 0 <= m <= n <= 2147483647, return the bitwise AND 
of all numbers in this range, inclusive. 
For example, given the range [5, 7], you should return 4.

        int rangeBitwiseAnd(int m, int n) {
            int a = 0;
            while(m != n) {
                m >>= 1;
                n >>= 1;
                a++;
            }
            return m<<a; 
        }

2.8) Number of 1 Bits Write a function that takes an unsigned integer 
    and returns the number of ’1' bits it has (also known as the Hamming weight).

        int hammingWeight(uint32_t n) {
            int count = 0;
            while(n) {
                n = n&(n-1);
                count++;
            }
            return count;
        }

        int hammingWeight(uint32_t n) {
            ulong mask = 1;
            int count = 0;
            for(int i = 0; i < 32; ++i){ //31 will not do, delicate;
                if(mask & n) count++;
                mask <<= 1;
            }
            return count;
        }

2.9) Application
Repeated DNA Sequences
All DNA is composed of a series of nucleotides abbreviated as 
A, C, G, and T, for example: "ACGAATTCCG". When studying DNA, 
it is sometimes useful to identify repeated sequences within the DNA. 
Write a function to find all the 10-letter-long sequences (substrings) 
that occur more than once in a DNA molecule.
For example,

        Given s = "AAAAACCCCCAAAAACCCCCCAAAAAGGGTTT",
        Return: ["AAAAACCCCC", "CCCCCAAAAA"].


        class Solution {
        public:
            vector<string> findRepeatedDnaSequences(string s) {
                int sLen = s.length();
                vector<string> v;
                if(sLen < 11) return v;
                char keyMap[1<<21]{0};
                int hashKey = 0;
                for(int i = 0; i < 9; ++i) hashKey = (hashKey<<2) | (s[i]-'A'+1)%5;
                for(int i = 9; i < sLen; ++i) {
                    if(keyMap[hashKey = ((hashKey<<2)|(s[i]-'A'+1)%5)&0xfffff]++ == 1)
                        v.push_back(s.substr(i-9, 10));
                }
                return v;
            }
        };

        But the above solution can be invalid when repeated sequence appears too many times, 
        in which case we should use unordered_map<int, int> 
        keyMap to replace char keyMap[1<<21]{0}here.

3.0) Majority Element
        Given an array of size n, find the majority element. 
        The majority element is the element that appears more than ⌊ n/2 ⌋ times. 
        (bit-counting as a usual way, but here we actually 
        also can adopt sorting and Moore Voting Algorithm)

        Solution
        int majorityElement(vector<int>& nums) {
            int len = sizeof(int)*8, size = nums.size();
            int count = 0, mask = 1, ret = 0;
            for(int i = 0; i < len; ++i) {
                count = 0;
                for(int j = 0; j < size; ++j)
                    if(mask & nums[j]) count++;
                if(count > size/2) ret |= mask;
                mask <<= 1;
            }
            return ret;
        }


3.1) Single Number III
        Given an array of integers, every element appears three 
        times except for one. Find that single one. (Still this type 
        can be solved by bit-counting easily.)
        But we are going to solve it by digital logic design

        Solution
        //inspired by logical circuit design and boolean algebra;
        //counter - unit of 3;
        //current   incoming  next
        //a b            c    a b
        //0 0            0    0 0
        //0 1            0    0 1
        //1 0            0    1 0
        //0 0            1    0 1
        //0 1            1    1 0
        //1 0            1    0 0
        //a = a&~b&~c + ~a&b&c;
        //b = ~a&b&~c + ~a&~b&c;
        //return a|b since the single number can appear once or twice;

        int singleNumber(vector<int>& nums) {
            int t = 0, a = 0, b = 0;
            for(int i = 0; i < nums.size(); ++i) {
                t = (a&~b&~nums[i]) | (~a&b&nums[i]);
                b = (~a&b&~nums[i]) | (~a&~b&nums[i]);
                a = t;
            }
            return a | b;
        };



3.2) Maximum Product of Word Lengths
        Given a string array words, find the maximum value of length(word[i]) * length(word[j]) 
        where the two words do not share common letters. 
        You may assume that each word will contain only lower case letters. 
        If no such two words exist, return 0.

        Example 1:
        Given ["abcw", "baz", "foo", "bar", "xtfn", "abcdef"]
        Return 16
        The two words can be "abcw", "xtfn".

        Example 2:
        Given ["a", "ab", "abc", "d", "cd", "bcd", "abcd"]
        Return 4
        The two words can be "ab", "cd".

        Example 3:
        Given ["a", "aa", "aaa", "aaaa"]
        Return 0
        No such pair of words.

        Solution
        Since we are going to use the length of the word very frequently and we are to compare 
        the letters of two words checking whether they have some letters in common:

        using an array of int to pre-store the length of each word reducing the frequently measuring process;
        since int has 4 bytes, a 32-bit type, and there are only 26 different letters, so we can just use 
        one bit to indicate the existence of the letter in a word.

        int maxProduct(vector<string>& words) {
            vector<int> mask(words.size());
            vector<int> lens(words.size());
            for(int i = 0; i < words.size(); ++i) lens[i] = words[i].length();
            int result = 0;
            for (int i=0; i<words.size(); ++i) {
                for (char c : words[i])
                    mask[i] |= 1 << (c - 'a');
                for (int j=0; j<i; ++j)
                    if (!(mask[i] & mask[j]))
                        result = max(result, lens[i]*lens[j]);
            }
            return result;
        }

        Attention
        result after shifting left(or right) too much is undefined
        right shifting operations on negative values are undefined
        right operand in shifting should be non-negative, otherwise the result is undefined
        The & and | operators have lower precedence than comparison operators
        Sets

3.3) All the subsets

        A big advantage of bit manipulation is that it is trivial 
        to iterate over all the subsets of an N-elemen
        set: every N-bit value represents some subset. 
        Even better, if A is a subset of B then the number
        representing A is less than that representing B, which 
        is convenient for some dynamic programming solutions.

        It is also possible to iterate over all the subsets of a 
        particular subset (represented by a bit pattern), provided 
        that you don’t mind visiting them in reverse order 
        (if this is problematic, put them in a list as they’re 
        generated, then walk the list backwards). The trick 
        is similar to that for finding the lowest bit in a number. 
        If we subtract 1 from a subset, then the lowest set element 
        is cleared, and every lower element is set. However, we only 
        want to set those lower elements that are in the superset. 
        So the iteration step is just i = (i - 1) & superset.

        vector<vector<int>> subsets(vector<int>& nums) {
            vector<vector<int>> vv;
            int size = nums.size(); 
            if(size == 0) return vv;
            int num = 1 << size;
            vv.resize(num);
            for(int i = 0; i < num; ++i) {
                for(int j = 0; j < size; ++j)
                    if((1<<j) & i) vv[i].push_back(nums[j]);   
            }
            return vv;
        }
        Actually there are two more methods to handle this using recursion and iteration respectively.

        Bitset
        A bitset stores bits (elements with only two possible values: 0 or 1, true or false, ...).
        The class emulates an array of bool elements, but optimized for space allocation: 
        generally, each element occupies only one bit (which, on most systems, 
        is eight times less than the smallest elemental type: char).

        // bitset::count
        #include <iostream>       // std::cout
        #include <string>         // std::string
        #include <bitset>         // std::bitset

        int main () {
            std::bitset<8> foo (std::string("10110011"));
            std::cout << foo << " has ";
            std::cout << foo.count() << " ones and ";
            std::cout << (foo.size()-foo.count()) << " zeros.\n";
            return 0;
        }


3.9) The bitwise operators should not be used in place of logical operators.

4) The left-shift and right-shift operators are equivalent to multiplication and division by 2 respectively.
As mentioned in point 1, it works only if numbers are positive.

5) The & operator can be used to quickly check if a number is odd or even
The value of expression (x & 1) would be non-zero only if x is odd, otherwise the value would be zero.

6) The ~ operator should be used carefully
The result of ~ operator on a small number can be a big number if the result is stored in an
unsigned variable. And result may be negative number if result is stored in signed 
variable (assuming that the negative numbers are stored in 2’s complement 
form where leftmost bit is the sign bit)


-> X ^ 0s = x
-> X ^ 1s = ~x
x ^ x = 0

7) Compute XOR from 1 to n (direct method) :

        // Direct XOR of all numbers from 1 to n 
        int computeXOR(int n) 
        {
        	if (n % 4 == 0) 
        		return n; 
        	if (n % 4 == 1) 
        		return 1; 
        	if (n % 4 == 2) 
        		return n + 1; 
        	else
        		return 0; 
        } 

8) We can quickly calculate the total number of combinations with numbers smaller than or
   equal to with a number whose sum and XOR are equal. Instead of using looping 
   (Brute force method), we can directly find it by a mathematical trick i.e.

    // Refer Equal Sum and XOR for details.
    Answer = pow(2, count of zero bits)

9) How to know if a number is a power of 2?
        // Function to check if x is power of 2 
        bool isPowerOfTwo(int x) 
        { 
        	// First x in the below expression is 
        	// for the case when x is 0 
        	return x && (!(x & (x - 1))); 
        } 

10) Find XOR of all subsets of a set. We can do it in O(1) time. 
    The answer is always 0 if given set has more than one elements. 
    For set with single element, the answer is value of single element. 

11) We can quickly find number of leading, trailing zeroes and number of 1’s 
    in a binary code of an integer in C++ using GCC. 
    It can be done by using inbuilt function i.e.
  
    Number of leading zeroes: builtin_clz(x)
    Number of trailing zeroes : builtin_ctz(x)
    Number of 1-bits: __builtin_popcount(x) 
    Refer GCC inbuilt functions for details.

12) Convert binary code directly into an integer in C++.
        // Conversion into Binary code// 
        #include <iostream> 
        using namespace std; 
        
        int main() 
        { 
            auto number = 0b011; 
            cout << number; 
            return 0; 
        } 
        Output: 3


13) Simple approach to flip the bits of a number: It can be done by a simple way, 
    just simply subtract the number from the value obtained when all the bits are equal to 1 .


14) We can quickly check if bits in a number are in alternate pattern (like 101010). 
    We compute n ^ (n >> 1). If n has an alternate pattern, then n ^ (n >> 1) operation 
    will produce a number having set bits only. ‘^’ is a bitwise XOR operation. 

COOL NOTES PART 3: USING XOR TO SOLVE PROBLEMS EXAMPLES: ####################################

1) You are given a list of n-1 integers and these integers are in the range of 1 to n. 
There are no duplicates in list. One of 
the integers is missing in the list. Write an efficient code to find the missing integer.

METHOD 2(Use XOR)

  1) XOR all the array elements, let the result of XOR be X1.
  2) XOR all numbers from 1 to n, let XOR be X2.
  3) XOR of X1 and X2 gives the missing number.


2) How to swap two numbers without using a temporary variable?
   Given two variables, x and y, swap two variables without using a third variable.

   int main() 
{ 
    int x = 10, y = 5; 
  
    // Code to swap 'x' and 'y' 
    x = x + y; // x now becomes 15 
    y = x - y; // y becomes 10 
    x = x - y; // x becomes 5 
    cout << "After Swapping: x =" << x << ", y=" << y; 
} 

OR:  (WITH XOR)

int main() 
{ 
    int x = 10, y = 5; 
    // Code to swap 'x' (1010) and 'y' (0101) 
    x = x ^ y; // x now becomes 15 (1111) 
    y = x ^ y; // y becomes 10 (1010) 
    x = x ^ y; // x becomes 5 (0101) 
    cout << "After Swapping: x =" << x << ", y=" << y; 
    return 0; 
} 

3) XOR Linked List – A Memory Efficient Doubly Linked List | Set 1

An ordinary Doubly Linked List requires space for two address 
fields to store the addresses of previous and next nodes. 
A memory efficient version of Doubly Linked List can be 
created using only one space for address field with every node. 
This memory efficient Doubly Linked List is called XOR Linked List 
or Memory Efficient as the list uses bitwise XOR operation to save space 
for one address. In the XOR linked list, instead of storing actual memory 
addresses, every node stores the XOR of addresses of previous and next nodes.

Traversal of XOR Linked List:
We can traverse the XOR list in both forward 
and reverse direction. While traversing the 
list we need to remember the address of 
the previously accessed node in order to 
calculate the next node’s address. 
For example when we are at node C, we must have address of 
B. XOR of add(B) and npx of C gives us the add(D). The reason 
is simple: npx(C) is “add(B) XOR add(D)”. If we do xor of npx(C) 
with add(B), we get the result as “add(B) XOR add(D) XOR add(B)” 
which is “add(D) XOR 0” which is “add(D)”. So we have the address of next node. 
Similarly we can traverse the list in backward direction.

4) Find the two non-repeating elements in an array of repeating elements

    Let x and y be the non-repeating elements we are looking for and arr[] be the input array.
    First, calculate the XOR of all the array elements.

        xor = arr[0]^arr[1]^arr[2].....arr[n-1]
    All the bits that are set in xor will be set in one non-repeating 
    element (x or y) and not in others. So if we take any set bit of xor 
    and divide the elements of the array in two sets – one set of elements
    with same bit set and another set with same bit not set. By doing so, 
    we will get x in one set and y in another set. Now if we do XOR of all 
    the elements in the first set, we will get the first non-repeating element,
    and by doing same in other sets we will get the second non-repeating element.

    Let us see an example.
    arr[] = {2, 4, 7, 9, 2, 4}
    1) Get the XOR of all the elements.
        xor = 2^4^7^9^2^4 = 14 (1110)
    2) Get a number which has only one set bit of the xor.   
    Since we can easily get the rightmost set bit, let us use it.
        set_bit_no = xor & ~(xor-1) = (1110) & ~(1101) = 0010
    Now set_bit_no will have only set as rightmost set bit of xor.
    3) Now divide the elements in two sets and do xor of         
    elements in each set and we get the non-repeating 
    elements 7 and 9. Please see the implementation for this step.
    /* Now divide elements in two sets by comparing rightmost set 
   bit of xor with bit at same position in each element. */
    for(i = 0; i < n; i++) 
    { 
        if(arr[i] & set_bit_no) 
        *x = *x ^ arr[i]; /*XOR of first set */
        else
        *y = *y ^ arr[i]; /*XOR of second set*/
    } 

5)   Find the two numbers with odd occurrences in an unsorted array
        # Python3 program to find the 
        # two odd occurring elements 
        
        # Prints two numbers that occur odd 
        # number of times. The function assumes 
        # that the array size is at least 2 and 
        # there are exactly two numbers occurring 
        # odd number of times. 
        def printTwoOdd(arr, size): 
            
            # Will hold XOR of two odd occurring elements  
            xor2 = arr[0]  
            
            # Will have only single set bit of xor2 
            set_bit_no = 0  
            n = size - 2
            x, y = 0, 0
        
            # Get the xor of all elements in arr[].  
            # The xor will basically be xor of two 
            # odd occurring elements  
            for i in range(1, size): 
                xor2 = xor2 ^ arr[i] 
        
            # Get one set bit in the xor2. We get  
            # rightmost set bit in the following  
            # line as it is easy to get  
            set_bit_no = xor2 & ~(xor2 - 1) 
        
            # Now divide elements in two sets:  
            # 1) The elements having the corresponding bit as 1.  
            # 2) The elements having the corresponding bit as 0.  
            for i in range(size): 
            
                # XOR of first set is finally going to   
                # hold one odd  occurring number x  
                if(arr[i] & set_bit_no): 
                    x = x ^ arr[i] 
        
                # XOR of second set is finally going  
                # to hold the other odd occurring number y  
                else: 
                    y = y ^ arr[i]  
        
            print("The two ODD elements are", x, "&", y) 
        
        # Driver Code 
        arr = [4, 2, 4, 5, 2, 3, 3, 1] 
        arr_size = len(arr) 
        printTwoOdd(arr, arr_size) 
    

6) Add two numbers without using arithmetic operators

        Write a function Add() that returns sum of two integers. 
        The function should not use any of the arithmetic operators (+, ++, –, -, .. etc).
        Sum of two bits can be obtained by performing XOR (^) of the two bits. 
        Carry bit can be obtained by performing AND (&) of two bits.
        Above is simple Half Adder logic that can be used to add 2 single bits.
        We can extend this logic for integers. If x and y don’t have set bits at same position(s), 
        then bitwise XOR (^) of x and y gives the sum of x and y. To incorporate common set bits also, 
        bitwise AND (&) is used. Bitwise AND of x and y 
        gives all carry bits. We calculate (x & y) << 1 and 
        add it to x ^ y to get the required result.

        # Python3 Program to add two numbers 
        # without using arithmetic operator 
        def Add(x, y): 
        
            # Iterate till there is no carry  
            while (y != 0): 
            
                # carry now contains common 
                # set bits of x and y 
                carry = x & y 
        
                # Sum of bits of x and y where at 
                # least one of the bits is not set 
                x = x ^ y 
        
                # Carry is shifted by one so that    
                # adding it to x gives the required sum 
                y = carry << 1
            
            return x 
        
        print(Add(15, 32)) 
  
7. Count number of bits to be flipped to convert A to B

        Given two numbers ‘a’ and b’. Write a program to count number 
        of bits needed to be flipped to convert ‘a’ to ‘b’.

        1. Calculate XOR of A and B.      
                a_xor_b = A ^ B
        2. Count the set bits in the above 
            calculated XOR result.
                countSetBits(a_xor_b)

        # Function that count set bits 
        def countSetBits( n ): 
            count = 0
            while n: 
                count += n & 1
                n >>= 1
            return count 
            
        # Function that return count of 
        # flipped number 
        def FlippedCount(a , b): 
        
            # Return count of set bits in 
            # a XOR b 
            return countSetBits(a^b) 
        
        # Driver code 
        a = 10
        b = 20
        print(FlippedCount(a, b)) 

8.      Find the element that appears once. Given an array where every element occurs three times, 
        except one element which occurs only once. Find the element that occurs once.

        Run a loop for all elements in array. At the end of every iteration, maintain following two values.

        ones: The bits that have appeared 1st time or 4th time or 7th time .. etc.

        twos: The bits that have appeared 2nd time or 5th time or 8th time .. etc.

        Finally, we return the value of ‘ones’

        How to maintain the values of ‘ones’ and ‘twos’?
        ‘ones’ and ‘twos’ are initialized as 0. For every new element in array, 
        find out the common set bits in the new element and previous value of ‘ones’. 
        These common set bits are actually the bits that should be added to ‘twos’. 
        So do bitwise OR of the common set bits with ‘twos’. ‘twos’ also gets 
        some extra bits that appear third time. These extra bits are removed later.
        Update ‘ones’ by doing XOR of new element with previous value of ‘ones’.
        There may be some bits which appear 3rd time. These extra bits are also removed later.

        Both ‘ones’ and ‘twos’ contain those extra bits which appear 3rd time. 
        Remove these extra bits by finding out common set bits in ‘ones’ and ‘twos’.



        Below is the implementation of above approach:

        # Python3 code to find the element that  
        # appears once 

        def getSingle(arr, n): 
            ones = 0
            twos = 0

            for i in range(n): 
                # one & arr[i]" gives the bits that 
                # are there in both 'ones' and new 
                # element from arr[]. We add these 
                # bits to 'twos' using bitwise OR 
                twos = twos | (ones & arr[i]) 

                # one & arr[i]" gives the bits that 
                # are there in both 'ones' and new 
                # element from arr[]. We add these 
                # bits to 'twos' using bitwise OR 
                ones = ones ^ arr[i] 

                # The common bits are those bits  
                # which appear third time. So these 
                # bits should not be there in both  
                # 'ones' and 'twos'. common_bit_mask 
                # contains all these bits as 0, so 
                # that the bits can be removed from 
                # 'ones' and 'twos' 
                common_bit_mask = ~(ones & twos) 

                # Remove common bits (the bits that  
                # appear third time) from 'ones' 
                ones &= common_bit_mask 

                # Remove common bits (the bits that 
                # appear third time) from 'twos' 
                twos &= common_bit_mask 
            return ones 

        # driver code 
        arr = [3, 3, 2, 3] 
        n = len(arr) 
        print("The element with single occurrence is ", 
                getSingle(arr, n)) 

9. Detect if two integers have opposite signs

        Given two signed integers, write a function that returns true if the signs of 
        given integers are different, otherwise false. For example, the function 
        should return true -1 and +100, and should return false for -100 and -200. 
        The function should not use any of the arithmetic operators.

        Let the given integers be x and y. The sign bit is 1 in negative numbers, 
        and 0 in positive numbers. The XOR of x and y will have the sign bit as 1 
        iff they have opposite sign. In other words, XOR of x and y will be negative 
        number number iff x and y have opposite signs. The following code use this logic.

        # Python3 Program to Detect  
        # if two integers have  
        # opposite signs. 
        def oppositeSigns(x, y): 
            return ((x ^ y) < 0); 

        x = 100
        y = 1

        if (oppositeSigns(x, y) == True): 
            print "Signs are opposite"
        else: 
            print "Signs are not opposite"

10. Return the rightmost 1 in the binary representation of a number.
        Example: For 1010, you should perform some operations to give 0010 as the output. 
        For 1100, you should give 0100. Similarly for 0001, you should return 0001.
    
        For this problem, you need to know a property of binary subtraction. 
        Check if you can find out the property in the examples below,

        1000 – 0001 = 0111
        0100 – 0001 = 0011
        1100 – 0001 = 1011

        The property is, the difference between a binary number n and n-1 
        is all the bits on the right of the rightmost 1 are flipped 
        including the rightmost 1.  
        Using this amazing property, we can get our solution as
        x ^ (x & (x - 1))
        
        You now already know 80% about a powerful data structure called 
        Fenwick Tree or Binary Indexed Tree. You can look up on it to 
        learn the 20% or let me know if you want my next article to be about it. )
