##################################################################################

SHORT CIRCUITING TO GET VALUES TRICK:

For any one else having the same question:
simple or statements:

The statement x or y returns x if x evaluates to True, otherwise it 
returns y (even if both are False), let us look at a few examples:

1 or 2 returns 1, because 1 evaluates to True
0 or 1 returns 1
0 or '' returns ''

simple and statements:
The statement x and y returns x if x evaluates to False, otherwise it returns y (even if both are True), 

let us look at a few examples:
1 and 2 returns 2
1 and 0 returns 0
0 and 2 returns 0
So we can see that intuitively the above statements are evaluated in a "short circuit" manner, 
i.e. the statement is evaluated from left to right and whichever variable determines 
the value of the boolean expression first is returned.

Now let us have a look at some complicated examples with the above intuition:
Continuous or statements
The variable which first evaluates to True is returned else the last variable is returned.
Examples:
1 or 2 or 3 or 4 returns 1
'' or {} or [] or 4 returns 4
'' or {} or [] returns []
Continuous and statements
The variable which first evaluates to False is returned else the last variable is returned
Examples:
1 and 2 and 3 returns 3
1 and '' and 4 returns ''
0 and '' and 4 returns 0

More complex statements:
What if compound statements mixed with and and or are used?
In such cases we have to remember that and has a higher precedence than 
or and the order of evaluation of the expression is always from left to right, 
and lastly remember the 'short circuit' intuition.

Let us have a look at some statements:
1 and 2 or 4 returns 2, why?
1 and 2 or 4 is evaluated as (1 and 2) or (4), (1 and 2) evaluates to True, 
so the or statement returns 1 and 2 which further returns 2

Infact the ternary condition x if condition else y can be rewritten as
condition and x or y ! (prove it to yourself) , although it is not recommended for readability purposes.



################################################################################33
PRIORITY QUEUE:
HEAPQ IS A MIN HEAP BY DEFAULT.

how to make it a max heap?

The easiest and ideal solution
Multiply the values by -1
There you go. All the highest numbers are now the lowest and vice versa.
Just remember that when you pop an element to multiply it with -1 
in order to get the original value again.


HEAPQ API:

These two make it possible to view the heap as a regular Python 
list without surprises: heap[0] is the smallest item, 
and heap.sort() maintains the heap invariant!

To create a heap, use a list initialized to [], or you can 
transform a populated list into a heap via function heapify().

heapq.heappush(heap, item)
Push the value item onto the heap, maintaining the heap invariant.

heapq.heappop(heap)
Pop and return the smallest item from the heap, maintaining the heap invariant. 
If the heap is empty, IndexError is raised. To access the smallest 
item without popping it, use heap[0].

heapq.heappushpop(heap, item)
Push item on the heap, then pop and return the smallest item from the heap. 
The combined action runs more efficiently than heappush() 
followed by a separate call to heappop().

heapq.heapify(x)
Transform list x into a heap, in-place, in linear time.

heapq.heapreplace(heap, item)
Pop and return the smallest item from the heap, and also push the new item. 
The heap size doesn’t change. If the heap is empty, IndexError is raised.

This one step operation is more efficient than a heappop() followed by heappush() and
can be more appropriate when using a fixed-size heap. The pop/push combination 
always returns an element from the heap and replaces it with item.

The value returned may be larger than the item added. If that isn’t desired, 
consider using heappushpop() instead. Its push/pop combination returns the 
smaller of the two values, leaving the larger value on the heap.

The module also offers three general purpose functions based on heaps.

heapq.merge(*iterables)
Merge multiple sorted inputs into a single 
sorted output (for example, merge timestamped 
entries from multiple log files). Returns an iterator over the sorted values.

Similar to sorted(itertools.chain(*iterables)) but returns an iterable, 
does not pull the data into memory all at once, and assumes 
that each of the input streams is already sorted (smallest to largest).

New in version 2.6.

heapq.nlargest(n, iterable[, key])
Return a list with the n largest elements from the 
dataset defined by iterable. key, if provided, 
specifies a function of one argument that is used 
to extract a comparison key from each element in the 
iterable: key=str.lower Equivalent to: sorted(iterable, key=key, reverse=True)[:n]

New in version 2.4.

Changed in version 2.5: Added the optional key argument.

heapq.nsmallest(n, iterable[, key])
Return a list with the n smallest elements from 
the dataset defined by iterable. key, if provided, 
specifies a function of one argument that is used to 
extract a comparison key from each element in the iterable: 
key=str.lower Equivalent to: sorted(iterable, key=key)[:n]

New in version 2.4.

Changed in version 2.5: Added the optional key argument.

The latter two functions perform best for smaller 
values of n. For larger values, it is more efficient 
to use the sorted() function. Also, when n==1, it is 
more efficient to use the built-in min() and max() functions. 
If repeated usage of these functions is required, consider 
turning the iterable into an actual heap.

##############################################################################################3

ORDERED DICT

OrderedDict preserves the order in which the keys are inserted. 
A regular dict doesn’t track the insertion order, and iterating 
it gives the values in an arbitrary order. By contrast, the order the 
items are inserted is remembered by OrderedDict.

Important Points:

Key value Change: If the value of a certain key is changed, the position of the key remains unchanged in OrderedDict.

Deletion and Re-Inserting: Deleting and re-inserting the same key will push it to the back 
                           as OrderedDict however maintains the order of insertion.


Ordered Dict can be used as a stack with the help of popitem function. 
Try implementing LRU cache with Ordered Dict.

from collections import OrderedDict 
  
print("Before deleting:\n") 
od = OrderedDict() 
od['a'] = 1
od['b'] = 2
od['c'] = 3
od['d'] = 4
  
for key, value in od.items(): 
    print(key, value) 
  
print("\nAfter deleting:\n") 
od.pop('c') 
for key, value in od.items(): 
    print(key, value) 
  
print("\nAfter re-inserting:\n") 
od['c'] = 3
for key, value in od.items(): 
    print(key, value) 

##########################################################################################################

8.5. bisect — Array bisection algorithm
New in version 2.1.


This module provides support for maintaining a list in sorted order without 
having to sort the list after each insertion. For long lists of items with 
expensive comparison operations, this can be an improvement over the more common approach. 
The module is called bisect because it uses a basic bisection algorithm to do its work. 
The source code may be most useful as a working example of the algorithm 
(the boundary conditions are already right!).


The following functions are provided:

bisect.bisect_left(a, x, lo=0, hi=len(a))
Locate the insertion point for x in a to maintain sorted order. 
The parameters lo and hi may be used to specify a subset of the list 
which should be considered; by default the entire list is used. If x is
already present in a, the insertion point will be before (to the left of) 
any existing entries. The return value is suitable for use as the first 
parameter to list.insert() assuming that a is already sorted.

The returned insertion point i partitions the array a into two halves so that 
all(val < x for val in a[lo:i]) for the left side and all(val >= x for val in a[i:hi]) for the right side.

bisect.bisect_right(a, x, lo=0, hi=len(a))
bisect.bisect(a, x, lo=0, hi=len(a))

Similar to bisect_left(), but returns an insertion point which 
comes after (to the right of) any existing entries of x in a.

The returned insertion point i partitions the array a into two 
halves so that all(val <= x for val in a[lo:i]) for the left side 
and all(val > x for val in a[i:hi]) for the right side.

bisect.insort_left(a, x, lo=0, hi=len(a))
Insert x in a in sorted order. This is 
equivalent to a.insert(bisect.bisect_left(a, x, lo, hi), x) assuming that a 
is already sorted. Keep in mind that the O(log n) search 
is dominated by the slow O(n) insertion step.

bisect.insort_right(a, x, lo=0, hi=len(a))
bisect.insort(a, x, lo=0, hi=len(a))
Similar to insort_left(), but inserting x in a after any existing entries of x.

##############################################################################

FROZEN SETS, AND HASHING PERFORMANCE:

    652. Find Duplicate Subtrees
    Medium
    1261
    198

    Given a binary tree, return all duplicate subtrees. 
    For each kind of duplicate subtrees, you only need to 
    return the root node of any one of them.

    STEFANS SOLUTION: 

    First the basic version, which is O(n2) 
    time and gets accepted in about 150 ms:

    def findDuplicateSubtrees(self, root):
        def tuplify(root):
            if root:
                tuple = root.val, tuplify(root.left), tuplify(root.right)
                trees[tuple].append(root)
                return tuple
        trees = collections.defaultdict(list)
        tuplify(root)
        return [roots[0] for roots in trees.values() if roots[1:]]

    I convert the entire tree of nested TreeNodes to a tree of nested tuples. 
    Those have the advantage that they already support hashing and deep 
    comparison (for the very unlikely cases of hash collisions). So 
    then I can just use each subtree's tuple version as a key in my 
    dictionary. And equal subtrees have the same key and thus get 
    collected in the same list.

    Overall this costs only O(n) memory (where n is the number of 
    nodes in the given tree). The string serialization I've seen 
    in other posted solutions costs O(n^2) memory (and thus also at least that much time).


    So far only O(n2) time
    Unfortunately, tuples don't cache their own hash value 
    (see this for a reason). So if I use a tuple as key and thus 
    it gets asked for its hash value, it will compute it again. 
    Which entails asking its content elements for their hashes. 
    And if they're tuples, then they'll do the same and ask 
    their elements for their hashes. And so on. So asking a 
    tuple tree root for its hash traverses the entire tree. 
    Which makes the above solution only O(n^2) time, as the 
    following test demonstrates. It tests linear trees, and 
    doubling the height quadruples the run time, exactly 
    what's expected from a quadratic time algorithm.

    The code:

    from timeit import timeit
    import sys
    sys.setrecursionlimit(5000)

    def tree(height):
        if height:
            root = TreeNode(0)
            root.right = tree(height - 1)
            return root

    solution = Solution().findDuplicateSubtrees
    for e in range(5, 12):
        root = tree(2**e)
        print(timeit(lambda: solution(root), number=1000))
    
    Caching hashes
    There's an easy way to add caching, though. 
    Simply wrap each tuple in a frozenset, which 
    does cache its hash value:

    def findDuplicateSubtrees(self, root):
        def convert(root):
            if root:
                result = frozenset([(root.val, convert(root.left), convert(root.right))])
                trees[result].append(root)
                return result
        trees = collections.defaultdict(list)
        convert(root)
        return [roots[0] for roots in trees.values() if roots[1:]]
    
    Running the above test again now shows O(n) behaviour as 
    expected, doubling of size causing doubling of run time:

    There is an O(N) solution check the question file. 
