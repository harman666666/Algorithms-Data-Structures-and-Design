-> Compressed Tries

-> Binary/Binomial/Fibonacci heaps
-> Splay trees

-> Range Tree
-> KD trees, quad trees, 
-> 2-3 trees, m-n trees

-> Balanced BSTs -> AVL/REDBLACK, Find a python one. 
-> Skip lists
-> Treaps?
-> Suffix Trees, and Suffix tries (http://www.cs.jhu.edu/~langmea/resources/lecture_notes/tries_and_suffix_tries.pdf)

van Emde Boas Trees
B-Trees
Red black trees, 
2-3 search trees
2-3-4 Trees (aka 2-4 trees)
Huffman trees and compression?
Block Cut Trees
Fenwick Tree


LOOOK AT CS240 DATASTRUCTURES NOTES IN FOLDER AND WRITE NOTES HERE FOR 
HASHING
AVL Trees
B TREES
TRIES, COMPRESSED TRIES (PATRICIA TRIES)
################################################################

Sparse Table
    The main problem that we can solve is RMQ problem, we have an array a1, a2, ..., an 
    and some queries. Each query gives you numbers l and r (l ≤ r) and you 
    should print the value of min(al, al + 1, ..., ar) .

    Solving using Sparse Table : For each i that 1 ≤ i ≤ n and for each j that 0 ≤ j 
    and i + 2j - 1 ≤ n, we keep the value of min(ai, ai + 1, ..., ai + 2j - 1) 
    in st[i][j] (preprocess) : (code is 0-based)

    for(int j = 0;j < MAX_LOG;j++)
        for(int i = 0; i < n;i ++)if(i + (1 << j) - 1 < n)
            st[i][j] = (j ? min(st[i][j-1], st[i + (1 << (j-1)) - 1][j-1]): a[i]);

    And then for each query, first of all, find the maximum x 
    such that 2x ≤ r - l + 1 and answer is min(st[l][x], st[r - 2x + 1][x]) .

    So, the main idea of Sparse Table, is to keep 
    the value for each interval of length 2k (for each k).

    You can use the same idea for LCA problem 
    and so many other problems.

    So preprocess will be in O(n.log(n)) and query will be in O(1)

    Problems : Strip, GCDSSQ, LCM Query .

#############################################################

Heavy light decomp tut (https://www.youtube.com/watch?v=1PvT2d9lgqY)

    Heavy light decomposition is a way to partition a tree's vertices (or edges) in a good way.

    In this kind of decomposition, we have some chains, and each vertex belongs to only one chain.

    If vertex v is the parent of u size_of_subtree_of(v)/2 < size_of_subtree_of(u), 
    u and v are in a chain and we call the edge uv, heavy, otherwise light.

    There is at most one such child for each vertex v. If we consider the 
    path from any vertex v to the root, there will be at most log(n) 
    light edges there (go from v to the root, every time we see a light 
    edge, size of subtree will be at least doubled). So, the number of 
    chains on the way = O(log(n)) .

    In each of these chains, we can contain a container or another 
    data structure like segment tree or etc.


###############################################################

HEAP  WHY IS SIFTDOWN BETTER THAN SIFT UP?

    Actually, building a heap with repeated calls of siftDown has a complexity of O(n) 
    whereas building it with repeated calls of siftUp has a complexity of O(nlogn).

    This is due to the fact that when you use siftDown, the time taken by each call 
    decreases with the depth of the node because these nodes are closer to the 
    leaves. When you use siftUp, the number of swaps increases with the depth of 
    the node because if you are at full depth, you may have to swap all the way 
    to the root. As the number of nodes grows exponentially with the depth of the tree, 
    using siftUp gives a more expensive algorithm.

    Moreover, if you are using a Max-heap to do some sort of sorting where you pop 
    the max element of the heap and then reheapify it, it's easier to do so by 
    using siftDown. You can reheapify in O(logn) time by popping the max element, 
    putting the last element at the root node (which was empty because you popped it) 
    and then sifting it down all the way back to its correct spot.


##################################################################################
BINARY HEAP

    A Binary Heap is a Binary Tree with following properties.

    1) It’s a complete tree (All levels are completely filled except possibly the last 
    level and the last level has all keys as left as possible). 
    This property of Binary Heap makes them suitable to be stored in an array.

    2) A Binary Heap is either Min Heap or Max Heap. In a Min Binary Heap, 
    the key at root must be minimum among all keys present in Binary Heap. 
    The same property must be recursively true for all nodes in Binary Tree. 
    Max Binary Heap is similar to MinHeap.


    Arr[(i-1)/2]	Returns the parent node
    Arr[(2*i)+1]	Returns the left child node
    Arr[(2*i)+2]	Returns the right child node

    4) Many problems can be efficiently solved using Heaps. See following for example.
    a) K’th Largest Element in an array.
    b) Sort an almost sorted array/
    c) Merge K Sorted Arrays.

    Operations on Min Heap:
    1) getMini(): It returns the root element of Min Heap.
     Time Complexity of this operation is O(1).

    2) extractMin(): Removes the minimum element from MinHeap. 
    Time Complexity of this Operation is O(Logn) as this operation 
    needs to maintain the heap property (by calling heapify()) after removing root.

    3) decreaseKey(): Decreases value of key. The time complexity of this operation is O(Logn). 
    If the decreases key value of a node is greater than the parent of the node, 
    then we don’t need to do anything. Otherwise, we need 
    to traverse up to fix the violated heap property.



############################################
BINOMIAL HEAP




#############################################################################

BINOMIAL HEAP
VS
FIBONNACI HEAPS -> USED IN PRIMS MST algorithm

    In terms of Time Complexity, Fibonacci Heap beats both Binary and Binomial Heaps.

    Below are amortized time complexities of Fibonacci Heap.

    1) Find Min:      Θ(1)     [Same as both Binary and Binomial]
    2) Delete Min:    O(Log n) [Θ(Log n) in both Binary and Binomial]
    3) Insert:        Θ(1)     [Θ(Log n) in Binary and Θ(1) in Binomial]
    4) Decrease-Key:  Θ(1)     [Θ(Log n) in both Binary and Binomial]
    5) Merge:         Θ(1)     [Θ(m Log n) or Θ(m+n) in Binary and
                                Θ(Log n) in Binomial]

    Like Binomial Heap, Fibonacci Heap is a collection of trees with min-heap or 
    max-heap property. In Fibonacci Heap, trees can can have any shape even 
    all trees can be single nodes (This is unlike Binomial Heap where 
    every tree has to be Binomial Tree).

    Binomial heap takes O(log n) time in all operations while Fibonacci 
    heap takes amortized running time O(1) in Insert, find, 
    decrease key operations and O(log n) time in delete min, delete operations.


    Binomial heaps use a singly linked circular link list and 
    Fibonacci heaps use a doubly linked circular linked list.

    every Binomial heap is a Fibonacci heap but every Fibonacci heap isn't Binomial heap.

    Delete-min in Binomial heaps involves the combining of trees where as delete-min or 
    delete in Fibonacci heaps is performed without 
    joining the trees obtained after deletion.

    Data members in a node for Binomial heaps are data, link, degree and child. 
    Whereas in Fibonacci heaps it is data, parent, childcut, child, link and degree.

#################################################################################################
Fenwick Intro:


    Suppose that we have n elements numbered from 1 to n.

    Fenwick or BIT(Binary Indexed Tree) is a data structure with n 
    nodes that node number i has some information about 
    elements in the interval (i -  i& - i, i] .

    Actually, you don't need to know what each node contains. 
    The only thing you should know, it this (then you can change and convert it) :

    We have an array a1, a2, ..., an and all of them are initially 0. 
    We are gives some queries, 
    1.increase ap by val and print a1 + a2 + ... + ap .

    Only thing you should know is that how to solve this 
    problem using Fenwick (and then you can change 
    it and solve so many problems).

    

    We perform each query in O(log(n)). Code : (1-based)

    int fen[MAX_N];
    void update(int p,int val){
        for(int i = p;i <= n;i += i & -i)
            fen[i] += val;
    }
    int sum(int p){
        int ans = 0;
        for(int i = p;i;i -= i & -i)
            ans += fen[i];
        return ans;
    }
    Please note that it should be 1-based. It can't be done 0-based.



#################################################################################################
    Fenwick Tree youtube video ideas (BEST EXAPLANATION): 

    1, -7, 15, 9, 4, 2, 0, 10
    We keep grouping elements, first by 2, then by 4, then by 8
 
    1, -7, 15, 9, 4, 2, 0, 10
     -6,     24,    6,   10
          18,          16
                34
    
    Make fenwick tree indexed by 1 -> whatever lenght array we get, make fenwick array 1 size bigger.
    8 blocks -> size 9 array. 
    
    INITIALIZATION: 
    4 bits to represent 9 blocks. 
    First node is always dummy node in fenwick tree, and represents 0.  
    
    Explained:
    No number between 1 and 2 -> is there a number between 2 and 4 -> need 2 bits to represent 3,
    so it goes into level 2
    Between 4 and 8 are there numbers -> with 2 bits we can represent 
                                        5 and 6 so they go to level 2.
    We still have 7 and we need 3 bits to represent 7 -> so it goes to level 3.


    Level 0 (use no bits)                                  0000
    Level 1 (use 1 bit)          (1) 0001, (2)0010,       (4)0100,                    (8)1000
    Leve  2 (use 2 bits)                           (3)0011         5(0101) 6(0110)
    Level 3 (use 3 bits)                                                        7(0111)

    LEVEL 0 NODES STORE VALUES FROM [0 to 2^(i-1) - 1]
    node 1 stores interval -> [0,0]
    node 2 stores interval -> [0, 1]
    node 4 stores interval -> [0, 3]
    node 8 stores interval -> [0, 7]
    
    kids store in between spaces. 

    Parent relationships of tree are following: 
    Parent of 3 is 2,  
    parent of 8 is 0, 
    parent of 7 is 6, 
    parent of 6 is 4, parent of 5 is 4
    parent of 3 is 2
    parent of 1 is 0. 
    parent of 4 is 0
    parent of 2 is 0
    To go from number to parent -> remove the rightmost 1 or the rightmost 1 bit. 

    so parent = i - (i & -i)
        i is 7 -> parent is 6
        7                -> 0111
        -7 2s complement -> 1001
                        and it -> 1
        7 - 1 = 6
        So that trick works -> parent = i - (i & -i)

    We need to cumulatively sum everything in the array and put in fenwick tree. 
    So for:
    1, -7, 15, 9, 4, 2, 0, 10
    
    Fenwick array: 0, 1, -6, 9, 18, 22, 24, 24, 34
    OK finally, 
    you have to subtract the parent from the child in above fenwick array. 
    From 34 you subtract 0. 
    From 24 you subtract 24
    from 24 you subtract 18
    from 22 subtract 18
    from 9 subtract -6
    from 1 subtract 0. 

    Use the trick of parent. 
    Final fenwick array: 
    0, 1, -6, 15, 18, 4, 6, 0, 34

    To get sum from idx 0 to 6: -> its 24. 
    fenwick tree indexed by +1, so to get indx 0-6, need to do 0 to 7 
    from 7 go up the tree -> 0 + 6 + 18 + 0 -> 24

    INITIALIZE FENWICK TREE IN O(N) time:

    int n = length of array
    int[] fw = new int[n+1];
    fw[1] = arr[0];
    for(int i = 1; i < n; i++) {
        fw[i+1] = fw[i] + arr[i];
    }

    // now remove value of parent node from given node. 
    for(int i = n; i >0 ; i--) {
        parent = i - (i& -i);
        if (parent >= 0) {
            fw[i] -= fw[parent];
        }
    }


    SUM OPERATION (LOGN operation):
    Fenwick incremented by 1, so always add 1 before you start. 
    int sum(int x) {
        x ++;
        int res = 0; 
        while(x > 0) {
            res += fw[x];
            x = x - (x & -x)
        } 
    }

    //Increment (LOG N)
    // i is index, v is val.
    // go top down tree 
    // find parent -> do opposite to findnext node. 
    void increment(int i, int val) {
        i ++; //fenwick tree do + 1
        while(i <= n ) {
            fw[i] += val;
            // find next node, not parent this time. 
            i = i + (i&-i)
        } 
    }

    LEETCODE 307 Range Sum Query: 

    sumRange(int i, int j) {
        // want sum inclusive.
        // its i-1 because we want INCLUSIVE SUM, 
        // THIS IS TRUE FOR 1D GRIDS AND 2D GRID SUMS.  
        sum(j) - sum(i-1)

    }
    
    void update(int i, int val) {
        //change ith location to val
        int diff = val - arr[i];
        arr[i] = val;
        increment(i, diff);
    }

    OK LETS GO OVER ANOTHER YOUTUBE VIDEO: 
    https://www.youtube.com/watch?v=CWDQJGaN1gY


    FENWICK TREE WHAT THE INDEXES MEAN, WHAT PARENTS MEAN, WHAT INTERVALS EACH IDX REFERS TO:
    GUIDEEEE:

    idx 0 stores value 0 [BECAUSE FENWICK TREE IS ONE INDEXED STRUCTURE]

    idx 1 stores interval ranging from [start:0, size: 2^0 ] aka [0,0] -> because 1 = 0 + 2^0
    idx 2 stores interval range from [start:0, size: 2^1] aka [0, 1] -> because 2 = 0 + 2^1
    idx 3 stores interval range from [start:2^1, size: 2^0  ] aka [2, 2] because 3 = 2^1 + 2^0 
                and we start the interval from the larger exponent
    idx 4 stores range [start: 2^0, size: 2^2] aka [0, 3] because 4 = 0 + 2^2 
    5 -> 2^2 + 2^0 -> so [start: 2^2, size: 2^0] aka [4, 4]
    6 -> 2^2 + 2^1 -> so[start: 2^2, size: 2^1] aka [4, 5]
    7 -> 2^2 + 2^1 + 2^0 -> so [start: 4 + 2, size -> 1] aka [6, 6]

    8 -> 0 + 2^3 so [start: 0, size -> 8], aka [0, 7]
    9 -> 2^3 + 2^0 so [start: 8, size 1] aka [8, 8]
    10 -> 2^3 + 2^1 so [start: 8, size 2] aka [8, 9 ]
    11 -> 2^3 + 2^1 + 2^0 so [start: 10, size: 1 ] -> [10, 10]

    OK GIVE ME SUM FROM 0 TO 5
    start from index 6 take value, go to parent -> 4 -> then go to parent sum all of em: 
    what are those intervals?
    6 -> [4, 5]
    4 -> [0, 3] 
    0 -> 0
    STOP
    WE COVERED THE INTERVAL [0, 5]

    SUM FROM O TO 9
    start from 10th index in fenwick: 
    10 -> parent is 8 -> parent is 0 
    [8, 9] + [0, 7] + [0]
    THE INTERVAL COVERS [0, 9]

    110 -> 1000

    THE GET Next function is also wierd remember that 
    -> GET NEXT IS:
    i = i + (i&-i) this does not find parent but a different entire subranch of fenwick tree outside of your 
                  current sub branch. 

    We need next because when we update certain nodes that enclose an interval such as 
    node 6 encloses ->  [4, 5] we should update 
    node 8 that encloses [0, 7] which is the start of a seperate subbranch and has parent of idx 0
    since node 6's interval is in node 8's interval if you know what i mean. 

    doing next jumps around in fenwick tree to other intervals that enclose you!!!!!!!!!!!!!!!!!!!!

    





#################################################################################################
Fenwick Trees (https://cp-algorithms.com/data_structures/fenwick.html)

    Let, f be some reversible function and A be an array of integers of length N.

    Fenwick tree is a data structure which:

    calculates the value of function f in the given range [l,r] (i.e. f(Al,Al+1,…,Ar)) in O(logn) time;
    updates the value of an element of A in O(logn) time;
    requires O(N) memory, or in other words, exactly the same memory required for A;
    is easy to use and code, especially, in the case of multidimensional arrays.
    Fenwick tree is also called Binary Indexed Tree, or just BIT abbreviated.

    The most common application of Fenwick tree is calculating the sum of a 
    range (i.e. f(A1,A2,…,Ak)=A1+A2+⋯+Ak).

    Fenwick tree was first described in a paper titled "A new data structure for 
    cumulative frequency tables" (Peter M. Fenwick, 1994).


    One-based indexing approach
    For this approach we change the requirements and definition for T[] and g() a 
    little bit. We want T[i] to store the sum of [g(i)+1;i]. This changes the 
    implementation a little bit, and allows for a similar nice definition for g(i):

    def sum(int r):
        res = 0
        while (r > 0):
            res += t[r]
            r = g(r)
        return res

    def increase(int i, int delta):
        for all j with g(j) < i <= j:
            t[j] += delta
            
    The computation of g(i) is defined as: toggling of the last set 1 bit 

    The last set bit can be extracted using i & (−i), so the operation can be expressed as:
    g(i)=i−(i & (−i).
    
    And it's not hard to see, that you need to change all values T[j] in 
    the sequence i, h(i), h(h(i)), … when you want to update A[j], where h(i) is defined as:
    h(i)=i+(i & (−i)).

    As you can see, the main benefit of this approach is that the binary operations 
    complement each other very nicely.

    The following implementation can be used like the other implementations, 
    however it uses one-based indexing internally.

    struct FenwickTreeOneBasedIndexing {
        vector<int> bit;  // binary indexed tree
        int n;

        FenwickTreeOneBasedIndexing(int n) {
            this->n = n + 1;
            bit.assign(n + 1, 0);
        }

        FenwickTreeOneBasedIndexing(vector<int> a)
            : FenwickTreeOneBasedIndexing(a.size()) {
            for (size_t i = 0; i < a.size(); i++)
                add(i, a[i]);
        }

        int sum(int idx) {
            int ret = 0;
            for (++idx; idx > 0; idx -= idx & -idx)
                ret += bit[idx];
            return ret;
        }

        int sum(int l, int r) {
            return sum(r) - sum(l - 1);
        }

        void add(int idx, int delta) {
            for (++idx; idx < n; idx += idx & -idx)
                bit[idx] += delta;
        }
    };

    Range operations
    A Fenwick tree can support the following range operations:

    Point Update and Range Query

    Range Update and Point Query
    
    Range Update and Range Query
    
    1. Point Update and Range Query
        This is just the ordinary Fenwick tree as explained above.


    2. Range Update and Point Query
        Using simple tricks we can also do the reverse operations: 
        increasing ranges and querying for single values.

        Let the Fenwick tree be initialized with zeros. Suppose that we want 
        to increment the interval [l,r] by x. We make two point update operations 
        on Fenwick tree which are add(l, x) and add(r+1, -x).

        If we want to get the value of A[i], we just need to take the prefix sum 
        using the ordinary range sum method. To see why this is true, 
        we can just focus on the previous increment operation again. 
        If i<l, then the two update operations have no effect on the 
        query and we get the sum 0. If i∈[l,r], then we get the answer 
        x because of the first update operation. And if i>r, then the 
        second update operation will cancel the effect of first one.

        The following implementation uses one-based indexing.

        void add(int idx, int val) {
            for (++idx; idx < n; idx += idx & -idx)
                bit[idx] += val;
        }

        void range_add(int l, int r, int val) {
            add(l, val);
            add(r + 1, -val);
        }

        int point_query(int idx) {
            int ret = 0;
            for (++idx; idx > 0; idx -= idx & -idx)
                ret += bit[idx];
            return ret;
        }
        
        Note: of course it is also possible to increase
        a single point A[i] with range_add(i, i, val).

    3. Range Updates and Range Queries
        To support both range updates and range queries we will use two BITs 
        namely B1[] and B2[], initialized with zeros.

        Suppose that we want to increment the interval [l,r] by the value x. 
        Similarly as in the previous method, we perform two point updates 
        on B1: add(B1, l, x) and add(B1, r+1, -x). And we also update B2. 
        The details will be explained later.

        def range_add(l, r, x):
            add(B1, l, x)
            add(B1, r+1, -x)
            add(B2, l, x*(l-1))
            add(B2, r+1, -x*r))

        After the range update (l,r,x) the range sum query should return the following values:
        
        
        
        sum[0,i]= 0 if i < l
                = x*(i-(l-1)) if l <= i <= r
                = x*(r-l+1) if i > r
        
        sum[0,i] = sum(B1, i)*i - sum(B2, i)
        = {
            0*i - 0 if i < l
            x*i - x*(l-1)   if l <= i <= r
            0*i - (x*(l-1) - x*r)   if i > r
        }




        We can write the range sum as difference of two terms, where we use B1 for first term 
        and B2 for second term. The difference of the queries will give us prefix sum over [0,i].
        
        
        
        sum[0,i]=sum(B1,i)⋅i−sum(B2,i)=⎧⎩⎨0⋅i−0x⋅i−x⋅(l−1)0⋅i−(x⋅(l−1)−x⋅r)i<ll≤i≤ri>r

        The last expression is exactly equal to the required terms. Thus we can 
        use B2 for shaving off extra terms when we multiply B1[i]×i.

        We can find arbitrary range sums by computing the prefix sums for l−1 and 
        r and taking the difference of them again.

        def add(b, idx, x):
            while idx <= N:
                b[idx] += x
                idx += idx & -idx

        def range_add(l,r,x):
            add(B1, l, x)
            add(B1, r+1, -x)
            add(B2, l, x*(l-1))
            add(B2, r+1, -x*r)

        def sum(b, idx):
            total = 0
            while idx > 0:
                total += b[idx]
                idx -= idx & -idx
            return total

        def prefix_sum(idx):
            return sum(B1, idx)*idx -  sum(B2, idx)

        def range_sum(l, r):
            return prefix_sum(r) - prefix_sum(l-1)


    Practice Problems
        UVA 12086 - Potentiometers
        LOJ 1112 - Curious Robin Hood
        LOJ 1266 - Points in Rectangle
        Codechef - SPREAD
        SPOJ - CTRICK
        SPOJ - MATSUM
        SPOJ - DQUERY
        SPOJ - NKTEAM
        SPOJ - YODANESS
        SRM 310 - FloatingMedian
        SPOJ - Ada and Behives
        Hackerearth - Counting in Byteland
        DevSkills - Shan and String
        Codeforces - Little Artem and Time Machine
        Codeforces - Hanoi Factory
        SPOJ - Tulip and Numbers
        SPOJ - SUMSUM
        SPOJ - Sabir and Gifts
        SPOJ - The Permutation Game Again
        SPOJ - Zig when you Zag
        SPOJ - Cryon
        SPOJ - Weird Points
        SPOJ - Its a Murder
        SPOJ - Bored of Suffixes and Prefixes
        SPOJ - Mega Inversions
        Codeforces - Subsequences
        Codeforces - Ball
        GYM - The Kamphaeng Phet's Chedis
        Codeforces - Garlands
        Codeforces - Inversions after Shuffle
        GYM - Cairo Market
        Codeforces - Goodbye Souvenir
        SPOJ - Ada and Species
        Codeforces - Thor
        Latin American Regionals 2017 - Fundraising



#################################################################################################
SUPER FAST COMPETITIVE PROGRAMMING SHORT IMPLEMENTATION OF SEGMENT TREES TO USE FOR OA'S and in Interview:
    (https://codeforces.com/blog/entry/18051)
    Segment tree with single element modifications

    Let's start with a brief explanation of segment trees. They are used when we have an array, 
    perform some changes and queries on continuous segments. 
    In the first example we'll consider 2 operations:

    modify one element in the array;
    find the sum of elements on some segment. .
    Perfect binary tree
    I like to visualize a segment tree in the following way:  (post has image)
    Node 1 (root): [0,16)
    Node 2 [0, 8)
    Node 3 [8, 16)

    Node 4 [0, 4)
    Node 5 [4 8)

    Node 6 [8, 12)
    Node 7 [12, 16)
    ...
    Node 16: 0
    Node 17: 1
    Node 18: 2
    Node 19:  3
    ...



    Notation is node_index: corresponding segment (left border included, right excluded). 
    At the bottom row we have our array (0-indexed), the leaves of the tree. For now suppose 
    it's length is a power of 2 (16 in the example), so we get perfect binary tree. When going 
    up the tree we take pairs of nodes with indices (2 * i, 2 * i + 1) and combine their values 
    in their parent with index i. This way when we're asked to find a sum on interval [3, 11), 
    we need to sum up only values in the nodes 19, 5, 12 and 26 (marked with bold), not all 
    8 values inside the interval. 
    Let's jump directly to implementation (in C++) to see how it works:



    const int N = 1e5;  // limit for array size
    int n;  // array size
    int t[2 * N];

    void build() {  // build the tree
        for (int i = n - 1; i > 0; --i) t[i] = t[i<<1] + t[i<<1|1];
    }

    void modify(int p, int value) {  // set value at position p
        for (t[p += n] = value; p > 1; p >>= 1) t[p>>1] = t[p] + t[p^1];
    }

    int query(int l, int r) {  // sum on interval [l, r)
        int res = 0;
        for (l += n, r += n; l < r; l >>= 1, r >>= 1) {
            if (l&1) res += t[l++];
            if (r&1) res += t[--r];
        }
        return res;
    }

    int main() {
        scanf("%d", &n);
        for (int i = 0; i < n; ++i) scanf("%d", t + n + i);
        build();
        modify(0, 1);
        printf("%d\n", query(3, 11));
        return 0;
    }

    That's it! Fully operational example. Forget about those cumbersome 
    recursive functions with 5 arguments!

    Now let's see why this works, and works very efficient.

        1) As you could notice from the picture, leaves are stored in 
        continuous nodes with indices starting with n, element with 
        index i corresponds to a node with index i + n. So we can read 
        initial values directly into the tree where they belong.

        2) Before doing any queries we need to build the tree, which is 
        quite straightforward and takes O(n) time. Since parent always 
        has index less than its children, we just process all the internal 
        nodes in decreasing order. In case you're confused by bit operations, 
        the code in build() is equivalent to t[i] = t[2*i] + t[2*i+1].

        3) Modifying an element is also quite straightforward and takes 
        time proportional to the height of the tree, which is O(log(n)). 
        We only need to update values in the parents of given node. So we 
        just go up the tree knowing that parent of node p is p / 2 or p>>1, 
        which means the same. p^1 turns 2 * i into 2 * i + 1 and vice versa, 
        so it represents the second child of p's parent.

        4) Finding the sum also works in O(log(n)) time. To better understand it's 
        logic you can go through example with interval [3, 11) and verify that 
        result is composed exactly of values in nodes 19, 26, 12 and 5 (in that order).

    General idea is the following. If l, the left interval border, is 
    odd (which is equivalent to l&1) then l is the right child of its parent. 
    Then our interval includes node l but doesn't include it's parent. 
    So we add t[l] and move to the right of l's parent by setting l = (l + 1) / 2. 
    
    If l is even, it is the left child, and the interval includes 
    its parent as well (unless the right border interferes), so we 
    just move to it by setting l = l / 2. Similar argumentation is 
    applied to the right border. We stop once borders meet.

    No recursion and no additional computations like finding the middle 
    of the interval are involved, we just go through all the nodes we need, 
    so this is very efficient.


    Arbitrary sized array

    For now we talked only about an array with size equal to some power of 2, 
    so the binary tree was perfect. The next fact may be stunning, so prepare yourself.

    The code above works for any size n.

    Explanation is much more complex than before, so let's focus 
    first on the advantages it gives us.

    Segment tree uses exactly 2 * n memory, not 4 * n like some other implementations offer.
    Array elements are stored in continuous manner starting with index n.
    All operations are very efficient and easy to write.

    For those interested in some kind of explanation, here's how the tree for n = 13 looks:

    It's not actually a single tree any more, but a set of perfect 
    binary trees: with root 2 and height 4, root 7 and height 2, 
    root 12 and height 2, root 13 and height 1. 

    I won't bother with formal proof here, let's just go through 
    the example with interval [0, 7). We have l = 13, r = 20, 
    l&1 => add t[13] and borders change to l = 7, r = 10. 
    Again l&1 => add t[7], borders change to l = 4, r = 5, 
    and suddenly nodes are at the same height. Now we have r&1 => add t[4 = --r], 
    borders change to l = 2, r = 2, so we're finished.


    PLEASE FINISH NOTES HERE START WRITING NOTES FROM MODIFICTION ON INTERVAL SINGLE ELEMENT access.





###################################################################################################
Segment trees are soooo cool. 
SIMPLE IMPLEMENTATION 

    Basically, if you have some list, and you want to calculate.

    reduce(operation, arr[i:j], default_value)

    And you want to do this repeatedly. You can have O(n) for this operation 
    every time and O(1) for updating the array, or you can have O(log(n)) to 
    calculate this value and O(log(n)) to update using a Segment Tree.

    class SegmentTree:
        
        def __init__(self, arr, operator, default):
            self.n = len(arr)
            self.default = default
            self.arr = [0 for _ in range(2 * len(arr) - 1)]
            self.operator = operator
            
            for i in range(len(arr) - 1, len(self.arr)):
                self.arr[i] = arr[i - len(arr) + 1]

            for i in range(len(arr) - 2, -1, -1):
                self.arr[i] = self.operator(self.arr[i * 2 + 1], self.arr[i * 2 + 2])

        def update(self, idx, value):
            idx = self.n - 1 + idx
            self.arr[idx] = value
            while idx > 0:
                idx = (idx - 1)/2
                self.arr[idx] = self.operator(self.arr[idx * 2 + 1], self.arr[idx * 2 + 2])

        def get_segment_value(self, left, right):
            left = self.n - 1 + left
            right = self.n - 1 + right
            ans = self.default
            while left < right:
                if left % 2 == 0:
                    ans = self.operator(ans, self.arr[left])
                    left += 1
                if right % 2 == 0:
                    right -= 1
                    ans = self.operator(ans, self.arr[right])
                left, right = (left - 1)/2, (right - 1)/2
            return ans
############################################################################

An efficient way to strengthen up your segment tree:
(https://codeforces.com/blog/entry/13703)

    By kien_coi_1997, 6 years ago, In English
    I'm going to talking about a coding style in segment tree which I used for 
    a long time. Not only is it more systematically, 
    but it also support more kind of segment tree.

    1. Old style
        Assume that we are making a segment tree support operators assign elements 
        in a range (assign-range L R X) and get max element in a range (max-range L R).

        I found a large number of people use the following way to build segment tree:

        void lazy_update(int u, int ll, int rr) {
            if (Lazy[u]==-1) return; // assume that -1 is unused value
            if (ll!=rr) Lazy[u*2]=Lazy[u*2+1]=Lazy[u];
            Max[u]=Lazy[u]; Lazy[u]=-1;
        }

        void assign_range(int u, int ll, int rr, int L, int R, int X) {
            lazy_update(u, ll, rr); // call a function to lazy-update node u (which operate segment ll..rr)
            if (ll>R || L>rr) return;
            if (L<=ll && rr<=R) { 
                Lazy[u]=X; 
                lazy_update(u, ll, rr); 
                return; 
            }
            assign_range(2*u, ll, (ll+rr)/2, L, R, X);
            assign_range(2*u+1, (ll+rr)/2+1, rr, L, R, X);
            Max[u] = max(Max[2*u], Max[2*u+1]);
        }

        int max_range(int u, int ll, int rr, int L, int R) {
            lazy_update(u, ll, rr);
            if (ll>R || L>rr) return -oo;
            if (L<=ll && rr<=R) return Max[u];
            int Max1 = max_range(2*u, ll, (ll+rr)/2, L, R);
            int Max2 = max_range(2*u+1, (ll+rr)/2+1, rr, L, R);
            return max(Max1, Max2);
        }

        int main(){
            ...
            cin >> L >> R >> X;
            assign_range(1, 1, n, L, R, X);
            ...
            cin >> L >> R;
            cout << max_range(1, 1, n, L, R) << endl;
        ...
        }

        There are some duplicated code which need to be reduce:

        int u, int ll, int rr : appear in both three function declarations
        lazy_update(u, ll, rr); : appear in beginning of both two functions
        (2*u, ll, (ll+rr)/2 and 2*u+1, (ll+rr)/2+1, rr : they appear four times.
        They will be reduced efficienly in new style.

    2. New style
        Forcing people to use a personal style is a bad idea. I share with you 
        this style to give you a suggestion in coding segment tree.

        struct node {
            int ll, rr, id;

            node(int L, int R, int X) { 
                ll=L, rr=R, id=X; 
                lazy_update(); 
            }

            node left() 
                { return node(ll, (ll+rr)/2, id*2); }
            node right() 
                { return node((ll+rr)/2+1, rr, id*2+1); }

            void lazy_update() { 
                if (Lazy[id]==-1) return; // assume that -1 is unused value
                if (ll!=rr) Lazy[id*2]=Lazy[id*2+1]=Lazy[id];
                Max[id]=Lazy[id]; Lazy[id]=-1;
            }
            
            void assign_range(int L, int R, int X){ // don't need to call lazy_update() at the beginning
                if (ll>R || L>rr) return ;
                if (L<=ll && rr<=R) 
                { Lazy[id]=X; lazy_update(); return ; }
                left().assign_range(L, R, X); // easier to read
                right().assign_range(L, R, X);
                Max[id]=max(Max[id*2], Max[id*2+1]);
            }
            
            int max_range(int L, int R) {
                if (ll>R || L>rr) return -oo;
                if (L<=ll && rr<=R) return Max[id];
                int Max1 = left().max_range(L, R);
                int Max2 = right().max_range(L, R);
                return max(Max1, Max2);
            }
        };

        int main(){
        ...
        cin >> L >> R >> X;
        node(1, n, 1).assign_range(L, R, X); // easier to read
        ...
        node Root(1, n, 1); // use this if we have to write to much node(1, n, 1)
        cin >> L >> R;
        cout << Root.max_range(L, R) << endl;
        ...
        }
        Let's list advantages of new style:

        Reduce duplicated code
        Average lines' length and functions' length is reduced.
        Easier to read
        The more complex problem, the more efficient this new style.

    3. Additionally feature in new style
        Assume that we are facing this problem:

        There is a string S which contains lowercase letters. 
        Execute following operators on this string:

        check i j k: Check if S[i..i+k-1] is equal to S[j..j+k-1].
        delete k: Delete k-th element.
        To solve above problem, we need to build a segment tree 
        which support two operators : hash-range L R return 
        hash value of S[L..R], and remove X remove X-th element. 
        I called the following structure indexable segment tree. 
        In each node, we maintain hash value and size of this node.

        #define long long long

        struct node {
            int ll, rr, id;
            node(int L, int X) 
                { ll=L, rr=L+Size[X]-1, id=X; }
            node left() 
                { return node(ll, id*2); }
            node right() 
                { return node(ll+Size[id*2], id*2+1); }

            void update() {
                Hash[id]=sum_hash(Hash[id*2], Hash[id*2+1], Size[id*2+1]);
                Size[id]=Size[id*2] + Size[id*2+1];
            }
            
            long hash_range(int L, int R) {
                if (ll>R || L>rr) return 0LL;
                if (L<=ll && rr<=R) return Hash[id];
                long Hash1 = left().hash_range(L, R);
                long Hash2 = right().hash_range(L, R);
                return sum_hash(Hash1, Hash2, Size[id*2+1]); // easy to implement sum_hash()
            }
            
            void remove(int X){
                if (ll>X || X>rr) return ;
                if (ll==rr) { Size[id]=0; Hash[id]=0; return; }
                right().remove(X); // if call left().remove(X) first and succeeded, ...
                left().remove(X); // ... we are not allowed to call right().remove(X)
                update();
            }

            void build(char a[], int L, int R) { // Note: ll, rr are not valid now but id
                if (L==R) 
                { Size[id]=1; Hash[id]=a[L]; return ; }
                left().build(a, L, (L+R)/2);
                right().build(a, (L+R)/2+1, R);
                update();
        }
        };

        char a[N]; // zero-based;

        main(){
        cin >> a; n=strlen(a);
        node(0, 1).build(a, 0, n-1); // initialize segment tree
        ...
        cin >> i >> j >> k;
        long Hash1 = node(0, 1).hash_range(i, i+k-1);
        long Hash2 = node(0, 1).hash_range(j, j+k-1);
        cout << (Hash1 == Hash2 ? "Yes" : "No") << endl;
        ...
        cin >> k;
        node(0, 1).remove(k);
        ...
        }
        In the above code, managed segment of each nodes in segment 
        tree is consecutively changed. And struct node 
        become very flexible and efficient.

        In this example, we are not allowed to use node Root(0, 1) because 
        Root content is always change (rr field). If you want to use Root 
        variable, you should update Root after every remove query: 
        node(0, 1).remove(k); Root=node(0,1); (and I don't like this).

    4. Conclusion
        It is hard to write both long and detailed blog. Therefore, you 
        can comment anything which you didn't understand well. 
        I will reply (or update this blog if it is necessary).



###########################################################################

Segment Trees (https://cp-algorithms.com/data_structures/segment_tree.html)
USE CASES AND INTUITION
    A Segment Tree is a data structure that allows answering range 
    queries over an array effectively, while still being flexible 
    enough to allow modifying the array. This includes finding the 
    sum of consecutive array elements a[l…r], or finding the minimum 
    element in a such a range in O(logn) time. Between answering such 
    queries the Segment Tree allows modifying the array by replacing 
    one element, or even change the elements of a whole subsegment (e.g. 
    assigning all elements a[l…r] to any value, or adding a value to all 
    element in the subsegment).

    In general a Segment Tree is a very flexible data structure, and a huge 
    number of problems can be solved with it. Additionally it is also 
    possible to apply more complex operations and answer more complex 
    queries (see Advanced versions of Segment Trees). In particular the 
    Segment Tree can be easily generalized to larger dimensions. For 
    instance with a two-dimensional Segment Tree you can answer sum or 
    minimum queries over some subrectangle of a given matrix. However 
    only in O(log2n) time.

    One important property of Segment Trees is, that they require only a 
    linear amount of memory. The standard Segment Tree requires 4n 
    vertices for working on an array of size n.


    Simplest form of a Segment Tree
    To start easy, we consider the simplest form of a Segment Tree. 
    We want to answer sum queries efficiently. The formal definition 
    of our task is: We have an array a[0…n−1], and the Segment Tree 
    must be able to find the sum of elements between the indices 
    l and r (i.e. computing the sum ∑ri=la[i]), and also handle 
    changing values of the elements in the array (i.e. perform assignments 
    of the form a[i]=x). The Segment Tree should be able to process 
    both queries in O(logn) time.

Structure of the Segment Tree
    So, what is a Segment Tree?

    We compute and store the sum of the elements of the whole array, i.e. 
    the sum of the segment a[0…n−1]. We then split the array into two 
    halves a[0…n/2] and a[n/2+1…n−1] and compute the sum of each 
    halve and store them. Each of these two halves in turn also 
    split in half, their sums are computed and stored. And this 
    process repeats until all segments reach size 1. In other words 
    we start with the segment a[0…n−1], split the current segment 
    in half (if it has not yet become a segment containing a single element), 
    and then calling the same procedure for both halves. For each such segment 
    we store the sum of the numbers on it.

    We can say, that these segments form a binary tree: the root of this 
    tree is the segment a[0…n−1], and each vertex (except leaf vertices) 
    has exactly two child vertices. This is why the data structure is 
    called "Segment Tree", even though in most implementations the tree 
    is not constructed explicitly (see Implementation).


    From this short description of the data structure, we can already 
    conclude that a Segment Tree only requires a linear number of vertices. 
    The first level of the tree contains a single node (the root), the second 
    level will contain two vertices, in the third it will contain four 
    vertices, until the number of vertices reaches n. Thus the number of 
    vertices in the worst case can be estimated by the sum 
    1+2+4+⋯+2^⌈logn⌉=2^(⌈logn⌉+1)<4n.

    It is worth noting that whenever n is not a power of two, not all levels of 
    the Segment Tree will be completely filled. We can see that behavior in the 
    image. For now we can forget about this fact, but it will become important 
    later during the implementation.

    The height of the Segment Tree is O(logn), because when going down from the 
    root to the leaves the size of the segments decreases approximately by half.


Construction
    Before constructing the segment tree, we need to decide:

    the value that gets stored at each node of the segment tree. 
    For example, in a sum segment tree, a node would store the sum 
    of the elements in its range [l,r].

    the merge operation that merges two siblings in a segment tree. 
    For example, in a sum segment tree, the two nodes corresponding to 
    the ranges a[l1…r1] and a[l2…r2] would be merged into a node 
    corresponding to the range a[l1…r2] by adding the values of the two nodes.
    Note that a vertex is a "leaf vertex", if its corresponding segment 
    covers only one value in the original array. It is present at 
    the lowermost level of a segment tree. Its value would be equal 
    to the (corresponding) element a[i].

    Now, for construction of the segment tree, we start at the bottom 
    level (the leaf vertices) and assign them their respective values. 
    On the basis of these values, we can compute the values of the previous 
    level, using the merge function. And on the basis of those, we can 
    compute the values of the previous, and repeat the procedure until 
    we reach the root vertex.

    It is convenient to describe this operation recursively in the other 
    direction, i.e., from the root vertex to the leaf vertices. The 
    construction procedure, if called on a non-leaf vertex, does the following:

        recursively construct the values of the two child vertices
        merge the computed values of these children.

    We start the construction at the root vertex, and hence, we are 
    able to compute the entire segment tree.

    The time complexity of this construction is O(n), assuming 
    that the merge operation is constant time (the merge operation gets 
    called n times, which is equal to the number of internal nodes in the segment tree).


Sum queries
    For now we are going to answer sum queries. As an input we receive two 
    integers l and r, and we have to compute the sum of the segment a[l…r] in O(logn) time.

    To do this, we will traverse the Segment Tree and use the precomputed sums 
    of the segments. Let's assume that we are currently at the vertex 
    that covers the segment a[tl…tr]. There are three possible cases.

    The easiest case is when the segment a[l…r] is equal to the 
    corresponding segment of the current vertex (i.e. a[l…r]=a[tl…tr]), 
    then we are finished and can return the precomputed sum that is stored in the vertex.

    Alternatively the segment of the query can fall completely into the 
    domain of either the left or the right child. Recall that the 
    left child covers the segment a[tl…tm] and the right vertex covers 
    the segment a[tm+1…tr] with tm=(tl+tr)/2. In this case we can 
    simply go to the child vertex, which corresponding segment 
    covers the query segment, and execute the algorithm described
    here with that vertex.

    And then there is the last case, the query segment intersects 
    with both children. In this case we have no other option 
    as to make two recursive calls, one for each child. First we go 
    to the left child, compute a partial answer for this vertex 
    (i.e. the sum of values of the intersection between the 
    segment of the query and the segment of the left child), 
    then go to the right child, compute the partial answer using 
    that vertex, and then combine the answers by adding them. 
    In other words, since the left child represents the segment a[tl…tm] 
    and the right child the segment a[tm+1…tr], we compute the sum 
    query a[l…tm] using the left child, and the sum query a[tm+1…r] 
    using the right child.

    So processing a sum query is a function that recursively calls 
    itself once with either the left or the right child (without changing 
    the query boundaries), or twice, once for the left and once 
    for the right child (by splitting the query into two subqueries). 
    And the recursion ends, whenever the boundaries of the current 
    query segment coincides with the boundaries of the segment 
    of the current vertex. In that case the answer will be the 
    precomputed value of the sum of this segment, which is stored in the tree.

    In other words, the calculation of the query is a traversal of the tree, 
    which spreads through all necessary branches of the tree, 
    and uses the precomputed sum values of the segments in the tree.

    Obviously we will start the traversal from the root vertex of the Segment Tree.

Sum Query LOG N performance explanation:
    Why is the complexity of this algorithm O(logn)? To show this complexity 
    we look at each level of the tree. It turns out, that for each level 
    we only visit not more than four vertices. And since the height 
    of the tree is O(logn), we receive the desired running time.

    We can show that this proposition (at most four vertices each level) 
    is true by induction. At the first level, we only visit one vertex, the 
    root vertex, so here we visit less than four vertices. Now let's 
    look at an arbitrary level. By induction hypothesis, we 
    visit at most four vertices. If we only visit at most two vertices, 
    the next level has at most four vertices. That trivial, 
    because each vertex can only cause at most two recursive calls. 
    So let's assume that we visit three or four vertices in the current level. 
    From those vertices, we will analyze the vertices in the middle 
    more carefully. Since the sum query asks for the sum of a continuous 
    subarray, we know that segments corresponding to the visited vertices 
    in the middle will be completely covered by the segment of the sum query. 
    Therefore these vertices will not make any recursive calls. So only 
    the most left, and the most right vertex will have the potential to 
    make recursive calls. And those will only create at most four 
    recursive calls, so also the next level will satisfy the assertion. 
    We can say that one branch approaches the left boundary of the query, 
    and the second branch approaches the right one.

    Therefore we visit at most 4logn vertices in total, and that is 
    equal to a running time of O(logn).

    In conclusion the query works by dividing the input segment 
    into several sub-segments for which all the sums are already 
    precomputed and stored in the tree. And if we stop partitioning 
    whenever the query segment coincides with the vertex segment, 
    then we only need O(logn) such segments, which gives the effectiveness 
    of the Segment Tree.

Update Queries:
    Now we want to modify a specific element in the array, let's say we 
    want to do the assignment a[i]=x. And we have to rebuild the Segment Tree, 
    such that it correspond to the new, modified array.

    This query is easier than the sum query. Each level of a Segment Tree 
    forms a partition of the array. Therefore an element a[i] only 
    contributes to one segment from each level. Thus only O(logn) vertices need to be updated.

    It is easy to see, that the update request can be implemented 
    using a recursive function. The function gets passed the current 
    tree vertex, and it recursively calls itself with one of the two 
    child vertices (the one that contains a[i] in its segment), and after 
    that recomputes its sum value, similar how it is done in the build 
    method (that is as the sum of its two children).

    Again here is a visualization using the same array. Here we perform the 
    update a[2]=3. The green vertices are the vertices that we visit and update.

Implementation:

    We only store the sums in an array. The sum of the root vertex at index 1, 
    the sums of its two child vertices at indices 2 and 3, the sums of the 
    children of those two vertices at indices 4 to 7, and so on. 
    It is easy to see, that the left child of a vertex at index i 
    is stored at index 2i, and the right one at index 2i+1.

    This simplifies the implementation a lot. We don't need to 
    store the structure of the tree in memory. It is defined implicitly. 
    We only need one array which contains the sums of all segments.

    As noted before, we need to store at most 4n vertices. It might 
    be less, but for convenience we always allocate an array of size 4n.
    There will be some elements in the sum array, that will 
    not correspond to any vertices in the actual tree, but this 
    doesn't complicate the implementation.

    So, we store the Segment Tree simply as an array t[] with a size 
    of four times the input size n:

    int n, t[4*MAXN];
    The procedure for constructing the Segment Tree from a given 
    array a[] looks like this: it is a recursive function with the 
    parameters a[] (the input array), v (the index of the current vertex), 
    and the boundaries tl and tr of the current segment. In the main 
    program this function will be called with the parameters of the 
    root vertex: v=1, tl=0, and tr=n−1.


    void build(int a[], int v, int tl, int tr) {
        if (tl == tr) {
            t[v] = a[tl];
        } else {
            int tm = (tl + tr) / 2;
            build(a, v*2,   tl,   tm);
            build(a, v*2+1, tm+1, tr);
            t[v] = t[v*2] + t[v*2+1];
        }
    }

    Further the function for answering sum queries is also a recursive function, 
    which receives as parameters information about the current vertex/segment 
    (i.e. the index v and the boundaries tl and tr) and also the information 
    about the boundaries of the query, l and r. In order to simplify the code, 
    this function always does two recursive calls, even if only one is necessary 
    - in that case the superfluous recursive call will have l>r, and this 
    can easily be caught using an additional check at the 
    beginning of the function.

    int sum(int v, int tl, int tr, int l, int r) {
        if (l > r) 
            return 0;
        if (l == tl && r == tr) {
            return t[v];
        }
        int tm = (tl + tr) / 2;
        return sum(v*2,   tl,   tm, l,            min(r, tm))
            +  sum(v*2+1, tm+1, tr, max(l, tm+1), r);
    }

    Finally the update query. The function will also receive information 
    about the current vertex/segment, and additionally also the parameter 
    of the update query (i.e. the position of the element and its new value).

    void update(int v, int tl, int tr, int pos, int new_val) {
        if (tl == tr) {
            t[v] = new_val;
        } else {
            int tm = (tl + tr) / 2;
            if (pos <= tm)
                update(v*2, tl, tm, pos, new_val);
            else
                update(v*2+1, tm+1, tr, pos, new_val);
            t[v] = t[v*2] + t[v*2+1];
        }
    }

Memory efficient implementation
    Most people use the implementation from the previous section. If you 
    look at the array t you can see that it follows the numbering of the 
    tree nodes in the order of a BFS traversal (level-order traversal). 
    Using this traversal the children of vertex v are 2v and 2v+1 respectively. 
    However if n is not a power of two, this method will skip some indices and 
    leave some parts of the array t unused. The memory consumption is limited 
    by 4n, even though a Segment Tree of an array of n elements 
    requires only 2n−1 vertices.

    However it can be reduced. We renumber the vertices of the tree in the order 
    of an Euler tour traversal (pre-order traversal), and we write all 
    these vertices next to each other.

    Lets look at a vertex at index v, and let him be responsible for the 
    segment [l,r], and let mid=(l+r)/2. It is obvious that the left child 
    will have the index v+1. The left child is responsible for the segment 
    [l,mid], i.e. in total there will be 2∗(mid−l+1)−1 vertices in the left 
    child's subtree. Thus we can compute the index of the right child of v.
    The index will be v+2∗(mid−l+1). By this numbering we achieve a 
    reduction of the necessary memory to 2n.


################################################################
Segment Tree INTERVIEW QUESTIONS -> A lot of Cool Use Cases:
(https://cp-algorithms.com/data_structures/segment_tree.html)

More complex queries
    It can be quite easy to change the Segment Tree in a direction, 
    such that it computes different queries (e.g. computing the 
    minimum / maximum instead of the sum), but 
    it also can be very nontrivial.

    Finding the maximum
        Let us slightly change the condition of the problem 
        described above: instead of querying the sum, 
        we will now make maximum queries.

        The tree will have exactly the same structure as the tree described above. 
        We only need to change the way t[v] is computed in the build and update 
        functions. t[v] will now store the maximum of the corresponding segment. 
        And we also need to change the calculation of the 
        returned value of the sum function (replacing 
        the summation by the maximum).

        Of course this problem can be easily changed into computing
        the minimum instead of the maximum.

        Instead of showing an implementation to this problem, the 
        implementation will be given to a more complex version of 
        this problem in the next section.

    Finding the maximum and the number of times it appears

        This task is very similar to the previous one. In addition of 
        finding the maximum, we also have to find the number 
        of occurrences of the maximum.

        To solve this problem, we store a pair of numbers at each 
        vertex in the tree: In addition to the maximum we also 
        store the number of occurrences of it in the corresponding segment. 
        Determining the correct pair to store at t[v] can still be 
        done in constant time using the information of the pairs stored 
        at the child vertices. Combining two such pairs should be done 
        in a separate function, since this will be an operation that we 
        will do while building the tree, while answering maximum queries 
        and while performing modifications.


        pair<int, int> t[4*MAXN];

        pair<int, int> combine(pair<int, int> a, pair<int, int> b) {
            if (a.first > b.first) 
                return a;
            if (b.first > a.first)
                return b;
            return make_pair(a.first, a.second + b.second);
        }

        void build(int a[], int v, int tl, int tr) {
            if (tl == tr) {
                t[v] = make_pair(a[tl], 1);
            } else {
                int tm = (tl + tr) / 2;
                build(a, v*2, tl, tm);
                build(a, v*2+1, tm+1, tr);
                t[v] = combine(t[v*2], t[v*2+1]);
            }
        }

        pair<int, int> get_max(int v, int tl, int tr, int l, int r) {
            if (l > r)
                return make_pair(-INF, 0);
            if (l == tl && r == tr)
                return t[v];
            int tm = (tl + tr) / 2;
            return combine(get_max(v*2, tl, tm, l, min(r, tm)), 
                           get_max(v*2+1, tm+1, tr, max(l, tm+1), r));
        }

        void update(int v, int tl, int tr, int pos, int new_val) {
            if (tl == tr) {
                t[v] = make_pair(new_val, 1);
            } else {
                int tm = (tl + tr) / 2;
                if (pos <= tm)
                    update(v*2, tl, tm, pos, new_val);
                else
                    update(v*2+1, tm+1, tr, pos, new_val);
                t[v] = combine(t[v*2], t[v*2+1]);
            }
        }


    Compute the greatest common divisor / least common multiple
        In this problem we want to compute the GCD / LCM of all numbers 
        of given ranges of the array.

        This interesting variation of the Segment Tree can be solved 
        in exactly the same way as the Segment Trees we derived for 
        sum / minimum / maximum queries: it is enough to store the 
        GCD / LCM of the corresponding vertex in each vertex of the 
        tree. Combining two vertices can be done by computing the 
        GCD / LCM of both vertices.

    Counting the number of zeros, searching for the k-th zero
        In this problem we want to find the number of zeros in a given 
        range, and additionally find the index of the k-th zero 
        using a second function.

        Again we have to change the store values of the tree a bit: 
        This time we will store the number of zeros in each segment 
        in t[]. It is pretty clear, how to implement the build, update and 
        count_zero functions, we can simply use the ideas from the 
        sum query problem. Thus we solved the first part of the problem.

        Now we learn how to solve the problem of finding the k-th zero 
        in the array a[]. To do this task, we will descend the Segment Tree, 
        starting at the root vertex, and moving each time to either 
        the left or the right child, depending on which segment 
        contains the k-th zero. In order to decide to which child we 
        need to go, it is enough to look at the number of zeros 
        appearing in the segment corresponding to the left vertex. 
        If this precomputed count is greater or equal to k, it is 
        necessary to descend to the left child, and otherwise descent 
        to the right child. Notice, if we chose the right child, 
        we have to subtract the number of zeros of the left child from k.

        In the implementation we can handle the special case, 
        a[] containing less than k zeros, by returning -1.


        int find_kth(int v, int tl, int tr, int k) {
            if (k > t[v])
                return -1;
            if (tl == tr)
                return tl;
            int tm = (tl + tr) / 2;
            if (t[v*2] >= k)
                return find_kth(v*2, tl, tm, k);
            else 
                return find_kth(v*2+1, tm+1, tr, k - t[v*2]);
        }


    Searching for an array prefix with a given amount
        The task is as follows: for a given value x we have to quickly 
        find smallest index i such that the sum of the first i elements 
        of the array a[] is greater or equal to x (assuming that the array 
        a[] only contains non-negative values).
        
        This task can be solved using binary search, computing the sum of 
        the prefixes with the Segment Tree. However 
        this will lead to a O(log^2(n) ) solution.


        Instead we can use the same idea as in the previous section, 
        and find the position by descending the tree: by moving each 
        time to the left or the right, depending on the sum of the 
        left child. Thus finding the answer in O(logn) time.


    Searching for the first element greater than a given amount

        The task is as follows: for a given value x and a range a[l…r] 
        find the smallest i in the range a[l…r], 
        such that a[i] is greater than x.

        This task can be solved using binary search over max prefix 
        queries with the Segment Tree. However, this will lead to a O(log^2(n) ) solution.

        Instead, we can use the same idea as in the previous sections, 
        and find the position by descending the tree: by moving each
        time to the left or the right, depending on the maximum value of the 
        left child. Thus finding the answer in O(logn) time.

        int get_first(int v, int lv, int rv, int l, int r, int x) {
            if(lv > r || rv < l) return -1;
            // segment tree interval too small.
            if(l <= lv && rv <= r) {
                if(t[v] <= x) return -1;
                while(lv != rv) {
                    int mid = lv + (rv-lv)/2;
                    if(t[2*v] > x) {
                        v = 2*v;
                        rv = mid;
                    }else {
                        v = 2*v+1;
                        lv = mid+1;
                    }
                }
                return lv;
            }
            // segment tree interval too large -> break it up and recurse on each side. 
            int mid = lv + (rv-lv)/2;
            int rs = get_first(2*v, lv, mid, l, r, x);
            if(rs != -1) return rs;
            return get_first(2*v+1, mid+1, rv, l ,r, x);
        }


    Finding subsegments with the maximal sum
        
        Here again we receive a range a[l…r] for each query, this 
        time we have to find a subsegment a[l′…r′] such that 
        l≤l′ and r′≤r and the sum of the elements of this segment is 
        maximal. As before we also want to be able to modify individual 
        elements of the array. The elements of the array can be negative, 
        and the optimal subsegment can be empty (e.g. if all elements are negative).

        This problem is a non-trivial usage of a Segment Tree. This time 
        we will store four values for each vertex: the sum of the segment, 
        the maximum prefix sum, the maximum suffix sum, and the sum of 
        the maximal subsegment in it. In other words for each segment of 
        the Segment Tree the answer is already precomputed as well as 
        the answers for segments touching the left and the 
        right boundaries of the segment.


        How to build a tree with such data? Again we compute it in a 
        recursive fashion: we first compute all four values 
        for the left and the right child, and then combine 
        those to archive the four values for the current vertex. 
        Note the answer for the current vertex is either:

        the answer of the left child, which means that the optimal 
        subsegment is entirely placed in the segment of the left child

        the answer of the right child, which means that the optimal 
        subsegment is entirely placed in the segment of the right child

        the sum of the maximum suffix sum of the left child and the 
        maximum prefix sum of the right child, which means that the 
        optimal subsegment intersects with both children.

        Hence the answer to the current vertex is the maximum of 
        these three values. Computing the maximum prefix / suffix sum 
        is even easier. Here is the implementation of the combine function, 
        which receives only data from the left and right child, 
        and returns the data of the current vertex.

        struct data {
            int sum, pref, suff, ans;
        };

        data combine(data l, data r) {
            data res;
            res.sum = l.sum + r.sum;
            res.pref = max(l.pref, l.sum + r.pref);
            res.suff = max(r.suff, r.sum + l.suff);
            res.ans = max(max(l.ans, r.ans), l.suff + r.pref);
            return res;
        }

        Using the combine function it is easy to build the Segment Tree.
        We can implement it in exactly the same way as in the previous 
        implementations. To initialize the leaf vertices, we 
        additionally create the auxiliary function make_data, 
        which will return a data object holding the information of a single value.

        data make_data(int val) {
            data res;
            res.sum = val;
            res.pref = res.suff = res.ans = max(0, val);
            return res;
        }

        void build(int a[], int v, int tl, int tr) {
            if (tl == tr) {
                t[v] = make_data(a[tl]);
            } else {
                int tm = (tl + tr) / 2;
                build(a, v*2, tl, tm);
                build(a, v*2+1, tm+1, tr);
                t[v] = combine(t[v*2], t[v*2+1]);
            }
        }

        void update(int v, int tl, int tr, int pos, int new_val) {
            if (tl == tr) {
                t[v] = make_data(new_val);
            } else {
                int tm = (tl + tr) / 2;
                if (pos <= tm)
                    update(v*2, tl, tm, pos, new_val);
                else
                    update(v*2+1, tm+1, tr, pos, new_val);
                t[v] = combine(t[v*2], t[v*2+1]);
            }
        }

        It only remains, how to compute the answer to a query. 
        To answer it, we go down the tree as before, 
        breaking the query into several subsegments that 
        coincide with the segments of the Segment Tree, 
        and combine the answers in them into a single answer 
        for the query. Then it should be clear, that the work 
        is exactly the same as in the simple Segment Tree, 
        but instead of summing / minimizing / maximizing the values, 
        we use the combine function.

        data query(int v, int tl, int tr, int l, int r) {
            if (l > r) 
                return make_data(0);
            if (l == tl && r == tr) 
                return t[v];
            int tm = (tl + tr) / 2;
            return combine(query(v*2, tl, tm, l, min(r, tm)), 
                        query(v*2+1, tm+1, tr, max(l, tm+1), r));
        }




################################################################
SEGMENT TREE WITH NODES THAT STORE SUBARRAYS INSTEAD OF COMPRESSED VALUES 
+ INTERVIEW QUESTIONS (We want to do this when we want to return array values instead of 
array indexes as answers? thats my currrent thinking vs above approach)
(https://cp-algorithms.com/data_structures/segment_tree.html)

    Intuition +  Mem Cost:

        This is a separate subsection that stands apart from the others, because at each 
        vertex of the Segment Tree we don't store information about the corresponding 
        segment in compressed form (sum, minimum, maximum, ...), but store all 
        elements of the segment. Thus the root of the Segment Tree will store 
        all elements of the array, the left child vertex will store the first 
        half of the array, the right vertex the second half, and so on.

        In its simplest application of this technique we store the elements in 
        sorted order. In more complex versions the elements are not stored in 
        lists, but more advanced data structures (sets, maps, ...). But all 
        these methods have the common factor, that each vertex requires 
        linear memory (i.e. proportional to the length of the corresponding segment).

        The first natural question, when considering these Segment Trees, is 
        about memory consumption. Intuitively this might look like O(n2) memory, 
        but it turns out that the complete tree will only need O(nlogn) memory. 
        Why is this so? Quite simply, because each element of the array falls 
        into O(logn) segments (remember the height of the tree is O(logn)).

        So in spite of the apparent extravagance of such a Segment Tree, it 
        consumes only slightly more memory than the usual Segment Tree.

        Several typical applications of this data structure are described below. 
        It is worth noting the similarity of these Segment Trees with 2D data 
        structures (in fact this is a 2D data structure, but with rather limited capabilities).

    Find the smallest number greater or equal to a specified number. 
    No modification queries.


        We want to answer queries of the following form: for three given numbers 
        (l,r,x) we have to find the minimal number in the segment a[l…r] 
        which is greater than or equal to x.

        We construct a Segment Tree. In each vertex we store a sorted list 
        of all numbers occurring in the corresponding segment, like described above.
        How to build such a Segment Tree as effectively as possible? 
        As always we approach this problem recursively: 
        let the lists of the left and right children already be 
        constructed, and we want to build the list for the current vertex. 
        From this view the operation is now trivial and can be accomplished 
        in linear time: We only need to combine the two sorted lists into one, 
        which can be done by iterating over them using two pointers. 
        The C++ STL already has an implementation of this algorithm.

        Because this structure of the Segment Tree and the similarities 
        to the merge sort algorithm, the data structure is also often 
        called "Merge Sort Tree".

        vector<int> t[4*MAXN];

        void build(int a[], int v, int tl, int tr) {
            if (tl == tr) {
                t[v] = vector<int>(1, a[tl]);
            } else { 
                int tm = (tl + tr) / 2;
                build(a, v*2, tl, tm);
                build(a, v*2+1, tm+1, tr);
                merge(t[v*2].begin(), t[v*2].end(), t[v*2+1].begin(), t[v*2+1].end(),
                    back_inserter(t[v]));
            }
        }

        We already know that the Segment Tree constructed in this way will 
        require O(nlogn) memory. And thanks to this implementation 
        its construction also takes O(nlogn) time, after all each list 
        is constructed in linear time in respect to its size.

        Now consider the answer to the query. We will go down the tree, 
        like in the regular Segment Tree, breaking our segment a[l…r] 
        into several subsegments (into at most O(logn) pieces). 
        It is clear that the answer of the whole answer is the 
        minimum of each of the subqueries. So now we only need to 
        understand, how to respond to a query on one such subsegment
        that corresponds with some vertex of the tree.

        We are at some vertex of the Segment Tree and we want to compute the answer 
        to the query, i.e. find the minimum number greater that or equal to a 
        given number x. Since the vertex contains the list of elements in sorted order, 
        we can simply perform a binary search on this list and return the first number, 
        greater than or equal to x.

        Thus the answer to the query in one segment of the tree takes O(logn) time, 
        and the entire query is processed in O(log2n).

        int query(int v, int tl, int tr, int l, int r, int x) {
            if (l > r)
                return INF;
            if (l == tl && r == tr) {
                vector<int>::iterator pos = lower_bound(t[v].begin(), t[v].end(), x);
                if (pos != t[v].end())
                    return *pos;
                return INF;
            }
            int tm = (tl + tr) / 2;
            return min(query(v*2, tl, tm, l, min(r, tm), x), 
                    query(v*2+1, tm+1, tr, max(l, tm+1), r, x));
        }

        The constant INF is equal to some large number that is bigger than all 
        numbers in the array. Its usage means, that there is no number greater 
        than or equal to x in the segment. It has the meaning of "there is no 
        answer in the given interval".
    

    Find the smallest number greater or equal to a specified number. 
    With modification queries. (Solution requres Red Black Tree)

    (ALSO PYTHON DOES NOT HAVE RED BLACK TREE SORTED BINARY TREE MULTISET IMPLEMENTATIONS. 
    THESE ARE ALSO KNOWN AS SORTED LISTS IN C++ COMMUNITY. WHAT SHOULD WE DO?? LEARN C++
    I GUESS LOL)

        This task is similar to the previous. The last approach has a disadvantage, 
        it was not possible to modify the array between answering queries. 
        Now we want to do exactly this: a modification query will do the assignment a[i]=y.

        The solution is similar to the solution of the previous problem, but 
        instead of lists at each vertex of the Segment Tree, 
        we will store a balanced list that allows you to quickly search for numbers, 
        delete numbers, and insert new numbers. Since the array can contain a 
        number repeated, the optimal choice is the data structure multiset.

        The construction of such a Segment Tree is done in pretty much the 
        same way as in the previous problem, only now we need to 
        combine multisets and not sorted lists. This leads to a construction 
        time of O(nlog^2(n) ) (in general merging two red-black trees 
        can be done in linear time, but the C++ STL doesn't 
        guarantee this time complexity).

        The query function is also almost equivalent, only now the lower_bound 
        function of the multiset function should be called instead 
        (std::lower_bound only works in O(logn) time if used with random-access iterators).

        Finally the modification request. To process it, we must go down 
        the tree, and modify all multiset from the corresponding segments 
        that contain the effected element. We simply delete the old value 
        of this element (but only one occurrence), and insert the new value.

        void update(int v, int tl, int tr, int pos, int new_val) {
            t[v].erase(t[v].find(a[pos]));
            t[v].insert(new_val);
            if (tl != tr) {
                int tm = (tl + tr) / 2;
                if (pos <= tm)
                    update(v*2, tl, tm, pos, new_val);
                else
                    update(v*2+1, tm+1, tr, pos, new_val);
            } else {
                a[pos] = new_val;
            }
        }

        Processing of this modification query also takes O(log^2(n)) time.


        Other possible variations
        This technique implies a whole new class of possible applications. 
        Instead of storing a vector or a multiset in each vertex, other 
        data structures can be used: other Segment Trees (somewhat discussed in
        Generalization to higher dimensions), Fenwick Trees, Cartesian trees, etc.


################################################################
2D Segment Tree Interview questions

    Idea:

    A Segment Tree can be generalized quite natural to higher dimensions. 
    If in the one-dimensional case we split the indices of the array 
    into segments, then in the two-dimensional we make an ordinary 
    Segment Tree with respect to the first indices, and for each segment
    we build an ordinary Segment Tree with respect to the second indices.


    Simple 2D Segment Tree
        A matrix a[0…n−1,0…m−1] is given, and we have to find the sum 
        (or minimum/maximum) on some submatrix a[x1…x2,y1…y2], as well 
        as perform modifications of individual matrix elements 
        (i.e. queries of the form a[x][y]=p).

        So we build a 2D Segment Tree: first the Segment Tree using 
        the first coordinate (x), then the second (y).

        To make the construction process more understandable, you can 
        forget for a while that the matrix is two-dimensional, and 
        only leave the first coordinate. We will construct an ordinary 
        one-dimensional Segment Tree using only the first coordinate. 
        But instead of storing a number in a segment, be store an 
        entire Segment Tree: i.e. at this moment we remember that we 
        also have a second coordinate; but because at this moment the 
        first coordinate is already fixed to some interval [l…r], we 
        actually work with such a strip a[l…r,0…m−1] and for 
        it we build a Segment Tree.

        Here is the implementation of the construction of a 2D Segment Tree. 
        It actually represents two separate blocks: the construction of 
        a Segment Tree along the x coordinate (buildx), and the y 
        coordinate (buildy). For the leaf nodes in buildy we have to 
        separate two cases: when the current segment of the first 
        coordinate [tlx…trx] has length 1, and when it has a length greater 
        than one. In the first case, we just take the corresponding value 
        from the matrix, and in the second case we can combine the values of 
        two Segment Trees from the left and the right son in the coordinate x.

        void build_y(int vx, int lx, int rx, int vy, int ly, int ry) {
            if (ly == ry) {
                if (lx == rx)
                    t[vx][vy] = a[lx][ly];
                else
                    t[vx][vy] = t[vx*2][vy] + t[vx*2+1][vy];
            } else {
                int my = (ly + ry) / 2;
                build_y(vx, lx, rx, vy*2, ly, my);
                build_y(vx, lx, rx, vy*2+1, my+1, ry);
                t[vx][vy] = t[vx][vy*2] + t[vx][vy*2+1];
            }
        }

        void build_x(int vx, int lx, int rx) {
            if (lx != rx) {
                int mx = (lx + rx) / 2;
                build_x(vx*2, lx, mx);
                build_x(vx*2+1, mx+1, rx);
            }
            build_y(vx, lx, rx, 1, 0, m-1);
        }

        Such a Segment Tree still uses a linear amount of memory, 
        but with a larger constant: 16nm. It is clear that the described 
        rocedure buildx also works in linear time.

        Now we turn to processing of queries. We will answer to the two-dimensional 
        query using the same principle: first break the query on the first coordinate, 
        and then for every reached vertex, we call the corresponding Segment Tree 
        of the second coordinate.

        int sum_y(int vx, int vy, int tly, int try_, int ly, int ry) {
            if (ly > ry) 
                return 0;
            if (ly == tly && try_ == ry)
                return t[vx][vy];
            int tmy = (tly + try_) / 2;
            return sum_y(vx, vy*2, tly, tmy, ly, min(ry, tmy))
                + sum_y(vx, vy*2+1, tmy+1, try_, max(ly, tmy+1), ry);
        }

        int sum_x(int vx, int tlx, int trx, int lx, int rx, int ly, int ry) {
            if (lx > rx)
                return 0;
            if (lx == tlx && trx == rx)
                return sum_y(vx, 1, 0, m-1, ly, ry);
            int tmx = (tlx + trx) / 2;
            return sum_x(vx*2, tlx, tmx, lx, min(rx, tmx), ly, ry)
                + sum_x(vx*2+1, tmx+1, trx, max(lx, tmx+1), rx, ly, ry);
        }

        This function works in O(lognlogm) time, since it first descends 
        the free in the first coordinate, and for each traversed vertex in 
        the tree it makes a query in the corresponding Segment Tree 
        along the second coordinate.

        Finally we consider the modification query. We want to learn how 
        to modify the Segment Tree in accordance with the change in the 
        value of some element a[x][y]=p. It is clear, that the changes 
        will occur only in those vertices of the first Segment Tree that 
        cover the coordinate x (and such will be O(logn)), and for Segment 
        Trees corresponding to them the changes will only occurs at those 
        vertices that covers the coordinate y (and such will be O(logm)). 
        Therefore the implementation will be not very different form 
        the one-dimensional case, only now we first descend the first 
        coordinate, and then the second.

        void update_y(int vx, int lx, int rx, int vy, int ly, int ry, int x, int y, int new_val) {
            if (ly == ry) {
                if (lx == rx)
                    t[vx][vy] = new_val;
                else
                    t[vx][vy] = t[vx*2][vy] + t[vx*2+1][vy];
            } else {
                int my = (ly + ry) / 2;
                if (y <= my)
                    update_y(vx, lx, rx, vy*2, ly, my, x, y, new_val);
                else
                    update_y(vx, lx, rx, vy*2+1, my+1, ry, x, y, new_val);
                t[vx][vy] = t[vx][vy*2] + t[vx][vy*2+1];
            }
        }

        void update_x(int vx, int lx, int rx, int x, int y, int new_val) {
            if (lx != rx) {
                int mx = (lx + rx) / 2;
                if (x <= mx)
                    update_x(vx*2, lx, mx, x, y, new_val);
                else
                    update_x(vx*2+1, mx+1, rx, x, y, new_val);
            }
            update_y(vx, lx, rx, 1, 0, m-1, x, y, new_val);
        }


    Compression of 2D Segment Tree

        Let the problem be the following: there are n points on the plane 
        given by their coordinates (xi,yi) and queries of the form "count 
        the number of points lying in the rectangle ((x1,y1),(x2,y2))". 
        It is clear that in the case of such a problem it becomes unreasonably 
        wasteful to construct a two-dimensional Segment Tree with O(n^2) elements. 
        Most on this memory will be wasted, since each single point can only get 
        into O(logn) segments of the tree along the first coordinate, 
        and therefore the total "useful" size of all tree segments on 
        the second coordinate is O(nlogn).

        So we proceed as follows: at each vertex of the Segment Tree with 
        respect to the first coordinate we store a Segment Tree constructed
        only by those second coordinates that occur in the current segment 
        of the first coordinates. In other words, when constructing a Segment 
        Tree inside some vertex with index vx and the boundaries tlx and trx, 
        we only consider those points that fall into this interval x∈[tlx,trx], 
        and build a Segment Tree just using them.

        Thus we will achieve that each Segment Tree on the 
        second coordinate will occupy exactly as much memory as it should.
        As a result, the total amount of memory will decrease to O(nlogn). 
        We still can answer the queries in O(log^2(n) ) time, we just have to 
        make a binary search on the second coordinate, 
        but this will not worsen the complexity.

        But modification queries will be impossible with this structure: 
        in fact if a new point appears, we have to add a new element in 
        the middle of some Segment Tree along the second coordinate, which 
        cannot be effectively done.

        In conclusion we note that the two-dimensional Segment Tree contracted 
        in the described way becomes practically equivalent to the modification 
        of the one-dimensional Segment Tree (see Saving the entire subarrays 
        in each vertex). In particular the two-dimensional Segment Tree is 
        just a special case of storing a subarray in each vertex of the tree. 
        It follows, that if you gave to abandon a two-dimensional Segment Tree 
        due to the impossibility of executing a query, it makes 
        sense to try to replace the nested Segment Tree with 
        some more powerful data structure, for example a Cartesian tree.
    
    (CONTINUE STUDY OF SEGMENT TREES WITH PRESERVING 
    THE HISTORY OF ITS VALUES (PERSISTENT SEG TREES))


################################################################
SEGMENT TREE RANGE UPDATES AND LAZY PROPOGATION. 
(https://cp-algorithms.com/data_structures/segment_tree.html)

    All p roblems in the above sections discussed modification queries 
    that only effected a single element of the array each. However the 
    Segment Tree allows applying modification queries to an entire segment 
    of contiguous elements, and perform the query in the same time O(logn).

    Addition on segments
        We begin by considering problems of the simplest form: 
        the modification query should add a number x to all numbers 
        in the segment a[l…r]. The second query, that we are supposed to answer, 
        asked simply for the value of a[i].

        To make the addition query efficient, we store at each vertex in the 
        Segment Tree how many we should add to all numbers in the corresponding 
        segment. For example, if the query "add 3 to the whole array a[0…n−1]" 
        comes, then we place the number 3 in the root of the tree. In general 
        we have to place this number multiple to multiple segments, which form a 
        partition of the query segment. Thus we don't have to change all O(n) values, 
        but only O(logn) many.

        If now there comes a query that asks the current value of a particular 
        array entry, it is enough to go down the tree and add up all 
        values found along the way.

        void build(int a[], int v, int tl, int tr) {
            if (tl == tr) {
                t[v] = a[tl];
            } else {
                int tm = (tl + tr) / 2;
                build(a, v*2, tl, tm);
                build(a, v*2+1, tm+1, tr);
                t[v] = 0;
            }
        }

        void update(int v, int tl, int tr, int l, int r, int add) {
            if (l > r)
                return;
            if (l == tl && r == tr) {
                t[v] += add;
            } else {
                int tm = (tl + tr) / 2;
                update(v*2, tl, tm, l, min(r, tm), add);
                update(v*2+1, tm+1, tr, max(l, tm+1), r, add);
            }
        }

        int get(int v, int tl, int tr, int pos) {
            if (tl == tr)
                return t[v];
            int tm = (tl + tr) / 2;
            if (pos <= tm)
                return t[v] + get(v*2, tl, tm, pos);
            else
                return t[v] + get(v*2+1, tm+1, tr, pos);
        }


    Assignment on segments
        Suppose now that the modification query asks to assign each element 
        of a certain segment a[l…r] to some value p. As a second query we 
        will again consider reading the value of the array a[i].

        To perform this modification query on a whole segment, you have 
        to store at each vertex of the Segment Tree whether 
        the corresponding segment is covered entirely with the 
        same value or not. This allows us to make a "lazy" update: 
        instead of changing all segments in the tree that cover the 
        query segment, we only change some, and leave others unchanged. 
        A marked vertex will mean, that every element of the corresponding 
        segment is assigned to that value, and actually also 
        the complete subtree should only contain this value. In a sense we 
        are lazy and delay writing the new value to all those vertices.
        We can do this tedious task later, if this is necessary.

        So after the modification query is executed, some parts of the tree 
        become irrelevant - some modifications remain unfulfilled in it.

        For example if a modification query "assign a number to the 
        whole array a[0…n−1]" gets executed, in the Segment Tree only 
        a single change is made - the number is placed in the root of 
        the tree and this vertex gets marked. The remaining segments 
        remain unchanged, although in fact the number should be placed in the whole tree.

        Suppose now that the second modification query says, that the 
        first half of the array a[0…n/2] should be assigned with some other number. 
        To process this query we must assign each element in the 
        whole left child of the root vertex with that number. But before 
        we do this, we must first sort out the root vertex first. The 
        subtlety here is that the right half of the array should 
        still be assigned to the value of the first query, and at 
        the moment there is no information for the right half stored.

        The way to solve this is to push the information of 
        the root to its children, i.e. if the root of the tree was 
        assigned with any number, then we assign the left and the 
        right child vertices with this number and remove the mark 
        of the root. After that, we can assign the left child with 
        the new value, without loosing any necessary information.

        Summarizing we get: for any queries (a modification or reading query) 
        during the descent along the tree we should always 
        push information from the current vertex into both of 
        its children. We can understand this in such a way, that 
        when we descent the tree we apply delayed modifications, 
        but exactly as much as necessary (so not to degrade the complexity of O(logn).

        For the implementation we need to make a push function, 
        which will receive the current vertex, and it will push 
        the information for its vertex to both its children. We 
        will call this function at the beginning of the query 
        functions (but we will not call it from the leaves, 
        because there is no need to push information from 
        them any further).

        void push(int v) {
            if (marked[v]) {
                t[v*2] = t[v*2+1] = t[v];
                marked[v*2] = marked[v*2+1] = true;
                marked[v] = false;
            }
        }

        void update(int v, int tl, int tr, int l, int r, int new_val) {
            if (l > r) 
                return;
            if (l == tl && tr == r) {
                t[v] = new_val;
                marked[v] = true;
            } else {
                push(v);
                int tm = (tl + tr) / 2;
                update(v*2, tl, tm, l, min(r, tm), new_val);
                update(v*2+1, tm+1, tr, max(l, tm+1), r, new_val);
            }
        }

        int get(int v, int tl, int tr, int pos) {
            if (tl == tr) {
                return t[v];
            }
            push(v);
            int tm = (tl + tr) / 2;
            if (pos <= tm) 
                return get(v*2, tl, tm, pos);
            else
                return get(v*2+1, tm+1, tr, pos);
        }

        Notice: the function get can also be implemented in a 
        different way: do not make delayed updates, but immediately
        return the value t[v] if marked[v] is true.

    Adding on segments, querying for maximum
        Now the modification query is to add a number to all elements 
        in a range, and the reading query is to find the maximum in a range.

        So for each vertex of the Segment Tree we have to store 
        the maximum of the corresponding subsegment. 
        The interesting part is how to recompute 
        these values during a modification request.

        For this purpose we keep store an additional value 
        for each vertex. In this value we store the addends 
        we haven't propagated to the child vertices. 
        Before traversing to a child vertex, we call 
        push and propagate the value to both children. 
        We have to do this in both the update 
        function and the query function.

        void push(int v) {
            t[v*2] += lazy[v]; # update maxes
            lazy[v*2] += lazy[v];
            t[v*2+1] += lazy[v]; # update maxes
            lazy[v*2+1] += lazy[v];
            lazy[v] = 0;
        }

        void update(int v, int tl, int tr, int l, int r, int addend) {
            if (l > r) 
                return;
            if (l == tl && tr == r) {
                t[v] += addend;
                lazy[v] += addend;
            } else {
                push(v);
                int tm = (tl + tr) / 2;
                update(v*2, tl, tm, l, min(r, tm), addend);
                update(v*2+1, tm+1, tr, max(l, tm+1), r, addend);
                t[v] = max(t[v*2], t[v*2+1]);
            }
        }

        int query(int v, int tl, int tr, int l, int r) {
            if (l > r)
                return -INF;
            if (l <= tl && tr <= r)
                return t[v];
            push(v);
            int tm = (tl + tr) / 2;
            return max(query(v*2, tl, tm, l, min(r, tm)), 
                    query(v*2+1, tm+1, tr, max(l, tm+1), r));
        }


####################################################################
Another segment tree tutorial: 
Segment trees Analysis and in C++

    Let our data be in an array arr[] of size nn.

    The root of our segment tree typically represents the entire interval of data 
    we are interested in. This would be arr[0:n-1].
    
    -> Each leaf of the tree represents a range comprising of just a single element. 
    -> Thus the leaves represent arr[0], arr[1] and so on till arr[n-1].
    -> The internal nodes of the tree would represent the merged or union result of their children nodes.
    -> Each of the children nodes could represent approximately half of the range represented by their parent.
    -> A segment tree for an n element range can be comfortably represented using an array of size n≈4∗n.
    PROOF:
        -> What is happening here is, if you have an array of n elements, 
        then the segment tree will have a leaf node for each of these n entries. 
        Thus, we have (n) leaf nodes, and also (n-1) internal nodes.
        -> Total number of nodes= n + (n-1) = 2n-1 
        -> Now, we know its a full binary tree and thus the height is: ceil(Log2(n)) +1
        -> Total no. of nodes = 2^0 + 2^1 + 2^2 + … + 2^ceil(Log2(n)) 
        // which is a geometric progression where 2^i denotes, the number of nodes at level i.
        -> Formula of summation G.P. = a * (r^size - 1)/(r-1) where a=2^0
        -> Total no. of nodes = 1*(2^(ceil(Log2(n))+1) -1)/(2-1)
        = 2* [2^ceil(Log2(n))] -1 (you need space in the array for each of the internal 
        as well as leaf nodes which are this count in number), thus it is the array of size.
        = O(4 * n) approx..
    
    EASIER PROOF:
        Also, the better explanation is: if the array size n is a power of 2, 
        then we have exactly n-1 internal nodes, summing up to 2n-1 total nodes. 
        But not always, we have n as the power of 2, so we basically 
        need the smallest power of 2 which is greater than n. That means this,
        int s=1;
        for(; s<n; s<<=1);

    The node of the tree is at index 0. Thus tree[0] is the root of our tree.
    The children of tree[i] are stored at tree[2*i+1] and tree[2*i+2].

    1. Build the tree from the original data.
    void buildSegTree(vector<int>& arr, int treeIndex, int lo, int hi)
    {
        if (lo == hi) {                 // leaf node. store value in node.
            tree[treeIndex] = arr[lo];
            return;
        }

        int mid = lo + (hi - lo) / 2;   // recurse deeper for children.
        buildSegTree(arr, 2 * treeIndex + 1, lo, mid);
        buildSegTree(arr, 2 * treeIndex + 2, mid + 1, hi);

        // merge build results
        tree[treeIndex] = merge(tree[2 * treeIndex + 1], tree[2 * treeIndex + 2]);
    }

    // call this method as buildSegTree(arr, 0, 0, n-1);
    // Here arr[] is input array and n is its size.

    The method builds the entire tree in a bottom up fashion. When the condition 
    lo = hi is satisfied, we are left with a range comprising of 
    just a single element (which happens to be arr[lo]). 
    This constitutes a leaf of the tree. The rest of the 
    nodes are built by merging the results of their two children.
    treeIndex is the index of the current node of the segment tree which is being processed.

    Input -> 10 nodes -> arr[] = { 18, 17, 13, 19, 15, 11, 20, 12, 33, 25 };
    tree[] = { 183, 82, 101, 48, 34, 43, 58, 35, 13, 19, 15, 31, 12, 33, 
               25, 18, 17, 0, 0, 0, 0, 0, 0, 11, 20, 0, 0, 0, 0, 0, 0 };

    Notice the the groups of zeros near the end of the tree[] array? 
    Those are null values we used as padding to ensure a complete binary tree 
    is formed (since we only had 1010 leaf elements. Had we had, say, 
    16 leaf elements, we wouldn't need any null element

    NOTE: The merge operation varies from problem to problem. 
    You should closely think of what to store in a node of the segment 
    tree and how two nodes will merge to provide a result before you even 
    start building a segment tree.

    2. Read/Query on an interval or segment of the data.
    int querySegTree(int treeIndex, int lo, int hi, int i, int j)
    {
        // query for arr[i..j]

        if (lo > j || hi < i)               // segment completely outside range
            return 0;                       // represents a null node

        if (i <= lo && j >= hi)             // segment completely inside range
            return tree[treeIndex];
        
        // partial overlap of current segment and queried range. Recurse deeper.
        int mid = lo + (hi - lo) / 2;       

        if (i > mid)
            return querySegTree(2 * treeIndex + 2, mid + 1, hi, i, j);
        else if (j <= mid)
            return querySegTree(2 * treeIndex + 1, lo, mid, i, j);

        // When mid is between i and j. Find the range by traversing left and right subtrees
        // but now look for intervals [i, mid] and [mid+1, j] which is [i, j]

        int leftQuery = querySegTree(2 * treeIndex + 1, lo, mid, i, mid);
        int rightQuery = querySegTree(2 * treeIndex + 2, mid + 1, hi, mid + 1, j);

        // merge query results, for instance sum.
        return merge(leftQuery, rightQuery);
    }

    // call this method as querySegTree(0, 0, n-1, i, j);
    // Here [i,j] is the range/interval you are querying.
    // This method relies on "null" nodes being equivalent to storing zero.

    In the above example, we are trying to find the sum of 
    the elements in the range [2, 8] . No segment completely 
    represents the range [2, 8]. 
    However we can see that [2, 8] can be built up using the ranges 
    [2, 2], [3, 4], [5, 7] and [8, 8]. 
     
    void updateValSegTree(int treeIndex, int lo, int hi, int arrIndex, int val)
    {
        if (lo == hi) {                 // leaf node. update element.
            tree[treeIndex] = val;
            return;
        }

        int mid = lo + (hi - lo) / 2;   // recurse deeper for appropriate child

        if (arrIndex > mid)
            updateValSegTree(2 * treeIndex + 2, mid + 1, hi, arrIndex, val);
        else if (arrIndex <= mid)
            updateValSegTree(2 * treeIndex + 1, lo, mid, arrIndex, val);

        // merge updates, and update the upper levels of the tree straight to the root.
        tree[treeIndex] = merge(tree[2 * treeIndex + 1], tree[2 * treeIndex + 2]);
    }
    
    This makes the build process run in O(n) linear complexity.
    Both the read and update queries now take logarithmic O(log_2(n))
    
##########################################################################################3
PYTHON SEGMENT TREE FOR ABOVE:

class NumArray:
    tree = None
    n = None
    def __init__(self, nums: List[int]):
        self.n = len(nums)
        if self.n:
            self.tree = [0] * 4 * len(nums)
            self.buildTree(nums, 0, 0, len(nums) - 1)

    '''
    arr: The original array
    index: the Segment tree index
    low: the lower bound
    high: the upper bound
    '''
    def buildTree(self, arr, index, low, high):
        if low == high:
            self.tree[index] = arr[low] if low < len(arr) else 0
        else:
            mid = (low + high) // 2
            self.buildTree(arr, 2 * index + 1, low, mid)
            self.buildTree(arr, 2 * index + 2, mid + 1, high)
            self.tree[index] = self.tree[2 * index + 1] + self.tree[2 * index + 2]
    
    '''
    i: the index that needs to be updated
    val: the value been updated
    index: the index of segment tree
    low: the lower bound
    high: the higher bound
    '''
    def update(self, i: int, val: int, index = 0, low = 0, high = float('inf')) -> None:
        if high == float('inf'):
            high = self.n - 1
        if low == high:
            self.tree[index] = val
        else:
            mid = (low + high) // 2
            if mid >= i:
                self.update(i, val, 2 * index + 1, low, mid)
            else:
                self.update(i, val , 2 * index + 2, mid + 1, high)
            self.tree[index] = self.tree[2 * index + 1] + self.tree[2 * index + 2]

    '''
    i: the lower bound of the query
    j: the upper bound of the query
    '''
    def sumRange(self, i: int, j: int, index = 0, low = 0, high = float('inf')) -> int:
        if high == float('inf'):
            high = self.n - 1
        if low > j or high < i:
            return 0
        if i <= low and j >= high:
            return self.tree[index]
        mid = (low + high) // 2
        if i > mid:
            return self.sumRange(i, j, 2 * index + 2, mid + 1, high)
        elif j <= mid:
            return self.sumRange(i, j, 2 * index + 1, low, mid)

        left = self.sumRange(i, mid , 2 * index + 1, low, mid)
        right = self.sumRange(mid + 1, j , 2 * index + 2, mid + 1, high)
        return left + right    

###########################################################################################
LAZY PROPOGATION SEGMENT TREE:

    Till now we have been updating single elements only. 
    That happens in logarithmic time and it's pretty efficient.
    But what if we had to update a range of elements? By our current method, 
    each of the elements would have to be updated 
    independently, each incurring some run time cost.
    The construction of a tree poses another issue called ancestral locality. 
    Ancestors of adjacent leaves are guaranteed to be common at 
    some levels of the tree. Updating each of these leaves individually 
    would mean that we process their common ancestors multiple times. 
    What if we could reduce this repetitive computation?
    A third kind of problem is when queried ranges do not contain frequently updated elements. 
    We might be wasting valuable time updating nodes which are rarely going to be accessed/read.

    TO IMPLEMENT:
    We use another array lazy[] which is the same size as our segment tree 
    array tree[] to represent a lazy node. lazy[i] holds the amount by which 
    the node tree[i] needs to be incremented, when that node is finally accessed 
    or queried. When lazy[i] is zero, it means that node 
    tree[i] is not lazy and has no pending updates.

    1. Updating a range lazily
    This is a three step process:

    -> Normalize the current node. This is done by removing laziness. 
       We simple increment the current node by appropriate amount to 
       remove it's laziness. Then we mark its children to be lazy as 
       the descendants haven't been processed yet.
    
    -> Apply the current update operation to the current node if the 
       current segment lies inside the update range.

    -> Recurse for the children as you would normally to find appropriate segments to update.

    void updateLazySegTree(int treeIndex, int lo, int hi, int i, int j, int val)
    {
        if (lazy[treeIndex] != 0) {                             // this node is lazy
            tree[treeIndex] += (hi - lo + 1) * lazy[treeIndex]; // normalize current node by removing laziness

            if (lo != hi) {                                     // update lazy[] for children nodes
                lazy[2 * treeIndex + 1] += lazy[treeIndex];
                lazy[2 * treeIndex + 2] += lazy[treeIndex];
            }

            lazy[treeIndex] = 0;                                // current node processed. No longer lazy
        }

        if (lo > hi || lo > j || hi < i)
            return;                                             // out of range. escape.

        if (i <= lo && hi <= j) {                               // segment is fully within update range
            tree[treeIndex] += (hi - lo + 1) * val;             // update segment

            if (lo != hi) {                                     // update lazy[] for children
                lazy[2 * treeIndex + 1] += val;
                lazy[2 * treeIndex + 2] += val;
            }

            return;
        }

        int mid = lo + (hi - lo) / 2;                             // recurse deeper for appropriate child

        updateLazySegTree(2 * treeIndex + 1, lo, mid, i, j, val);
        updateLazySegTree(2 * treeIndex + 2, mid + 1, hi, i, j, val);

        // merge updates
        tree[treeIndex] = tree[2 * treeIndex + 1] + tree[2 * treeIndex + 2];
    }
    // call this method as updateLazySegTree(0, 0, n-1, i, j, val);
    // Here you want to update the range [i, j] with value val.

    2. Querying a lazily propagated tree
    This is a two step process:
    Normalize the current node by removing laziness. This step is the same as the update step.
    Recurse for the children as you would normally to find appropriate segments which fit in queried range.

        int queryLazySegTree(int treeIndex, int lo, int hi, int i, int j)
    {
        // query for arr[i..j]

        if (lo > j || hi < i)                                   // segment completely outside range
            return 0;                                           // represents a null node

        if (lazy[treeIndex] != 0) {                             // this node is lazy
            tree[treeIndex] += (hi - lo + 1) * lazy[treeIndex]; // normalize current node by removing laziness

            if (lo != hi) {                                     // update lazy[] for children nodes
                lazy[2 * treeIndex + 1] += lazy[treeIndex];
                lazy[2 * treeIndex + 2] += lazy[treeIndex];
            }

            lazy[treeIndex] = 0;                                // current node processed. No longer lazy
        }

        if (i <= lo && j >= hi)                                 // segment completely inside range
            return tree[treeIndex];
        
        // partial overlap of current segment and queried range. Recurse deeper.
        int mid = lo + (hi - lo) / 2;                           

        if (i > mid)
            return queryLazySegTree(2 * treeIndex + 2, mid + 1, hi, i, j);
        else if (j <= mid)
            return queryLazySegTree(2 * treeIndex + 1, lo, mid, i, j);

        int leftQuery = queryLazySegTree(2 * treeIndex + 1, lo, mid, i, mid);
        int rightQuery = queryLazySegTree(2 * treeIndex + 2, mid + 1, hi, mid + 1, j);

        // merge query results
        return leftQuery + rightQuery;
    }
    // call this method as queryLazySegTree(0, 0, n-1, i, j);
    // Here [i,j] is the range/interval you are querying.
    // This method relies on "null" nodes being equivalent to storing zero.
    

########################## DESIGN CIRCULAR BIDIRECTIONAL LINKED LIST PYTHON ############################

class Node:
    def __init__(self, v, p=None, n=None):
        self.val = v
        self.prev = p
        self.next = n

class MyLinkedList:

    def __init__(self):
        """
        Initialize your data structure here.
        """
        self.key = Node(-1)
        self.key.prev = self.key.next = self.key

    def get(self, index: int) -> int:
        """
        Get the value of the index-th node in the linked list. 
        If the index is invalid, return -1.

        """
        i, node = 0, self.key.next
        while i < index and node != self.key:
            node = node.next
            i += 1
        return node.val if index >= 0 else -1

    def addAtHead(self, val: int) -> None:
        """
        Add a node of value val before the first element of the linked list. 
        After the insertion, the new node will be the first node of the linked list.
        """
        self.key.next.prev = self.key.next = Node(val, p=self.key, n=self.key.next)

    def addAtTail(self, val: int) -> None:
        """
        Append a node of value val to the last element of the linked list.
        """
        self.key.prev.next = self.key.prev = Node(val, p=self.key.prev, n=self.key)

    def addAtIndex(self, index: int, val: int) -> None:
        """
        Add a node of value val before the index-th node in the linked list. 
        If index equals to the length of linked list, the node will be appended 
        to the end of linked list. If index is greater than the length, the node will not be inserted.
        """
        index = max(0, index)
        i, node = 0, self.key.next
        while i < index and node != self.key:
            node = node.next
            i += 1
        if node != self.key or i == index:
            node.prev.next = node.prev = Node(val, p=node.prev, n=node)

    def deleteAtIndex(self, index: int) -> None:
        """
        Delete the index-th node in the linked list, if the index is valid.
        """
        if index < 0: return
        i, node = 0, self.key.next
        while i < index and node != self.key:
            node = node.next
            i += 1
        if node != self.key:
            node.prev.next = node.next
            node.next.prev = node.prev
            del node


# Your MyLinkedList object will be instantiated and called as such:
# obj = MyLinkedList()
# param_1 = obj.get(index)
# obj.addAtHead(val)
# obj.addAtTail(val)
# obj.addAtIndex(index,val)
# obj.deleteAtIndex(index)


########################## DESIGN CIRCULAR BIDIRECTIONAL LINKED LIST C++ ############################
class MyLinkedList {
    struct Node {
        Node* prev;
        Node* next;
        int val;
    };

    Node head;

    Node* addAfter(Node* position, int val) {
        const auto node = new Node{position, position->next, val};
        position->next->prev = node;
        position->next = node;
        return node;
    }

    Node* addBefore(Node* position, int val) {
        const auto node = new Node{position->prev, position, val};
        position->prev->next = node;
        position->prev = node;
        return node;
    }

    void remove(Node* node) {
        const auto prev = node->prev;
        const auto next = node->next;
        node->prev->next = next;
        node->next->prev = prev;
        delete node;
    }

    pair<Node*, int> at(int index) {
        Node* node = &head;
        index++;
        while (index > 0) {
            index--;
            node = node->next;
            if (node == &head) {
                break;
            }
        }
        return {node, index};
    }

public:
    /** Initialize your data structure here. */
    MyLinkedList() {
        head = {&head, &head, -1};
    }

    /** Get the value of the index-th node in the linked list. If the index is invalid, return -1. */
    int get(int index) {
        return at(index).first->val;
    }

    /** Add a node of value val before the first element of the linked list. After the insertion, the new node will be the first node of the linked list. */
    void addAtHead(int val) {
        addAfter(&head, val);
    }

    /** Append a node of value val to the last element of the linked list. */
    void addAtTail(int val) {
        addBefore(&head, val);
    }

    /** Add a node of value val before the index-th node in the linked list. If index equals to the length of linked list, the node will be appended to the end of linked list. If index is greater than the length, the node will not be inserted. */
    void addAtIndex(int index, int val) {
        const auto [node, excess] = at(index);
        if (excess == 0) {
            addBefore(node, val);
        }
    }

    /** Delete the index-th node in the linked list, if the index is valid. */
    void deleteAtIndex(int index) {
        const auto node = at(index).first;
        if (node != &head) {
            remove(node);
        }
    }
};

##########################################################################################

MinHeap Implementation

    Maxheap can be implemented similarly, mainly 
    just know the heapify algorithm and you should be fine.

    class MinHeap:
        def __init__(self):
            self.heap = []
        def parent(self, i):
            return (i - 1)/2
        def left_child(self, i):
            return (i * 2 + 1)
        def right_child(self, i):
            return (i * 2 + 2)
        def insertKey(self, k):
            self.heap.append(k)
            i = len(self.heap) - 1
            while i != 0 and self.heap[self.parent(i)] > self.heap[i]:
                self.heap[i], self.heap[self.parent(i)] = self.heap[self.parent(i)], self.heap[i]
                i = self.parent(i)
        def decreaseKey(self, i, new_val):
            self.heap[i] = new_val
            while i != 0 and self.heap[self.parent(i)] > self.heap[i]:
                self.heap[i], self.heap[self.parent(i)] = self.heap[self.parent(i)], self.heap[i]
                i = self.parent(i)
        def increaseKey(self, i, new_val):
            heap[i] = new_val
            minHeapify(i)
        def getMin(self):
            return self.heap[0]
        def minHeapify(self, i):
            left_child = self.left_child(i)
            right_child = self.right_child(i)
            smallest = i
            if left_child < len(self.heap) and self.heap[left_child] < self.heap[smallest]:
                smallest = left_child
            if right_child < len(self.heap) and self.heap[right_child] < self.heap[smallest]:
                smallest = right_child
            if smallest != i:
                self.heap[i], self.heap[smallest] = self.heap[smallest], self.heap[i]
                self.minHeapify(smallest)
        def extractMin(self):
            tmp = self.heap[0]
            self.heap[0] = self.heap[-1]
            self.heap.pop()
            self.minHeapify(0)
            return tmp
        def deleteKey(self, i):
            self.decreaseKey(i, float('inf') * -1)
            self.extractMin()


############################## BUILD HEAP AND WHY ITS O(N) (Using MAX HEAP HERE)############################

Making the correct choice between siftUp and siftDown is critical 
to get O(n) performance for buildHeap

siftDown swaps a node that is too small with its largest child (thereby moving it down) 
until it is at least as large as both nodes below it.

siftUp swaps a node that is too large with its parent (thereby moving it up) 
until it is no larger than the node above it.

The number of operations required for siftDown and siftUp is proportional 
to the distance the node may have to move. For siftDown, it is the distance 
to the bottom of the tree, so siftDown is expensive for nodes at the top 
of the tree. With siftUp, the work is proportional to the distance to the 
top of the tree, so siftUp is expensive for nodes at the bottom of the tree. 
Although both operations are O(log n) in the worst case, in a heap, only one 
node is at the top whereas half the nodes lie in the bottom layer. So it 
shouldn't be too surprising that if we have to apply an operation to every node, 
we would prefer siftDown over siftUp.

Two ways:

Start at the top of the heap (the beginning of the array) and call 
siftUp on each item. At each step, the previously sifted items (the items before the current 
item in the array) form a valid heap, and sifting the next item up places it into a 
valid position in the heap. After sifting up each node, all items satisfy the heap property.

Or, go in the opposite direction: start at the end of the array and 
move backwards towards the front. At each iteration, you sift an item 
down until it is in the correct location.

Both of these solutions will produce a valid heap. Unsurprisingly, 
the more efficient one is the second operation that uses siftDown.

Let h = log n represent the height of the heap. 
The work required for the siftDown approach is given by the sum
(0 * n/2) + (1 * n/4) + (2 * n/8) + ... + (h * 1).

In contrast, the sum for calling siftUp on each node is
(h * n/2) + ((h-1) * n/4) + ((h-2)*n/8) + ... + (0 * 1).

USE SIFT DOWN!!

BUILD HEAP (BUT FOR MIN HEAP):

def heapify(A):
    for root in xrange(len(A)//2-1, -1, -1):
        rootVal = A[root]
        child = 2*root + 1
        while child < len(A):
            # we pick the smaller child to sort?
            # makes sense because the smaller child is the one
            # that has to fight with the parent in a min heap.
            if child+1 < len(A) and A[child] > A[child+1]:
                child += 1
            if rootVal <= A[child]:
                break
            A[child], A[(child-1)//2] = A[(child-1)//2], A[child]
            child = child *2 + 1


############################################ TREE ANALYSIS ######################33

Segment tree stores intervals, and optimized for "which of these intervals contains a given point" queries.
Interval tree stores intervals as well, but optimized for "which of these intervals overlap with a given interval" queries. 
        It can also be used for point queries - similar to segment tree.
Range tree stores points, and optimized for "which points fall within a given interval" queries.
Binary indexed tree stores items-count per index, and optimized for "how many items are there between index m and n" queries.

Performance / Space consumption for one dimension:

Segment tree - O(n logn) preprocessing time, O(k+logn) query time, O(n logn) space
Interval tree - O(n logn) preprocessing time, O(k+logn) query time, O(n) space
Range tree - O(n logn) preprocessing time, O(k+logn) query time, O(n) space
Binary Indexed tree - O(n logn) preprocessing time, O(logn) query time, O(n) space
(k is the number of reported results).

All data structures can be dynamic, in the sense that 
the usage scenario includes both data changes and queries:

Segment tree - interval can be added/deleted in O(logn) time (see here)
Interval tree - interval can be added/deleted in O(logn) time
Range tree - new points can be added/deleted in O(logn) time (see here)
Binary Indexed tree - the items-count per index can be increased in O(logn) time
Higher dimensions (d>1):

Segment tree - O(n(logn)^d) preprocessing time, O(k+(logn)^d) query time, O(n(logn)^(d-1)) space
Interval tree - O(n logn) preprocessing time, O(k+(logn)^d) query time, O(n logn) space
Range tree - O(n(logn)^d) preprocessing time, O(k+(logn)^d) query time, O(n(logn)^(d-1))) space
Binary Indexed tree - O(n(logn)^d) preprocessing time, O((logn)^d) query time, O(n(logn)^d) space






########################## HASH MAP AND HASH SET NOTES ###############################3

Hashing vs. Balanced Search Trees
Advantages of Balanced Search Trees
O(log n) worst-case operation cost
Does not require any assumptions, special functions,
or known properties of input distribution
No wasted space
Never need to rebuild the entire structure


Advantages of Hash Tables
O(1) cost, but only on average
Flexible load factor parameters
Cuckoo hashing achieves O(1) worst-case for search & delete

How to handle Collisions?
There are mainly two methods to handle collision:
1) Separate Chaining
2) Open Addressing

Collision Resolution
Even the best hash function may have collisions:
when we want to insert (k, v ) into the table,
but T [h(k)] is already occupied.
Two basic strategies:
Allow multiple items at each table location (buckets)
Allow each item to go into multiple locations (open addressing)

We will examine the average cost of search, insert, delete,
in terms of n, M, and/or the load factor α = n/M.

n is number of items in hash table, M is number of spots 
Requirement: For a given M ∈ N,
every key k is an integer with 0 ≤ k < M.

We probably want to rebuild the whole hash table and change
the value of M when the load factor gets too large or too small.
This is called rehashing , and should cost roughly Θ(M + n).

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
SEPERATE CHAINING VS OPEN ADDRESSING PERFORMACNE

Separate Chaining
Keys are stored inside the hash table as well as outside the hash table.	
The number of keys to be stored in the hash table can even exceed the size of the hash table.	
Deletion is easier.	
Extra space is required for the pointers to store the keys outside the hash table.	
Cache performance is poor. This is because of linked lists which store the keys outside the hash table.
Some buckets of the hash table are never used which leads to wastage of space.

Open Addressing
All the keys are stored only inside the hash table.
No key is present outside the hash table.
The number of keys to be stored in the hash table can never exceed the size of the hash table.
Deletion is difficult.
No extra space is required.
Cache performance is better.This is because here no linked lists are used.
Buckets may be used even if no key maps to those particular buckets.

Separate Chaining-
Separate Chaining is advantageous when it is required to perform
all the following operations on the keys stored in the hash table-
Insertion Operation
Deletion Operation
Searching Operation
NOTE-
Deletion is easier in separate chaining.
This is because deleting a key from the hash table does not affect the other keys stored in the hash table.
 
Open Addressing-
Open addressing is advantageous when it is required to perform only 
the following operations on the keys stored in the hash table-
Insertion Operation
Searching Operation
NOTE-
Deletion is difficult in open addressing.
This is because deleting a key from the hash table requires some extra efforts.
After deleting a key, certain keys have to be rearranged.


Seperate Chaining >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> 

Each table entry is a bucket containing 0 or more KVPs.
This could be implemented by any dictionary (even another hash table!).
The simplest approach is to use an unsorted linked list in each bucket.
This is called collision resolution by chaining .

search(k): Look for key k in the list at T [h(k)].
insert(k, v ): Add (k, v ) to the front of the list at T [h(k)].
delete(k): Perform a search, then delete from the linked list.

The bucket chains are often searched sequentially using the order 
the entries were added to the bucket. If the load factor is large 
and some keys are more likely to come up than others, then rearranging 
the chain with a move-to-front heuristic may be effective. More sophisticated data structures, 
such as balanced search trees, are worth considering only if the load factor is large (about 10 or more), 
or if the hash distribution is likely to be very non-uniform, or if one must guarantee good performance 
even in a worst-case scenario. However, using a larger table and/or a 
better hash function may be even more effective in those cases.

Advantages:
1) Simple to implement.
2) Hash table never fills up, we can always add more elements to the chain.
3) Less sensitive to the hash function or load factors.
4) It is mostly used when it is unknown how many and how frequently keys may be inserted or deleted.

Disadvantages:
1) Cache performance of chaining is not good as keys are stored using a linked list. 
    Open addressing provides better cache performance as everything is stored in the same table.
2) Wastage of Space (Some Parts of hash table are never used)
3) If the chain becomes long, then search time can become O(n) in the worst case.
4) Uses extra space for links.

Implementing hash table using Chaining through Doubly Linked List is similar to 
implementing Hashtable using Singly Linked List. The only difference is that every 
node of Linked List has the address of both, the next and the previous node. This 
will speed up the process of adding and removing elements from the list, hence the 
time complexity will be reduced drastically.

Some chaining implementations store the first record of each chain in the 
slot array itself.[4] The number of pointer traversals is decreased 
by one for most cases. The purpose is to 
increase cache efficiency of hash table access.




Recall the load balance α = n/M.
Assuming uniform hashing, average bucket size is exactly α.
Analysis of operations:
search Θ(1 + α) average-case, Θ(n) worst-case
insert O(1) worst-case, since we always insert in front.
delete Same cost as search: Θ(1 + α) average, Θ(n) worst-case
If we maintain M ∈ Θ(n), then average costs are all O(1).
This is typically accomplished by rehashing whenever n < c 1 M or n > c 2 M,
for some constants c 1 , c 2 with 0 < c 1 < c 2 .


Open addressing >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>.:

Main idea: Each hash table entry holds only one item,
but any key k can go in multiple locations.
search and insert follow a probe sequence of possible locations for key k:
<h(k, 0), h(k, 1), h(k, 2), . . .>

delete becomes problematic; we must distinguish between
empty and deleted locations.


Simplest idea: linear probing
h(k, i) = (h(k) + i) mod M, for some hash function h.

SO BASICALLY, when you see a collision in hash keys, just put it in the first empty array spot that you
identify by probing linearly, increase the index by 1 each time. If we linear probe until the end of the array
wrap around and start probing from index 0 of the array. This is done when you mod it by M above to search for 
empty array spot.

When you delete something, MARK THAT ARRAY SPOT AS DELETED SO IT THE FOLLOWING REMAINS TRUE:
    During insertion, the buckets marked as “deleted” are treated like any other empty bucket.
    During searching, the search is not terminated on encountering the bucket marked as “deleted”.
    The search terminates only after the required key or an empty bucket is found.

Well-known probe sequences include:
Linear probing, in which the interval between probes is fixed (usually 1)

Quadratic probing, in which the interval between probes is increased by adding the 
successive outputs of a quadratic polynomial to the 
starting value given by the original hash computation

Double hashing, in which the interval between probes is computed by a second hash function
Double hashing is a collision resolving technique in Open Addressed Hash tables. 
Double hashing uses the idea of applying a second hash function to key when a collision occurs.

Double hashing can be done using :
(hash1(key) + i * hash2(key)) % TABLE_SIZE
Here hash1() and hash2() are hash functions and TABLE_SIZE
is size of hash table.

(We repeat by increasing i when collision occurs)
First hash function is typically hash1(key) = key % TABLE_SIZE

A popular second hash function is : hash2(key) = PRIME – (key % PRIME) 
where PRIME is a prime smaller than the TABLE_SIZE.

A good second Hash function is:
    - It must never evaluate to zero
    - Must make sure that all cells can be probed

Uniform Hashing Assumption: Each hash function value is equally likely.
Proving is usually impossible, as it requires knowledge of
the input distribution and the hash function distribution.
We can get good performance by following a few rules.
A good hash function should:
    be very efficient to compute
    be unrelated to any possible patterns in the data
    depend on all parts of the key
If all keys are integers (or can be mapped to integers),
the following two approaches tend to work well:
Division method: h(k) = k mod M.
We should choose M to be a prime.

Multiplication method: h(k) = floor(M(kA − floor(kAc)),
for some constant floating-point
number A with 0 < A < 1. -> Knuth suggests A = 0.618

What if the keys are multi-dimensional, such as strings?
Standard approach is to flatten string w to integer f (w ) ∈ N, e.g.
A · P · P · L · E
→ 65 · 80 · 80 · 76 · 69

→ 65R^4 + 80R^3 + 80R^2 + 76R^1 + 68R^0
(for some radix R, e.g. R = 255)
We combine this with a standard hash function
h : N → {0, 1, 2, . . . , M − 1}.
With h(f (k)) as the hash values, we then use any standard hash table.
Note: computing each h(f(k)) takes Ω(length of w) time

So, under uniform hashing, we assume the probability that a key k
has h1(k) = a and h2(k) = b, for any particular a and b, is 1/(M^2)
For double hashing , define h(k, i) = h1(k) + i · h2(k) mod M.
search, insert, delete work just like for linear probing,
but with this different probe sequence.


1. Linear Probing-
In linear probing,
When collision occurs, we linearly probe for the next bucket.
We keep probing until an empty bucket is found.
Advantage-
It is easy to compute.
Disadvantage-
The main problem with linear probing is clustering.
Many consecutive elements form groups.
Then, it takes time to search an element or to find an empty bucket.
 
Time Complexity-
Worst time to search an element in linear probing is O (table size).
This is because-
Even if there is only one element present and all other elements are deleted.
Then, “deleted” markers present in the hash table makes search the entire table.
 
2. Quadratic Probing-
In quadratic probing,
When collision occurs, we probe for i2‘th bucket in ith iteration.
We keep probing until an empty bucket is found.
 
3. Double Hashing-
In double hashing,
We use another hash function hash2(x) and look for i * hash2(x) bucket in ith iteration.
It requires more computation time as two hash functions need to be computed.

Linear Probing has the best cache performance but suffers from clustering.
Quadratic probing lies between the two in terms of cache performance and clustering.
Double caching has poor cache performance but no clustering.


A drawback of all these open addressing schemes is that the number of stored entries cannot 
exceed the number of slots in the bucket array. In fact, even with good hash functions, 
their performance dramatically degrades when the load factor grows beyond 0.7 or so. 
For many applications, these restrictions mandate the use of dynamic resizing, 
with its attendant costs.

Open addressing schemes also put more stringent requirements on the hash function: 
besides distributing the keys more uniformly over the buckets, the function must also 
minimize the clustering of hash values that are consecutive in the probe order. Using 
separate chaining, the only concern is that too many objects map to the same hash value; 
whether they are adjacent or nearby is completely irrelevant.[citation needed]

Open addressing only saves memory if the entries are small (less than four times the size of a pointer) 
and the load factor is not too small. If the load factor is close to zero (that is, there are far more 
buckets than stored entries), open addressing is wasteful even if each entry is just two words.

This graph compares the average number of cache misses 
required to look up elements in tables with chaining 
and linear probing. As the table passes the 80%-full mark, 
linear probing's performance drastically degrades.

Open addressing avoids the time overhead of allocating each new entry record, and 
can be implemented even in the absence of a memory allocator. It also avoids the extra 
indirection required to access the first entry of each bucket (that is, usually the only one). 
It also has better locality of reference, particularly with linear probing. With small record sizes, 
these factors can yield better performance than chaining, particularly for lookups. Hash tables with 
open addressing are also easier to serialize, because they do not use pointers.[citation needed]

On the other hand, normal open addressing is a poor choice for large elements, because these 
elements fill entire CPU cache lines (negating the cache advantage), and a large amount of space 
is wasted on large empty table slots. If the open addressing table only stores references to 
elements (external storage), it uses space comparable to chaining even for large records 
but loses its speed advantage.[citation needed]

Generally speaking, open addressing is better used for hash tables with small 
records that can be stored within the table (internal storage) and fit in a cache line. 
They are particularly suitable for elements of one word or less. If the table is expected 
to have a high load factor, the records are large, or the data is variable-sized, 
chained hash tables often perform as well or better.

>>>>>>>>>>>>>>(TODO) talk about Coalesced hashing

A hybrid of chaining and open addressing, coalesced hashing links together 
chains of nodes within the table itself.[18] Like open addressing, 
it achieves space usage and (somewhat diminished) cache advantages over 
chaining. Like chaining, it does not exhibit clustering effects; 
in fact, the table can be efficiently filled to a high density. 
Unlike chaining, it cannot have more elements than table slots.

>>>>>>>>>>>>>>>>>>> CUCKOO HASHING

This is a relatively new idea from Pagh and Rodler in 2001.
Again, we use two independent hash functions h1 , h2.
The idea is to always insert a new item into h1(k).

This might “kick out” another item, which we then attempt to re-insert
into its alternate position.

Insertion might not be possible if there is a loop.

In this case, we have to rehash with a larger M.

The big advantage is that an element with key k
can only be in T [h1(k)] or T[h2(k)]. (WORST CASE O(1) LOOKUP!!)

cuckoo-insert(T,x)
T : hash table, x: new item to insert
1.  y ← x, i ← h1(x.key)
2.  do at most n times:
3.      swap(y , T [i])
4.      if y is “empty” then return “success”
5.      if i = h1(y.key) then i ← h2 (y.key)
6.      else i ← h 1 (y .key )
7.  return “failure”

 By combining multiple hash functions with multiple cells per bucket, very high space utilization can be achieved.

>>>>>>>>>>>>>>> HOPSCOTCH HASHING
(TODO FINISH THIS: https://en.wikipedia.org/wiki/Hash_table#Separate_chaining_with_list_head_cells)

>>>>>>>>>>>>>>>> ROBIN HOOD HASHING

>>>>>>>>>>>>>>>> TWO CHOICE HASHING

2-choice hashing employs two different hash functions, h1(x) and h2(x), 

for the hash table. Both hash functions are used to compute two table locations. 
When an object is inserted in the table, it is placed in the table location that 
contains fewer objects (with the default being the h1(x) table location if there 
is equality in bucket size). 2-choice hashing employs the principle of 
the power of two choices.[25]


>>>>>>>>>>>>>>>> HASH TABLE CACHE PERFORMANCE EXPLAINED;

So my questions are:
What causes chaining to have a bad cache performance?

Where is the cache being used?

Why would open addressing provide better cache performance as 

I cannot see how the cache comes into this?

Also what considerations what you take into account when deciding 
between chaining and linear probed open addressing 
and quadratic probed open addressing?

Sorry, due to quite wide questions, the answers also will be 
quite generic with some links for more detailed information.

It is better to start with the question:

Where is the cache being used?

On modern CPUs, cache is used everywhere: to read program instructions 
and read/write data in memory. On most CPUs cache is transparent, i.e. 
there is no need to explicitly manage the cache.

Cache is much faster than the main memory (DRAM). Just to give 
you a perspective, accessing data in Level 1 cache is ~4 CPU cycles, 
while accessing the DRAM on the same CPU is ~200 CPU cycles, 
i.e. 50 times faster.

Cache operate on small blocks called cache lines, 
which are usually 64 bytes long.

More info: https://en.wikipedia.org/wiki/CPU_cache

What causes chaining to have a bad cache performance?

Basically, chaining is not cache friendly. It is not only 
about this case in the hash tables, 
same issue with "classical" lists.

Hash keys (or list nodes) are far away from each other, 
so each key access generates a "cache miss", i.e. 
slow DRAM access. So checking 10 keys in a chain takes 
10 DRAM accesses, i.e. 200 x 10 = 2000 cycles for our generic CPU.

The address of the next key is not known until a next pointer is 
read in the current key, so there is not much room for an optimization...

Why would open addressing provide better cache performance 
as I cannot see how the cache comes into this?

Linear probing is cache friendly. Keys are "clustered" together, 
so once we accessed the first key (slow DRAM access), most probably the 
next key will be already in cache, since the cache line is 64 bytes. 
So accessing the same 10 keys with open addressing takes 1 DRAM access 
and 9 cache accesses, i.e. 200 x 1 + 9 x 4 = 236 cycles for our generic CPU. 
It is much faster than 2000 cycles for chained keys.

Also, since we access the memory in predictable manner, there 
is a room for optimizations like cache prefetching: 
https://en.wikipedia.org/wiki/Cache_prefetching

Also what considerations what you take into account when deciding 
between chaining and linear probed open addressing and 
quadratic probed open addressing?

Chaining or linear probing is not a good sign anyway. 
So the first thing I would consider is to make sure the probability 
of collisions is at minimum by using a good hash function and reasonable hash size.

The second thing I would consider is a ready to use solution. 
Sure, there are still might be some rare 
cases when you need your own implementation...

Not sure about the language, but here is blazingly fast hash 
table implementation with BSD license: http://dpdk.org/browse/dpdk/tree/lib/librte_hash/rte_cuckoo_hash.h

So, if you still need your own hash table implementation and 
you do care about performance, the next quite easy thing to 
implement would be to use cache aligned buckets instead 
of plain hash elements. It will waste few bytes per each element 
(i.e. each hash table element will be 64 bytes long), but in case 
of a collision there will be some fast storage for at least few keys. 
The code to manage those buckets will be also a bit more complicated, 
so it is a thing to consider if it is worth for you to bother...


########################%#################################
HASHMAPS:  LOAD FACTOR AND REHASHING
How hashing works:

For insertion of a key(K) – value(V) pair into a hash map, 2 steps are required:

K is converted into a small integer (called its hash code) using a hash function.

The hash code is used to find an index (hashCode % arrSize) and the entire linked list 
at that index(Separate chaining) is first searched for the presence of the K already.

If found, it’s value is updated and if not, the K-V pair is stored as a new node in the list.
Complexity and Load Factor

For the first step, time taken depends on the K and the hash function.
For example, if the key is a string “abcd”, then it’s hash function may depend 
on the length of the string. But for very large values of n, the number of entries 
into the map, length of the keys is almost negligible in comparison to n so hash 
computation can be considered to take place in constant time, i.e, O(1).

For the second step, traversal of the list of K-V pairs present at that index needs to be done. 
For this, the worst case may be that all the n entries are at the same index. 
So, time complexity would be O(n). But, enough research has been done to make 
hash functions uniformly distribute the keys in the array so this almost never happens.

So, on an average, if there are n entries and b is the size of the array 
there would be n/b entries on each index. This value n/b is called the 
load factor that represents the load that is there on our map.

This Load Factor needs to be kept low, so that number of entries at 
one index is less and so is the complexity almost constant, i.e., O(1).

Rehashing:

As the name suggests, rehashing means hashing again. 
Basically, when the load factor increases to more than its pre-defined value 
(default value of load factor is 0.75), the complexity increases. So to overcome this, 
the size of the array is increased (doubled) and all the values are hashed again and 
stored in the new double sized array to maintain a low load factor and low complexity.

Why rehashing?

Rehashing is done because whenever key value pairs are inserted into the map, 
the load factor increases, which implies that the time complexity also increases 
as explained above. This might not give the required time complexity of O(1).

Hence, rehash must be done, increasing the size of the bucketArray so 
as to reduce the load factor and the time complexity.

How Rehashing is done?

Rehashing can be done as follows:

For each addition of a new entry to the map, check the load factor.
If it’s greater than its pre-defined value (or default value of 0.75 if not given), then Rehash.
For Rehash, make a new array of double the previous size and make it the new bucketarray.
Then traverse to each element in the old bucketArray and call the insert() 
for each so as to insert it into the new larger bucket array.

########################### HASH SET ################### (OPEN ADDRESSING SOLUTION)

This implementation was based on some data structures concepts 
and what I've read about Python's dict implementation.

The underlying structure that my hash set uses is a list. The list simply contains 
a key at the index the key is hashed to, unless there are multiple keys 
at the same index (ie a collision). More on that later...

My hashset is designed to use a limited amount of memory, but expands itself by a factor of 2 
when the load factor (size divided by array spots) exceeds 2/3. 
This will allow for O(1) operations on average. The downside to this is that every time the 
hashset doubles, it has to create a new list and rehash every element which takes O(n) each time. 
The average time will be O(1) for each add call as the cost of rehashing the set is amortized over the calls.

Open addressing and chaining each have their own advantages and disadvantages. I'm not 
going to explain the nuances of the methods, but know that chaining hash sets/tables 
have the head of a linked list of keys in each array spot, 
while open addressing just moves the key to an empty index.

I used open addressing for this problem. If we add an element that is hashed to the same 
index as another key, then we apply a secondary operation on the index until we 
find an empty spot (or a previously removed spot). This is called double hashing.
The formula I used is similar to that of the Python dict implementation, 
but without the perturb part. This is better than linear probing since the 
hash function (which just mods the key by the capacity of the list) is likely 
to fill contiguous array spots and double hashing makes the probability 
of finding an empty spot more uniform in those cases than linear probing.

For removing, the removed element is replaced by a tombstone so that 
the contains function won't get messed up when the path to an existing 
element has an empty spot in it, causing the contains function to return 
false. The add function will know that 
tombstones are able to be replaced by new elements.

class MyHashSet(object):

    def __init__(self):
        """
        Initialize your data structure here.
        """
        self.capacity = 8
        self.size = 0
        self.s = [None]*8
        self.lf = float(2)/3
        
    def myhash(self, key): # can be modified to hash other hashable objects like built in python hash function
        return key%self.capacity
        

    def add(self, key):
        """
        :type key: int
        :rtype: void
        """
        if float(self.size)/self.capacity >= self.lf:
            self.capacity <<= 1
            ns = [None]*self.capacity
            for i in range(self.capacity >> 1):
                if self.s[i] and self.s[i] != "==TOMBSTONE==":
                    n = self.myhash(self.s[i])
                    while ns[n] is not None:
                        n = (5*n+1)%self.capacity
                    ns[n] = self.s[i]
            self.s = ns
        h = self.myhash(key)
        while self.s[h] is not None:
            if self.s[h] == key:
                return
            h = (5*h + 1) % self.capacity
            if self.s[h] == "==TOMBSTONE==":
                break
        self.s[h] = key
        self.size += 1
        
        

    def remove(self, key):
        """
        :type key: int
        :rtype: void
        """
        h = self.myhash(key)
        while self.s[h]:
            if self.s[h] == key:
                self.s[h] = "==TOMBSTONE=="
                self.size -= 1
                return
            h = (5*h+1)%self.capacity
        
    def contains(self, key):
        """
        Returns true if this set contains the specified element
        :type key: int
        :rtype: bool
        """
        h = self.myhash(key)
        while self.s[h] is not None:
            if self.s[h] == key:
                return True
            h = (5*h + 1)%self.capacity
        return False


#################################### HASH MAP ################################### (OPEN CHAINING)
### THIS SOLUTION SHOULD USE LOAD FACTORS! => LIKE THE SOLUTION ABOVE.


# using just arrays, direct access table
# using linked list for chaining

class ListNode:
    def __init__(self, key, val):
        self.pair = (key, val)
        self.next = None

class MyHashMap:

    def __init__(self):
        """
        Initialize your data structure here.
        """
        self.m = 1000;
        self.h = [None]*self.m
        

    def put(self, key, value):
        """
        value will always be non-negative.
        :type key: int
        :type value: int
        :rtype: void
        """
        index = key % self.m
        if self.h[index] == None:
            self.h[index] = ListNode(key, value)
        else:
            cur = self.h[index]
            while True:
                if cur.pair[0] == key:
                    cur.pair = (key, value) #update
                    return
                if cur.next == None: break
                cur = cur.next
            cur.next = ListNode(key, value)
        

    def get(self, key):
        """
        Returns the value to which the specified key is mapped, or -1 if this map contains no mapping for the key
        :type key: int
        :rtype: int
        """
        index = key % self.m
        cur = self.h[index]
        while cur:
            if cur.pair[0] == key:
                return cur.pair[1]
            else:
                cur = cur.next
        return -1
            
    def remove(self, key):
        """
        Removes the mapping of the specified value key if this map contains a mapping for the key
        :type key: int
        :rtype: void
        """
        index = key % self.m
        cur = prev = self.h[index]
        if not cur: return
        if cur.pair[0] == key:
            self.h[index] = cur.next
        else:
            cur = cur.next
            while cur:
                if cur.pair[0] == key:
                    prev.next = cur.next
                    break
                else:
                    cur, prev = cur.next, prev.next
                


# Your MyHashMap object will be instantiated and called as such:
# obj = MyHashMap()
# obj.put(key,value)
# param_2 = obj.get(key)
# obj.remove(key)


###########################################################################################################################
################################# SKIP LIST


###########################################################################################################################
################################# CIRCULAR DEQUE:


###########################################################################################################################
################################# CIRCULAR QUEUE




###############################################################################
################################################################################

PLEASE FINISH YOUR NOTES ON FRACTIONAL CASCADING!!


Improving Binary search with fractional cascading!

    Things become more interesting when we have to perform an 
    iterative binary search on k lists in which we find the target 
    value in each of the k lists independently. The problem statement could be formally defined as

    Given k lists of n sorted integers each, and a target value x, return the 
    position of the smallest value greater than or equal to x in each of the k lists. 
    Preprocessing of the list is allowed before answering the queries.  


    Naive approach do binary search in each list -> klogn

    Second approach (memory expensive):
    Unified binary search
    This approach uses some extra space, preprocessing and computations to reduce search time. The preprocessing actually involves precomputing the positions of all elements in all the k lists. This precomputation enables us to perform just one binary search and get the required precalculated positions in one go.

    Preprocess
    The preprocessing is done in two phases; in the first phase, we compute a position tuple for each element and associate it with the same. In phase two of preprocessing, we create an auxiliary list containing all the elements of all the lists, on which we then perform a binary search for the given target value.

    FRACTIONAL CASCADING APPROACH:

    Fractional cascading is a technique through which we speed up the 
    iterative binary searches by creating bridges between the lists. 
    The main idea behind this approach is to dampen the need to perform 
    binary searches on subsequent lists after performing the search on one.

    In the k-binary searches approach, we solved the problem by performing k 
    binary searches on k lists. If, after the binary search on the first list, 
    we would have known a range within which the target value was present in the 
    2nd list, we would have limited our search within that subset which helps us 
    save a bunch of computation time. The bridges, defined above, provides us 
    with a shortcut to reach the subset of the other list where that target value would be present.


    Fractional cascading is just an idea through which we could speed up binary searches, 
    implementations vary with respect to the underlying data. The bridges could be 
    implemented using pointers, graphs, or array indexes.

    Preprocess
    Preprocessing is a super-critical step in fractional cascading because it is 
    responsible for speeding up the iterative binary searches. Preprocessing actually 
    sets up all the bridges from all the elements from one list to the range of items 
    in the lower list where the element could be found. These bridges then 
    cascade to all the lists on the lower levels.

    Create Auxiliary Lists
    The first step in pre-processing is to create k auxiliary lists from k original lists. 
    These lists are created bottom-up which means lists on the lower levels are created 
    first - M(i+1) is created before M(i). An auxiliary list M(i) is created as a 
    sorted list of elements of the original list L(i) and half of the previously 
    created auxiliary list M(i+1). The half elements of auxiliary lists are 
    chosen by picking every other element from it.

    Create Auxiliary Lists

    By picking every other element from lower-level lists, we fill the gaps in 
    value ranges in the original list L(i), giving us a uniform spread of values across 
    all auxiliary lists. Another advantage of picking every other element is that we eradicate 
    the need for performing binary searches on subsequent lists altogether. Now we only need to 
    perform a binary search for list M(0) and for every other list, we only need to check the 
    element we reach via the bridge and an element before that - a constant time comparison.

    Position tuples
    A position tuple for Fractional Cascading is a 2 item tuple, associated with 
    each element of the auxiliary list, where the first item is the position of the 
    element in the original list on the same level - serving as the required position - 
    and the second element is the position of the element in the auxiliary list on 
    the lower level - serving as the bridge from one level to another.

    Create position pointerss

    The position tuple for each element in the auxiliary array can be created by 
    doing a binary search on the original list and the auxiliary list on the lower 
    level. Given a 2-dimensional array arr and auxiliary lists m_arr we compute the 
    position tuples for element (i, j) by performing a binary search on all k original 
    and auxiliary lists as shown in python code below

    for i, l in enumerate(m_arr):
        for j, m in enumerate(m_arr[i]):
            pointers[i][j] = [
                bisect.bisect_left(arr[i], m_arr[i][j]),
                bisect.bisect_left(m_arr[i+1], m_arr[i][j]),
            ]
            
    Fractional Cascading in action
    We start by performing a binary search on the first auxiliary list M(0) from which we get the element corresponding to the target value. The position tuple for this element contains the position corresponding to the original list L(0) and bridge that will take us to the list M(1). Now when we move to the list M(1) through the bridge and have reached the index b.

    Since auxiliary lists have uniform range spread, because of every other element being promoted, we are sure that the target value should be checked again at the index b and b - 1; because if the value was any lower it would have been promoted and bridged to other value and hence the trail we trace would be different from what we are tracing now.

    Once we know which of the b and b-1 index to pick (depending on the values at the index and the target value) we add the first item of the position tuple to the solution set and move the auxiliary list on the lower level and the entire process continues.

    Once we reach the last auxiliary list and process the position tuple there and pick the element, our solution set contains the required positions and we can stop the iteration.

    def get_locations_fractional_cascading(x): 
        locations = []

        # the first and only binary search on the auxiliary list M[0]
        index = bisect.bisect_left(m_arr[0], x)

        # loc always holds the required location from the original list on same level
        # next_loc holds the bridge index on the lower level
        loc, next_loc = pointers[0][index]

        # adding loc to the solution
        locations.append(loc)

        for i in range(1, len(m_arr)):
            # we check for the element we reach through the bridge
            # and the one before it and make the decision to go with one
            # depending on the target value.
            if x <= m_arr[i][next_loc-1]:
                loc, next_loc = pointers[i][next_loc-1]
            else:
                loc, next_loc = pointers[i][next_loc]

            # adding loc to the solution
            locations.append(loc)

        # returning the required locations
        return locations
    The entire working code could be found here github.com/arpitbbhayani/fractional-cascading  