diff a/ALGO_README.md b/ALGO_README.md	(rejected hunks)
@@ -71,856 +71,1247 @@ TOPICS TO UNDERSTAND:
 
 THESE ARE HARMAN'S PERSONAL SET OF PARADIGMS/ INTERVIEW NOTES:
 
--104) FIND RIGHT INTERVAL C++ WITH PRIORITY QUEUE (fast solution):
-      (2 ARRAY INTERVAL SOLUTIONS WITH SORTED START END TIMES + POINTERS)
-
-    
-
 
+-117) Learn to simplify your thoughts after finding a soln. You make a bunch of assumptions but you actually need less assumptions to solve the problem.
+      Stop adding so many artificial constraints yourself, and think beyound about your own assumptons to solution!!
 
 
+      Find Peak Element 1D 
+        162. Find Peak Element
+        Medium
 
--103) FIND RIGHT INTERVAL C++ WITH PRIORITY QUEUE (slow solution):
-    Find Right Interval
-    Medium
-    You are given an array of intervals, where 
-    intervals[i] = [starti, endi] and each starti is unique.
+        5689
 
-    The right interval for an interval i is an interval j 
-    such that startj >= endi and startj is minimized.
+        3628
 
-    Return an array of right interval indices for each interval i. 
-    If no right interval exists for interval i, then put -1 at index i.
+        Add to List
 
-    Example 1:
+        Share
+        A peak element is an element that is strictly greater than its neighbors.
+        Given an integer array nums, find a peak element, and return its index. If the array contains multiple peaks, return the index to any of the peaks.
+        You may imagine that nums[-1] = nums[n] = -∞.
+        You must write an algorithm that runs in O(log n) time.
 
-    Input: intervals = [[1,2]]
-    Output: [-1]
-    Explanation: There is only one interval in the collection, so it outputs -1.
-    Example 2:
+        
+        Example 1:
 
-    Input: intervals = [[3,4],[2,3],[1,2]]
-    Output: [-1,0,1]
-    Explanation: There is no right interval for [3,4].
-    The right interval for [2,3] is [3,4] since start0 = 3 is the smallest start that is >= end1 = 3.
-    The right interval for [1,2] is [2,3] since start1 = 2 is the smallest start that is >= end2 = 2.
-    Example 3:
+        Input: nums = [1,2,3,1]
+        Output: 2
+        Explanation: 3 is a peak element and your function should return the index number 2.
+        Example 2:
 
-    Input: intervals = [[1,4],[2,3],[3,4]]
-    Output: [-1,2,-1]
-    Explanation: There is no right interval for [1,4] and [3,4].
-    The right interval for [2,3] is [3,4] since start2 = 3 is the smallest start that is >= end1 = 3.
+        Input: nums = [1,2,1,3,5,6,4]
+        Output: 5
+        Explanation: Your function can return either index number 1 where the peak element is 2, or index number 5 where the peak element is 6.
 
 
-    class Solution {
-        public:
-            vector<int> findRightInterval(vector<vector<int>>& intervals) {
-                // sort by start time. 
-                // then just choose the right interval as you go through? 
-                /*
-                sorting + binary search?
-                sorting + heap?
-                sorting + treemap? 
-                sorting + 2 arrays [ayyy the best soln ]
-                
-                The reason we shoud seek something faster than heap/treemap is because
-                we are dealing with static data that doesnt change, and those structures are used 
-                for dynamic data, hence 2 array soln. 
-                */    
-                
-                //loop through intervals and save the index as part of tuple!
-                for(int i = 0; i != intervals.size(); ++i) {
-                    intervals[i].push_back(i);
-                }
-                
-                sort(intervals.begin(), intervals.end(), [](auto x, auto y) { return x[0] < y[0];});
+        class Solution:
+            def findPeakElement(self, nums: List[int]) -> int:
+                l = 0 
+                r = len(nums) - 1 
                 
-                // sort by largest finish time at top!
-                // IF YOU LOOK AT CMP, TO DO LEAST TO GREATEST, YOU ACTUALLY HAVE TO INVERSE
-                // so its not a[1] < b[1] like in sort function above but a[1] > b[1]
-                auto cmp = [](vector<int> a, vector<int>  b) {return a[1] > b[1];};
-                priority_queue< vector<int>, vector< vector<int> >, decltype(cmp)> pq(cmp);
+                # just append -inf to front and end of array!
+                # kills log n behavior! =c
                 
-                vector<int> res;
-                res.resize(intervals.size());
+                # deal with size = 0 array here. 
                 
-                for(int i = 0; i!= intervals.size(); ++i) {
-                    vector<int> inte = intervals[i];
+                while l < r:
+                    # right bias used here just for fun
+                    mid = l + (r-l + 1)//2
+                    # if mid == 0 && 
                     
-                    while(pq.size() > 0 && pq.top()[1] <= inte[0]) {
-                        res[pq.top()[2]] = inte[2];
-                        pq.pop();
-                    }
-                    pq.push(inte);
-                }
+                    leftElement = nums[mid-1] if mid - 1 >= 0 else float("-inf")
+                    rightElement = nums[mid + 1] if mid + 1 < len(nums) else float("-inf")
+                    
+                    if nums[mid] > leftElement and nums[mid] > rightElement:
+                        return mid
+                    
+                    elif leftElement < nums[mid] and nums[mid] < rightElement: 
+                        # ok so its on right side
+                        l = mid 
+                    else:
+                        r = mid - 1
                 
-                while(pq.size() > 0) {
-                    res[pq.top()[2]] = -1;
-                    pq.pop();
+                # returning either l or r works here. 
+                return r
+        
+
+        Much simpler soln: (you need to take out that BS assumption!) -> otherwise followup problems become much harder
+        
+        public class Solution {
+            public int findPeakElement(int[] nums) {
+                int l = 0, r = nums.length - 1;
+                while (l < r) {
+                    int mid = (l + r) / 2;
+                    if (nums[mid] > nums[mid + 1])
+                        r = mid;
+                    else
+                        l = mid + 1;
                 }
-                return res; 
+                return l;
             }
-    };
+        }
 
 
 
 
+-116) Identifying when DP is needed and BITMASK DP
 
--102) BINARY SEARCH AND THE TEMPLATES: 
+        [* H * * * ]
+        [H * * * * ]
+        [ * * * * H]
+        [ * * H * *]
 
-        1.   Peak Index in a Mountain Array
-        Let's call an array arr a mountain if the following properties hold:
-        arr.length >= 3
-        There exists some i with 0 < i < arr.length - 1 such that:
-        arr[0] < arr[1] < ... arr[i-1] < arr[i]
-        arr[i] > arr[i+1] > ... > arr[arr.length - 1]
-        Given an integer array arr that is guaranteed to be a mountain, 
-        return any i such that arr[0] < arr[1] < ... arr[i - 1] < arr[i] > arr[i + 1] > ... > arr[arr.length - 1].
+        2D matrix, H stands for house, * stands for empty spots and these empty spots can be planted with trees
+        Find the minium number of trees need to be planted and they will be neighbouring to each house, and the neighbouring condition is 8 directions neighbored
 
-        Example 1:
+        the answer should be ( t stands for trees)
+        [* H * * * ]
+        [H t * * * ]
+        [ * * * t H]
+        [ * * H * *]
 
-        Input: arr = [0,1,0]
-        Output: 1
-        Example 2:
+    Initial idea (Greedy):
+        you can collect the trees all around the houses.
+        Then you can take the tree that covers the max number of houses, 
+        remove that tree, then compute the next tree that covers the max number of houses,
+        and end it.
 
-        Input: arr = [0,2,1,0]
-        Output: 1
+    The greedy soln doesnt work for the following case: 
+        * * * H * * *
+        * * * * * * *
+        * * * H * * *
+        H * H * H * H
+        * * * H * * *
+        * * * * * * *
+        * * * H * * *
+        This only takes 4 trees to plant optimally, but with your algorithm it'd take 5. I think that this problem is NP-hard, and that we'll need DP to solve it.
 
-        class Solution {
-            public:
-            int peakIndexInMountainArray(vector<int>& arr) {
-                int low = 0;
-                int high = arr.size();
 
-                while(low < high) {
-                    int mid = low + (high - low)/2;
-                    
-                    /*
-                    if(mid - 1 < 0) {
-                        low = low+1;
-                        continue;
-                    }    
-                    if(mid + 1 >= arr.size()) {
-                        high = high-1; 
-                        continue;
-                    }
-                    */
-                    
-                    int left = arr[mid-1];
-                    int right= arr[mid+1];
-                    
-                    if(left < arr[mid] && arr[mid] < right) {
-                        // search right side 
-                        low = mid + 1;
-                    } else if(left < arr[mid] && arr[mid] > right) {
-                        return mid; 
-                    } else if(left > arr[mid] && arr[mid] > right) {
-                        high = mid;
-                    } 
-                }
-                return -9999999; // should never reach this. 
-            }
-        };
+    -> Ok so DP.
+    
+    At the very start of DP what you want to do is try to write out the recursion and do what you think will happen and 
+    that will pwoer your bottom up! Lets try it.
 
+    If you solve recursively, you have to take or not take certain tree locations, 
+    and that will update the subset of houses that are covered.
+    Label each house 1 to N, and then you can start taking subsets of 1 to N. 
+    You can also just use a bitmask instead of a set()
 
--101.7) Binary Search with chocolates:
+    Like this:
 
-     Divide Chocolate
-     You have one chocolate bar that consists of some chunks. 
-     Each chunk has its own sweetness given by the array sweetness.
+    def soln(grid):
+        N = len(grid)
+        M = len(grid[0])
+        treeLocations = []
 
-     You want to share the chocolate with your K friends so you start 
-     cutting the chocolate bar into K+1 pieces using K cuts, 
-     each piece consists of some consecutive chunks.
+        M = {}
+        
+        k = 0
+        for i in range(N):
+            for j in range(M):
+                if grid[i][j] == "H":
+                    treeLocations.extend([(i+1, j), (i-1,j)])...ETC!
+                    M[(i,j)] = k
+                    k += 1
 
-     Being generous, you will eat the piece with the minimum total 
-     sweetness and give the other pieces to your friends.
+        @lru_cache(None)
+        def recursion(i, setProcessed):
 
-     Find the maximum total sweetness of the piece you can 
-     get by cutting the chocolate bar optimally.
+            (treeX, treeY) = treeLocations[i]
+            if setProcssed == 2^(len(m)) - 1:
+                # alrdy processed all
+                return 0
 
-      
+            # ok either process take it or not. 
+            # find all houses around me!
+            dirs = [(-1,-1), (-1, 0), (1,1), (1,0), (0,1), (0, -1), (-1, 1), (1, -1)]
+            taken = setProcessed
+            for i,j in dirs:
+                houseLabel = M.get(treeX+i, treeY+j)
+                if houseLabel is not None:
+                    taken |= ( 1 << houseLabel)
 
-     Example 1:
+            # ok either take or dont take
+            return min( 1 + recursion(i+1, taken), recursion(i+1, setProcessed) )
 
-     Input: sweetness = [1,2,3,4,5,6,7,8,9], K = 5
-     Output: 6
-     Explanation: You can divide the chocolate to [1,2,3], [4,5], [6], [7], [8], [9]
 
-    class Solution {
-        public:
-            
-            int enough(const vector<int> & sweetness, int minSweet, int K) {
-                int res = 0;
-                int groups = 0;
-                for(auto & i: sweetness) {
-                    if(res + i >= minSweet) {
-                        groups += 1;
-                        res = 0;
-                    } else {
-                        res += i;
-                    }
-                }
-                if(groups >= K+1) 
-                    return true;
-                return false; 
-            }
-            
-            int maximizeSweetness(vector<int>& sweetness, int K) {
-                int low = *min_element(sweetness.begin(), sweetness.end());
-                int high = std::accumulate(sweetness.begin(), sweetness.end(), 0) + 1;
-                int mid;
-                
-                while(low < high) {
-                    mid =  low + (high - low)/2;
-                    if(enough(sweetness, mid, K)) {
-                        low = mid + 1;
-                    }  else {
-                        high = mid;
-                    }
-                }
-                return low - 1;
-            }
-    };
+        # Now go over the trees and see which houses covered
 
-    PYTHON SOLN:
-    def maximizeSweetness(self, A, K):
-        left, right = 1, sum(A) / (K + 1)
-        while left < right:
-            mid = (left + right + 1) / 2
-            cur = cuts = 0
-            for a in A:
-                cur += a
-                if cur >= mid:
-                    cuts += 1
-                    cur = 0
-            if cuts > K:
-                left = mid
-            else:
-                right = mid - 1
-        return right
+    Recursively, we want to find the min, and solve for every subset -> therefore our DP would be
 
+    OPT[ith tree processed][set(houses covered)] = Minimum trees required to cover the set of houses. 
 
+    Choosing or not choosing ith tree will affect all house coverages from 1 to i-1th coverages!
 
+    To get index of a house use a map that maps (housex, housey) -> idxofhouseinsubset
 
--101.5) Binary Search again: 
+    OPT[0][0] = 0
+    
+    OPT[i][x] = 
+        min(OPT[i-1][x], 1 + OPT[i-1][all partial x which when introducing tree i -> results in x]) 
 
-     1.    Find the Smallest Divisor Given a Threshold
+    You can space optimize out the i parameter given you only need the previous to generate next
+    x goes from 0 to 2^n - 1
+    
+    Total complexity (2^n - 1) * #ofCandidateTrees
+    
+    Maybe forward DP is easier. 
+    # Process tree i, calculate all the x it generates -> set the mins!
+    # Relax it from infinite!
 
-     Share
-     Given an array of integers nums and an integer threshold, we will 
-     choose a positive integer divisor and divide all the array by it and 
-     sum the result of the division. Find the smallest divisor such that the 
-     result mentioned above is less than or equal to threshold.
+    -> Exercise: check if this is correct:
 
-     Each result of division is rounded to the nearest integer greater 
-     than or equal to that element. (For example: 7/3 = 3 and 10/2 = 5).
-     It is guaranteed that there will be an answer.
+    F = len(treeLocations)
+    prev = [0] # base case
+    curr = [0] # base case
 
+    prev.extend([float("inf") for i in range(1, 2**N)])
+    curr.extend([float("inf") for i in range(1, 2**N)])
+    
+    dirs = [(-1,-1), (-1, 0), (1,1), (1,0), (0,1), (0, -1), (-1, 1), (1, -1)]
 
 
-    class Solution {
-    public:
-        bool enough(vector<int>& nums, const int & threshold, const int & divisor) {
-            int res = 0;
-            for(auto & i : nums) {
-                // cieling
-                res += (i/divisor) + (i % divisor != 0);
-                if(res  > threshold){
-                    return false;
-                }
-            } 
-            return true;
-        }
-        
-        int smallestDivisor(vector<int>& nums, int threshold) {
-            int low = 1; 
-            int high = *max_element(nums.begin(), nums.end());
-            while(low < high) {   
-                int mid = low + (high - low)/2;
-                if(enough(nums, threshold, mid)) {
-                    // divisor worked go smaller. 
-                    high = mid;
-                } else {
-                    //divisior too small, need bigger. 
-                    low = mid + 1;
-                }
-            }
-            return low;
-        }
-    };
 
+    for i in range(F):
+        for j in range(2**N - 1):
+            # -> check all the houses you cover and forward update!
+            # all_forward_updates = []
+            # or should we just do 1 forward update for all the houses we covered!
 
+            new_houses_covered = j
+            for i,j in dirs:
+                houseLabel = M.get(treeX+i, treeY+j)
+                if houseLabel is not None:
+                    new_houses_covered |= ( 1 << houseLabel)
 
--101) Binary Search VARIABLES HOW TO SET:
-    STUDY HOW Low, high, and the condiition in if statement for binary search
-    // both solutions below work. 
+            curr[new_houses_covered] = min(curr[new_houses_covered], 1 + prev[j])
 
-    1.   Split Array Largest Sum
-    Share
-    Given an array nums which consists of non-negative integers and an integer m, 
-    you can split the array into m non-empty continuous subarrays.
+        prev = curr
 
-    Write an algorithm to minimize the largest sum among these m subarrays.
-    Example 1:
-    Input: nums = [7,2,5,10,8], m = 2
-    Output: 18
+    return curr[2**N-1]
 
-    Solution: 
+    
 
-    class Solution {
-        public:
+
+
+-115) Lazy Deleting VS doubly linked list:
+    
+        Design a wait list for customers at restaurant:
+
+        Add customers to wait list (for example: Bob, party of 4 people)
+        Remove a customer from wait list
+        Given a open table with N seats, remove and return the first customer party of size N
+        Clarifications:
+
+        10 unique table sizes
+        Customer names unique
+        FIFO if two parties have the same number of people
+        Table with N seats must have exactly N people
+        Ideal solution O(1) runtime for all 3 methods
+
+    Soln1 :
+        map {
+
+        tableIdx -> [customer1, customer2]
+        1...10 keys
+        }
+
+         Add to waitlist, -> add him to the end
+        Remove from waitlsit. just mark him removed in some set!
+        Assign table -> check if customer has been removed before assinging, otherwise go to next customer. 
+
+        Guranteed O(1) delete complexity + FIFO
+
+        -> Otherwise, you can use a doubly linked list to remove him quickly!
+
+        My solution is to use 3 maps.
+
+        One map for table(size) and list of customer waiting for it in order. customer_wait_list_map <Table_id, List>
+        One map for table(size) and its availability count. <Table_Id, Count> (Optional if we have multiple same table with same size)
+        One map for customer and it's Node address. <Customer_name, Node>
+        Node is Doubly Linked List.
+        So all 3 could be done in O(1)
+
+
+-114)   Understand how to do graph property type questions, where you have to satisfy a graph shape:
+    
+        Give a undirected graph as a list of edges [(1, 2), (1, 3), (1, 4), (2, 3)], check if the graph forms a grid?
+        For examples,
+
+        True Case: [(1, 2), (1, 4), (2, 3), (2, 5), (3, 6), (4, 5), (5, 6)]
+
+        Because we can form grid,
+
+        1 2 3
+        4 5 6
+
+        False Case: [(1, 2), (1, 4), (2, 3), (2, 5), (3, 6), (4, 5)]
+
+        Because we cannot form grid,
+
+        1 2 3
+        4 5
+
+        there should be 4 nodes with degree 2
+        Check weather all the vertices with degree less than or equal to 4
+        choose one corner and run a bfs until you get 2 more corners, so now you have your row size and column size.
+        from the corner other than the one found in step 3 bfs again and check if m,n are satisfied here as well
+        now you should have 4 two degree vertices, 2*(m+n)-8 three degree vertices, nm-2(m+n)+4 four degree vertices.
+
+
+-113) Insert, Delete, GetRandom O(1)
+
+    Implement the RandomizedSet class:
+
+    RandomizedSet() Initializes the RandomizedSet object.
+    bool insert(int val) Inserts an item val into the set if not present. Returns true if the item was not present, false otherwise.
+    bool remove(int val) Removes an item val from the set if present. Returns true if the item was present, false otherwise.
+    int getRandom() Returns a random element from the current set of elements (it's guaranteed that at least one element exists when this method is called). Each element must have the same probability of being returned.
+    You must implement the functions of the class such that each function works in average O(1) time complexity.
+
+    class RandomizedSet:
+        def __init__(self):
+            self.arr = []
+            self.m = {}
             
-            int enough(vector<int>& nums, int m, int k) {
-                int groups = 0;
-                int curr = 0;
-                for(auto & i : nums) {
-                    if(curr + i > k)  {
-                        groups += 1;
-                        curr = 0;
-                    }
-                    curr += i;
-                }
-                groups += 1; // last group
-                if(groups > m) {
-                    return false;
-                } 
-                return true; 
-            }
+        def insert(self, val: int) -> bool:
+            if(val in self.m):
+                return False
             
-            int splitArray(vector<int>& nums, int m) {
-                // binary search because we only want the minimized value as answer 
-                int high = std::accumulate(nums.begin(), nums.end(), 0);
-                // low is actually the largest element in the array? 
-                int low = *max_element(nums.begin(), nums.end());
-                int ans = high;
-                
-                while(low < high) {
-                    
-                    int mid = low + (high - low)/2;
-                    if(enough(nums, m, mid)) {
-                        high = mid;
-                        ans = min(ans, mid);
-                    } else {
-                        low = mid+1; 
-                    }   
-                }
-                // returning low or high below also works!
-                // bc at end of loop low==high==mid -> enough
-                return ans;
-            }
+            self.arr.append(val)
+            idx = len(self.arr) - 1
+            self.m[val] = idx
+            return True
 
-            int splitArray2(vector<int>& nums, int m) {
-                // binary search because we only want the minimized value as answer 
-                int high = std::accumulate(nums.begin(), nums.end(), 0);
-                // low is actually the largest element in the array? 
-                int low = *max_element(nums.begin(), nums.end());
-                int ans = high;
-                
-                while(low <= high) {
+        def remove(self, val: int) -> bool:
+            # -> get idx from val  
+            
+            if(self.m.get(val) is None):
+                return False
+            
+            idx = self.m[val] 
+        
+            lastIdx = len(self.arr) - 1
+            lastIdxVal = self.arr[lastIdx]
+            
+            self.m[lastIdxVal] = idx
+            self.arr[idx], self.arr[lastIdx] = self.arr[lastIdx], self.arr[idx]
+            
+            del self.m[val]     
+            self.arr.pop()
+            
+            
+            # what if removing the last one? edge case
+            return True
+        
+        def getRandom(self) -> int:
+            r = random.randint(0, len(self.arr)-1)
+            return self.arr[r]
+
+
+
+-112) Multisource BFS:
+        For multisource BFS you will have to use visited set twice if yu fck it up.
+        Make sure you process every node once, or if your parent is processing the child, 
+        multiple parents arent processing the same child!!!
+
+        Look at below example for correctness!
+
+        '''
+        663 · Walls and Gates
+
+        You are given a m x n 2D grid initialized with these three possible values.
+
+        -1 - A wall or an obstacle.
+        0 - A gate.
+        INF - Infinity means an empty room. We use the value 2^31 - 1 = 2147483647 to represent INF as you may assume that the distance to a gate is less than 2147483647.
+        Fill each empty room with the distance to its nearest gate. If it is impossible to reach a Gate, that room should remain filled with INF
+
+        Explanation:
+        the 2D grid is:
+        INF  -1  0  INF
+        INF INF INF  -1
+        INF  -1 INF  -1
+        0  -1 INF INF
+        the answer is:
+        3  -1   0   1
+        2   2   1  -1
+        1  -1   2  -1
+        0  -1   3   4
+        Example2
+
+        Input:
+        [[0,-1],[2147483647,2147483647]]
+        Output:
+        [[0,-1],[1,2]]
+        '''
+
+        from collections import deque
+
+        class Solution:
+            """
+            @param rooms: m x n 2D grid
+            @return: nothing
+            """
+            def walls_and_gates(self, rooms: List[List[int]]):
+                N = len(rooms)
+                M = len(rooms[0])
+
+                d = deque()
+                visited = set()
+                dist = {}
+                for i in range(N):
+                    for j in range(M):
+                        if rooms[i][j] == 0:
+                            d.append((i,j))
+                            dist[(i,j)] = 0
+                            # rooms[i][j] = 0
+            
+
+                directions = [(0,1), (0,-1), (1,0), (-1,0)]
+
+                # THIS PROBLEM ILLUSTRATES WHEN NODES SHOULD BE ADDED TO VISITED!
+                # to reduce any duplication that can occur in updates.
+                # nodes should be processed once and know that defn!
+
+                while len(d) > 0:
+                    r, c = d.popleft()
+                    # Both visiteds are required in multisource BFS 
+                    # The below visited can be removed if you add the  gate nodes at the very start 
+                    # to the visited set
+                    # BE CAREFUL WHEN YOU ARE DOING PARENT TO CHILD UPDATE aka parent updates child
+                    # that means child was processed! so 2 parents shouldnt update same child!!
                     
-                    int mid = low + (high - low)/2;
-                    // cout << "testing value " << mid << endl; 
-                    if(enough(nums, m, mid)) {
-                        // ok that worked. can we go smaller?
-                        high = mid-1;
-                        ans = min(ans, mid);
-                    } else {
-                        // we need it bigger. 
-                        low = mid+1; 
-                    }   
-                }
-                // only returning low or ans works here. cant return high
-                return ans;
-            }   
-    };
+                    visited.add((r,c) )
+
+                    for (i,j) in directions:
+                        if(r + i < N and r + i >=0 and c + j < M and c + j >= 0 and (r+i, c+j) not in visited
+                            and rooms[r+i][c+j] !=-1):
+                            
+                            d.append((r+i, c+j))
+                            dist[(r+i, c+j)] = dist[(r,c)] + 1
+                            
+                            # The child should be updating based on parent!
+                            # The child should be updated once its accessed, not from parent to child update!!!
+                            # because children are accessed multiple times before they get added to visited in top 
+                            # statement. So we have to add child to visited as well!
 
+                            rooms[r+i][c+j] = dist[(r,c)] + 1
+                            # effectively child was processed in above statement. 
+                            visited.add((r+i, c+j))
+                            # 
+                            print("updated ", (r, c, ))
 
 
 
+-111) Realize in the question when things are sorted for you. Will the datastructure calls come in a sorted manner?
+    Do we need to sort it based on time using a BST or does it come presorted just by how it is called. If it comes presorted
+        put it in a deque or a priority queue instead of a bst. 
 
--100) MOD TRICKS -> GET MOD IN BETWEEN [0, K]
 
+-110)   Doubly Linked List O(1) popping requirement VS Lazy Popping with a deque + map
+        Which soln is better for these datastructures??
 
-    /*
-    1.    Check If Array Pairs Are Divisible by k
+        Build a data structure to perform three operations (Restaurant is full initially):
+        1) waitList (string customer_name, int table_size):
+        Add customer with given name and table size they want to book into the waitlist
+        2) leave (string customer_name):
+        Customer wants to leave the waitlist so remove them.
+        3) serve (int table_size):
+        This means restaurant now has a free table of size equal to table_size. Find the best customer to serve from waitlist
+        Best Customer: Customer whose required size is less than or equal to the table_size. 
+
+        If multiple customers are matching use first come first serve.
+        For e.g. if waitlist has customers with these table requirements => [2, 3, 4, 5, 5, 7] 
+        and restaurant is serving table_size = 6 then best customer is index 3 (0-based indexing).
+
+
+
+        Add to waitlist -> keep it sorted first on size, then on time. 
+
+        to keep sorted on time push into a deque, append!!
+        and also popLeft. (for getting the earlist person!)
+
+
+        map{
+            size -> [customers in deque]
+        }
+
+        Also:  
+        customerName -> locate idx in deque! (Need it implemented as doubly linked list for O(1) removal!)
+
+        map {
+        customerName -> (size, locInDeque/Node in deque)
+        }
+
+        Then when we want to serve someone,
+            binary search the tree map for the queue of names, and give the first name, then remove the first name. 
+
+        Someone elses soln, doesnt use Doubly linked list??
+
+
+            from sortedcontainers import SortedList
+            from collections import deque
+
+            class Restaurant:
+                def __init__(self):
+                    # maps customer to the table they're waiting for
+                    self.customerToTable = {}
+                    # sorted list of unique table sizes that people are waiting for
+                    self.sortedWaitList = SortedList()
+                    # maps table size to a deque of customer names waiting for that table
+                    # in order of arrival. some of these names may have left, so we have 
+                    # to check at the end of each leave call to ensure that we always have
+                    # a valid, present customer waiting for a table at the leftmost element.
+                    self.tableSizeDeques = {}
+
+                def waitList(self, cn, ts):
+                    self.customerToTable[cn] = ts
+                    if ts not in self.sortedWaitList:
+                        self.sortedWaitList.add(ts)
+                    if ts not in self.tableSizeDeques:
+                        self.tableSizeDeques[ts] = deque()
+                    self.tableSizeDeques[ts].append(cn)
+
+                def leave(self, cn):
+                    ts = self.customerToTable[cn]
+                    del self.customerToTable[cn]
+
+                    # this while loop ensures that the leftmost customer has not
+                    # yet left the restaurant for this table size, and if there are 
+                    # no customers left for this table size, we will delete the
+                    # entry for this table size. that means we always have a valid
+                    # customer to use for this table size if it still exists in the waitlist.
+                    while self.tableSizeDeques[ts] and \
+                        self.tableSizeDeques[ts][0] not in self.customerToTable:
+                        self.tableSizeDeques[ts].popleft()
+
+                    if len(self.tableSizeDeques[ts]) == 0:
+                        self.sortedWaitList.remove(ts)
+                        del self.tableSizeDeques[ts]
+
+                def serve(self, ts):
+                    i = min(self.sortedWaitList.bisect_left(ts), \
+                            len(self.sortedWaitList) - 1)
+
+                    customer = self.tableSizeDeques[i][0]
+                    # instead of rewriting our leave code, let's just call it here to make the customer leave
+                    self.leave(self, customer)
+                    return customer
+
+
+
+
+
+
+
+
+-109) Integer Break (Dp soln, not cool math one):
+    In the DP you might have a lot of edge casey stuff around 1 state, or a few states, and
+    then all the other states are easy. In this case, the edge casey stuff was around computing
+    answers to the small input values, dealing with only 2 factors in the product:
+
+    343. Integer Break
     Medium
-    Share
-    Given an array of integers arr of even length n and an integer k.
-    We want to divide the array into exactly n / 2 pairs such that the sum of each pair is divisible by k.
-    Return True If you can find a way to do that or False otherwise.
 
-        #include <bits/stdc++.h> 
+    Given an integer n, break it into the sum of k positive integers, where k >= 2, and maximize the product of those integers.
 
-        class Solution {
-        public:
-            bool canArrange(vector<int>& arr, int k) {
-                unordered_multiset<int> s;
-                
-                for(auto & i : arr) {
-                    if(i < 0){ 
-                        // HOW TO MAKE NUMBER POSITIVE
-                        i += (abs(i)/k + (i%k != 0))*k;
-                    }
-                    // ANOTHER WAY  TO KEEP MODS BETWEEN [0, K-1 is just do following]
-                    // i = (i%k + k)%k
-                    if(s.find(k - i%k) != s.end()) {
-                        s.erase(s.find(k - i%k));
-                    } else {
-                        if(i%k == 0) {
-                            s.insert(k);
-                        }else {                
-                            s.insert(i%k);
-                        }
-                    }
-                }
-                if(s.size() == 0) {
-                    return true;
-                }
-                return false;
-            }
-        };
+    Return the maximum product you can get.
 
+    Example 1:
 
-    // VERY CLEAN SOLUTION
+    Input: n = 2
+    Output: 1
+    Explanation: 2 = 1 + 1, 1 × 1 = 1.
+    Example 2:
 
-    class Solution {
-    public:
-        bool canArrange(vector<int>& arr, int k) {
-            vector<int> freq(k);
+    Input: n = 10
+    Output: 36
+    Explanation: 10 = 3 + 3 + 4, 3 × 3 × 4 = 36.
+    
+    Soln:
+
+    class Solution:
+        def integerBreak(self, n: int) -> int:
             
-            for (int x : arr)
-                freq[((x % k) + k) % k]++;
+            '''
+            OPT[i] = OPT product we get for i
+            OPT[0] = 0
+            OPT[1] = 0?
+            OPT[2] = 1 -> 1*1? I GUESS
+            OPT[3] = 2
+            OPT[i] = OPT[i - k] * k for every k from n to 1
+            k can go from n to 2 
             
-            if (freq[0] % 2)
-                return false;
             
-            for (int i=1, j=k-1; i<j; i++, j--)
-                if (freq[i] != freq[j])
-                    return false;
+            The below solution needs the extra 
+            (i-k)*(k)
+            in the max, 
+            because there are so many edge cases with doing products when small numbers are involved.
+            So calculating anything with 2 factors is edge casey, but 3 or more can build of the 2 
+            product stuff we calculate with the above.
             
-            return true;
-        }
-    };
+            
+            '''
+            OPT = [0 for i in range(max(n+1, 4))]
+            
+            for i in range(n+1):
+                for k in range(1, n+1):
+                    if i - k >= 0:
+                        OPT[i] = max(OPT[i], max((i-k)*(k), OPT[i-k]*k))
 
-    /*
-    FASTER CPP SOLUTIONS
-    */
+            return OPT[n]
 
-    class Solution {
-    public:
-        bool canArrange(vector<int>& arr, int k) {
-            vector<int> freq(k,0);
-            int n = arr.size();
-            for(int i = 0; i < n; ++i) {
-                if(arr[i] >= 0) {
-                    freq[arr[i] % k] = ((freq[arr[i] % k] + 1) % k);
-                }
-                else {
-                    int temp = k - abs(arr[i] % k);
-                    if(temp == k)
-                        temp = 0;
-                    freq[temp] = ((freq[temp] + 1) % k);
-                }
-            }
 
-            if(freq[0] % 2 != 0) 
-                return false;
-            for(int i = 1; i <= freq.size() / 2; i++){
-                if(freq[i] != freq[k - i]) return false;
-            }
-            return true;
-        }
-        
-    };
 
-    static const auto speedup = []() {
-            std::ios::sync_with_stdio(false); std::cin.tie(nullptr); cout.tie(nullptr); return 0;
-    }();
 
 
 
--99) Use 2 MULTISET TREEMAPS instead of 2 Heaps for Median Finding Trick!!
-    1)   Sliding Window Median
-    (However slightly slower because of log(N) 
-    cost retrival of best elements vs PQ)
-    Window position                Median
-    ---------------               -----
-    [1  3  -1] -3  5  3  6  7       1
-    1 [3  -1  -3] 5  3  6  7       -1
-    1  3 [-1  -3  5] 3  6  7       -1
-    1  3  -1 [-3  5  3] 6  7       3
-    1  3  -1  -3 [5  3  6] 7       5
-    1  3  -1  -3  5 [3  6  7]      6
+-108) Linked list cycle detection start algo with treess:
+
+        LeetCode 1650. Lowest Common Ancestor of a Binary Tree III
+        Tree
+        Given two nodes of a binary tree p and q, return their lowest common ancestor (LCA).
+        Each node will have a reference to its parent node. The definition for Node is below:
+        class Node {
+            public int val;
+            public Node left;
+            public Node right;
+            public Node parent;
+        }
+
+        /*
+        // Definition for a Node.
+        class Node {
+        public:
+            int val;
+            Node* left;
+            Node* right;
+            Node* parent;
+        };
+        */
 
         class Solution {
         public:
-            void insertTree(int element, multiset<double> & l, multiset<double> & r) {
-                if(l.size() == r.size()) {
-                    // insert into left. 
-                    
-                    if(r.size() > 0 && *(r.begin()) < element) { 
-                        double temp = *(r.begin());
-                        
-                        // ERASING BY VALUE IS BUG FOR MULTISET BECAUSE IT REMOVES ALL COPIES
-                        // ONLY ERASE THE ITERATOR!! TO ERASE ONE. 
-                        r.erase(r.begin());
-                        r.insert(element);
-                        element = temp;
-                    }
-                    l.insert(element);
-                } else {
-                    // l is bigger, insert into right. 
-                    
-                    if( *(--l.end()) > element ) {
-                        double temp = *(--l.end()) ;
-                        l.erase(--l.end()); //COOL TIP, YOU CAN ERASE WITH EITHER VALUE OR ITERATOR
-                        l.insert(element);
-                        element = temp; 
-                    }
-                    
-                    r.insert(element);
+            Node* lowestCommonAncestor(Node* p, Node * q) {
+                Node* a = p, *b = q;
+                while (a != b) {
+                    a = (a == nullptr ? q : a->parent);
+                    b = (b == nullptr ? p : b->parent);
                 }
+                return a;
             }
+        };
+
+
+
+-107) PRINTING QUESTIONS -> good pattern is to enumerate all the indices you are going
+    to print to make it easier to figure out a good way to traverse the array 
+    Diagonal Matrix:
+    98. Diagonal Traverse
+
+    Given an m x n matrix mat, return an array of all the 
+    elements of the array in a diagonal order.
+        
+    class Solution:
+        def findDiagonalOrder(self, mat: List[List[int]]) -> List[int]:
             
-            void deleteTree(int element, multiset<double> & l, multiset<double> & r ) {
-                // Find tree that contains element, remove, then rebalance. 
-                bool leftBigger = l.size() > r.size();
-                
-                auto leftSearch =l.find(element);  
-                if( leftSearch != l.end()) {
-                    l.erase(leftSearch);
-                    // if left is greater than right by 1 dont do anything    
-                    // if left is same size as right, move right element to left.  
-                    if(!leftBigger) {
-                        // move right to left. 
-                        auto rightEle = *(r.begin());
-                        r.erase(r.begin());
-                        l.insert(rightEle);
-                    }            
-                } else {
-                    // search right, has to contain it.  
-                    auto rightSearch = r.find(element);
-                    r.erase(rightSearch);
-                    
-                    // if left is same size as right do nothing
-                    // otherwise, move left to right. 
-                    
-                    if(leftBigger) {
-                        auto leftEle = *(--l.end());
-                        l.erase(--l.end());
-                        r.insert(leftEle);
-                    }
-                }
-            }
             
+            '''
+            LC Pattern:
+            One trick for these questions is to enumerate how the indexes should be visited and find 
+            patttersn in that enumeration.
             
-            double calcMedian(const multiset<double> & l, const multiset<double> & r) {
-            // always ensure left has 1 more element than right. 
-            // then always return *(left.end() - 1)
-                
-                if(l.size() == r.size()) {
-                    
-                    return ( *(--l.end()) + *(r.begin()) ) / 2.0;  
-                }  else {
-                    return *(--l.end());
-                }
-            } 
+            '''
+            i = 0 
+            j = 0 
+            go_up = True
             
-            vector<double> medianSlidingWindow(vector<int>& nums, int k) {    
-                // keep 2 multsets. 
-                multiset<double> l;
-                multiset<double> r;
-                
-                int i = 0;
-                int j = 0;
+            collect = []
+            N = len(mat)
+            M = len(mat[0])
 
-                while(j < k) {            
-                    insertTree(nums[j], l, r);
-                    j += 1;
-                }
-                
-                vector<double> res;
-                double med = calcMedian(l, r);
-                res.push_back(med);
-                
-                while(j != nums.size()) {            
-                    insertTree(nums[j], l, r);
-                    deleteTree(nums[i], l, r);
-                
-                    med = calcMedian(l, r);
-                    res.push_back(med);
-                    i += 1;
-                    j += 1;
-                }
-                return res;    
-            }
-        };
+            while True:
+                print("i, j, go_up", i, j, go_up)
+                collect.append(mat[i][j])
+                if(i == N -1 and j == M-1):
+                    return collect
+                if go_up:
+                    if(i-1 < 0 or j + 1 >= M):
+                        if( j + 1 >= M):
+                            i += 1
+                        else:
+                            j += 1
+                        go_up = False
+                    else:
+                        i -= 1
+                        j += 1
+                else:
+                    if(j - 1 < 0 or i + 1 >= N ):
+                        if(i + 1  >= N ):
+                            j += 1
+                        else:    
+                            i += 1
+                        go_up = True
+                    else:
+                        i += 1
+                        j -=  1
 
+-106) Research this math problem (Hidden bit manipulation): 
+    Convert 0 into N in minimum steps by multiplying with 2 or by adding 1.
 
-    
+    Input: 19;  Output: 6
+    Medium level problem
+    Explained: Recursion -> DP -> Better{ O(n) } -> Optimal{ O(log(n)} }
 
--98) C++ A Priority Queue USAGE VS BINARY TREE MAP USAGE: 
-    
-    1. Find K Pairs with Smallest Sums
+    After that question was updated with if you are only allowed to multiply by 2, K times.
+    Explained: Optimal{ O(logK) }
 
-    You are given two integer arrays nums1 and nums2 
-    sorted in ascending order and an integer k.
+    This is a bit manipulation question (possibly???). 
 
-    Define a pair (u,v) which consists of one element from the first array and one element from the second array.
+    N -> we need to check how many set bits are there. 
+    For instnace N = 6  -> 0110
 
-    Find the k pairs (u1,v1),(u2,v2) ...(uk,vk) with the smallest sums.
+    Add 1          –> 0 + 1 = 1.
+    Multiply 2  –> 1 * 2 = 2.
+    Add 1          –> 2 + 1 = 3. 
+    Multiply 2  –> 3 * 2 = 6.
+    Therefore number of operations = 4.  
 
-    Example 1:
+    divide by 2, subtract 1, divide by 2 then subtract 1?
 
-    Input: nums1 = [1,7,11], nums2 = [2,4,6], k = 3
-    Output: [[1,2],[1,4],[1,6]] 
-    Explanation: The first 3 pairs are returned from the sequence: 
-                [1,2],[1,4],[1,6],[7,2],[7,4],[11,2],[7,6],[11,4],[11,6]
-    Example 2:
+    0 + 1 = 1 * 2 = 2 + 1 = 3 * 2 = 6
 
-    Input: nums1 = [1,1,2], nums2 = [1,2,3], k = 2
-    Output: [1,1],[1,1]
-    Explanation: The first 2 pairs are returned from the sequence: 
-                [1,1],[1,1],[1,2],[2,1],[1,2],[2,2],[1,3],[1,3],[2,3]
-    Example 3:
+    # QUESTION DOES THE BELOW MODIFIED GEEKS FOR GEEKS SOLN ALWAYS 
+    # WORK OR DO YOU ALWAYS NEED TO DO SOME TYPE OF DP??
+    def minimumOperation(N):
+    
+        # Stores the count of set bits
+        count = 0
+    
+        while (N):
+    
+            # If N is odd, then it
+            # a set bit
+            if (N & 1 == 1):
+                count += 1
+    
+            N = N >> 1
+            count += 1
 
-    Input: nums1 = [1,2], nums2 = [3], k = 3
-    Output: [1,3],[2,3]
-    Explanation: All possible pairs are returned from the sequence: [1,3],[2,3]
+        # Return the result
+        return count
 
-    C++ SOLUTION A (fastest):
 
-    class Solution {
-        public:
-        vector<pair<int, int>> kSmallestPairs(vector<int>& nums1, vector<int>& nums2, int k) {
-            vector<pair<int,int>> result;
-            if (nums1.empty() || nums2.empty() || k <= 0)
-                return result;
-            auto comp = [&nums1, &nums2](pair<int, int> a, pair<int, int> b) {
-                return nums1[a.first] + nums2[a.second] > nums1[b.first] + nums2[b.second];};
-            priority_queue<pair<int, int>, vector<pair<int, int>>, decltype(comp)> min_heap(comp);
-            min_heap.emplace(0, 0);
-            while(k-- > 0 && min_heap.size())
-            {
-                auto idx_pair = min_heap.top(); min_heap.pop();
-                result.emplace_back(nums1[idx_pair.first], nums2[idx_pair.second]);
-                if (idx_pair.first + 1 < nums1.size())
-                    min_heap.emplace(idx_pair.first + 1, idx_pair.second);
-                if (idx_pair.first == 0 && idx_pair.second + 1 < nums2.size())
-                    min_heap.emplace(idx_pair.first, idx_pair.second + 1);
-            }
-            return result;
-        }
-    };
 
+-105) Read leftmost column with at least a one:
+      Abuse the fact that pointers can move both row and column in a 2d array 
+      and try to continue to be greedy as you optimize for the soln. 
+    
+      Think about wierd traversals in a  matrix as well!!
 
 
-    C++ SOLUTION B (slower):
 
-    struct compare
-    {
-        bool operator() (const pair<int, int> & a, const pair<int, int> & b)
-        {
-            return a.first + a.second >= b.first + b.second;
-        }
-    };
+-104) SOMETIMES YOU CAN ANSWER GOING BOTH LEFT TO RIGHT, OR RIGHT TO LEFT
 
-    class Solution {
-    public:
-        vector<vector<int>> kSmallestPairs(vector<int>& nums1, vector<int>& nums2, int k) {
-            
-            if (nums1.empty() || nums2.empty() || k == 0)
-                return {};
-                
-            priority_queue< pair<int, int>, vector<pair<int, int>>, compare > que;
-            
-            int N = nums1.size();
-            int M = nums2.size();
+        You are given an integer num. You can swap two digits at 
+        most once to get the maximum valued number.
+        Return the maximum valued number you can get.
+
+        
+        class Solution:
             
-            for (int i = 0; i < N; i++)
-            {
-                for (int j = 0; j < M; j++)
-                {
-                    que.push({nums1[i], nums2[j]});       
-                }
-            }
+            def maximumSwap(self, num: int) -> int:
+                return self.maximumSwapLtoR(num)
+                # this soln also works:
+                #return self.maximumSwapRtoL(num)
             
-            vector<vector<int>> ans;
+            # SOLN THAT GOES RIGHT TO LEFT!
+            def maximumSwapRtoL(self, num: int) -> int:
+                '''
+                2736
+                ^
+                Go right to left soln
+                '''
+                
+                nums_arr = [int(i) for i in str(num)]
+                
+                j = len(nums_arr) - 1
+                biggest = -1
+                biggest_idx = -1
+                
+                left_idx = -1
+                
+                viable_soln = None
+                while j > -1:
+                    if nums_arr[j] > biggest:
+                        # SAVE THE PREVIOUS VIABLE SOLN!
+                        if(biggest_idx != -1 and left_idx != -1):
+                            viable_soln = (biggest_idx, left_idx)  
+                            
+                        # keep track of previous viable soln, in case we cant find a better one?
+                        biggest= nums_arr[j]  
+                        biggest_idx = j
+                        left_idx = -1
+                    elif nums_arr[j] < biggest:
+                        left_idx = j
+                    j -= 1
+                
+                def create_soln(i, j):
+                    nums_arr[i], nums_arr[j] = nums_arr[j], nums_arr[i]
+                    return int("".join([str(i) for i in nums_arr]))
+                
+                ans = num
+                if left_idx == -1:
+                    if viable_soln != None:
+                        return create_soln(viable_soln[0], viable_soln[1])
+                else:
+                    return create_soln(biggest_idx, left_idx)
+                        
+                return ans
             
-            int count = min(k, (int)que.size());
             
-            for (int s = 0; s < count; s++)
-            {
-                auto item = que.top();
-                que.pop();
+            # SOLN THAT GOES LEFT TO RIGHT
+            def maximumSwapLtoR(self, num: int) -> int:
+                '''
+                Left to right
+                just make sure its descending,
+                when its not descending fix max valu to the right,
+                then swap it with something in the left. 
+                '''
                 
-                ans.push_back({});
-                ans.back().push_back(item.first);
-                ans.back().push_back(item.second);
-            }
-            
-            return ans;
-        }
-    };
+                nums_arr = [int(i) for i in str(num)]
+                prev = float("inf")
+                break_idx = None
+                
+                for idx, i in enumerate(nums_arr):
+                    if i <= prev:
+                        prev = i
+                    else:
+                        break_idx = idx
+                        break
+                
+                if break_idx == None:
+                    return num
 
+                biggest = nums_arr[break_idx]
+                biggest_idx = break_idx
+                
+                for i in range(break_idx+1, len(nums_arr)):
+                    if nums_arr[i] >= biggest:
+                        biggest = nums_arr[i]
+                        biggest_idx = i
+                
+                def create_soln(i, j):
+                    nums_arr[i], nums_arr[j] = nums_arr[j], nums_arr[i]
+                    return int("".join([str(i) for i in nums_arr]))
+                
+                # ok now we need a left idx...
+                for i in range(len(nums_arr)):
+                    if biggest > nums_arr[i]:
+                        # then swap it and return 
+                        return create_soln(i, biggest_idx)
+                    
 
-    class Solution {
-    public:
-        vector<vector<int>> kSmallestPairs(vector<int>& v1, vector<int>&v2, int k) {
-            map<int,vector<pair<int,int>>>mp;
-            int sz1=v1.size(),sz2=v2.size();
-            for(int i=0;i<sz1;++i){
-                for(int j=0;j<sz2;++j)
-                    mp[v1[i]+v2[j]].push_back({v1[i],v2[j]});
-            }
 
-            vector<vector<int>>res;
-            for(auto it=mp.begin();it!=mp.end();++it){
-                for(pair<int,int>p:it->second){
-                    if(res.size()==k)
-                    break;
-                    res.push_back({p.first,p.second});
-                }
-            }
-            return res;
-        }
-    };
+-103) FIND RIGHT INTERVAL C++ WITH PRIORITY QUEUE (slow solution):
+    Find Right Interval
+    Medium
+    You are given an array of intervals, where 
+    intervals[i] = [starti, endi] and each starti is unique.
 
+    The right interval for an interval i is an interval j 
+    such that startj >= endi and startj is minimized.
 
+    Return an array of right interval indices for each interval i. 
+    If no right interval exists for interval i, then put -1 at index i.
 
+    Example 1:
 
+    Input: intervals = [[1,2]]
+    Output: [-1]
+    Explanation: There is only one interval in the collection, so it outputs -1.
+    Example 2:
 
--97) INTERVAL QUESTIONS THAT CAN BE 
-     SOLVED BY EITHER SORTING BY START TIME OR END TIME
+    Input: intervals = [[3,4],[2,3],[1,2]]
+    Output: [-1,0,1]
+    Explanation: There is no right interval for [3,4].
+    The right interval for [2,3] is [3,4] since start0 = 3 is the smallest start that is >= end1 = 3.
+    The right interval for [1,2] is [2,3] since start1 = 2 is the smallest start that is >= end2 = 2.
+    Example 3:
 
-    Hanging Banners
-    Question 212 of 858
-    You are given a list of list of integers 
-    intervals of the form [start, end] representing 
-    the starts and end points of banners you want to hang. 
-    Each banner needs at least one pin to stay up, and one 
-    pin can hang multiple banners. Return the smallest number 
-    of pins required to hang all the banners.
+    Input: intervals = [[1,4],[2,3],[3,4]]
+    Output: [-1,2,-1]
+    Explanation: There is no right interval for [1,4] and [3,4].
+    The right interval for [2,3] is [3,4] since start2 = 3 is the smallest start that is >= end1 = 3.
 
-    Note: The endpoints are inclusive, so if two banners are 
-    touching, e.g. [1, 3] and [3, 5], you can put a pin at 
-    3 to hang both of them.
 
-    intervals = [
-        [1, 4],
-        [4, 5],
-        [7, 9],
-        [9, 12]
-    ]
-    Output
+    class Solution {
+        public:
+            vector<int> findRightInterval(vector<vector<int>>& intervals) {
+                // sort by start time. 
+                // then just choose the right interval as you go through? 
+                /*
+                sorting + binary search?
+                sorting + heap?
+                sorting + treemap? 
+                sorting + 2 arrays [ayyy the best soln ]
+                
+                The reason we shoud seek something faster than heap/treemap is because
+                we are dealing with static data that doesnt change, and those structures are used 
+                for dynamic data, hence 2 array soln. 
+                */    
+                
+                //loop through intervals and save the index as part of tuple!
+                for(int i = 0; i != intervals.size(); ++i) {
+                    intervals[i].push_back(i);
+                }
+                
+                sort(intervals.begin(), intervals.end(), [](auto x, auto y) { return x[0] < y[0];});
+                
+                // sort by largest finish time at top!
+                // IF YOU LOOK AT CMP, TO DO LEAST TO GREATEST, YOU ACTUALLY HAVE TO INVERSE
+                // so its not a[1] < b[1] like in sort function above but a[1] > b[1]
+                auto cmp = [](vector<int> a, vector<int>  b) {return a[1] > b[1];};
+                priority_queue< vector<int>, vector< vector<int> >, decltype(cmp)> pq(cmp);
+                
+                vector<int> res;
+                res.resize(intervals.size());
+                
+                for(int i = 0; i!= intervals.size(); ++i) {
+                    vector<int> inte = intervals[i];
+                    
+                    while(pq.size() > 0 && pq.top()[1] <= inte[0]) {
+                        res[pq.top()[2]] = inte[2];
+                        pq.pop();
+                    }
+                    pq.push(inte);
+                }
+                
+                while(pq.size() > 0) {
+                    res[pq.top()[2]] = -1;
+                    pq.pop();
+                }
+                return res; 
+            }
+    };
 
-    2
-    Explanation
 
-    You can put two pins at 4 and 9 to hang all the banners..
 
-    Example 2
-    Input
+-103.5) FIND RIGHT INTERVAL C++ WITH PRIORITY QUEUE (fast solution):
+      (2 ARRAY INTERVAL SOLUTIONS WITH SORTED START END TIMES + POINTERS)
 
-    intervals = [
-        [1, 10],
-        [5, 10],
-        [6, 10],
-        [9, 10]
-    ]
-    Output
+    
+-102) BINARY SEARCH AND THE TEMPLATES: 
 
-    1
-    Explanation
+        1.   Peak Index in a Mountain Array
+        Let's call an array arr a mountain if the following properties hold:
+        arr.length >= 3
+        There exists some i with 0 < i < arr.length - 1 such that:
+        arr[0] < arr[1] < ... arr[i-1] < arr[i]
+        arr[i] > arr[i+1] > ... > arr[arr.length - 1]
+        Given an integer array arr that is guaranteed to be a mountain, 
+        return any i such that arr[0] < arr[1] < ... arr[i - 1] < arr[i] > arr[i + 1] > ... > arr[arr.length - 1].
 
-    You can put one pin at 10.
+        Example 1:
 
-    // TWO WAYS TO SOLVE WOWOWO
-    // YOU CAN EITHER SORT BY START TIME LIKE BELOW
-    int solve1(vector<vector<int>>& intervals) {
-        /*
-        sort by start time, 
+        Input: arr = [0,1,0]
+        Output: 1
+        Example 2:
 
-        keep set of end times. 
-        update with smallest end time so far seen. 
+        Input: arr = [0,2,1,0]
+        Output: 1
 
-        if next interval is past the current smallest end time, pop all intervals and add a pin,
-        then restart algo. 
-        */
-        sort(intervals.begin(), intervals.end(), 
-             [](vector<int> a, vector<int> b)-> bool {return a[0] < b[0];} );
-        
-        int pins = 0;
-        int nearestEnd = -1;
-        
-        for(int i = 0; i != intervals.size(); ++i) {
-            
-            auto intv = intervals[i];
-            if(intv[0] > nearestEnd) {
-                pins += 1;
-                nearestEnd = intv[1];
-            } else {
-                // keep in set of intervals!
-                nearestEnd = min(nearestEnd, intv[1]);
+        class Solution {
+            public:
+            int peakIndexInMountainArray(vector<int>& arr) {
+                int low = 0;
+                int high = arr.size();
+
+                while(low < high) {
+                    int mid = low + (high - low)/2;
+                    
+                    /*
+                    if(mid - 1 < 0) {
+                        low = low+1;
+                        continue;
+                    }    
+                    if(mid + 1 >= arr.size()) {
+                        high = high-1; 
+                        continue;
+                    }
+                    */
+                    
+                    int left = arr[mid-1];
+                    int right= arr[mid+1];
+                    
+                    if(left < arr[mid] && arr[mid] < right) {
+                        // search right side 
+                        low = mid + 1;
+                    } else if(left < arr[mid] && arr[mid] > right) {
+                        return mid; 
+                    } else if(left > arr[mid] && arr[mid] > right) {
+                        high = mid;
+                    } 
+                }
+                return -9999999; // should never reach this. 
             }
-        }
-        return pins;
-    }
+        };
 
-    // YOU CAN SORT BY END TIME TOO LIKE BELOW: 
 
-    class Solution:
-        def solve(self, intervals):
-            intervals.sort(key=lambda i: i[1])
-            last = float("-inf")
-            ans = 0
-            for s, e in intervals:
-                if s <= last:
-                    continue
-                last = e
-                ans += 1
-            return ans
+-101.7) Binary Search with chocolates:
 
+     Divide Chocolate
+     You have one chocolate bar that consists of some chunks. 
+     Each chunk has its own sweetness given by the array sweetness.
 
+     You want to share the chocolate with your K friends so you start 
+     cutting the chocolate bar into K+1 pieces using K cuts, 
+     each piece consists of some consecutive chunks.
 
+     Being generous, you will eat the piece with the minimum total 
+     sweetness and give the other pieces to your friends.
 
+     Find the maximum total sweetness of the piece you can 
+     get by cutting the chocolate bar optimally.
 
--96) Largest Rectangle in Histogram with Pointer Segment Tree:
+      
 
-    // Largest Rectangle in Histogram
-    // Stack solution, O(NlogN) solution
+     Example 1:
 
-    class SegTreeNode {
-    public:
-    int start;
-    int end;
-    int min;
-    SegTreeNode *left;
-    SegTreeNode *right;
-    SegTreeNode(int start, int end) {
-        this->start = start;
-        this->end = end;
-        left = right = NULL;
-    }
-    };
+     Input: sweetness = [1,2,3,4,5,6,7,8,9], K = 5
+     Output: 6
+     Explanation: You can divide the chocolate to [1,2,3], [4,5], [6], [7], [8], [9]
 
     class Solution {
-    public:
-    int largestRectangleArea(vector<int>& heights) {
-        if (heights.size() == 0) return 0;
-        // first build a segment tree
-        SegTreeNode *root = buildSegmentTree(heights, 0, heights.size() - 1);
-        // next calculate the maximum area recursively
-        return calculateMax(heights, root, 0, heights.size() - 1);
-    }
-    
-    int calculateMax(vector<int>& heights, SegTreeNode* root, int start, int end) {
-        if (start > end) {
-        return -1;
-        }
-        if (start == end) {
-        return heights[start];
+        public:
+            
+            int enough(const vector<int> & sweetness, int minSweet, int K) {
+                int res = 0;
+                int groups = 0;
+                for(auto & i: sweetness) {
+                    if(res + i >= minSweet) {
+                        groups += 1;
+                        res = 0;
+                    } else {
+                        res += i;
+                    }
+                }
+                if(groups >= K+1) 
+                    return true;
+                return false; 
+            }
+            
+            int maximizeSweetness(vector<int>& sweetness, int K) {
+                int low = *min_element(sweetness.begin(), sweetness.end());
+                int high = std::accumulate(sweetness.begin(), sweetness.end(), 0) + 1;
+                int mid;
+                
+                while(low < high) {
+                    mid =  low + (high - low)/2;
+                    if(enough(sweetness, mid, K)) {
+                        low = mid + 1;
+                    }  else {
+                        high = mid;
+                    }
+                }
+                return low - 1;
+            }
+    };
+
+    PYTHON SOLN:
+    def maximizeSweetness(self, A, K):
+        left, right = 1, sum(A) / (K + 1)
+        while left < right:
+            mid = (left + right + 1) / 2
+            cur = cuts = 0
+            for a in A:
+                cur += a
+                if cur >= mid:
+                    cuts += 1
+                    cur = 0
+            if cuts > K:
+                left = mid
+            else:
+                right = mid - 1
+        return right
+
+
+
+
+-101.5) Binary Search again: 
+
+     1.    Find the Smallest Divisor Given a Threshold
+
+     Share
+     Given an array of integers nums and an integer threshold, we will 
+     choose a positive integer divisor and divide all the array by it and 
+     sum the result of the division. Find the smallest divisor such that the 
+     result mentioned above is less than or equal to threshold.
+
+     Each result of division is rounded to the nearest integer greater 
+     than or equal to that element. (For example: 7/3 = 3 and 10/2 = 5).
+     It is guaranteed that there will be an answer.
+
+
+
+    class Solution {
+    public:
+        bool enough(vector<int>& nums, const int & threshold, const int & divisor) {
+            int res = 0;
+            for(auto & i : nums) {
+                // cieling
+                res += (i/divisor) + (i % divisor != 0);
+                if(res  > threshold){
+                    return false;
+                }
+            } 
+            return true;
+        }
+        
+        int smallestDivisor(vector<int>& nums, int threshold) {
+            int low = 1; 
+            int high = *max_element(nums.begin(), nums.end());
+            while(low < high) {   
+                int mid = low + (high - low)/2;
+                if(enough(nums, threshold, mid)) {
+                    // divisor worked go smaller. 
+                    high = mid;
+                } else {
+                    //divisior too small, need bigger. 
+                    low = mid + 1;
+                }
+            }
+            return low;
+        }
+    };
+
+
+
+-101) Binary Search VARIABLES HOW TO SET:
+    STUDY HOW Low, high, and the condiition in if statement for binary search
+    // both solutions below work. 
+
+    1.   Split Array Largest Sum
+    Share
+    Given an array nums which consists of non-negative integers and an integer m, 
+    you can split the array into m non-empty continuous subarrays.
+
+    Write an algorithm to minimize the largest sum among these m subarrays.
+    Example 1:
+    Input: nums = [7,2,5,10,8], m = 2
+    Output: 18
+
+    Solution: 
+
+    class Solution {
+        public:
+            
+            int enough(vector<int>& nums, int m, int k) {
+                int groups = 0;
+                int curr = 0;
+                for(auto & i : nums) {
+                    if(curr + i > k)  {
+                        groups += 1;
+                        curr = 0;
+                    }
+                    curr += i;
+                }
+                groups += 1; // last group
+                if(groups > m) {
+                    return false;
+                } 
+                return true; 
+            }
+            
+            int splitArray(vector<int>& nums, int m) {
+                // binary search because we only want the minimized value as answer 
+                int high = std::accumulate(nums.begin(), nums.end(), 0);
+                // low is actually the largest element in the array? 
+                int low = *max_element(nums.begin(), nums.end());
+                int ans = high;
+                
+                while(low < high) {
+                    
+                    int mid = low + (high - low)/2;
+                    if(enough(nums, m, mid)) {
+                        high = mid;
+                        ans = min(ans, mid);
+                    } else {
+                        low = mid+1; 
+                    }   
+                }
+                // returning low or high below also works!
+                // bc at end of loop low==high==mid -> enough
+                return ans;
+            }
+
+            int splitArray2(vector<int>& nums, int m) {
+                // binary search because we only want the minimized value as answer 
+                int high = std::accumulate(nums.begin(), nums.end(), 0);
+                // low is actually the largest element in the array? 
+                int low = *max_element(nums.begin(), nums.end());
+                int ans = high;
+                
+                while(low <= high) {
+                    
+                    int mid = low + (high - low)/2;
+                    // cout << "testing value " << mid << endl; 
+                    if(enough(nums, m, mid)) {
+                        // ok that worked. can we go smaller?
+                        high = mid-1;
+                        ans = min(ans, mid);
+                    } else {
+                        // we need it bigger. 
+                        low = mid+1; 
+                    }   
+                }
+                // only returning low or ans works here. cant return high
+                return ans;
+            }   
+    };
+
+
+
+
+
+
+-96) Largest Rectangle in Histogram with Pointer Segment Tree:
+
+    // Largest Rectangle in Histogram
+    // Stack solution, O(NlogN) solution
+
+    class SegTreeNode {
+    public:
+    int start;
+    int end;
+    int min;
+    SegTreeNode *left;
+    SegTreeNode *right;
+    SegTreeNode(int start, int end) {
+        this->start = start;
+        this->end = end;
+        left = right = NULL;
+    }
+    };
+
+    class Solution {
+    public:
+    int largestRectangleArea(vector<int>& heights) {
+        if (heights.size() == 0) return 0;
+        // first build a segment tree
+        SegTreeNode *root = buildSegmentTree(heights, 0, heights.size() - 1);
+        // next calculate the maximum area recursively
+        return calculateMax(heights, root, 0, heights.size() - 1);
+    }
+    
+    int calculateMax(vector<int>& heights, SegTreeNode* root, int start, int end) {
+        if (start > end) {
+        return -1;
+        }
+        if (start == end) {
+        return heights[start];
         }
         int minIndex = query(root, heights, start, end);
         int leftMax = calculateMax(heights, root, start, minIndex - 1);
@@ -1420,270 +1808,27 @@ THESE ARE HARMAN'S PERSONAL SET OF PARADIGMS/ INTERVIEW NOTES:
             return max_a;
         }
 
+-89) Round 1:
 
+    In this round i was asked a constructive problem. It goes like this:
+    Let's say we have a permutation P of length n(n = 5 here) = [3, 5, 1, 4, 2]
+    Now we delete elements from this permutation P from 1 to n in order and write their index to
+    another array Q. When an element is deleted, remaining elements are shifted to left by 1.
+    Initial: P = [3, 5, 1, 4, 2], Q = []
+    delete 1, P = [3, 5, 4, 2], Q = [3] (index of 1 was 3 so write 3(bcz it's index of 1) in Q)
+    delete 2, P = [3, 5, 4], Q = [3, 4]
+    delete 1, P = [5, 4], Q = [3,4,1]
+    delete 1, P = [5], Q = [3, 4, 1, 2]
+    delete 1, P = [], Q = [3, 4, 1, 2, 1]
 
+    Now given Q, we have to restore P.
 
+    I gave a Nlog^N solution using fenwick tree and binary search.
+    He asked me a follow up in which i have to optimize space.
 
--93) Bloomberg BINARY SEARCHING ON AN OBJECTIVE QUESTION. 
-     Calculate amt you can take out monthly that leads to balance 0
-    when balance also gets interest rate of 6%.
-
-    Just make guesses from 0 to totalamt     through binary searching,
-    and then check through math formula if 
-    taking out that specific monthly amount X will 
-    lead to balance of 0
-    when person dies. 
-
-    When do math approximations -> TRY BINARY SEARCH. 
-
-
--92) HOW TO SORT PARTIALLY UNSORTED ARRAYS: ( SPLIT + JOIN)
-    Round 1: Given a sorted n-size array, there are k elements 
-    have been changed i.e. [1, 3, 5, 6, 4, 2, 12] (it might be changed from [1, 3, 5, 6, 7, 8, 12] with k = 2). Important to know is that k is unknown and k is much smaller than n. 
-    The task is to re-sort the entire array.
-    The interviewer wants O(n) solution. I bombed this one. In the end, the 
-    interviewer kind of fed the solution to me. What he suggested: 
-    a. break the array into two: one sorted array and one unsorted array e.g. [1, 3, 5, 12] 
-    and [6, 4, 2]. This takes O(n) 
-    b. Sort the unsorted array. This takes O(klogk) 
-    c. Merge two sorted arrays. This takes O(n). Because k is very small, so in the end O(n) + O(klogk) ~= O(n).
-        
-
-
--91) 
-    Round 2
-    You have two arrays of odd length (same length). 
-    You should check if you can pair elements from both arrays such that 
-    xor of each pair is the same.
-    
-    Ex : [a, b, c] and [d, e, f] check we can find a pairing 
-         say (arrays actually have integers)
-    a xor e = v
-    b xor d = v
-    c xor f = v
-
-    SOLUTION:
-    O(N). XOR all => v. we can take advantage of the property that a^b=v => a^v=>b 
-        and use a hashset.
-
-
-
--90) USING TREESETS AND TREE MAPS C++
-
-    Round 1
-    Design a data structure with two operations 1. addRange(int start, int end) 
-    and 2. contains(int point)
-    Here range means an interval, so the data structure contains information 
-    of all ranges added uptil that point and you can have interleaved queries 
-    of the form contains(int point) which returns true if the point 
-    is contained in any of the ranges or false otherwise.
-
-    The solution I thought of was to store the ranges/intervals as a 
-    list of sorted disjoint intervals (i.e merge overlapping intervals). 
-    Now when we get a contains query, we can perform binary 
-    search(interval with start point equal to or less than point) 
-    to find a potential interval that may contain it. addRange would 
-    be O(n) and contains would be O(logn). I believe there is a better 
-    solution with interval trees but interviewer said this solution 
-    was okay which I ended up coding.
-
-    USE sortedcontainers in python or
-    Q1:
-    Use a treemap => amortized O(logn) merge and O(logn) contains.
-    
-    STL map is inherently a binary search tree - just use map::find. 
-    Using container member functions, where they are present, 
-    is preferable to algorithms.
-
-    How to find all elements in a range in STL map(set)
-
-    If you are using std::map, it's already sorted, your 
-    can use lower_bound/upper_bound an example from cplusplus.com:
-
-    // map::lower_bound/upper_bound
-    #include <iostream>
-    #include <map>
-
-    int main ()
-    {
-        std::map<char,int> mymap;
-        std::map<char,int>::iterator itlow,itup;
-
-        mymap['a']=20;
-        mymap['b']=40;
-        mymap['c']=60;
-        mymap['d']=80;
-        mymap['e']=100;
-
-        itlow=mymap.lower_bound ('b');  // itlow points to b
-        itup=mymap.upper_bound ('d');   // itup points to e (not d!)
-
-        mymap.erase(itlow,itup);        // erases [itlow,itup)
-
-        // print content:
-        for (std::map<char,int>::iterator it=mymap.begin(); it!=mymap.end(); ++it)
-            std::cout << it->first << " => " << it->second << '\n';
-
-        return 0;
-    }
-
-
-    
--89) Round 1:
-
-    In this round i was asked a constructive problem. It goes like this:
-    Let's say we have a permutation P of length n(n = 5 here) = [3, 5, 1, 4, 2]
-    Now we delete elements from this permutation P from 1 to n in order and write their index to
-    another array Q. When an element is deleted, remaining elements are shifted to left by 1.
-    Initial: P = [3, 5, 1, 4, 2], Q = []
-    delete 1, P = [3, 5, 4, 2], Q = [3] (index of 1 was 3 so write 3(bcz it's index of 1) in Q)
-    delete 2, P = [3, 5, 4], Q = [3, 4]
-    delete 1, P = [5, 4], Q = [3,4,1]
-    delete 1, P = [5], Q = [3, 4, 1, 2]
-    delete 1, P = [], Q = [3, 4, 1, 2, 1]
-
-    Now given Q, we have to restore P.
-
-    I gave a Nlog^N solution using fenwick tree and binary search.
-    He asked me a follow up in which i have to optimize space.
-
-    How to use fenwick tree?
-    
-
-
-
-
-
-
-
-
--88)  You are a traveling salesperson who travels 
-      back and forth between two cities (A and B). 
-      You are given a pair of arrays (revA and revB) of length n.
-
-    You can only sell goods in one city per day.
-    At the end of each day you can choose to travel to another 
-    city but it will cost a constant amount of money (travelCost).
-
-    Ex::
-    revA[] = {3, 7,2,100};
-
-    revB[] = {1,1,1,10};
-
-    travelCost = 2;
-    Find maximum profit.
-        int MaxProfitBySalesMan ( int arr1 [] , int arr2 [] , int n )
-        {
-            int dp [ 2 ] [ n ] ; 
-            dp [ 0 ] [ 0 ]  = arr1 [ 0 ] ; 
-            dp [ 1 ] [ 0 ]  = arr2 [ 0 ] ;
-            for ( int i = 1 ; i < n ; i ++ )
-            {
-                dp [ 0 ] [ i ] = max ( dp [ 0 ] [ i -  1 ] , dp [ 1 ][ i  - 1 ] - 2  ) + arr1 [ i ]  ; 
-                dp [ 1 ] [ i ] = max ( dp [ 1 ] [ i -  1 ] , dp [ 0 ][ i  - 1 ] - 2  ) + arr2 [ i ]  ;
-            }
-            return max ( dp [ 0] [ n - 1 ] , dp [ 1 ] [ n - 1 ] ) ;
-        }
-
-
-
--87)Optimizing binary tree questions with bottom up DP: 
-    One way to optimize these questions is to use post-order traversal.
-    Compute the value for the children then compute for parent sorta like DP:
-
-    1.   Count Univalue Subtrees
-    中文English
-    Given a binary tree, count the number of uni-value subtrees.
-    
-    A Uni-value subtree means all nodes of the subtree have the same value.
-    
-    Example
-    Example1
-    
-    Input:  root = {5,1,5,5,5,#,5}
-    Output: 4
-    Explanation:
-                  5
-                 / \
-                1   5
-               / \   \
-              5   5   5
-    Example2
-    
-    Input:  root = {1,3,2,4,5,#,6}
-    Output: 3
-    Explanation:
-                  1
-                 / \
-                3   2
-               / \   \
-              4   5   6
-
-    Solution:
-    def countUnivalSubtrees(self, root):
-        count = 0
-        def helper(node):
-            nonlocal count 
-            if node is None:
-                return None
-            left_result = helper(node.left)
-            right_result = helper(node.right)
-            if left_result == False:
-                return False
-            if right_result == False:
-                return False
-            if left_result and left_result != node.val:
-                return False
-            if right_result and right_result != node.val:
-                return False
-            count += 1
-            return node.val
-        helper(root)
-        return count
-
-
-
-
--86) monotonic stack vs monotonic queue and how to build a monotonic structure
-        LOOK AT HRT PROBLEM.
-        
-
-
--85) think of the algo to do citadel problem -> round robin ALGORITHM!!!
-
-
--84) Using cumulative array for sums in 1D and 2D case tricks:
-    1D) sum between i and j inclsuive:
-        sum(j) - sum(i-1)
-        REMEMBER TO DO I-1 to make it INCLUSIVE!
-
-    2D)
-    Have a 2D cumulative array,
-    of size N+1, M+1, for NxM array
-    top row is all 0s.
-    left column is all 0s.
-    similar to cumualtive array. 
-    
-    2 coordinates is top left and bottom right. 
-    
-    (from snap interview)
-    SUM OF LARGE RECTANGE - SUM OF TOP RIGHT - SUM OF BOTTOM LEFT + SUM OF SMALL RECTANGLE. 
-    
-
-
-    topleft -> tlx, tly
-    bottomright -> brx, bry
-    
-    # because inclusive, not sure though, do lc to check below part.
-    tlx -= 1
-    tly -= 1
-
-    arr[brx][bry] - arr[brx][tly] - arr[tlx][bry]  + arr[tlx][tly]
-
-
-
-
--83) Fenwick Trees youtube video explanation
+    How to use fenwick tree?
+    
+-83) Fenwick Trees youtube video explanation
 
 
     Fenwick Tree youtube video ideas: 
@@ -2188,5416 +2246,11524 @@ THESE ARE HARMAN'S PERSONAL SET OF PARADIGMS/ INTERVIEW NOTES:
         return "".join(res)
 
 
+-60) You cannot use union find to detect cycles in a directed graph. 
+     only undirected. 
+     You cannot use bfs and bipartition coloring to detect even cycles in
+     directed cycle. Only odd cycles can be found. 
+     You can use BFS to do topo sort with indegree 0, then indegree 1 etc. 
 
+     Use bellman ford for negative cycle finding. 
 
--78) Maximal Square DP - DP vs cumulative array strategy?
-    
-    You have a 2D binary matrix that's filled with 0s and 1s. 
-    In the matrix, find the largest square that 
-    contains only 1s and return its area.
-
-    NOTES:
-        When a problem looks like a cumulative array problem try other accumulations,
-        rather than sum, such as 2d segment trees, or 2d maximum slice accumations.
-
-        In this probem -> we did our accumulation based on 3 other coordinates in matrix. 
-        Up your preprocessing game
-        ALWAYS USE THE DIAGONAL SOMEHOW IN 2D ARRAYS + DONT FORGET TOP-LEFT COORDINATE.
-    
-    SOLUTION:
-        def maximalSquare(matrix):
-            
-            '''
-            then do maximal rectangle. 
-            Go right and go down. 
-            question -> how many 1's below me?
-            
-            1 1 1 1
-            1 2 2 2 
-            1 2 3
-
-            Recurrence:
-            dp(i,j) = min(dp(i−1, j), dp(i−1, j−1), dp(i, j−1)) + 1
-
-            BASE CASE: 
-            matrix[i,j] == '0' THEN return 0        
-            '''
-            R = len(matrix)
-            if R == 0:
-                return 0
-            C = len(matrix[0])
-            prevRow = [0 for j in range(C+1)]
-            maxSquare = 0
-            for i in range(R):
-                # we have to zero pad. 
-                currRow = [0]
-                
-                for j in range(1, C+1):
-                    # if current value is 0, put 0.
-                    val = matrix[i][j-1]
-                    if val == "0":
-                        currRow.append(0)
-                    else:
-                        minOfTopAndLeft = min(currRow[-1], prevRow[j-1], prevRow[j])
-                        cellVal = minOfTopAndLeft + 1
-                        maxSquare = max(maxSquare, cellVal**2)
-                        currRow.append(cellVal)
-                        
-                prevRow = currRow[::]
-            return maxSquare
-            
-
-
-
-
-
--77) Painted Ladies BACKWARD DP
-
-    In San Francisco, there is a row of several beautiful houses called 
-    the Painted Ladies. Each of the Painted Ladies can be painted with 
-    one of three colors: red, blue or green. The cost of painting each 
-    house with a certain color is different. cost[i][0] for each i is 
-    the cost of painting house i red, cost[i][1] is the cost of painting 
-    it blue, and cost[i][2] is the cost of painting it green.
-
-    You want to paint all the houses in a way such that no two adjacent 
-    Painted Ladies have the same color. Find the minimum cost to achieve this.
+-59) BUCKET SORT K most frequent elements:
+    Bucket Sort Algorithm: Steps on how it works:
+    Create an empty array.
+    Loop through the original array and put each object in a “bucket”.
+    Sort each of the non-empty buckets
+    Check the buckets in order and then put all objects back into the original array.
 
-    Example
+    function bucketSort(array, k) is
+        buckets ← new array of k empty lists
+        M ← the maximum key value in the array
+        for i = 1 to length(array) do
+            insert array[i] into buckets[floor(k × array[i] / M)]
+        for i = 1 to k do
+            nextSort(buckets[i])
+        return the concatenation of buckets[1], ...., buckets[k]
 
-    For cost = [[1, 3, 4], [2, 3, 3], [3, 1, 4]], the output should be
-    paintHouses(cost) = 5.
+    Here array is the array to be sorted and k is the number of buckets to use. 
+    The maximum key value can be computed in linear time by looking up all the keys 
+    once. The floor function must be used to convert a floating number to an integer. 
+    The function nextSort is a sorting function used to sort each bucket. 
+    Conventionally, insertion sort would be used, but other algorithms 
+    could be used as well. Using bucketSort itself as nextSort 
+    produces a relative of radix sort; in particular, the case 
+    n = 2 corresponds to quicksort (although potentially with poor pivot choices).
 
-    def paintHouses(cost):
-        
-        '''
-        recurrence 
-        OPT[i, color] = minimum cost as a result of choosing a specific color. 
-        # compute all three! -> BACKWARD DP. 
-        OPT[i, Blue] = min(OPT[i-1, RED], OPT[i-1, GREEN])
-        OPT[i, RED] =  min(OPT[i-1, BLUE], OPT[i-1, GREEN])
-        OPT[i, GREEN] =  min(OPT[i-1, BLUE], OPT[i-1, RED])
-        answer is min(of all colors OPT[i])
-        
-        recursive
-        fn(idx, prev_color)
-            we know prev color -> choose other 2 colors. 
-            take min of choosing either color!
-        
-        Space optimize to 3 variables!        
-        '''
-        opt_b, opt_r, opt_g = cost[0][0], cost[0][1], cost[0][2]
-        IDX_b, IDX_r, IDX_g = 0, 1, 2
-        
-        for i in range(1, len(cost)):
-            blue_cost = cost[i][IDX_b]
-            red_cost = cost[i][IDX_r]
-            green_cost = cost[i][IDX_g]
-            
-            opt_b, opt_g, opt_r = \
-                min(opt_r, opt_g) + blue_cost, min(opt_r, opt_b) + green_cost, min(opt_b, opt_g) + red_cost  
-            
-        return min(opt_b, opt_g, opt_r)
 
+    Given a non-empty array of integers, return the k most frequent elements.
 
+    Example 1:
 
+    Input: nums = [1,1,1,2,2,3], k = 2
+    Output: [1,2]
 
--76) Linked Lists, 2 Pointers and simplifying problems by  respecting   
-     OPEN-CLOSE 2 pointers which satisfy a <= b < c aka [X, Y) for start and end. 
+    Bucket sort is O(N):
 
-    Given a singly linked list of integers l and a non-negative integer n, 
-    move the last n list nodes to the beginning of the linked list.
+    def topKFrequent(self, nums, k):
+        bucket = [[] for _ in range(len(nums) + 1)]
+        Count = Counter(nums).items()  
+        for num, freq in Count: bucket[freq].append(num) 
+        flat_list = [item for sublist in bucket for item in sublist]
+        return flat_list[::-1][:k]
 
-    Example
+    
 
-    For l = [1, 2, 3, 4, 5] and n = 3, the output should be
-    rearrangeLastN(l, n) = [3, 4, 5, 1, 2];
-    For l = [1, 2, 3, 4, 5, 6, 7] and n = 1, the output should be
-    rearrangeLastN(l, n) = [7, 1, 2, 3, 4, 5, 6].
 
-    HARMAN SOLUTION WHICH USES 2POINTERS that refer to [start, end]
-    problem is both pointers can point to same node so this case 
-    has to be handled seperately!! + other edge cases.
-    
-        def rearrangeLastN(l, n):     
-            # use 2 pointers that occupy n space. 
-            # go to the  second last element. do you know why? 
-            # because we have to set None to the element we are 
-            # splitting from. 
-            i = l 
-            j = l
-            
-            if l is None:
-                return None
-            if n == 0:
-                return l
-                
-            # n-1 spaces between n nodes
-            for _ in range(n-1):
-                j = j.next
-            
-            # the whole list was chosen as n. 
-            if j.next == None:
-                return l
+-58) HOARES PARTITION, QUICK SELECT K most frequent elements: 
+     Approach 2: Quickselect
+     Hoare's selection algorithm
+ 
+     Quickselect is a textbook algorthm typically used to solve the problems 
+     "find kth something": kth smallest, kth largest, kth most 
+     frequent, kth less frequent, etc. Like quicksort,  
+     quickselect was developed by Tony Hoare, and also known as Hoare's selection algorithm.
+ 
+     It has O(N) average time complexity and widely used in practice. It worth to note that its worth 
+     case time complexity is O(N^2), although the probability 
+     of this worst-case is negligible.
+ 
+     The approach is the same as for quicksort.
+ 
+     One chooses a pivot and defines its position in a sorted array in a 
+     linear time using so-called partition algorithm.
+ 
+     As an output, we have an array where the pivot is on its perfect position 
+     in the ascending sorted array, sorted by the frequency. All elements 
+     on the left of the pivot are less frequent  than the pivot, and 
+     all elements on the right are more frequent or have the same frequency.
+ 
+     Hence the array is now split into two parts. If by chance our pivot element 
+     took N - kth final position, then k elements on the right are 
+     these top k frequent we're looking for. If  not, we can choose 
+     one more pivot and place it in its perfect position.
+ 
+     If that were a quicksort algorithm, one would have to process both parts of the array. 
+     Quickselect just deal with one side -> O(N)
+ 
+     Algorithm
+ 
+     The algorithm is quite straightforward :
+ 
+     Build a hash map element -> its frequency and convert its keys into the 
+     array unique of unique elements. Note that elements are unique, but 
+     their frequencies are not. That means we need  
+     a partition algorithm that works fine with duplicates.
+ 
+     Work with unique array. Use a partition scheme (please check the next section) 
+     to place the pivot into its perfect position pivot_index in the sorted array, 
+     move less frequent elements  to the left of pivot, 
+     and more frequent or of the same frequency - to the right.
+ 
+     Compare pivot_index and N - k.
+ 
+     If pivot_index == N - k, the pivot is N - kth most frequent element, 
+     and all elements on the right are more frequent or of the 
+     same frequency. Return these top kk frequent elements.
+ 
+     Otherwise, choose the side of the array to proceed recursively.
+ 
+     Hoare's Partition vs Lomuto's Partition
+ 
+     There is a zoo of partition algorithms. 
+     The most simple one is Lomuto's Partition Scheme.
+     The drawback of Lomuto's partition is 
+     it fails with duplicates.
+ 
+     Here we work with an array of unique elements, but they are 
+     compared by frequencies, which are not unique. 
+     That's why we choose Hoare's Partition here.
+ 
+     Hoare's partition is more efficient than Lomuto's partition
+     because it does three times fewer swaps on average, and 
+     creates efficient partitions even when all values are equal.
+ 
+     Here is how it works:
+     Move pivot at the end of the array using swap.
+ 
+     Set the pointer at the beginning of the array store_index = left.
+ 
+     Iterate over the array and move all less frequent elements to the 
+     left swap(store_index, i). Move store_index 
+     one step to the right after each swap.
+ 
+     Move the pivot to its final place, and return this index.
+
+    from collections import Counter
+    class Solution:
+        def topKFrequent(self, nums: List[int], k: int) -> List[int]:
+            count = Counter(nums)
+            unique = list(count.keys())
             
-            # second last.
-            while j and j.next and j.next.next:
-                i = i.next
-                j = j.next
+            def partition(left, right, pivot_index) -> int:
+                pivot_frequency = count[unique[pivot_index]]
+                # 1. move pivot to end
+                unique[pivot_index], unique[right] = unique[right], unique[pivot_index]  
+                
+                # 2. move all less frequent elements to the left
+                store_index = left
+                for i in range(left, right):
+                    if count[unique[i]] < pivot_frequency:
+                        unique[store_index], unique[i] = unique[i], unique[store_index]
+                        store_index += 1
+
+                # 3. move pivot to its final place
+                unique[right], unique[store_index] = unique[store_index], unique[right]  
+                
+                return store_index
             
-            # get last node. 
-            j.next.next = l
+            def quickselect(left, right, k_smallest) -> None:
+                """
+                Sort a list within left..right till kth less frequent element
+                takes its place. 
+                """
+                # base case: the list contains only one element
+                if left == right: 
+                    return
+                
+                # select a random pivot_index
+                pivot_index = random.randint(left, right)     
+                                
+                # find the pivot position in a sorted list   
+                pivot_index = partition(left, right, pivot_index)
+                
+                # if the pivot is in its final sorted position
+                if k_smallest == pivot_index:
+                    return 
+                # go left
+                elif k_smallest < pivot_index:
+                    quickselect(left, pivot_index - 1, k_smallest)
+                # go right
+                else:
+                    quickselect(pivot_index + 1, right, k_smallest)
             
-            # end
-            newStart = i.next            
-            # SET THE NULLS AT THE END BECAUSE WE CAN 
-            # BREAK LINKED LIST FUNCTIONALITY
-            # IF BOTH POINTERS POINT AT SAME NODE!
-            i.next = None
-            return newStart
-
-    OPEN CLOSE NOTATION SOLUTION CLEANNN:
+            n = len(unique) 
+            # kth top frequent element is (n - k)th less frequent.
+            # Do a partial sort: from less frequent to the most frequent, till
+            # (n - k)th less frequent element takes its place (n - k) in a sorted array. 
+            # All element on the left are less frequent.
+            # All the elements on the right are more frequent.  
+            quickselect(0, n - 1, n - k)
+            # Return top k frequent elements
+            return unique[n - k:]
 
-        def rearrangeLastN(l, n):
-            if n == 0:
-                return l
-            front, back = l, l
-            for _ in range(n):
-                front = front.next
-            if not front:
-                return l
-            while front.next:
-                front = front.next
-                back = back.next
-            out = back.next
-            back.next = None
-            front.next = l
-            return out
 
+-52) Random Node: Create a binary tree class, which in addition to 
+    insert, find, and delete, has a method getRandomNode() which 
+    returns a random node from teh tree. All nodes should be equally likely to be chosen
 
-        
+    Just traverse left, return current, or right node with 1/3 probability
+    But this isnt O(N) for all nodes, top nodes more likely.
 
+    Return root with 1/N prb
+    odds of picking left node is LEFT_SIZE * 1/N, odds of going right is RIGHT_SIZE * 1/n
 
+    But we dont want to make that many RNG calls. Use inorder traversal to help:
 
+    Generate one random number -> this is the node (i) to return, and then 
+    we locate ith node using inorder traversal. Suubtracting leftsz + 1 from i 
+    reflects that, when we go right, we skip over left+1 nodes in the inorder traversal. 
 
 
 
 
+-51) Inorder Succcesor. Find next node of a given node in a BST. You
+    may assume each node has link to parent:
 
+    Node inorderSucc(Node n): 
+        if n has a right subtree:
+            return leftmost child of right subtree
+        else: 
+            while n is a right child of n.parent:
+                n = n.parent
+            
+            return n.parent
+    
 
--75) ORDERED SETS vs PRIORTIY QUEUES (Python does not have ordered set aka bst)
 
-    Since both std::priority_queue and std::set (and std::multiset) are data 
-    containers that store elements and allow you to access them in an ordered 
-    fashion, and have same insertion complexity O(log n), what are the advantages 
-    of using one over the other (or, what kind of situations call for the one or the other?)?
+-50) Cool counting trick to count pairs: (Done in CodeSignal HARD)
+    ALSO RECALL THEORY THAT SORTEDNESS OF NUMBERS YIELDS COMBINATIONS NOT PERMUTATIONS 
+    In case you have a problem where you need to get all combinations! just enforce 
+    a sort on the list before picking elements. 
 
-    While I know that the underlying structures are different, I am not as much 
-    interested in the difference in their implementation as I am in the comparison 
-    their performance and suitability for various uses.
+    Problem: A reverse is a number reversed. 
+    So 20 reversed is 2, 420 reversed is 24, 56060 reversed is 6065
 
-    Note: I know about the no-duplicates in a set. That's why I also mentioned std::multiset 
-    since it has the exactly same behavior as the std::set but can be used 
-    where the data stored is allowed to compare as equal elements. 
-    So please, don't comment on single/multiple keys issue.
+    Given 2 arrays, A and ReverseA, count all pairs i <= j
+    where A[i] + ReverseA[j] == Reverse[i] + A[j].
+    
+    So for instance given input: [1, 20, 3,  19 ] ->   A[i] + ReverseA[j] 
+                ReverseA is then [1,  2, 3,  91 ]
+        A[i] + ReverseA[j] == Reverse[i] + A[j] indexes are:
+        [(0,0),(1,1), (2,2), (3,3), (0,2)]
 
-    The priority queue only offers access to the largest element, while the set 
-    gives you a complete ordering of all elements. This weaker interface means that 
-    implementations may be more efficient (e.g. you can store the actual queue 
-    data in a vector, which may have better performance on account of its memory locality).
+    SINCE WE ARE COUNTING AND DONT HAVE TO LIST OUT ALL THE PAIRS IN THE
+    SOLUTION THIS TIPS US OFF THAT THERE IS AN O(N) soln. 
+    Brute force soln -> Enumerating pairs is O(N^2). 
 
+    OK BE SMART BY REARRANGING CONSTRAINT SO THAT WE CAN DO EASILY PRECOMPUTATIONS. 
+    A[i] + ReverseA[j] == Reverse[i] + A[j]
+    Rearrange to have variables of same type on same side:
+    
+    A[i] - Reverse[i] == A[j] - ReverseA[j]
+    Ok now precompute the top array. 
 
-    A priority queue only gives you access to one element in sorted order -- i.e., 
-    you can get the highest priority item, and when you remove that, you can get 
-    the next highest priority, and so on. A priority queue also allows duplicate 
-    elements, so it's more like a multiset than a set. [Edit: As @Tadeusz Kopec pointed out, 
-    building a heap is also linear on the number of items in the heap, where building a 
-    set is O(N log N) unless it's being built from a sequence that's already 
-    ordered (in which case it is also linear).]
+    differences = []
+    for i,j in zip(A, RevA):
+        differences.append(i - j )
+    
+    AND RMBR YOU CAN COUNT PAIRS USING A MAP!! Pairs where i <= j
+    Use formula n*(n-1)/2
 
-    A set allows you full access in sorted order, so you can, for example, find 
-    two elements somewhere in the middle of the set, then traverse in order from one to the other.
+    m = defaultdict(int)
+    
+    for diff in differences:
+        m[diff] += 1
 
+    So if m[3] -> means 3 different indexs have the same difference and 3 diff 
+                  indexes satisfy A[i] - Reverse[i] == A[j] - ReverseA[j]
+                  For instance index: (2, 4, 7)
+                  -> So 2<->4, 2<->7, and 4<->7 should be counted. Also rmbr 2<->2, 4<->4, 7<->7
+                     need to be counted too.
+                    Its a permutation of 2 elements (i,j), but with order, so to remove order, 
+                    divide by the ways it can be ordered which is 2!. Finanl solution is  
+                    aka _ _   (n) x (n-1) / 2!
+                    And then to sum the 2<->2, 4<->4, 7<->7, just add lenght of list. 
 
--74)MULTI TIMESTAMP DP FINITE STATE MACHINE problems. Bottom up with decode ways:
-    DECODE WAYS (REVIEW in most important)
-    class Solution:
-        def numDecodings(self, s):        
-            # BOTTOM UP ONLY!
-            '''        
-            ADD UP ALL THE WAYS WE ARRIVED TO A STATE FROM OTHER STATES!!
-            USE IF STATEMENTS TO DETECT IF WE CAN ARRIVE TO THE STATE. 
-            
-            OPT[i] = OPT[i-1]   (TAKE ONE ALWAYS POSSIBLE!)
-                    + OPT[i-2]   (TAKE 2 MAY NOT BE POSSIBLE)
-            
-            s = "12"
-            "0" does not map to anything -> can only be used with 10 or 20
-            
-            226
-            2 -> 1  b
-            22 -> 1 bb 
-            2 26
-            3 ways:
-            2 2 6
-            22 6
-            2 26
-            
-            Base case empty string = 1?
-            take 1 
-            2 
-            take 2:
-            22 
-            next timestamp?
-            we take 1 
-            
-            OPT[i] -> all the ways to decode up to index i. 
-            process index 0 -> only 1 way to decode unless its 0. 
-            can take 2 charcters if OPT[i-1] exists. 
-            
-            In other words solution relies on 3 timesteps to build finite automata
-            '''
-            
-            OPT = [0 for i in range(len(s) +1)]
-            
-            # BASE CASE
-            OPT[0] = 1 
-            prevCh = None
-            seeNonezero = False
-            
-            # BTW its easy to optimize this to O(N) space, using 2 variables for 
-            # previous 2 timestamps. 
-            
-            for idx in range(1, len(s)+1):
-                # 0 cannot become anything!
-                # take current character as single. 
-                ch = int(s[idx-1])
-                if ch != 0:
-                    OPT[idx] += OPT[idx-1]    
-                # only way we can use 0 is if we see prev.                         
-                # if you see 2 zeros in a row you cant decode it -> answer is 0. 
-                if prevCh != None: 
-                    # take current character + prev char!
-                    if (prevCh == 1 and ch < 10) or (prevCh == 2 and ch < 7):
-                        OPT[idx] += OPT[idx-2]
-                # loop end set prevCharacter
-                prevCh = ch            
-                
-            return OPT[len(s)]    
-
+                -> For example: count pairs from these indicies where i<=j : [1,3,4,5]
+                this is 4*3/2 -> 6
+                1<->3, 1<->4, 1<->5, 3<->4, 3<->5, 4<->5s
+                lst sz 4: 3+2+1 -> 6
 
+    count = 0
+    for k,v in m.items():
+        count += v*(v-1)/2
+    count += len(differences)
+    return count
 
--73) To solve weird optimization problems, write out the problem constraints in 
-     mathematical notation!  
-     + english words
-     + greedy detection/hill finding/maximization/montonic queue/segment tree optimize/binary search/quick select   
-     + As you find constraints -> think of edge cases -> can they be solved by setting the base case in a recurrence?
-     + NEGATIVE SPACE. 
-     + or through other means? 
     
-    1.    Remove Covered Intervals: 
 
-    Given a list of intervals, remove all intervals that are covered by another interval in the list.
 
-    Interval [a,b) is covered by interval [c,d) if and only if c <= a and b <= d.
 
-    After doing so, return the number of remaining intervals.
-    
-    Example 1:
+-49) To do math cieling operation on num:
+    (num - 1) // divisor + 1
 
-    Input: intervals = [[1,4],[3,6],[2,8]]
-    Output: 2
-    Explanation: Interval [3,6] is covered by [2,8], therefore it is removed.
-    Example 2:
+-48) DP + BINARY Search (DELETE IF YOU DONT UNDERSTAND):
 
-    Input: intervals = [[1,2],[1,4],[3,4]]
-    Output: 1
-    class Solution:
-        def removeCoveredIntervals(self, intervals: List[List[int]]) -> int:
-            '''
-            Sort by start time. 
-            
-            Then check if interval after me I cover. If i do remove, 
-            otherwise keep. 
-            
-            sort intervals by start time.          
-            
-            when checking next interval, make sure its start time is after 
-            the max finish time, otherwise covered. 
-            
-            Compare end time of first one with endtime of second one, if its within its covered.
-            OTHERWISE!!,
-            
-            if you get an interval with further endtime -> update the FOCUS interval to that. 
-            because it will be able to cover more on the right. 
-            So keep the one with largest end time asthe main focus. 
-            
-            Requires sorting on start time  -> NLOGN.
-            
-            need to do 2 sorts, 
-            earliest start time,
-            then for those with same start time -> latest finish time comes first. 
-            So then the latest finish times can consume the earlier finish times and be used to consume intervals
-            without same start time. 
-            '''
-            
-            # DO A DOUBLE SORT -> MAJOR SORT ON START -> MINOR SORT ON FINISH TIME. 
-            intervals.sort(key=lambda x: (x[0], -x[1]))
-            
-            curr_fin = intervals[0][1]
-            
-            covered_count = 0
-            for i in range(1, len(intervals)):
-                nxt_fin = intervals[i][1]
+    1180 - Software Company
 
-                if nxt_fin <= curr_fin:
-                    covered_count += 1
-                else:
-                    curr_fin = nxt_fin
-                    
-            return len(intervals) - covered_count
+    This company has n employees to do the jobs. To manage the two 
+    projects more easily, each is divided into m independent subprojects. 
+    Only one employee can work on a single subproject at one
+    time, but it is possible for two employees to work 
+    on different subprojects of the same project
+    simultaneously. Our goal is to finish the projects as soon as possible.
 
+    Each case starts with two integers n (1 ≤ n ≤ 100), and m (1 ≤ m ≤ 100). Each of the next n lines
+    contains two integers which specify how much time in seconds it will take for the specified
+    employee to complete one subproject of each project. So if the line contains x and y, it means that it
+    takes the employee x seconds to complete a subproject from the first project, and y seconds to
+    complete a subproject from the second project.    
+    Input        -> Output : 
+    3 20           Case 1: 18
+    1 1           The input will be such that answer will be within 50000.
+    2 4
+    1 6
 
+    Run a binary search fixing the time needed to complete both the projects. 
+    Now you know for each employee, the doable max amount of sub-projects of A fixing 
+    the amount of sub-projects to do of type B. Keep a dp[i][j] which means the maximum 
+    number of sub-projects of B that can be done while j sub-projects of A are still 
+    to be done and we’re currently at employee i. If dp[0][m] >= m 
+    then the time fixed is ok. Answer is the minimum such time.
 
+    const int N = 107;
+    int dp[N][N];
+    int n, m;
+    int x[N], y[N];
 
+    bool ok(int tym) {
+        for(int i=1; i<=m; ++i) dp[n][i] = -INF;
+        dp[n][0] = 0;
+        for(int i=n-1; i>=0; --i) {
+            for(int j=0; j<=m; ++j) {
+                dp[i][j] = -INF;
+                int max_a = tym / x[i];
+                max_a = min(j, max_a);
+                for(int k=0; k<=max_a; ++k) {
+                    int max_b = (tym-k*x[i]) / y[i];
+                    dp[i][j] = max(dp[i][j], max_b + dp[i+1][j-k]);
+                }
+            }
+        }
+        return (dp[0][m] >= m);
+    }
 
+    int main() {
+        int t, tc=0;
+        scanf("%d", &t);
 
+        while(t--) {
+            scanf("%d %d", &n, &m);
+            for(int i=0; i<n; ++i) scanf("%d %d", x+i, y+i);
 
--72) Getting tripped up by doordash challanege:
-     WHEN TO USE DP VS SORTING+GREEDY+MAXIMALMUNCH+HEAPQ SOLUTION/HILLFINDING. 
+            int lo = 1, hi = 50000;
+            while(lo < hi) {
+                int mid = (lo + hi) / 2;
+                if(ok(mid)) hi = mid;
+                else lo = mid + 1;
+            }
+            printf("Case %d: %d\n", ++tc, hi);
+        }
 
-    Question: 
-    So given drivers, they have speed, and professionalism such as:
-    5 drivers and [100, 12, 4, 23, 5], [20, 30, 50, 12, 12]
+        return 0;
+    }
 
-    We can only select a maximum of 3 drivers and a minium of 1. 
-    We want to get the max quality of a set of drivers 
-    where quality = (Sum of drivers speed ) * min(of all drivers professionalism)
 
-    What we can do is sort by professionals, so we can always take the best drivers first
-    and then the worse drivers next. And we should take maximal because its sum for the speed.
-    HOWEVER WE ARE LIMITED IN THE NUMBER OF MAX DRIVERS WE CAN TAKE.
-    TO DEAL WITH THAT USE A HEAPQ TO STORE THE CURRENT SUM OF DRIVERS, AND POP THE SMALLEST
-    VALUE DRIVER FROM SET OF DRIVERS.
-    and keep track of max sum as you do this. 
+-47) GREEDY ALGORITHM INTERVAL DEADLINES C++
     
+    It is required to create such a schedule to accomplish the biggest number of jobs.
 
-    Initially i tried to solve with DP because thinking through the problem was hard.
-    You should know when to use dp and when not too. YOU MUST START BY EXPLOITING PROBLEM 
-    STRUCTURE AND THINKING GREEDY IN ALL DIRECTONS. Then when you figure that out, 
-    TRY HILL FINDING WITH A DEQUE/HEAPQ/SEGMENT TREE. 
+    struct Job {
+        int deadline, duration, idx;
 
-    THAT IS THE WAY!!!!
-    SOLUTION BELOW: 
+        bool operator<(Job o) const {
+            return deadline < o.deadline;
+        }
+    };
 
+    vector<int> compute_schedule(vector<Job> jobs) {
+        sort(jobs.begin(), jobs.end());
 
-    from heapq import heappush, heappop
+        set<pair<int,int>> s;
+        vector<int> schedule;
+        for (int i = jobs.size()-1; i >= 0; i--) {
+            int t = jobs[i].deadline - (i ? jobs[i-1].deadline : 0);
+            s.insert(make_pair(jobs[i].duration, jobs[i].idx));
+            while (t && !s.empty()) {
+                auto it = s.begin();
+                if (it->first <= t) {
+                    t -= it->first;
+                    schedule.push_back(it->second);
+                } else {
+                    s.insert(make_pair(it->first - t, it->second));
+                    t = 0;
+                }
+                s.erase(it);
+            }
+        }
+        return schedule;
+    }
+
+
+-43.5) USE BINARY SEARCH EVEN WHEN YOU DONT THINK YOU NEED IT.
+       USE IT WHEN YOU CAN MAP HALF THE VALUES TO TRUE AND THE OTHER HALF TO FALSE SOMEHOW
+       COME UP WITH MAPPING THEN UTILIZE BINSEARH!
 
-    def maximumTeamQuality(speed, professionalism, maxDashers):
-        '''
-        sort by professionalism.
         
-        keep taking ppl, and update max?
-        as we reduce professionalism -> speed increases. 
-        and we should always take everyone thats more professional
-        '''  
-        
-        zipped = sorted(zip(professionalism, speed), key=lambda x: x[0], reverse=True)
-                
-        # pop the lowest sum element each time when we go over maxDashers!
-        # since the professionalism doesnt matter for the chosen ones if we choosing lower
-        # professionalism one. 
-        # need minheap.
-        
-        maxQ = 0
-        curr_sum = 0
-        h = []
-        
-        for p, s in zipped: 
-            curr_sum += s
-            # check
-            if len(h) == maxDashers:
-                smallest = heappop(h)
-                curr_sum -= smallest[0]
-                
-            heappush(h, [s])    
-
-            maxQ = max(maxQ, curr_sum*p)
-        return maxQ
-
+        LC:  644-maximum-average-subarray-ii
+        Given an array consisting of n integers, find the contiguous 
+        subarray whose length is greater than or equal to k 
+        that has the maximum average value. 
+        And you need to output the maximum average value.
+        Input: [1,12,-5,-6,50,3], k = 4
+        Output: 12.75
+        Explanation:
+        when length is 5, maximum average value is 10.8,
+        when length is 6, maximum average value is 9.16667.
+        Thus return 12.75.
 
+        
+        Method 1: Use Binary Search
 
+            first we do a binary search on the average and let it be x
+            we decrease x from all of the array elements and if there exists a 
+            sub array with lengh more than k whose sum is more than zero then we can 
+            say that we have such a sub array whose average is more than x other wise 
+            we can say that there doesnt exist any such sub array
 
--71) Interval Problem Type Intuition, and Line Sweeping
-     Try 2 pointer! or heap!
-     
-    1.   Interval List Intersections
-    Given two lists of closed intervals, each list of 
-    intervals is pairwise disjoint and in sorted order.
+            how to find out if there is a sub array whose sum is more than zero and its 
+            length is more than k? we can say that a sub array [l, r) equals sum[1, r) — sum[1, l) 
+            so if we get the partial sums and fix the r of the sub array we just need an l 
+            which sum[1, r) >= sum[1, l) and l <= r — k this can 
+            be done with partial minimum of the partial sums
 
-    Return the intersection of these two interval lists.
+        Method 2: Use a diff bin search
+            Goal: Find the maximum average of continuous subarray of 
+            length greater than or equal to k.
 
-    (Formally, a closed interval [a, b] (with a <= b) denotes the set of real numbers x with a <= x <= b.  The intersection of two closed intervals is a set of real numbers that is either empty, or can be represented as a closed interval.  For example, the intersection of [1, 3] and [2, 4] is [2, 3].)
+            Assumption: The answer is between the maximum value 
+            and the minimum value in the array.
 
-    Example 1:
-    Input: A = [[0,2],[5,10],[13,23],[24,25]], B = [[1,5],[8,12],[15,24],[25,26]]
-    Output: [[1,2],[5,5],[8,10],[15,23],[24,24],[25,25]]
+            As a result, we can do a binary search for the answer, 
+            while using the minimum value and the maximum value as left and right boundary (inclusive).
 
-    2 POINTER SOLUTION OPTIMAL: 
-        def intervalIntersection(self, A: List[List[int]], B: List[List[int]]) -> List[List[int]]:
-            '''
-            FOR INTERVAL QUESTIONS RMBR:
-            SORTS FOR INTERSECTIONS USUALLY BEST TO SORT BY START TIME.
-            
-            BUT WHENEVER WE ARE CHECKING TO REMOVE INTERVALS FROM THE ACTIVE REGION!
-            REMOVE BASED ON EARLIEST FINISH TIME, RATHER THAN OTHER METRICS:
-            
-            SOLUTION IS 2 POINTERS:
-            
-            ANOTHER INTERSECTION HINT: 
-            INTERSECTIONS HAVE THE FORM OF THE FOLLOWING:
-            [max(Astart, Bstart), min(Aend, Bend)]
-            -> intersection exists if above computation is a real interval!
-                (aka has positive length)        
-            '''
-            
-            i = 0
-            j = 0
-            res = []
-            if len(A) == 0 or len(B) == 0:
-                return []
-            
-            '''
-            You dont move pointers based on what the next earlier one was
-            but the one that finished earlier, 
-            because that one can no longer intersect with anything!
-            '''
-            while i < len(A) and j < len(B):
-                
-                a_start, a_end = A[i]
-                b_start, b_end = B[j]
-                
-                pos_int_s = max(a_start, b_start)
-                pos_int_e = min(a_end, b_end)
-                if pos_int_s <= pos_int_e:
-                    res.append([pos_int_s, pos_int_e])
-                
-                if a_end < b_end:
-                    i += 1
-                else:
-                    j += 1 
-            return res
+            Given the initial value of left and right boundary, we can 
+            compute the mid value. The problem is how we decide where the
+            answer lies, in [left, mid) or [mid, right].
 
+            If and only if there exists a subarray whose length is at least k, 
+            and its average value is greater than or equal mid, 
+            then the answer lies in [mid, right].
 
-    LINE SWEEPING SOLUTION:
-        Remember when things are presorted, then line sweeep is not 
-        optimal because it requires sorting.
-        O(NLOGN) so it is slower than sorted variant!
+            The problem becomes: Decide if there exists a subarray 
+            whose length is at least k, and its average value is greater than mid.
 
+            Consider such scenario: The average of A[1..n] >= mid is the same 
+            as the average of B[1..n] >= 0 where B[i] = A[i] - mid.
 
-        Like every interval problem, this can be solved by line sweep. 
-        Note that, if the input is already pre-sorted, this 
-        isn't an optimal solution. But it is cool and interesting.
+            If we construct the new array B[] based on the given array A[], 
+            the problem becomes: Decides if there's a subarray whose length 
+            is at least k, and its sum is greater than 0,
 
-        The general idea here is that we have a window, keyed by 
-        person A or person B. When we add/remove intervals, we just need 
-        to be careful that we're extending any existing window values, 
-        if that person already exists in our window.
+            which is the same as finds the maximum subarray sum where 
+            the length of the subarray needs to be at least k.
 
-        Time: O(n log n)
-        Space: O(n)
+            When it comes to the maximum subarray sum, it is natural to 
+            think of the classic solution: "keep adding each integer to the 
+            sequence until the sum drops below 0. If sum is negative, reset the sequence."
 
-        class Solution:
-            def intervalIntersection(self, A: List[List[int]], B: List[List[int]]) -> List[List[int]]:
-                events = []
-                OPEN, CLOSE = 0, 1
-                
-                for start, end in A:
-                    events.append((start, OPEN, end, "A"))
-                    events.append((end, CLOSE, end, "A"))
-                    
-                for start, end in B:
-                    events.append((start, OPEN, end, "B"))
-                    events.append((end, CLOSE, end, "B"))
-                
-                events.sort()
-                window = {}
-                ans = []
-                
-                for time, event_type, end, key in events:
-                    if event_type == OPEN:
-                        window[key] = (time, end)
-                    else:
-                        del window[key]
+            However, it cannot work for our case, as we have requirement for the subarray length.
 
-                    if len(window) > 1:
-                        start_a, end_a = window["A"]
-                        start_b, end_b = window["B"]
-                        
-                        best_start = max(start_a, start_b)
-                        best_end = min(end_a, end_b)
-                        ans.append((best_start, best_end))
-                        
-                return ans
+            Another simple way to find the maximum subarray is dynamic programming. 
+            If we can use DP to calculate the presum of the array (every subarray 
+            with start from the first element), we only need to find the maximum 
+            increase in the presum array.
 
+            We can slightly modify this approach to solve our problem. 
+            When finding the maximum increase, we no longer record the smallest 
+            element appeared before, but record the smallest element appeared k positions before.
 
-    LINE SWEEPING second method.
+            You should easily see that this will cover the case where the 
+            length of the subarray is greater than k.
+            
+            Time complexity O(nlog(max-min))
+            Space complexity O(1)
 
-        class Solution {
-            public int[][] intervalIntersection(int[][] A, int[][] B) {
-                List<int[]> res = new ArrayList<>();
-                int n = A.length + B.length;
-                int[] start = new int[n], end = new int[n];
-                int c = 0;
-                for (int i = 0;  i < A.length; ++i) {
-                    start[c] = A[i][0];
-                    end[c++] = A[i][1];
-                }
-                
-                for (int i = 0;  i < B.length; ++i) {
-                    start[c] = B[i][0];
-                    end[c++] = B[i][1];
-                }
-                
-                // O(n log (n))
-                Arrays.sort(start);
-                Arrays.sort(end);
-                
-                /**
-                line sweep : go from left to right, stopping at start or end intervals.
-                if its a start the increment busy.
-                if its an end, decrement busy. before that check if 2 intervals are busy at the moment, if they are, it means A and B are indulged in the period end[e] and start[s - 1].
-                note that end[e - 1] < start[s - 1] if busy = 2 else busy < 2, so the interval of interest is start[s - 1] and end[e]. Also s cannot be 0.
-                */
-                int s = 0, e = 0, busy = 0;
-                while( e < n ) {
-                if (s < n && start[s] <= end[e]) {
-                    busy++;
-                    ++s;
-                } else {
-                    if (busy == 2) {
-                        res.add(new int[] {start[s - 1], end[e]});
+            class Solution {
+            public :
+                double findMaxAverage(vector< int >& nums, int k) {
+                    int n = nums.size();
+                    vector < double > sums(n + 1 , 0 );
+                    double left = * min_element(nums.begin(), nums.end());
+                    double right = * max_element(nums.begin(), nums.end()) ;
+                    while (right-left> 1e- 5 ) {
+                        double minSum = 0 , mid = left + (right-left) / 2 ;
+                        bool check = false ;
+                        for ( int i = 1 ; i <= n; ++ i) {
+                            sums[i] = sums[i- 1 ] + nums[i- 1 ] -mid;
+                            if (i >= k) {
+                                minSum = min(minSum, sums[i- k]);
+                            }
+                            if (i >= k && sums[i]> minSum) {check = true ; break ;}
+                        }
+                        if (check) left = mid;
+                        else right = mid;
                     }
-                    busy--;
-                    ++e;
-                }
+                    return left;
                 }
-                
-                return res.toArray(new int[0][0]); 
-            }
-        }
+            };
 
 
 
 
--70) Example of extracting dynamic programming traversal paths 
-     after doing DP problem.
-        '''
-        CombinationSum:
+-43) Maximum Slice problem, Kadane's algorithm and extensions
 
-        Given an array of integers a and an integer sum, find all of the 
-        unique combinations in a that add up to sum.
-        The same number from a can be used an unlimited number of times in 
-        a combination.
-        Elements in a combination (a1 a2 … ak) must be sorted in non-descending order, 
-        while the combinations themselves must be sorted in ascending order.
+    Now we give a full version of the solution, 
+    which additionally also finds the boundaries of the desired segment:
 
-        If there are no possible combinations that add up to sum, 
-        the output should be the string "Empty".
+    int ans = a[0], ans_l = 0, ans_r = 0;
+    int sum = 0, min_sum = 0, min_pos = -1;
 
-        Example
+    for (int r = 0; r < n; ++r) {
+        sum += a[r];
+        int cur = sum - min_sum;
+        if (cur > ans) {
+            ans = cur;
+            ans_l = min_pos + 1;
+            ans_r = r;
+        }
+        if (sum < min_sum) {
+            min_sum = sum;
+            min_pos = r;
+        }
+    }
 
-        For a = [2, 3, 5, 9] and sum = 9, the output should be
-        combinationSum(a, sum) = "(2 2 2 3)(2 2 5)(3 3 3)(9)".
 
 
-        The DP problem is simple, done previously before HARMAN!!
+-42.5) 2D Kadanes Algorithm: 
 
-        Here we try to return the paths themselves, that were traversed in the DP
-        2 ways to do so:
-        A parents map OR as we save our results in the DP array, we also save our paths in a DP paths array.
-        Look at both methods and learn!!
+    Two-dimensional case of the problem: search for maximum/minimum submatrix
 
-        '''
-        from collections import defaultdict, deque
-        def combinationSum(a, sum):
-            # parents map? 
-            g = defaultdict(list)
-            
-            # sort a and deduplicate. 
-            
-            a = sorted(list(set(a)))
-            
-            # we could also space optimize and just use One D array, because new 
-            # index doesnt use just previous index, but all previous indexes.
-            # so include all of em. 
-            OPT = [[0 for i in range(sum+1)]]
-            OPT[0][0] = 1
-            
-            
-            dp_paths = [[] for i in range(sum+1)]
-            dp_paths[0].append([])
-            
-            for idx, coinVal in enumerate(a):
-                # to compute for current index, 
-                # first copy previous, then operate on current. 
-                curr = OPT[-1][:]
-                '''
-                idx, coin?
-                '''
-                for i in range(sum+1):
-                    if i >= coinVal:
-                        # do we specify the coin type we used??
-                        # depends if we built from previous index, or 
-                        # coins from this index.  -> cant you use difference in amts
-                        # to determine coins -> YESS.
-                        # you dont need to save coinVal
-                        curr[i] += curr[i-coinVal]
-                        # can we save it, as we build the dp?
-                        
-                        parent_paths = dp_paths[i-coinVal]
-                        for p in parent_paths:
-                            cp = p[::]
-                            cp.append(coinVal)
-                            dp_paths[i].append(cp)
+    Kadane’s algorithm for 1D array can be used to reduce the time complexity to O(n^3). 
+    The idea is to fix the left and right columns one by one and find the maximum 
+    sum contiguous rows for every left and right column pair. We basically find top and bottom 
+    row numbers (which have maximum sum) for every fixed left and right column pair. 
+    To find the top and bottom row numbers, calculate sum of elements in every row from left 
+    to right and store these sums in an array say temp[]. So temp[i] indicates sum of elements 
+    from left to right in row i. If we apply Kadane’s 1D algorithm on temp[], 
+    and get the maximum sum subarray of temp, this maximum sum would be the maximum possible 
+    sum with left and right as boundary columns. To get the overall maximum sum, we compare 
+    this sum with the maximum sum so far.
 
-                        if(curr[i-coinVal] > 0):
-                            g[i].append(i-coinVal)
-                                
-                OPT.append(curr)
-            
-            # DP PATHS WORKS HOW YOU EXPECT. IF OPT[sum] = 6, then in DP paths there is 6 paths.
-            print("DP_PATHS", dp_paths)
-            print("OPT", OPT)
-            
-            '''
-            Problem with getting all paths: we end up with all permutations instead of 
-            combinations: 
-            
-            Output: "(2 2 2 2)(2 2 4)(2 4 2)(2 6)(4 2 2)(4 4)(6 2)(8)"
-            Expected Output: "(2 2 2 2)(2 2 4)(2 6)(4 4)(8)"
-            SO WE NEED LIMIT ARGUMENT.
-            '''
-            
-            results = []
+    def kadane(arr, start, finish, n): 
+        
+        # initialize sum, maxSum and  
+        Sum = 0
+        maxSum = -999999999999
+        i = None
+    
+        # Just some initial value to check 
+        # for all negative values case  
+        finish[0] = -1
+    
+        # local variable  
+        local_start = 0
+        
+        for i in range(n): 
+            Sum += arr[i]  
+            if Sum < 0: 
+                Sum = 0
+                local_start = i + 1
+            elif Sum > maxSum: 
+                maxSum = Sum
+                start[0] = local_start  
+                finish[0] = i 
+    
+        # There is at-least one 
+        # non-negative number  
+        if finish[0] != -1:  
+            return maxSum  
+    
+        # Special Case: When all numbers  
+        # in arr[] are negative  
+        maxSum = arr[0]  
+        start[0] = finish[0] = 0
+    
+        # Find the maximum element in array 
+        for i in range(1, n): 
+            if arr[i] > maxSum: 
+                maxSum = arr[i]  
+                start[0] = finish[0] = i 
+        return maxSum 
+    
+    # The main function that finds maximum 
+    # sum rectangle in M[][]  
+    def findMaxSum(M): 
+        global ROW, COL 
+        
+        # Variables to store the final output  
+        maxSum, finalLeft = -999999999999, None
+        finalRight, finalTop, finalBottom = None, None, None
+        left, right, i = None, None, None
+        
+        temp = [None] * ROW 
+        Sum = 0
+        start = [0] 
+        finish = [0]  
+    
+        # Set the left column  
+        for left in range(COL): 
             
-            def get_all_paths(node, path, limit):
-                kids = g[node]
-                if len(kids) == 0:
-                    # nonlocal results
-                    results.append(path)
-                
-                # USING A LIMIT ALLOWS YOU TO TURN 
-                # PERMUTATONS INTO COMBINATIONS IF ITS SORTED.
-                # BY TRAVERSING COINS FROM LARGEST TO SMALLEST ONLY. 
+            # Initialize all elements of temp as 0  
+            temp = [0] * ROW  
+    
+            # Set the right column for the left  
+            # column set by outer loop  
+            for right in range(left, COL): 
                 
-                for k in kids:
-                    coinVal = node-k
-                    if coinVal <= limit:
-                        cp = path.copy()
-                        cp.appendleft(coinVal)
-                        get_all_paths(k, cp, min(limit, coinVal))
-                        
-            get_all_paths(sum, deque([]), float("inf"))
-            final=[]
-            
-            # Uncomment this line and code still creates correct output!
-            # results = dp_paths[sum]
+                # Calculate sum between current left  
+                # and right for every row 'i' 
+                for i in range(ROW): 
+                    temp[i] += M[i][right]  
+    
+                # Find the maximum sum subarray in  
+                # temp[]. The kadane() function also  
+                # sets values of start and finish.  
+                # So 'sum' is sum of rectangle between   
+                # (start, left) and (finish, right) which  
+                # is the maximum sum with boundary columns  
+                # strictly as left and right.  
+                Sum = kadane(temp, start, finish, ROW)  
+    
+                # Compare sum with maximum sum so far.  
+                # If sum is more, then update maxSum  
+                # and other output values  
+                if Sum > maxSum: 
+                    maxSum = Sum
+                    finalLeft = left  
+                    finalRight = right  
+                    finalTop = start[0]  
+                    finalBottom = finish[0] 
+    
+        # Prfinal values  
+        print("(Top, Left)", "(", finalTop,  
+                                finalLeft, ")")  
+        print("(Bottom, Right)", "(", finalBottom,  
+                                    finalRight, ")")  
+        print("Max sum is:", maxSum) 
+    
+    # Driver Code 
+    ROW = 4
+    COL = 5
+    M = [[1, 2, -1, -4, -20], 
+        [-8, -3, 4, 2, 1],  
+        [3, 8, 10, 1, 3],  
+        [-4, -1, 1, 7, -6]]  
+    
+    findMaxSum(M) 
 
-            for r in results:
-                if len(r) == 0:
-                    continue
-                s = str(r[0])
-                for idx in range(1, len(r)):
-                    s += " " + str(r[idx])
-                final.append(s)
-            
-            final.sort()
-            
-            if len(final) == 0:
-                return "Empty"
-                
-            last = ")(".join(final)
-            return "(" + last + ")" 
 
+-42) RMQs and processing array index and value at same time using 
+     a monotonic queue philosophy + Divide and conquer trick with dealing with all ranges. 
+     Sometimes you have to deal with 2 constraints at the same time. 
 
+    Problem: 
+    You have an array and a set 
+         1. 1. 2. 3. 4
+    a = [4, 2, 1, 6, 3]
+    S = {0, 1,  3, 4}
 
--69) You can return a deduplicated sorted list of combinations from a 
-     sorted list that has repeated values without using the sort function, or sets.
-     When you dfs, include a limit argument, and dont include the current argument in the take/donttake 
-     if its the same as the previous argument, and the previous argument was not taken. 
-     Look at sumSubsets for more info. 
-
+    for each pair in the set, find the minimum value in that range,
+    then return sum of all minimum values as answer:
+    
+    0-1 => a[0:2] => [4, 2] => min([4, 2]) = 2
+    0-3 => [4, 2, 1, 6] => 1
+    1-3 => [2, 1, 6] => 1
+    Therefore the answer is ->  2 + 1 + 1 = 4 <-
 
+    To do this question, you have to satisfy both the range condition 
+    and the find minimum value condition. 
 
--68) Counting clouds by removing and growing as an alternative DFS:
+    My proposed garbage solution was precomputing all running minimum values 
+    for every (i, j) range like so: (This soln is in LunchclubIORMQ in most important problems)
+    [
+        [4, 2, 1,1,1]
+        [2, 1,1, 1]
+        [1,1, 1]
+        [6, 3]
+        [3]
+    ]
+    Then enumerate every set in O(n^2)
 
-    Given a 2D grid skyMap composed of '1's (clouds) and '0's (clear sky), 
-    count the number of clouds. A cloud is surrounded by clear sky, and is 
-    formed by connecting adjacent clouds horizontally or vertically. 
-    You can assume that all four edges of the skyMap are surrounded by clear sky.
+    CAN ALSO SOLVE WITH DP LIKE BELOW -----------------------------
+    Another way was solving the problem for all set ranges, was to compute the mins 
+    between you and the next element to you. THen to compute the min for ranges that 
+    are longer than that, just do the min of those precomputed solutions DP style.
 
-    Example
+    So compute [0,1], [1,3], [3,4] Then to compute [0, 3], and [1, 4] don't look at a, 
+    just take the min of the ranges that make up the bigger ranges!!
 
-    For
+    THE BEST WAY TO SOLVE BELOW -----------------------------
+    Better way was to think of ways to split the sets using array a. 
+    We can create a binary tree where it splits on minimum values with a, 
+    and query each subset range rite! The lca, is the min. 
 
-    skyMap = [['0', '1', '1', '0', '1'],
-              ['0', '1', '1', '1', '1'],
-              ['0', '0', '0', '0', '1'],
-              ['1', '0', '0', '1', '1']]
-    the output should be
-    countClouds(skyMap) = 2;
-    
-    
-    def countClouds(skyMap):
-        if not skyMap or not skyMap[0]:
-            return 0
-        m, n = len(skyMap), len(skyMap[0])
-        ones = {(i, j) for i in range(m) for j in range(n) if skyMap[i][j] == '1'}
-        cc = 0
-        while ones:
-            active = {ones.pop()}
-            while active:
-                ones -= active
-                nxt_active = set()
-                for x, y in active:
-                    for dx, dy in ((-1,0), (1,0), (0,-1), (0,1)):
-                        if 0 <= x+dx < m and 0 <= y + dy < n and \
-                            (x+dx, y+dy) in ones:
-                            nxt_active.add((x+dx, y+dy))
-                active = nxt_active
-            cc += 1
-        return cc
+    This ideation leads to another solution. 
+    Lets sort A: and keep track of the index as well. 
+    Since we sorted on the A[i], WE have to do the second order processing 
+    on the index, i. We sorted on A[i] so that we can linearly process it
+    and in a convenient way that respects the first constraint. 
 
 
--67) Lazy updates to build faster data structures (aka min stack extended ):
+    A = [(1, 2), (2,1 ), (3, 4), (4, 0), (6, 3)]
+    The trick in this problem is to binary search the index to satisfy the second
+    constraint, and do a divide and conquer technique on the problem. 
 
-        Similar hill finding question from IMC oa: 
-        Techniques: for stack 2.0, where we create a stack
-        but we can also increment alll elements below index i 
-        by a value
-        
-        -> implement push, pop, increment(index i, value v)
-        you use 2 stacks, and we do LAZY updates. Similar to min stack.
-        When we access an element that should have been increment. 
-        add stack value + increment stack value. 
-        When we increment we only save it at index i. not [0...i] with for loop
-        to do O(1) lookup, push, pop, increment. And when we pop that index,
-        assign to index i-1.
-        
-        THE IDEA IS: -> look at the very specific constraints of problem and solve 
-        for only what it is asking. nothing more (which allows you to simplify and 
-        improve solutions).
-        
-        Try to solve by being as LAZY as possible, and keeping track of critical indexes. 
-        Do it similar to how you as a lazy human would solve it IRL. 
-        
-        By waiting to do operations until it is necessary -> and being GREEDY and smart 
-        about how to update the state of the problem for only the next state[and just the next state], 
-        and not all states, we optimized stack 2.0. 
+    So process (1,2). its the smallest and it splits the set S in 2:
+    S = {0, 1, 3, 4, }
+              ^
+    All ranges that cross the binary insertion point have 1 as a minimum value!
+    So ranges 0-3, 0-4, 1-3, and 1-4 all have index 2 in the middle, and all 
+    will have the min value 1. 
 
-        IMPLEMENTATION OF SUPER STACK:
-    
-        def superStack(operations):
-            stack = []
-            inc = []
-            result = []
-            '''
-            Save and propogate lazy updates using inc[]
-            based on how we access stack 
-            '''
-            for op in operations:
-                
-                items = op.split()
-                cmd = items[0]  
-                if cmd == "push":
-                    stack.append(int(items[1]) )
-                    inc.append(0)
-                elif cmd == "pop":
-                    if len(stack) > 0:
-                        stack.pop()
-                        poppedInc = inc.pop()
-                        if len(inc) > 0:
-                            inc[-1] += poppedInc
-                elif cmd == "inc":
-                    # inc 2 2
-                    pos, val = int(items[1]), int(items[2])
-                    inc[pos-1] += val
-                
-                if len(stack) > 0:
-                    print(stack[-1] + inc[-1])
-                else:
-                    print("EMPTY")
+    Then we process next element in A, but we do not want to count the same ranges twice in 
+    our final resulting answer. You can fix this by using a visited set.
+    The smarter way is to divide and conquer S:
+    Split S in two: 
+    S1 = {0, 1}, and S2 = {3, 4}
+    Then binary search in the smaller subsets so that you do not see repeat ranges from 
+    having split it already on (A[1], 1)
 
+    Search with index 1 on S1 because S2 does not contain index 1.
+    You will process [0, 1] -> give min value 2. 
+    Then finally compute answer like so. 
 
 
 
 
+-41) Insert interval into a sorted set of intervals using 2 binary searches:
+    Binary search the start time on the end times (bisect_right), 
+    and the end time on the start times (bisect_left)
+    if same value you can insert, otherwise cant
+    Works on open close start end intervals. 
+    Review BookingTimes in Most important problems. 
 
 
+-39) LEADER ALGORITHM: 
+    Let us consider a sequence a0, a1, . . . , an−1. The leader of this sequence is the element whose
+    value occurs more than n/2 times.
 
--66)  Hill finding w/ stacks and queues and lazy updates in data structures: 
+    Notice that if the sequence a0, a1, . . . , an−1 
+    contains a leader, then after removing a pair of
+    elements of different values, the remaining sequence 
+    still has the same leader. Indeed, if we
+    remove two different elements then only one of them 
+    could be the leader. The leader in the
+    new sequence occurs more than (n/2) − 1 = (n−2)/2 times. 
+    Consequently, it is still the leader of the new sequence of n − 2 elements.
 
-        '''
-        Given an array a composed of distinct elements, find 
-        the next larger element for each element of the array, i.e. 
-        the first element to the right that is greater than this element, 
-        in the order in which they appear in the array, and return the 
-        results as a new array of the same length. If an element does 
-        not have a larger element to its right, put -1 in the 
-        appropriate cell of the result array.
+    1 def goldenLeader(A):
+    2   n = len(A)
+    3   size = 0
+    4   for k in xrange(n):
+    5       if (size == 0):
+    6           size += 1
+    7           value = A[k]
+    8       else:
+    9           if (value != A[k]):
+    10              size -= 1
+    11          else:
+    12              size += 1
+    13  candidate = -1
+    14  if (size > 0):
+    15      candidate = value
+    16  leader = -1
+    17  count = 0
+    18  for k in xrange(n):
+    19      if (A[k] == candidate):
+    20          count += 1
+    21  if (count > n // 2):
+    22      leader = candidate
+    23  return leader
 
-        Example
 
-        For a = [6, 7, 3, 8], the output should be
-        nextLarger(a) = [7, 8, 8, -1]
+    After removing all pairs of different
+    elements, we end up with a sequence containing all the same values. 
+    This value is not necessarily the leader; it is only a candidate for the leader. 
+    Finally, we should iterate through all
+    the elements and count the occurrences of the candidate; 
+    if it is greater than n/2 then we have
+    found the leader; otherwise the sequence does not contain a leader.
 
-        '''
-        # use queue. 
-        '''
-        HILL FINDING WITH CRITICAL INDEXES + LAZINESS LECTURE.  
-        KEEP TRACK OF KEY POINTS ONLY IN QUEUE/STACK. 
-        NO WASTE IN QUEUE, JUST WHAT WE NEED. 
-        AKA hill finding.         
-        '''
 
-        def nextLarger(a):        
-            st = []
-            res = []
 
-            for i in range(len(a)-1, -1, -1):
-                val = a[i]
-                while len(st) > 0:
-                    if a[i] > st[-1]:
-                        st.pop()
-                    else:
-                        break     
-                if len(st) == 0:
-                    res.append(-1)
-                else:
-                    res.append(st[-1])
-                st.append(val)
-            return res[::-1]
+-38) A comparison of Forward and Backward DP illustrated:
 
 
+    A game for one player is played on a board consisting of N consecutive squares, 
+    numbered from 0 to N − 1. There is a number written on each square. 
+    A non-empty array A of N integers contains the numbers written on the squares. 
+    Moreover, some squares can be marked during the game.
 
--65) REGEX REVIEW USAGE:
+    At the beginning of the game, there is a pebble on square number 0 and this 
+    is the only square on the board which is marked. The goal of the game is to
+    move the pebble to square number N − 1.
 
-    You categorize strings into three types: good, bad, or mixed. If a string has 
-    3 consecutive vowels or 5 consecutive consonants, or both, then it is categorized 
-    as bad. Otherwise it is categorized as good. Vowels in the English alphabet are 
-    ["a", "e", "i", "o", "u"] and all other letters are consonants.
+    During each turn we throw a six-sided die, with numbers from 1 to 6 on 
+    its faces, and consider the number K, which shows on the upper face after 
+    the die comes to rest. Then we move the pebble standing on square number 
+    I to square number I + K, providing that square number I + K exists. If 
+    square number I + K does not exist, we throw the die again until we obtain 
+    a valid move. Finally, we mark square number I + K.
 
-    The string can also contain the character ?, which can be replaced by either a 
-    vowel or a consonant. This means that the string "?aa" can be bad if ? is a 
-    vowel or good if it is a consonant. This kind of string is categorized as mixed.
+    After the game finishes (when the pebble is standing on square number N − 1), 
+    we calculate the result. The result of the game is the sum of the numbers 
+    written on all marked squares.
 
-    Implement a function that takes a string s and returns its category: good, bad, or mixed.
+    For example, given the following array:
 
-    def classifyStrings(s):
-        if re.search(r"[aeiou]{3}|[^aeiou?]{5}", s):
-            return "bad"
-        if "?" not in s:
-            return "good"
-        a = classifyStrings(s.replace("?", "a", 1))
-        b = classifyStrings(s.replace("?", "b", 1))
-        return "mixed" if a != b else a
-
-
--64) Bomber DP or is the DP just precomputation below? you should check:
-    (CAN DO WITH PRECOMPUTATION BUT LETS DO WITH DP!!!)
-    
-    Each cell in a 2D grid contains either a wall ('W') or an 
-    enemy ('E'), or is empty ('0'). Bombs can destroy enemies, 
-    but walls are too strong to be destroyed. A bomb placed in 
-    an empty cell destroys all enemies in the same row and column, 
-    but the destruction stops once it hits a wall.
+        A[0] = 1
+        A[1] = -2
+        A[2] = 0
+        A[3] = 9
+        A[4] = -1
+        A[5] = -2
 
-    Return the maximum number of enemies you can destroy using one bomb.
+    The marked squares are 0, 3 and 5, so the result of the 
+    game is 1 + 9 + (−2) = 8. This is the maximal possible result 
+    that can be achieved on this board.
 
-    Note that your solution should have O(field.length · field[0].length) 
-    complexity because this is what you will be asked during an interview.
+    Write a function:
 
-    Example
-    For
-    field = [["0", "0", "E", "0"],
-            ["W", "0", "W", "E"],
-            ["0", "E", "0", "W"],
-            ["0", "W", "0", "E"]]
-    the output should be
-    bomber(field) = 2.
+    def solution(A)
 
-    Sol'n A Easy (Cool Top Down):
-        from functools import lru_cache
-        def bomber(q):
-            if not q or not q[0]:
-                return 0
-            a , b = len(q),len(q[0])
-            @lru_cache(maxsize=None)
-            def g(m,n,x,y):
-                return 0 if m<0 or n<0 or m>=a or n>=b or q[m][n]=="W" \
-                    else g(m + x,n + y,x,y)+(q[m][n]=="E")
-            ans = 0
-            for i in range(a):
-                for j in range(b):
-                    if q[i][j] == "0":
-                        ans = max(ans,g(i-1,j,-1,0)+g(i,j-1,0,-1)+g(i+1,j,1,0)+g(i,j+1,0,1))
-            return ans
-    Soln B:
-        def bomber(F):
-            if not F or not F[0]         :   return 0
-            row ,col = len(F) ,len(F[0]) ;   F = numpy.array(F)
-            dp = numpy.zeros((row,col))  ;   t = zip(*numpy.where(F == 'E'))
-            for x,y in t:
-                for i in range(y-1,-1,-1):   
-                    if F[x,i] == 'W'  :   break
-                    if F[x,i] == '0' :   dp[x,i]+=1 
-                for i in range(y+1,col):
-                    if F[x,i] == 'W'  :   break
-                    if F[x,i] == '0'  :   dp[x,i]+=1 
-                for i in range(x-1,-1,-1):
-                    if F[i,y] == 'W'  :   break
-                    if F[i,y] == '0'  :   dp[i,y]+=1 
-                for i in range(x+1,row):
-                    if F[i,y] == 'W'  :   break
-                    if F[i,y] == '0'  :   dp[i,y]+=1 
-            return dp.max()
+    that, given a non-empty array A of N integers, returns the 
+    maximal result that can be achieved on the board represented by array A.
+    
+    SOLUTION:
+    from collections import deque
 
-    Soln C:
-        def bomber(A):
-            from itertools import groupby
-            if not A or not A[0]: return 0
-            R, C = len(A), len(A[0])
-            dp = [ [0] * C for _ in xrange(R) ]
-            for r, row in enumerate(A):
-                c = 0
-                for k, v in groupby(row, key = lambda x: x != 'W'):
-                    w = list(v)
-                    if k:
-                        enemies = w.count('E')
-                        for c2 in xrange(c, c + len(w)):
-                            dp[r][c2] += enemies
-                    c += len(w)
+    def backwardDP(A):
+        '''
+        Backward dp.
+            
+        Start with idx 0
+        update with max value, by using 6 behind you!
+            
+        OPT[i] = A[i] + max(OPT[i-1], OPT[i-2],..., OPT[i-5])
+            
+        do we ever double add...
+        nah
+        Just need array of size 6; to space optimize
+        '''
+        # the states represent the last 6 updated states. 
+        states = deque([float("-inf"),
+                        float("-inf"),
+                        float("-inf"),
+                        float("-inf"),
+                        float("-inf"),
+                        0])
+        
+        for i in range(1, len(A)):
+            
+            # We are always guranteed a link to something before us
+            # because we always sum in max states, unlike forward dp, 
+            # where you have to force it to use previous states, by 
+            # setting your own state to something really shitty, so
+            # relaxation forces you to pick up a state
+            maxVal = A[i] + max(states)
+            states.popleft()
+            states.append(maxVal)
+            # latestVal = maxVal
+        
+        # WE HAVE TO ALWAYS INCLUDE A[0] because its marked. 
+        return maxVal + A[0]
+    
+    '''
+    Forward DP 
+    Do 6 RELAXATIONS FORWARD. 
+        
+    OPT[i+1] -> max(OPT[i+1], A[i+1] + OPT[i])?
+    OPT[i+2] -> A[i+2] + A[i]?
+    '''
+    def forwardDP(A):
+        N = len(A)
+        OPT = [float("-inf") for i in range(N)]
+        
+        # YOU ALSO HAVE TO ENSURE THAT THE PIECES THAT ARE FURTHER THAN 
+        # 6 AWAY HAVE ACCESS TO SOMETHING that was used to reach it. 
+        # so FIRST 6 ARE ACCESSIBLE!
+        
+        # In other words, set the first 6 to the value of A[i]
+        OPT[0] = 0
+        
+        for i in range(N):
+            for k in range(1, 7):
+                if i + k < len(A):
+                    OPT[i+k] = max(OPT[i] + A[i+k], OPT[i+k]) 
+        
+        # WE HAVE TO ALWAYS INCLUDE A[0] because its marked. 
+        return OPT[-1] + A[0]
+        
+    def solution(A):
+        # FORWARD DP WORKS 100%
+        # return forwardDP(A)
+        return backwardDP(A)
+        
+-35) Find duplicate subtrees, Caching trees with UNIQUE IDS
+    Given a binary tree, return all duplicate subtrees. 
+    For each kind of duplicate subtrees, you only need to 
+    return the root node of any one of them.
+    
+    Normal soln -> create merkel hash with strings and postorder/preorder trav O(N^2)
+    This soln -> dont create those long strings. 
+    O(N) time and space. 
 
-            for c, col in enumerate(zip(*A)):
-                r = 0
-                for k, v in groupby(col, key = lambda x: x != 'W'):
-                    w = list(v)
-                    if k:
-                        enemies = w.count('E')
-                        for r2 in xrange(r, r + len(w)):
-                            dp[r2][c] += enemies
-                    r += len(w)
+    def findDuplicateSubtrees(self, root):
+        self.type_id_gen = 0
+        duplicated_subtrees = []
+        type_to_freq = defaultdict(int)
+        type_to_id = {}
+        
+        def dfs(node):
+            if not node:
+                return -1
+            type_id_left, type_id_right = (dfs(ch) for ch in (node.left, node.right))
+            tree_type = (node.val, type_id_left, type_id_right)
+            freq = type_to_freq[tree_type]
+            if freq == 0:
+                type_id = self.type_id_gen
+                self.type_id_gen += 1
+                type_to_id[tree_type] = type_id
+            elif freq == 1:
+                type_id = type_to_id[tree_type]
+                duplicated_subtrees.append(node)
+            else:
+                type_id = type_to_id[tree_type] 
+            type_to_freq[tree_type] += 1
+            return type_id
             
-            ans = 0
-            for r, row in enumerate(A):
-                for c, val in enumerate(row):
-                    if val == '0':
-                        ans = max(ans, dp[r][c])
-            return ans
+        dfs(root)
+        return duplicated_subtrees 
+    
+    Stefans version:
 
--63) IMPORTANT TRICK: 
-     PRECOMPUTING LEFT AND RIGHT INDEX SUMS WITH KADANES
 
-    Strategy:
-        Try other precomputes besides cumulative sums. 
-        Use the precomputed solution for one problem to 
-        make several other precomputes that can be used for 
-        a more difficult but similarly looking problem!!! 
+    def findDuplicateSubtrees(self, root, heights=[]):
+        def getid(root):
+            if root:
+                # get the id of tree and if there isnt one, assign it with a default value 
+                id = treeid[root.val, getid(root.left), getid(root.right)] 
+                trees[id].append(root) 
+                return id
 
-        For instance pre-computes of the Kadane algorithm.
+        trees = collections.defaultdict(list)
+        treeid = collections.defaultdict()
+        treeid.default_factory = treeid.__len__
+        getid(root)
+        return [roots[0] for roots in trees.values() if roots[1:]]
 
-    WITH KADANES, YOU CAN PRECOMPUTE maximum array sum that starts at i, 
-    and max array sum that ends at j. and use these to solve a question.
+    The idea is the same as Danile's: Identify trees by numbering them. 
+    The first unique subtree gets id 0, the next unique subtree gets 
+    id 1, the next gets 2, etc. Now the dictionary keys aren't deep 
+    nested structures anymore but just ints and triples of ints.
 
-    Problem: max_double_slice_sum
 
-    A non-empty array A consisting of N integers is given.
 
-    A triplet (X, Y, Z), such that 0 ≤ X < Y < Z < N, is called a double slice.
+-34) How to do transition functions and states for DP: 
+     Think of all the states, and transition functions you need
+     if its hard to precalculate a state, add another state!
+     
+     Also if you cant do backward DP, try Forward DP and relaxing states!
 
-    The sum of double slice (X, Y, Z) is the total of 
-        A[X + 1] + A[X + 2] + ... + A[Y − 1] + A[Y + 1] + A[Y + 2] + ... + A[Z − 1].
+     METHOD 1: Think in terms of Finite state machines!!
+     METHOD 2: The states may seem wierd BECAUSE YOU NEED TO CONSIDER MORE PREVIOUS LAYERS 
+               of i to come up with the solution, not just the last layer like usual DP.
 
-        A[0] = 3
-        A[1] = 2
-        A[2] = 6
-        A[3] = -1
-        A[4] = 4
-        A[5] = 5
-        A[6] = -1
-        A[7] = 2
-        
-    contains the following example double slices:
-
-    double slice (0, 3, 6), sum is 2 + 6 + 4 + 5 = 17,
-    double slice (0, 3, 7), sum is 2 + 6 + 4 + 5 − 1 = 16,
-    double slice (3, 4, 5), sum is 0.
-    The goal is to find the maximal sum of any double slice.
+     1.   House Robber
+     def rob(self, nums: List[int]) -> int:      
+         '''
+         Transition function: 
+         FREE state + ROB action -> FROZEN 
+         Free state + DONT ROB -> Free State
+         FROZEN state + Dont Rob -> Free State.  
+         '''
+         
+         COUNT = len(nums)
+         
+         FROZEN = 0
+         FREE = 0 
+         
+         NXT_FROZEN = 0
+         NXT_FREE = 0
+         
+         for val in nums:
+             NXT_FROZEN = FREE  + val
+             NXT_FREE = max(FREE, FROZEN)
+             
+             FROZEN = NXT_FROZEN
+             FREE = NXT_FREE
+         
+         return max(FREE, FROZEN)
 
-    Write a function:
+    The other way you can think of this, is we are dealing 
+    with 3 layers at a time given the following recurrent relation:
+    rob(i) = Math.max( rob(i - 2) + currentHouseValue, rob(i - 1) )
+    States are: i, i-1, i-2
+    
 
-    def solution(A)
-    that, given a non-empty array A consisting of N integers, 
-    returns the maximal sum of any double slice.
+    Understanding the number of layers you are dealing with tell you
+    how many states you will need to compute the current state!
 
-    For example for above array,
-    the function should return 17, because no double 
-    slice of array A has a sum of greater than 17.
 
-    ALGORITHM:
-    You can use a modified form of Kadane's algorithm that 
-    calculates the MAX Sum subarray ending at each index.
-    
-    For each index, calculate the max_sum_ending_at[i] value 
-    by using Kadane's algorithm in forward direction.
-    
-    For each index, calculate the max_sum_starting_from[i] 
-    value by using Kadane's algorithm in reverse direction.
-    
-    Iterate these arrays simultaneously and choose the 'Y' that has the maximum value of
 
-    max_sum_ending_at[Y-1] + max_sum_starting_from[Y+1]
 
+-33) For some grid problems that require mapping numbers to new numbers while 
+    keeping order with right neighbor, down neighbor, up neighbor and left neighbor 
+    (Abiscus interview).And you have to use as few numbers for the mapping as possible
+    Remember that to maintain multiple orderings in different directions
+    you should be using a GRAPH!! and do BFS to generate those new numbers (and not 
+    try to do grid DP like what i did in that interview). 
 
-    def solution(A):
-        l_max_slice_sum = [0] * len(A)
-        r_max_slice_sum = [0] * len(A)
+-32) An example of both forward and backward DP is 
+    -> 931. Minimum Falling Path Sum. Check it out! 
 
-        for i in range(1, len(A)-2): # A[X + 1] + A[X + 2] + ... + A[Y − 1]
-            # Let's assume that Y is equal to i+1.
-            # If l_max_slice_sum[i-1] + A[i] is negative, we assign X to i.
-            # It means that the slice sum is 0 because X and Y are consecutive indices.
-            l_max_slice_sum[i] = max(l_max_slice_sum[i-1] + A[i], 0)
 
-        for i in range(len(A)-2, 1, -1): # A[Y + 1] + A[Y + 2] + ... + A[Z − 1]
-            # We suppose that Y is equal to i-1.
-            # As aforementioned, Z will be assigned to i if r_max_slice_sum[i+1] + A[i]
-            # is negative, and it returns 0 because Y and Z becomes consecutive indices.
-            r_max_slice_sum[i] = max(r_max_slice_sum[i+1] + A[i], 0)
+-31) FINITE STATE MACHINES PROCESSING, AND BOTTOM UP DP TECHNIQUE. 
+     1.   Best Time to Buy and Sell Stock with Cool Down
+     Thinking about the problem as a finite state machine can be helpful
+     to figure out:
+        -> STATES 
+        -> HOW THE TRANSITION FUNCTION WORKS. MAKE SURE YOU GET ALL THE TRANSITIONS IN!
+        -> THE RECURENCE FOR THE PROBLEM OR MULTIPLE RECURRENCES FOR EACH STATE. 
 
-        max_slice_sum = l_max_slice_sum[0] + r_max_slice_sum[2]
-        for i in range(1, len(A)-1):
-            # Let's say that i is the index of Y.
-            # l_max_slice_sum[i-1] is the max sum of the left slice, and
-            # r_max_slice_sum[i+1] is the max sum of the right slice.
-            max_slice_sum = max(max_slice_sum, l_max_slice_sum[i-1]+r_max_slice_sum[i+1])
-            
-        return max_slice_sum
+     You need to figure out how many possible states there are for the DP, 
+     and create a grid for each state. 
+     
+    TO BUY OR SELL STOCK WITH COOLDOWN DP THOUGHT PROCESS O(1) SPACE:
 
+    Design an algorithm to find the maximum profit. You may
+    complete as many transactions as you like (ie, buy one and 
+    sell one share of the stockmultiple times) 
+    After you sell your stock, you cannot buy stock on next day. (ie, cooldown 1 day)
+    Example:
+    Input: [1,2,3,0,2]
+    Output: 3 
+    Explanation: transactions = [buy, sell, cooldown, buy, sell]
+     
+     In STOCK COOLDOWN problem (LEET 309), 
+     you tried to solve the DP with 2 states -> IS Cooldown/Not Cooldown.
+     
+     There is a solution where you create 3 Grids -> BUY/SELL/REST GRID. 
+     The grid comes from the fact that there are 3 states if you look 
+     at the finite state machine. 
 
+    3 GRID SOLUTION -> O(1) SPACE:
 
--62) RECURSION AND ENUMERATION WITH FROZENSET AND DP:
+    def maxProfit(self, prices):
+        free = 0
+        have = cool = float('-inf')
+        for p in prices:
+            free, have, cool = max(free, cool), max(have, free - p), have + p
+        return max(free, cool)
+    
+    '''
+    free is the maximum profit I can have while being free to buy.
+    have is the maximum profit I can have while having stock.
+    cool is the maximum profit I can have while cooling down.
 
-    You have a collection of coins, and you know the values of the 
-    coins and the quantity of each type of coin in it. You want to 
-    know how many distinct sums you can make from non-empty 
-    groupings of these coins.
+    free = max(free, cool)
+    have = max(have, free - p)  # if we were free last round and just bought, 
+                                # then our profit(in balance) need to 
+                                # adjust because buying cost money
+                        
+    cool = have + p # to be in cool-down, 
+                    # we just sold in last round (realizing profit), 
+                    # then profit would increase by the current price
+        
+    '''
 
-    Example
 
-    For coins = [10, 50, 100] and quantity = [1, 2, 1], the output should be
-    possibleSums(coins, quantity) = 9.
+-30) To create bottom up -> think of recursive solution. The parameters it needs!
+     Start bottom up with these parameter dimensions. Now we have to build 
+     forward from base case. So figure out base case and direction.  
+     
+     When bottom up DP isnt working, you are usually missing a case in your recurrence!
 
-    # RECURSIVE SOLUTION WITH DP. 
-    def possibleSums(coins, quantity):
-        @lru_cache(None)
-        def recursive(i):
-            if i == len(coins):
-                return frozenset([0])
-                
-            coinType = coins[i]
-            tot = quantity[i]
-            amts = recursive(i+1)
-            res = set()
-            for amt in amts:
-                for k in range(tot+1):
-                    res.add(amt + k*coinType)
-            return frozenset(res)
-            
-        s = recursive(0)
-        return len(s) - 1
+     Then create recurrence/thinking of the grid 
+     Does greater space optimization mean more performance or same performance because
+     its still the same amount of cache hits either way?  
+     
+     -> Greater space optimization may lead to higher performance, if there are fewer steps in 
+        the algorithm. 
+     -> An easy space optimization is using only the previous/next rather than saving all the states 
+        because the recurrence formula may only require the previous versions of all the states. 
 
+    
 
--61) Cycle detection in directed graph using BFS, and topological sort 
-     with indegree count. 
 
-    from collections import deque
-    def hasDeadlock(connections):
-        '''
-        If j is in the list connections[i], then there is a directed edge from process i to process j.
-        For connections = [[1], [2], [3, 4], [4], [0]], the output should be
-        hasDeadlock(connections) = true.
-        '''
-        N = len(connections)
-        
-        reverse_g = [[] for i in range(N)]
-        for parent, kids in enumerate(connections):
-            for k in kids:
-                reverse_g[k].append(parent)
-                
-        indegree = {}
-        q = deque([])
-        
-        for node, kids in enumerate(reverse_g):
-            indegree[node] = len(kids)
-            if indegree[node] == 0:
-                q.append(node)
-        
-        # no root nodes then cycle.
-        if len(q) == 0:
-            return True
-        
-        visited = set()
-        
-        while q:
-            print("process", q)
-            
-            node = q.popleft()
-            kids = connections[node]
-            
-            visited.add(node)
-            
-            for k in kids:
-                indegree[k] -= 1
-                
-                print("SAW KID with indg", k, indegree[k])
-                if(indegree[k] == 0):
-                    q.append(k)
-                #elif(indegree[k] <  0):
-                    # this elif was wrong because indegree will never fall below 0.
-                    # it just wont ever be added to queue if its part of cycle. 
-                    # Cycle because the indegrees dropped below 0!
-                    # return True
+-21) THE DUTCH PARTITIONING ALGORITHM WITH 3 POINTERS. 
+    
+    COMPARE AND CONTRAST THIS WITH MOVE ZEROS!!!
 
-        if len(visited) == N: # No cycle
-            return False
-        else:
-            return True # yes cycle
+    Using 3 pointers Algorithm  + Abusing LOOP invariants 
+    The trick is to move the MIDDLE POINTER FROM LEFT TO RIGHT AND 
+    use the left and right pointers to delimit the correctly processed sequence!
 
+    Otherwise, try moving the left pointer right to left or the left pointer, 
+    or try adding another pointer. Add as many pointers until the problem seems simple 
+    and we have untangled all the SEPERATE CONCERNS. 
 
+    Given an array with n objects colored red, white or blue, 
+    sort them in-place so that objects of the same color 
+    are adjacent, with the colors in the order red, white and blue.
 
+    Here, we will use the integers 0, 1, and 2 to represent the 
+    color red, white, and blue respectively.
 
+    Note: One pass algorithm with constant space only. 
 
--60) You cannot use union find to detect cycles in a directed graph. 
-     only undirected. 
-     You cannot use bfs and bipartition coloring to detect even cycles in
-     directed cycle. Only odd cycles can be found. 
-     You can use BFS to do topo sort with indegree 0, then indegree 1 etc. 
+    Example:
+    Input: [2,0,2,1,1,0]
+    Output: [0,0,1,1,2,2]    
 
-     Use bellman ford for negative cycle finding. 
 
--59) BUCKET SORT K most frequent elements:
-    Bucket Sort Algorithm: Steps on how it works:
-    Create an empty array.
-    Loop through the original array and put each object in a “bucket”.
-    Sort each of the non-empty buckets
-    Check the buckets in order and then put all objects back into the original array.
-
-    function bucketSort(array, k) is
-        buckets ← new array of k empty lists
-        M ← the maximum key value in the array
-        for i = 1 to length(array) do
-            insert array[i] into buckets[floor(k × array[i] / M)]
-        for i = 1 to k do
-            nextSort(buckets[i])
-        return the concatenation of buckets[1], ...., buckets[k]
-
-    Here array is the array to be sorted and k is the number of buckets to use. 
-    The maximum key value can be computed in linear time by looking up all the keys 
-    once. The floor function must be used to convert a floating number to an integer. 
-    The function nextSort is a sorting function used to sort each bucket. 
-    Conventionally, insertion sort would be used, but other algorithms 
-    could be used as well. Using bucketSort itself as nextSort 
-    produces a relative of radix sort; in particular, the case 
-    n = 2 corresponds to quicksort (although potentially with poor pivot choices).
+    def sortColors(self, nums: List[int]) -> None:
+        i = 0
+        l = 0         
+        j = len(nums) - 1
+        
+        while l != len(nums):
+            if nums[l] == 1:
+                l += 1
+            elif nums[l] == 0 and i == l:
+                l += 1
+            elif nums[l] == 0:
+                nums[l], nums[i] = nums[i], nums[l]
+                i += 1 
+            elif nums[l] == 2 and l >= j:
+                l += 1
+            elif nums[l] == 2:
+                nums[l], nums[j] = nums[j], nums[l]
+                j -= 1
+        return nums
 
 
-    Given a non-empty array of integers, return the k most frequent elements.
+    INVARIANTS ABUSE FOR SIMPLIFICATION: 
 
-    Example 1:
+    nums[0:red] = 0, nums[red:white] = 1, nums[white:blue + 1] = unclassified, 
+    nums[blue + 1:] = 2.
+    The code is written so that either 
+    (red < white and nums[red] == 1) or (red == white) at all times.
+    Think about the first time when white separates from red. 
+    That only happens when nums[white] == 1, 
+    so after the white += 1, 
+    we have nums[red] == 1, and notice that nums[red] 
+    will continue to be 1 as long as 
+    red != white. This is because red only gets 
+    incremented in the first case 
+    (nums[white] == 0), so we know that we are swapping nums[red] == 1 with nums[white] == 0.
 
-    Input: nums = [1,1,1,2,2,3], k = 2
-    Output: [1,2]
+ 
+    def sortColors(self, nums):
+        red, white, blue = 0, 0, len(nums)-1
+        while white <= blue:
+            if nums[white] == 0:
+                nums[red], nums[white] = nums[white], nums[red]
+                white += 1
+                red += 1
+            elif nums[white] == 1:
+                white += 1
+            else:
+                nums[white], nums[blue] = nums[blue], nums[white]
+                blue -= 1
 
-    Bucket sort is O(N):
 
-    def topKFrequent(self, nums, k):
-        bucket = [[] for _ in range(len(nums) + 1)]
-        Count = Counter(nums).items()  
-        for num, freq in Count: bucket[freq].append(num) 
-        flat_list = [item for sublist in bucket for item in sublist]
-        return flat_list[::-1][:k]
 
-    
+-18) Sorting algorithms and true space complexity. 
 
+    Quicksort: For quicksort, your intuition about recursion requiring O(log(n)) space is correct. 
+    Since quicksort calls itself on the order of log(n) times (in the average case, worst 
+    case number of calls is O(n)), at each recursive call a new stack frame of constant 
+    size must be allocated. Hence the O(log(n)) space complexity.
 
--58) HOARES PARTITION, QUICK SELECT K most frequent elements: 
-     Approach 2: Quickselect
-     Hoare's selection algorithm
- 
-     Quickselect is a textbook algorthm typically used to solve the problems 
-     "find kth something": kth smallest, kth largest, kth most 
-     frequent, kth less frequent, etc. Like quicksort,  
-     quickselect was developed by Tony Hoare, and also known as Hoare's selection algorithm.
- 
-     It has O(N) average time complexity and widely used in practice. It worth to note that its worth 
-     case time complexity is O(N^2), although the probability 
-     of this worst-case is negligible.
- 
-     The approach is the same as for quicksort.
- 
-     One chooses a pivot and defines its position in a sorted array in a 
-     linear time using so-called partition algorithm.
- 
-     As an output, we have an array where the pivot is on its perfect position 
-     in the ascending sorted array, sorted by the frequency. All elements 
-     on the left of the pivot are less frequent  than the pivot, and 
-     all elements on the right are more frequent or have the same frequency.
- 
-     Hence the array is now split into two parts. If by chance our pivot element 
-     took N - kth final position, then k elements on the right are 
-     these top k frequent we're looking for. If  not, we can choose 
-     one more pivot and place it in its perfect position.
- 
-     If that were a quicksort algorithm, one would have to process both parts of the array. 
-     Quickselect just deal with one side -> O(N)
- 
-     Algorithm
- 
-     The algorithm is quite straightforward :
- 
-     Build a hash map element -> its frequency and convert its keys into the 
-     array unique of unique elements. Note that elements are unique, but 
-     their frequencies are not. That means we need  
-     a partition algorithm that works fine with duplicates.
- 
-     Work with unique array. Use a partition scheme (please check the next section) 
-     to place the pivot into its perfect position pivot_index in the sorted array, 
-     move less frequent elements  to the left of pivot, 
-     and more frequent or of the same frequency - to the right.
- 
-     Compare pivot_index and N - k.
- 
-     If pivot_index == N - k, the pivot is N - kth most frequent element, 
-     and all elements on the right are more frequent or of the 
-     same frequency. Return these top kk frequent elements.
- 
-     Otherwise, choose the side of the array to proceed recursively.
- 
-     Hoare's Partition vs Lomuto's Partition
- 
-     There is a zoo of partition algorithms. 
-     The most simple one is Lomuto's Partition Scheme.
-     The drawback of Lomuto's partition is 
-     it fails with duplicates.
- 
-     Here we work with an array of unique elements, but they are 
-     compared by frequencies, which are not unique. 
-     That's why we choose Hoare's Partition here.
- 
-     Hoare's partition is more efficient than Lomuto's partition
-     because it does three times fewer swaps on average, and 
-     creates efficient partitions even when all values are equal.
- 
-     Here is how it works:
-     Move pivot at the end of the array using swap.
- 
-     Set the pointer at the beginning of the array store_index = left.
- 
-     Iterate over the array and move all less frequent elements to the 
-     left swap(store_index, i). Move store_index 
-     one step to the right after each swap.
- 
-     Move the pivot to its final place, and return this index.
+    Mergesort: Since mergesort also calls itself on the order of log(n) times, 
+    why the O(n) space requirement? The extra space comes from the merge operation. 
+    Most implementations of merge use an auxiliary array with length equal to the 
+    length of the merged result, since in-place merges are very complicated. 
+    In other words, to merge two sorted arrays of length n/2, most merges will 
+    use an auxiliary array of length n. The final step of mergesort 
+    does exactly this merge, hence the O(n) space requirement.
 
-    from collections import Counter
-    class Solution:
-        def topKFrequent(self, nums: List[int], k: int) -> List[int]:
-            count = Counter(nums)
-            unique = list(count.keys())
-            
-            def partition(left, right, pivot_index) -> int:
-                pivot_frequency = count[unique[pivot_index]]
-                # 1. move pivot to end
-                unique[pivot_index], unique[right] = unique[right], unique[pivot_index]  
-                
-                # 2. move all less frequent elements to the left
-                store_index = left
-                for i in range(left, right):
-                    if count[unique[i]] < pivot_frequency:
-                        unique[store_index], unique[i] = unique[i], unique[store_index]
-                        store_index += 1
 
-                # 3. move pivot to its final place
-                unique[right], unique[store_index] = unique[store_index], unique[right]  
-                
-                return store_index
-            
-            def quickselect(left, right, k_smallest) -> None:
-                """
-                Sort a list within left..right till kth less frequent element
-                takes its place. 
-                """
-                # base case: the list contains only one element
-                if left == right: 
-                    return
-                
-                # select a random pivot_index
-                pivot_index = random.randint(left, right)     
-                                
-                # find the pivot position in a sorted list   
-                pivot_index = partition(left, right, pivot_index)
-                
-                # if the pivot is in its final sorted position
-                if k_smallest == pivot_index:
-                    return 
-                # go left
-                elif k_smallest < pivot_index:
-                    quickselect(left, pivot_index - 1, k_smallest)
-                # go right
-                else:
-                    quickselect(pivot_index + 1, right, k_smallest)
-            
-            n = len(unique) 
-            # kth top frequent element is (n - k)th less frequent.
-            # Do a partial sort: from less frequent to the most frequent, till
-            # (n - k)th less frequent element takes its place (n - k) in a sorted array. 
-            # All element on the left are less frequent.
-            # All the elements on the right are more frequent.  
-            quickselect(0, n - 1, n - k)
-            # Return top k frequent elements
-            return unique[n - k:]
+    Merge sort on linked lists can be executed using only O(1) extra space if 
+    you take a bottom-up approach by counting where the boundaries of 
+    the partitions are and merging accordingly.
 
 
+-17.9)  For the GREEDY CANDY PROBLEM. You are given constraints to respect. 
+        The constraints are hard unless you break them up!
+        ALSO try to understand the problem before you start:
+        review it in most important problems.
+        
+        There are N children standing in a line. 
+        Each child is assigned a rating value.
 
+        You are giving candies to these children 
+        subjected to the following requirements:
 
+        Each child must have at least one candy.
+        Children with a higher rating get more candies than their neighbors.
+        What is the minimum candies you must give?
+        Input: [1,0,2] 
+        Output: 2, 1, 2  -> 5
+        Input: [1,2,2]
+        Output: 1, 2, 1 -> 4
 
+        def candy(self, ratings):
+            if not ratings:
+                return 0
 
+            n = len(ratings)
+            candy = [1] * n
+            for i in range(1, n):
+                if ratings[i] > ratings[i - 1]:
+                    candy[i] = candy[i - 1] + 1
+                
+            for i in range(n - 2, -1, -1):
+                if ratings[i] > ratings[i + 1] and candy[i] <= candy[i + 1]:
+                    candy[i] = candy[i + 1] + 1
 
+            return sum(candy)
 
--57) Counting all subarrays trick with prefixes:
-     
-     1.   Subarray Sums Divisible by K
-    
-    Given an array A of integers, return the number of 
-    (contiguous, non-empty) subarrays that have a sum divisible by K.
-
-    Example 1:
-
-    Input: A = [4,5,0,-2,-3,1], K = 5
-    Output: 7
-    Explanation: There are 7 subarrays with a sum divisible by K = 5:
-    [4, 5, 0, -2, -3, 1], [5], [5, 0], [5, 0, -2, -3], [0], [0, -2, -3], [-2, -3]
+        You can also solve with constant space by 
+        looking at rising and falling slopes
+        
+        class Solution:
+            def candy(self, ratings):
+                if not ratings:
+                    return 0
 
+                count = up = down = 1
 
-    class Solution(object):
-        def subarraysDivByK(self, A, K):
-            P = [0]
-            for x in A:
-                P.append((P[-1] + x) % K)
+                for i in range(1, len(ratings)):
+                    if ratings[i] >= ratings[i - 1]:
+                        if down > 1:
+                            count -= min(down, up) - 1
+                            up, down = 1, 1
+                        up = ratings[i] == ratings[i - 1] or up + 1
+                        count += up
+                    else:
+                        down += 1
+                        count += down
 
-            count = collections.Counter(P)
-            return sum(v*(v-1)/2 for v in count.values())
+                if down > 1:
+                    count -= min(down, up) - 1
 
+                return count
 
 
--56) Do N CHOOSE K. Generate all K combinations:
-     Recursively:
+-17.4) IMPLEMENTED QUICK SORT FOR LINKED LISTS:
+    (Not as important as reviewing merge sort below)
+            
+    # USE MORE DUMMY NODES TO SEPERATE CONCERNS, AND REDUCE MISTAKES
+    # I HAD A PROBLEM WITH CYCLES BECAUSE I WAS REUSING NODES.
 
-     // C++ program to print all combinations of size 
-    // k of elements in set 1..n 
-    #include <bits/stdc++.h> 
-    using namespace std; 
-    
-    void makeCombiUtil(vector<vector<int> >& ans, 
-        vector<int>& tmp, int n, int left, int k) 
-    { 
-        // Pushing this vector to a vector of vector 
-        if (k == 0) { 
-            ans.push_back(tmp); 
-            return; 
-        } 
-    
-        // i iterates from left to n. First time 
-        // left will be 1 
-        for (int i = left; i <= n; ++i) 
-        { 
-            tmp.push_back(i); 
-            makeCombiUtil(ans, tmp, n, i + 1, k - 1); 
-    
-            // Popping out last inserted element 
-            // from the vector 
-            tmp.pop_back(); 
-        } 
-    } 
-    
-    // Prints all combinations of size k of numbers 
-    // from 1 to n. 
-    vector<vector<int> > makeCombi(int n, int k) 
-    { 
-        vector<vector<int> > ans; 
-        vector<int> tmp; 
-        makeCombiUtil(ans, tmp, n, 1, k); 
-        return ans; 
-    } 
-    
-    // Driver code 
-    int main() 
-    { 
-        // given number 
-        int n = 5; 
-        int k = 3; 
-        vector<vector<int> > ans = makeCombi(n, k); 
-        for (int i = 0; i < ans.size(); i++) { 
-            for (int j = 0; j < ans[i].size(); j++) { 
-                cout << ans.at(i).at(j) << " "; 
-            } 
-            cout << endl; 
-        } 
-        return 0; 
-    } 
+    def sortList(self, head: ListNode) -> ListNode:
+        '''
+        random.randint(a, b)¶
+        Return a random integer N such that a <= N <= b. Alias for randrange(a, b+1).
+        '''
         
--55)
+        node = head
+        l = 0
+        while node:
+            l += 1
+            node = node.next
+            
+        def partition(head, start, end, pivot):
+            if start == end:
+                return head
+            if head is None:
+                return None
+            
+            pivotVal = pivot.val
+            before = ListNode(0)
+            after = ListNode(0)
+            afterCopy = after
+            beforeCopy = before
+            
+            temp = head
+            left_len = 0
+            
+            while temp:       
+                # print("processing temp", temp.val)
+                if temp == pivot:
+                    temp = temp.next
+                    continue
+                    
+                if temp.val < pivotVal: 
+                    left_len += 1
+                    before.next = temp
+                    before = before.next
+                    temp = temp.next
+                else:
+                    after.next = temp
+                    after = after.next
+                    temp = temp.next
+                        
+            before.next = None
+            after.next = None
+            return beforeCopy.next, left_len, afterCopy.next
+ 
+        def quicksort(head, start, end):
+            if head is None:
+                return None
+            
+            if end-start <= 1:
+                return head 
+            
+            pivotLoc = random.randint(start, end-1)            
+            pivot = head
+            i = 0
+            while i < pivotLoc:
+                pivot = pivot.next
+                i += 1
+                
+            if pivot is None:
+                return None
+               
+            left, left_len, right = partition(head, start, end, pivot) 
+            sorted_left = quicksort(left, 0, left_len)
+            sorted_right = quicksort(right, 0, end - left_len - 1)
+            
+            if sorted_left:
+                temp = sorted_left
+                while temp and temp.next:
+                    temp = temp.next
+                temp.next = pivot
+            else:
+                sorted_left = pivot
 
+            pivot.next = sorted_right
+            return sorted_left
+        
+        return quicksort(head, 0, l)
 
 
+-17.3 Bottom Up Merge Sort for Linked List (O(1) space )
+    class Solution {
+    public:
+        ListNode *sortList(ListNode *head) {
+            if(!head || !(head->next)) return head;
+            //get the linked list's length
+            ListNode* cur = head;
+            int length = 0;
+            while(cur){
+                length++;
+                cur = cur->next;
+            }
+            
+            ListNode dummy(0);
+            dummy.next = head;
+            ListNode *left, *right, *tail;
+            for(int step = 1; step < length; step <<= 1){
+                cur = dummy.next;
+                tail = &dummy;
+                while(cur){ 
+                    left = cur;  // includes current node, this is the start of the left piece
+                    right = split(left, step); // start right after left has been cut off
+                    cur = split(right,step); //  cut off a right piece for merge
+                    tail = merge(left, right, tail);
+                }
+            }
+            return dummy.next;
+        }
+    private:
+        // the purpose of split method is to set a node null so that we can use it in merge.
+        ListNode* split(ListNode *head, int n){
+            //if(!head) return NULL;
+            for(int i = 1; head && i < n; i++) head = head->next;
+            
+            if(!head) return NULL;
+            ListNode *second = head->next;
+            head->next = NULL;
+            return second;
+        }
+        ListNode* merge(ListNode* l1, ListNode* l2, ListNode* head){
+            ListNode *cur = head;
+            while(l1 && l2){
+                if(l1->val > l2->val){
+                    cur->next = l2;
+                    cur = l2;
+                    l2 = l2->next;
+                }
+                else{
+                    cur->next = l1;
+                    cur = l1;
+                    l1 = l1->next;
+                }
+            }
+            cur->next = (l1 ? l1 : l2);
+            while(cur->next) cur = cur->next;
+            return cur;
+        }
+    };
 
--53) Recursive Multiply:
-    Write a recursie function to multiply 2 positive integers without using the 
-    * operator. Only addition, subtraction and bit shifting but minimize ops. 
+-11) Merkle Hashing and Tree to String Methods:
 
-    Answer:
+    Given two non-empty binary trees s and t, check whether tree 
+    t has exactly the same structure and node values with a subtree of s.
+    A subtree of s is a tree consists of a node in s and all of this node's 
+    descendants. The tree s could also be considered as a subtree of itself.
 
-    int minProduct(int a, int b) {
-        int bigger = a< b ? b : a;
-        int smaller = a < b ? a: b;
-        return minProductHelper(a, b);
-    }
+    Normal way runtime is O(|s| * |t|)
+    Runtime O(|s| + |t|) (Merkle hashing):
 
-    int minProdHelper(smaller, bigger) {
-        if smaller == 0 return 0
-        elif smaller == 1 return 1
+    For each node in a tree, we can create node.merkle, 
+    a hash representing it's subtree. This hash is formed by hashing the 
+    concatenation of the merkle of the left child, the node's value, 
+    and the merkle of the right child. Then, two trees are identical if 
+    and only if the merkle hash of their roots are equal (except when 
+    there is a hash collision.) From there, finding the answer is straightforward: 
+    we simply check if any node in s has node.merkle == t.merkle
 
-        int s = smaller >> 1; //divide by 2
-        int halfPrd = minProductHelper(s, bigger);
-        if smaller % 2 == 0:
-            return halfProd + halfProd
-        else:
-            return halfProd + halfProd + bigger
-    }
-    Runtime O(log s)
+    def isSubtree(self, s, t):
+        from hashlib import sha256
+        def hash_(x):
+            S = sha256()
+            S.update(x)
+            return S.hexdigest()
+            
+        def merkle(node):
+            if not node:
+                return '#'
+            m_left = merkle(node.left)
+            m_right = merkle(node.right)
+            node.merkle = hash_(m_left + str(node.val) + m_right)
+            return node.merkle
+            
+        merkle(s)
+        merkle(t)
+        def dfs(node):
+            if not node:
+                return False
+            return (node.merkle == t.merkle or 
+                    dfs(node.left) or dfs(node.right))
+                        
+        return dfs(s)
     
+    QA below:
+    Soln doesnt check for hash collisions but we use hash resistant function:
+    For practical purposes, we can assume that there will not be a hash collision, 
+    as the probability of a collision will be in the order of |S|^2 / 2^256. 
+    A computer can do a sha256 hash in about 1 microsecond, 
+    but sha256 hashes are technically proportional to their input length, 
+    and you would be hashing hex digest (32 bytes each) as well as the node.val strings.
 
+    For this problem though, collision resistant hash functions like sha256 
+    are not necessary, from performance perspective. You can use some 
+    computationally cheaper hash functions. With an addition of O(|T|) 
+    checking every time hash values match, correctness is also made sure.
 
+    Convert Trees to Strings Method F strings:
+    Basically we convert our tree into string representation, 
+    then just check whether substring exists in target string.
+    
+    >>> f"Hello, {name}. You are {age}."
+    'Hello, Eric. You are 74.'
 
+    class Solution:
+        def isSubtree(self, s: TreeNode, t: TreeNode) -> bool:
+            string_s = self.traverse_tree(s)
+            string_t = self.traverse_tree(t)
+            if string_t in string_s:
+                return True
+            return False
+        
+        
+        def traverse_tree(self, s):
+            if s:
+                return f"#{s.val} {self.traverse_tree(s.left)} {self.traverse_tree(s.right)}"
+            return None
 
 
--52) Random Node: Create a binary tree class, which in addition to 
-    insert, find, and delete, has a method getRandomNode() which 
-    returns a random node from teh tree. All nodes should be equally likely to be chosen
-
-    Just traverse left, return current, or right node with 1/3 probability
-    But this isnt O(N) for all nodes, top nodes more likely.
+---------------------------------------------------------------------------------------------
+------------------------------------------------------------------------------------------------------------------------
+---------------------------------------------------------------------------------------------
+------------------------------------------------------------------------------------------------------------------------
+Start reading notes from here, when you are done going forwards, go backwards from here. 
 
-    Return root with 1/N prb
-    odds of picking left node is LEFT_SIZE * 1/N, odds of going right is RIGHT_SIZE * 1/n
 
-    But we dont want to make that many RNG calls. Use inorder traversal to help:
+ALGO README PART 1
 
-    Generate one random number -> this is the node (i) to return, and then 
-    we locate ith node using inorder traversal. Suubtracting leftsz + 1 from i 
-    reflects that, when we go right, we skip over left+1 nodes in the inorder traversal. 
 
+1)  For problems like parenthesis matching. You can use a stack to solve the matching. But you can also
+    do matching by incrementing and decrementing an integer variable. Or you can use colors or 
+    other types of INDICATOR VARIABLE TYPE SOLUTIONS that contain meta information on the problem. 
+    Also remember that as you see each element, you can push multiple times to stack, not just once
+    in case u need to keep count of something before a pop occurs. 
+    
+0.05) To solve a difficult 3D problem or 2D problem. Solve the lower dimension first, 
+     and then use it to guide your solution for higher dimensions. 
+     Such as max area of rectangle of 1's.
 
+0.1) When doing string splitting, there are helper functions 
+     but sometimes its better to for loop through the 
+     string character by character because you have more granularity 
+     which can help to solve the problem easily. 
 
+0.15)   One-line Tree in Python
+        Using Python's built-in defaultdict we can easily define a tree data structure:
 
--51) Inorder Succcesor. Find next node of a given node in a BST. You
-    may assume each node has link to parent:
+        def tree(): return defaultdict(tree)
+        
+        users = tree()
+        users['harold']['username'] = 'hrldcpr'
+        users['handler']['username'] = 'matthandlersux'
 
-    Node inorderSucc(Node n): 
-        if n has a right subtree:
-            return leftmost child of right subtree
-        else: 
-            while n is a right child of n.parent:
-                n = n.parent
-            
-            return n.parent
-    
+0.2) Learnings from interval coloring. Sometimes we care a lot about tracking our current running value
+    such as current running intersection to generate a solution output. However it can be better to
+    focus on the negative space, and care about what will be evicted first, as our main tracking 
+    concern using a priority queue. Look at problems with both positive and negative space in mind. 
+    Know whats best to track, and track it. dont be fooled by the question. 
+    You should be tracking the critical elements that directly affect the solution, and find them in either the 
+    positive or negative space. 
 
+0.25) Look to see if the question is a
+      in the negative space of questions you've 
+      seen before!
+      For instance, Non-overlapping intervals LC, where
+      you find the minimum number of intervals to remove 
+      to make the rest of the intervals non-overlapping
+      is the negative of max interval scheduling using
+      earliest finish time.
 
--50) Cool counting trick to count pairs: (Done in CodeSignal HARD)
-    ALSO RECALL THEORY THAT SORTEDNESS OF NUMBERS YIELDS COMBINATIONS NOT PERMUTATIONS 
-    In case you have a problem where you need to get all combinations! just enforce 
-    a sort on the list before picking elements. 
+      But you can also solve directly:
+      Sort the intervals by their start time. 
+      If two intervals overlap, the interval 
+      with larger end time will be removed 
+      so as to have as little impact on 
+      subsequent intervals
 
-    Problem: A reverse is a number reversed. 
-    So 20 reversed is 2, 420 reversed is 24, 56060 reversed is 6065
+0.26) Introduce multiple running variables, if maintaining one 
+        running variable makes the updates too difficult or tricky
+        (SEPERATION OF CONCERNS USING MULTIPLE VARS OR CONTAINERS TRICK)
 
-    Given 2 arrays, A and ReverseA, count all pairs i <= j
-    where A[i] + ReverseA[j] == Reverse[i] + A[j].
-    
-    So for instance given input: [1, 20, 3,  19 ] ->   A[i] + ReverseA[j] 
-                ReverseA is then [1,  2, 3,  91 ]
-        A[i] + ReverseA[j] == Reverse[i] + A[j] indexes are:
-        [(0,0),(1,1), (2,2), (3,3), (0,2)]
+        For instance: LC -> 
+        Given an integer array nums, find the contiguous 
+        subarray within an array (containing at least one number) 
+        which has the largest product.
 
-    SINCE WE ARE COUNTING AND DONT HAVE TO LIST OUT ALL THE PAIRS IN THE
-    SOLUTION THIS TIPS US OFF THAT THERE IS AN O(N) soln. 
-    Brute force soln -> Enumerating pairs is O(N^2). 
+        Example 1:
 
-    OK BE SMART BY REARRANGING CONSTRAINT SO THAT WE CAN DO EASILY PRECOMPUTATIONS. 
-    A[i] + ReverseA[j] == Reverse[i] + A[j]
-    Rearrange to have variables of same type on same side:
-    
-    A[i] - Reverse[i] == A[j] - ReverseA[j]
-    Ok now precompute the top array. 
+        Input: [2,3,-2,4]
+        Output: 6
+        Explanation: [2,3] has the largest product 6.
+        
+        Solution:
+        int maxProduct(int A[], int n) {
+            // store the result that is the max we have found so far
+            int r = A[0];
 
-    differences = []
-    for i,j in zip(A, RevA):
-        differences.append(i - j )
-    
-    AND RMBR YOU CAN COUNT PAIRS USING A MAP!! Pairs where i <= j
-    Use formula n*(n-1)/2
+            // imax/imin stores the max/min product of
+            // subarray that ends with the current number A[i]
+            for (int i = 1, imax = r, imin = r; i < n; i++) {
+                // multiplied by a negative makes big number smaller, small number bigger
+                // so we redefine the extremums by swapping them
+                if (A[i] < 0)
+                    swap(imax, imin);
 
-    m = defaultdict(int)
-    
-    for diff in differences:
-        m[diff] += 1
+                // max/min product for the current number is either the current number itself
+                // or the max/min by the previous number times the current one
+                imax = max(A[i], imax * A[i]);
+                imin = min(A[i], imin * A[i]);
 
-    So if m[3] -> means 3 different indexs have the same difference and 3 diff 
-                  indexes satisfy A[i] - Reverse[i] == A[j] - ReverseA[j]
-                  For instance index: (2, 4, 7)
-                  -> So 2<->4, 2<->7, and 4<->7 should be counted. Also rmbr 2<->2, 4<->4, 7<->7
-                     need to be counted too.
-                    Its a permutation of 2 elements (i,j), but with order, so to remove order, 
-                    divide by the ways it can be ordered which is 2!. Finanl solution is  
-                    aka _ _   (n) x (n-1) / 2!
-                    And then to sum the 2<->2, 4<->4, 7<->7, just add lenght of list. 
+                // the newly computed max value is a candidate for our global result
+                r = max(r, imax);
+            }
+            return r;
+        }
 
-                -> For example: count pairs from these indicies where i<=j : [1,3,4,5]
-                this is 4*3/2 -> 6
-                1<->3, 1<->4, 1<->5, 3<->4, 3<->5, 4<->5s
-                lst sz 4: 3+2+1 -> 6
 
-    count = 0
-    for k,v in m.items():
-        count += v*(v-1)/2
-    count += len(differences)
-    return count
+0.27) Binary Tree Max Path Sum: the binary tree version of max subarray sum:
 
+    Given a non-empty binary tree, find the maximum path sum.
+    For this problem, a path is defined as any sequence of nodes from 
+    some starting node to any node in the tree along the parent-child connections. 
+    The path must contain at least one node and does not need to go through the root.
     
+    def maxPathSum(self, root: TreeNode) -> int:
+        m = float(-inf)
+        def helper(node):
+            nonlocal m
+            if node is None:
+                return 0
+            maxRightPath =  helper(node.right)
+            maxLeftPath = helper(node.left)           
+            right = maxRightPath + node.val
+            left = maxLeftPath + node.val
+            connected = maxRightPath + maxLeftPath + node.val
+            m = max(m, right, left, connected, node.val)
+            maxPath = max(right, left, node.val, 0)
+            return maxPath
+        helper(root)
+        return m
 
 
+0.28) Given an unbalacned binary search tree, write a function 
+      kthSmallest to find the kth smallest element in it.
+    # GENERATOR SOLN:
+    def traverse(node):
+        if node:
+            yield from traverse(node.left)
+            yield node
+            yield from traverse(node.right)
+        
+    def kthSmallest(root, k):
+        k -= 1
+        for i, node in enumerate(traverse(root)):
+            if i == k:
+                return node.val
 
--49) To do math cieling operation on num:
-    (num - 1) // divisor + 1
-
--48) DP + BINARY Search (DELETE IF YOU DONT UNDERSTAND):
-
-    1180 - Software Company
 
-    This company has n employees to do the jobs. To manage the two 
-    projects more easily, each is divided into m independent subprojects. 
-    Only one employee can work on a single subproject at one
-    time, but it is possible for two employees to work 
-    on different subprojects of the same project
-    simultaneously. Our goal is to finish the projects as soon as possible.
+    # RECURSIVE
+    def kthSmallest(self, root: TreeNode, k: int) -> int:
+        # LETS DO INORDER THIS TIME. 
+        found = None
+        count = 0
 
-    Each case starts with two integers n (1 ≤ n ≤ 100), and m (1 ≤ m ≤ 100). Each of the next n lines
-    contains two integers which specify how much time in seconds it will take for the specified
-    employee to complete one subproject of each project. So if the line contains x and y, it means that it
-    takes the employee x seconds to complete a subproject from the first project, and y seconds to
-    complete a subproject from the second project.    
-    Input        -> Output : 
-    3 20           Case 1: 18
-    1 1           The input will be such that answer will be within 50000.
-    2 4
-    1 6
-
-    Run a binary search fixing the time needed to complete both the projects. 
-    Now you know for each employee, the doable max amount of sub-projects of A fixing 
-    the amount of sub-projects to do of type B. Keep a dp[i][j] which means the maximum 
-    number of sub-projects of B that can be done while j sub-projects of A are still 
-    to be done and we’re currently at employee i. If dp[0][m] >= m 
-    then the time fixed is ok. Answer is the minimum such time.
+        def inorder(node):
+            nonlocal found
+            nonlocal count
+            
+            # Ok found left side. 
+            if node is None:
+                return 
+            
+            inorder(node.left)
+            count += 1
+            if count == k:
+                found = node.val
+                return 
+            inorder(node.right)
+        inorder(root)
+        return found
+    
+    # ITERATION:
+    def kthSmallest(self, root, k):
+        stack = []
+        while True:
+            while root:
+                stack.append(root)
+                root = root.left
+            root = stack.pop()
+            k -= 1
+            if not k:
+                return root.val
+            root = root.right
+    
+    What if the BST is modified (insert/delete operations) 
+    often and you need to find the kth smallest frequently?
+    How would you optimize the kthSmallest routine?
+    
+    Seems like a database description, isn't it? Let's use here 
+    the same logic as for LRU cache design, and combine an 
+    indexing structure (we could keep BST here) with a double linked list.
+    Such a structure would provide:
 
-    const int N = 107;
-    int dp[N][N];
-    int n, m;
-    int x[N], y[N];
+    O(H) time for the insert and delete.
+    O(K) for the search of kth smallest.
 
-    bool ok(int tym) {
-        for(int i=1; i<=m; ++i) dp[n][i] = -INF;
-        dp[n][0] = 0;
-        for(int i=n-1; i>=0; --i) {
-            for(int j=0; j<=m; ++j) {
-                dp[i][j] = -INF;
-                int max_a = tym / x[i];
-                max_a = min(j, max_a);
-                for(int k=0; k<=max_a; ++k) {
-                    int max_b = (tym-k*x[i]) / y[i];
-                    dp[i][j] = max(dp[i][j], max_b + dp[i+1][j-k]);
-                }
-            }
-        }
-        return (dp[0][m] >= m);
-    }
+    You could also add a count field to each node but this would make performance:
+    It's not O(log n). O(h) instead. h is the height of the BST.
 
-    int main() {
-        int t, tc=0;
-        scanf("%d", &t);
+    The overall time complexity for insert/delete + search of kth smallest is O(H + k) instead of O(2H + k).
 
-        while(t--) {
-            scanf("%d %d", &n, &m);
-            for(int i=0; i<n; ++i) scanf("%d %d", x+i, y+i);
+    Complexity Analysis
 
-            int lo = 1, hi = 50000;
-            while(lo < hi) {
-                int mid = (lo + hi) / 2;
-                if(ok(mid)) hi = mid;
-                else lo = mid + 1;
-            }
-            printf("Case %d: %d\n", ++tc, hi);
-        }
+    Time complexity for insert/delete + search of kth smallest: O(H + k), where H is a tree height. 
+    O(logN+k) in the average case, O(N+k) in the worst case.
 
-        return 0;
-    }
+    Space complexity : O(N) to keep the linked list.
 
 
--47) GREEDY ALGORITHM INTERVAL DEADLINES C++
-    
-    It is required to create such a schedule to accomplish the biggest number of jobs.
+0.3) Granularity === Optimization. Break up variables and track everything. Structurd things like
+      for loops, and functional structures like reduction, and map, and filter 
+      that dont fit the required granlarity should be thrown away if it interferes. 
 
-    struct Job {
-        int deadline, duration, idx;
+0.4) HOW TO do cieling using python floor int truncation:
 
-        bool operator<(Job o) const {
-            return deadline < o.deadline;
-        }
-    };
+    def ceiling_division(n, d):
+        return -(n // -d)
 
-    vector<int> compute_schedule(vector<Job> jobs) {
-        sort(jobs.begin(), jobs.end());
+0.45) When you are solving a problem, and it seems like DP. 
+      take a step back and see if you can use  hash map abuse + greedy,
+      to solve the problem. DP uses hash maps too, but maybe you can
+      be smart and add direction, and running values, which will allow  
+      hash map abuse to work (try thinking of it bottom up, base case, direction,
+      to help you think of hash map abuse or a greedy soln). 
 
-        set<pair<int,int>> s;
-        vector<int> schedule;
-        for (int i = jobs.size()-1; i >= 0; i--) {
-            int t = jobs[i].deadline - (i ? jobs[i-1].deadline : 0);
-            s.insert(make_pair(jobs[i].duration, jobs[i].idx));
-            while (t && !s.empty()) {
-                auto it = s.begin();
-                if (it->first <= t) {
-                    t -= it->first;
-                    schedule.push_back(it->second);
-                } else {
-                    s.insert(make_pair(it->first - t, it->second));
-                    t = 0;
-                }
-                s.erase(it);
-            }
-        }
-        return schedule;
-    }
+0.5) Preprocess and do a running comparison between 2 containers. 
+    For instance, to do certain problems you need to sort a list and then compare the sorted list 
+    to another list to determine ways to do sliding window/2pointer type techniques. 
 
+0.55) GREEDY AND 2 POINTER SOLUTION GUIDE: 
+      
+      For an optimization problem, to do it greedily and efficiently, do not enumerate 
+      all states, only ones that you are sure could possibily be better under the problems
+      constraints. 
+      Do this first:
+      
+      DISCOVER ALL THE CONSTRIANTS INTRODUCED BY THE PROBLEM FIRST!
+      THEN THINK OF THEOREMS THAT MUST BE TRUE AS A RESULT OF THE CONSTRAINTS.
+      RUN THROUGH EXAMPLES, TO ENSURE THEOREMS ARE TRUE, and then step through a 
+      solution to see how they work: 
 
--43.5) USE BINARY SEARCH EVEN WHEN YOU DONT THINK YOU NEED IT.
-       USE IT WHEN YOU CAN MAP HALF THE VALUES TO TRUE AND THE OTHER HALF TO FALSE SOMEHOW
-       COME UP WITH MAPPING THEN UTILIZE BINSEARH!
+      Do both 1 and 2 at same time to come up with a solution:
+      1) EXPLOT THEOREMS TO CREATE the OPTIMIZATION PATTERNS AND STEPS TO EXECUTE.
+         Thinking of the problem using DP can help with greedy creation. 
+      2) THINK OF WHAT A PROOF TO THE GREEDY PROBLEM COULD BE GIVEN THE THEREMS;
+         use proof to guide creation of greedy.
 
+      Example: Container with most water: 
         
-        LC:  644-maximum-average-subarray-ii
-        Given an array consisting of n integers, find the contiguous 
-        subarray whose length is greater than or equal to k 
-        that has the maximum average value. 
-        And you need to output the maximum average value.
-        Input: [1,12,-5,-6,50,3], k = 4
-        Output: 12.75
-        Explanation:
-        when length is 5, maximum average value is 10.8,
-        when length is 6, maximum average value is 9.16667.
-        Thus return 12.75.
+        Find two lines, which together with x-axis forms a container, 
+        such that the container contains the most water.
+        Input: [1,8,6,2,5,4,8,3,7]
+        Output: 49
+        
+        class Solution:
+            def maxArea(self, height):
+                i, j = 0, len(height) - 1
+                water = 0
+                while i < j:
+                    water = max(water, (j - i) * min(height[i], height[j]))
+                    if height[i] < height[j]:
+                        i += 1
+                    else:
+                        j -= 1
+                return water
 
+0.56) SLIDING WINDOW ALGO DESIGN PATTERN:
+      Max Sum Contiguous Subarray: 
+      
+    # Function to find the maximum contiguous subarray 
+    from sys import maxint 
+    def maxSubArraySum(a,size): 
         
-        Method 1: Use Binary Search
+        max_so_far = -maxint - 1
+        max_ending_here = 0
+        
+        for i in range(0, size): 
+            max_ending_here = max_ending_here + a[i] 
+            if (max_so_far < max_ending_here): 
+                max_so_far = max_ending_here 
+    
+            if max_ending_here < 0: 
+                max_ending_here = 0   
+        return max_so_far 
 
-            first we do a binary search on the average and let it be x
-            we decrease x from all of the array elements and if there exists a 
-            sub array with lengh more than k whose sum is more than zero then we can 
-            say that we have such a sub array whose average is more than x other wise 
-            we can say that there doesnt exist any such sub array
 
-            how to find out if there is a sub array whose sum is more than zero and its 
-            length is more than k? we can say that a sub array [l, r) equals sum[1, r) — sum[1, l) 
-            so if we get the partial sums and fix the r of the sub array we just need an l 
-            which sum[1, r) >= sum[1, l) and l <= r — k this can 
-            be done with partial minimum of the partial sums
+0.57) Interval Coloring:
+    
+    from heapq import *
+    import itertools
 
-        Method 2: Use a diff bin search
-            Goal: Find the maximum average of continuous subarray of 
-            length greater than or equal to k.
+    def minMeetingRooms(self, intervals):
+        sorted_i = sorted(intervals, key=lambda x: x.start)
+        
+        pq = []
+        counter = itertools.count()
+        active_colors = 0
+        max_colors = 0
+        
+        for i in sorted_i:
+            iStart = i.start
+            iEnd = i.end
+            
+            while len(pq) != 0:
+                
+                min_end_time, _, interval_to_be_popped = pq[0]                
+                if(iStart <= min_end_time):
+                    break                
+                active_colors -= 1
+                _ = heappop(pq)
+                            
+            c = next(counter)
+            item = [iEnd, c, i]
+            heappush(pq, item)
+            print("increment active colors")
+            active_colors += 1
+            max_colors = max(active_colors, max_colors)
+        return max_colors
 
-            Assumption: The answer is between the maximum value 
-            and the minimum value in the array.
+0.58) Min Meeting rooms ii Approach 2) : Chronological Ordering
+    class Solution:
+        """
+        @param intervals: an array of meeting time intervals
+        @return: the minimum number of conference rooms required
+        """
+        def minMeetingRooms(self, intervals):
+            # Write your code here
+            '''
+            start < end
+            get all start times, get all end times, sort them together. 
+            If you see starts increment, if you see an end, decrement. 
+            Keep track of max overlapping rooms
+            '''
+            all_times = []
+            for i in intervals:
+                all_times.append( ("s", i.start) )
+                all_times.append( ("e", i.end))
 
-            As a result, we can do a binary search for the answer, 
-            while using the minimum value and the maximum value as left and right boundary (inclusive).
+            sorted_times = sorted(all_times, key=lambda x: x[1])
+            
+            cur = 0
+            ans = 0
 
-            Given the initial value of left and right boundary, we can 
-            compute the mid value. The problem is how we decide where the
-            answer lies, in [left, mid) or [mid, right].
+            for i in sorted_times:
+                if(i[0] == "s"):
+                    cur += 1
+                else:
+                    cur -= 1
+                ans = max(ans, cur)
+            return ans
 
-            If and only if there exists a subarray whose length is at least k, 
-            and its average value is greater than or equal mid, 
-            then the answer lies in [mid, right].
+0.6) To delete from a list in O(1), any index, you can swap the middle indexed element with
+    the last element in the array. then call array.pop(). This is O(1). You could also use a linked
+    list. The problem is, this will mess up the sorting of your array if you do this. 
+    so dont do it if your result needs to be sorted. 
 
-            The problem becomes: Decide if there exists a subarray 
-            whose length is at least k, and its average value is greater than mid.
 
-            Consider such scenario: The average of A[1..n] >= mid is the same 
-            as the average of B[1..n] >= 0 where B[i] = A[i] - mid.
+0.65) EMULATE DO WHILE IN PYTHON:
 
-            If we construct the new array B[] based on the given array A[], 
-            the problem becomes: Decides if there's a subarray whose length 
-            is at least k, and its sum is greater than 0,
+        i = 1
 
-            which is the same as finds the maximum subarray sum where 
-            the length of the subarray needs to be at least k.
+        while True:
+            print(i)
+            i = i + 1
+            if(i > 3):
+                break
 
-            When it comes to the maximum subarray sum, it is natural to 
-            think of the classic solution: "keep adding each integer to the 
-            sequence until the sum drops below 0. If sum is negative, reset the sequence."
+0.67) PYTHON AND BINARY Enumerate all subsets:
+    class Solution:
+        def subsets(self, nums):
+            numberOfSubsets = len(nums)
+            subsets = []
+            for i in range(0, 2 ** numberOfSubsets):
+                bits = bin(i)
+                subset = []
+                for j in range(0, numberOfSubsets):
+                    if i >> j & 1:  # Check if the first bit is on, 
+                                    # then check if second bit is on, 
+                                    # then check third bit is on, and keep going
+                        subset.append(nums[j])
 
-            However, it cannot work for our case, as we have requirement for the subarray length.
+                subsets.append(subset)
+            return subsets
 
-            Another simple way to find the maximum subarray is dynamic programming. 
-            If we can use DP to calculate the presum of the array (every subarray 
-            with start from the first element), we only need to find the maximum 
-            increase in the presum array.
+        Iterate through all subsets of a 
+        subset y (not including empty set) (TODO WRITE IN PYTHON):
 
-            We can slightly modify this approach to solve our problem. 
-            When finding the maximum increase, we no longer record the smallest 
-            element appeared before, but record the smallest element appeared k positions before.
+        given a set of numbers, we want to find the sum of all subsets.
 
-            You should easily see that this will cover the case where the 
-            length of the subarray is greater than k.
-            
-            Time complexity O(nlog(max-min))
-            Space complexity O(1)
+            Sol: This is easy to code using bitmasks. we can use an array to store all the results.
 
-            class Solution {
-            public :
-                double findMaxAverage(vector< int >& nums, int k) {
-                    int n = nums.size();
-                    vector < double > sums(n + 1 , 0 );
-                    double left = * min_element(nums.begin(), nums.end());
-                    double right = * max_element(nums.begin(), nums.end()) ;
-                    while (right-left> 1e- 5 ) {
-                        double minSum = 0 , mid = left + (right-left) / 2 ;
-                        bool check = false ;
-                        for ( int i = 1 ; i <= n; ++ i) {
-                            sums[i] = sums[i- 1 ] + nums[i- 1 ] -mid;
-                            if (i >= k) {
-                                minSum = min(minSum, sums[i- k]);
-                            }
-                            if (i >= k && sums[i]> minSum) {check = true ; break ;}
-                        }
-                        if (check) left = mid;
-                        else right = mid;
-                    }
-                    return left;
+            int sum_of_all_subset ( vector< int > s ){
+                        int n = s.size() ;
+                        int results[ ( 1 << n ) ] ;     // ( 1 << n )= 2^n
+
+                    //initialize results to 0
+                        memset( results, 0, sizeof( results ) ) ;
+
+                    // iterate through all subsets
+                    // for each subset, O(2^n)
+                    for( int i = 0 ; i < ( 1 << n ) ; ++ i ) {    
+                            // check membership, O(n)
+                            for ( int j = 0; j < n ; ++ j ) {       
+                                // test bit
+                                if ( ( i & ( 1 << j ) ) ! = 0 )    
+                                    results[i] += s [j] ;          
+                                }
                 }
-            };
+            }
 
+0.68) When you are doing a question that requires modifying a list as you go
+      dont save pointers to the list and reprocess list and other stuff. 
+      Do all the modifications in one loop as you go.
+      Such as for Insert Interval (LC 57)
+      
+0.69) When the question has products involved. Use Logs to turn it into a sums question. 
 
 
+0.7) Iterate backwards through array using python for dp:
+    for i in range(len(arr) - 1, -1, -1):
+        print(i)
 
--43) Maximum Slice problem, Kadane's algorithm and extensions
+0.71) Remember that its constant space when you are enumerating over the alphabet!!
 
-    Now we give a full version of the solution, 
-    which additionally also finds the boundaries of the desired segment:
+0.75) To get the fastest greedy solution possible, you must keep getting more
+     and more greedy and breaking assumptions you think you have. Only 
+     care about the answer, not the details of the question. Focus on 
+     what you REALLY NEED!!! when you keep breaking the questions rules
+     you thought were rules, find the true constraints!
+     Look at 621) Task Scheduler. It looked complicated but we just 
+     kept getting more greedy to get the most optimal MATHEMATICAL SOLUTION.
+     USE MATH AND ANALYSIS TO GET THE BEST SOLUTION!
 
-    int ans = a[0], ans_l = 0, ans_r = 0;
-    int sum = 0, min_sum = 0, min_pos = -1;
 
-    for (int r = 0; r < n; ++r) {
-        sum += a[r];
-        int cur = sum - min_sum;
-        if (cur > ans) {
-            ans = cur;
-            ans_l = min_pos + 1;
-            ans_r = r;
-        }
-        if (sum < min_sum) {
-            min_sum = sum;
-            min_pos = r;
-        }
-    }
+0.8) Sometimes you will get TLE with the bottom up solution. 
+     
+     This is because bottom up is slower since it is performing a BFS, 
+     rather than going directly to the solution unlike DFS + memoization, 
+     that tries to solve as quickly as possible. 
 
+     => If you only need a subset of the possible outputs 
+     from the algorithm, then the answer could also be yes. 
+     You only calculate the outputs you need, and so you avoid unneeded work.
+    => Jump 
 
 
--42.5) 2D Kadanes Algorithm: 
+0.85) When their is a max or min problem. 
+      TRY GREEDY first before doing GRAPH SEARCH + DP
+      Be smart first and do 
+      GREEDY + EXPLOIT PROBLEM STRUCTURE before anything 
+      else. 
 
-    Two-dimensional case of the problem: search for maximum/minimum submatrix
+0.9) Bidirectional BFS Reasons to use:
 
-    Kadane’s algorithm for 1D array can be used to reduce the time complexity to O(n^3). 
-    The idea is to fix the left and right columns one by one and find the maximum 
-    sum contiguous rows for every left and right column pair. We basically find top and bottom 
-    row numbers (which have maximum sum) for every fixed left and right column pair. 
-    To find the top and bottom row numbers, calculate sum of elements in every row from left 
-    to right and store these sums in an array say temp[]. So temp[i] indicates sum of elements 
-    from left to right in row i. If we apply Kadane’s 1D algorithm on temp[], 
-    and get the maximum sum subarray of temp, this maximum sum would be the maximum possible 
-    sum with left and right as boundary columns. To get the overall maximum sum, we compare 
-    this sum with the maximum sum so far.
+    Bi-directional BFS will yield much better 
+    results than simple BFS in most cases. Assume the 
+    distance between source and target is k, and the 
+    branching factor is B (every vertex has on average B edges).
 
-    def kadane(arr, start, finish, n): 
-        
-        # initialize sum, maxSum and  
-        Sum = 0
-        maxSum = -999999999999
-        i = None
-    
-        # Just some initial value to check 
-        # for all negative values case  
-        finish[0] = -1
-    
-        # local variable  
-        local_start = 0
-        
-        for i in range(n): 
-            Sum += arr[i]  
-            if Sum < 0: 
-                Sum = 0
-                local_start = i + 1
-            elif Sum > maxSum: 
-                maxSum = Sum
-                start[0] = local_start  
-                finish[0] = i 
-    
-        # There is at-least one 
-        # non-negative number  
-        if finish[0] != -1:  
-            return maxSum  
-    
-        # Special Case: When all numbers  
-        # in arr[] are negative  
-        maxSum = arr[0]  
-        start[0] = finish[0] = 0
-    
-        # Find the maximum element in array 
-        for i in range(1, n): 
-            if arr[i] > maxSum: 
-                maxSum = arr[i]  
-                start[0] = finish[0] = i 
-        return maxSum 
-    
-    # The main function that finds maximum 
-    # sum rectangle in M[][]  
-    def findMaxSum(M): 
-        global ROW, COL 
+    BFS will traverse 1 + B + B^2 + ... + B^k vertices.
+    Bi-directional BFS will traverse 2 + 2B^2 + ... + 2B^(k/2) vertices.
+    For large B and k, the second is obviously much faster the the first.
+
+1) Exploit problem structure
+
+    a) This means using a sliding window
+    b) This means keeping track of running values, and updating permanent values such as 
+        keeping tracking of curr_max_from_left to update overall_max when you are running through an array
+        -> running variables, running maps, running sets
+    c) Use 2 pointer solutions. Two pointers can be nodes or indexes in an array.
+
+1.25)   When the problem says sorted order, you can use
+        binary search or a very smart version of
+        2 pointer/2 index solutions. For instance,
+        2 SUM for ordered arrays can be 
+        solved in O(N) ( if you implement 
+        binary searching 2 pointers)
+
+        Two pointers: O(n) time and O(1) space
+        Dictionary: O(n) time and O(n) space
+        Binary search: O(nlogn) time and O(1) space
+        correct?
+
+        # two-pointer
+        def twoSum1(self, numbers, target):
+            l, r = 0, len(numbers)-1
+            while l < r:
+                s = numbers[l] + numbers[r]
+                if s == target:
+                    return [l+1, r+1]
+                elif s < target:
+                    l += 1
+                else:
+                    r -= 1
         
-        # Variables to store the final output  
-        maxSum, finalLeft = -999999999999, None
-        finalRight, finalTop, finalBottom = None, None, None
-        left, right, i = None, None, None
+        # dictionary           
+        def twoSum2(self, numbers, target):
+            dic = {}
+            for i, num in enumerate(numbers):
+                if target-num in dic:
+                    return [dic[target-num]+1, i+1]
+                dic[num] = i
         
-        temp = [None] * ROW 
-        Sum = 0
-        start = [0] 
-        finish = [0]  
-    
-        # Set the left column  
-        for left in range(COL): 
-            
-            # Initialize all elements of temp as 0  
-            temp = [0] * ROW  
-    
-            # Set the right column for the left  
-            # column set by outer loop  
-            for right in range(left, COL): 
-                
-                # Calculate sum between current left  
-                # and right for every row 'i' 
-                for i in range(ROW): 
-                    temp[i] += M[i][right]  
-    
-                # Find the maximum sum subarray in  
-                # temp[]. The kadane() function also  
-                # sets values of start and finish.  
-                # So 'sum' is sum of rectangle between   
-                # (start, left) and (finish, right) which  
-                # is the maximum sum with boundary columns  
-                # strictly as left and right.  
-                Sum = kadane(temp, start, finish, ROW)  
-    
-                # Compare sum with maximum sum so far.  
-                # If sum is more, then update maxSum  
-                # and other output values  
-                if Sum > maxSum: 
-                    maxSum = Sum
-                    finalLeft = left  
-                    finalRight = right  
-                    finalTop = start[0]  
-                    finalBottom = finish[0] 
-    
-        # Prfinal values  
-        print("(Top, Left)", "(", finalTop,  
-                                finalLeft, ")")  
-        print("(Bottom, Right)", "(", finalBottom,  
-                                    finalRight, ")")  
-        print("Max sum is:", maxSum) 
-    
-    # Driver Code 
-    ROW = 4
-    COL = 5
-    M = [[1, 2, -1, -4, -20], 
-        [-8, -3, 4, 2, 1],  
-        [3, 8, 10, 1, 3],  
-        [-4, -1, 1, 7, -6]]  
-    
-    findMaxSum(M) 
-
+        # binary search        
+        def twoSum(self, numbers, target):
+            for i in xrange(len(numbers)):
+                l, r = i+1, len(numbers)-1
+                tmp = target - numbers[i]
+                while l <= r:
+                    mid = l + (r-l)//2
+                    if numbers[mid] == tmp:
+                        return [i+1, mid+1]
+                    elif numbers[mid] < tmp:
+                        l = mid+1
+                    else:
+                        r = mid-1
 
--42) RMQs and processing array index and value at same time using 
-     a monotonic queue philosophy + Divide and conquer trick with dealing with all ranges. 
-     Sometimes you have to deal with 2 constraints at the same time. 
+1.3) Count set bits in integer:
+      (Log N!!) if N represents size of number
 
-    Problem: 
-    You have an array and a set 
-         1. 1. 2. 3. 4
-    a = [4, 2, 1, 6, 3]
-    S = {0, 1,  3, 4}
+    # Function to get no of set bits in binary 
+    # representation of positive integer n */ 
+    def  countSetBits(n): 
+        count = 0
+        while (n): 
+            count += n & 1
+            n >>= 1
+        return count 
 
-    for each pair in the set, find the minimum value in that range,
-    then return sum of all minimum values as answer:
-    
-    0-1 => a[0:2] => [4, 2] => min([4, 2]) = 2
-    0-3 => [4, 2, 1, 6] => 1
-    1-3 => [2, 1, 6] => 1
-    Therefore the answer is ->  2 + 1 + 1 = 4 <-
+1.5) LOOK AT PROBLEM IN ALL POSSIBLE DIRECTIONS to apply your techniques, whether its 2 pointer, 
+    sliding window, or Dynamic programming
+    a) think about left to right
+    b) right to left
+    c) 2 pointer on either side and you close into the middle
+    d) 2 pointers, one that traverses even indexes, and the other that traverses odd indexes
+    e) Linked list pointers, second moves twice as fast as the first. When second gets to end, first is at halfway node. 
+    f) Be creative in how you see the DIRECTIONALITY of the solution for a given problem. 
 
-    To do this question, you have to satisfy both the range condition 
-    and the find minimum value condition. 
 
-    My proposed garbage solution was precomputing all running minimum values 
-    for every (i, j) range like so: (This soln is in LunchclubIORMQ in most important problems)
-    [
-        [4, 2, 1,1,1]
-        [2, 1,1, 1]
-        [1,1, 1]
-        [6, 3]
-        [3]
-    ]
-    Then enumerate every set in O(n^2)
 
-    CAN ALSO SOLVE WITH DP LIKE BELOW -----------------------------
-    Another way was solving the problem for all set ranges, was to compute the mins 
-    between you and the next element to you. THen to compute the min for ranges that 
-    are longer than that, just do the min of those precomputed solutions DP style.
+1.51) Learn how to index for binsearch. 
+     Left index, getting mid, and right index is always boundary (so len(arr))
 
-    So compute [0,1], [1,3], [3,4] Then to compute [0, 3], and [1, 4] don't look at a, 
-    just take the min of the ranges that make up the bigger ranges!!
+    # Given an array where elements are sorted in ascending order, 
+    # convert it to a height balanced BST.
 
-    THE BEST WAY TO SOLVE BELOW -----------------------------
-    Better way was to think of ways to split the sets using array a. 
-    We can create a binary tree where it splits on minimum values with a, 
-    and query each subset range rite! The lca, is the min. 
+    class Solution:
+        def sortedArrayToBST(self, nums: List[int]) -> TreeNode:            
+            def build_tree(l, r):
+                if(l == r):
+                    return None
+                
+                mid =  l + (r-l)//2
+                root = nums[mid]
+                
+                # you never include right value
+                left = build_tree(l, mid)
+                right = build_tree(mid+1, r)
+                return TreeNode(val=root, left=left, right=right)
+                
+            return build_tree(0, len(nums))
 
-    This ideation leads to another solution. 
-    Lets sort A: and keep track of the index as well. 
-    Since we sorted on the A[i], WE have to do the second order processing 
-    on the index, i. We sorted on A[i] so that we can linearly process it
-    and in a convenient way that respects the first constraint. 
 
 
-    A = [(1, 2), (2,1 ), (3, 4), (4, 0), (6, 3)]
-    The trick in this problem is to binary search the index to satisfy the second
-    constraint, and do a divide and conquer technique on the problem. 
+1.52 Remember that you can do in-order and post-order to help you do
+   tree problems such as validate bst: 
+   (following is in-order!)
 
-    So process (1,2). its the smallest and it splits the set S in 2:
-    S = {0, 1, 3, 4, }
-              ^
-    All ranges that cross the binary insertion point have 1 as a minimum value!
-    So ranges 0-3, 0-4, 1-3, and 1-4 all have index 2 in the middle, and all 
-    will have the min value 1. 
+    def isValidBST(self, root):
+        res, self.flag = [], True
+        self.helper(root, res)
+        return self.flag
+    
+    def helper(self, root, res):
+        if root:
+            self.helper(root.left, res)
+            if res and root.val <= res[-1]:
+                self.flag = False
+                return
+            res.append(root.val)
+            self.helper(root.right, res)
 
-    Then we process next element in A, but we do not want to count the same ranges twice in 
-    our final resulting answer. You can fix this by using a visited set.
-    The smarter way is to divide and conquer S:
-    Split S in two: 
-    S1 = {0, 1}, and S2 = {3, 4}
-    Then binary search in the smaller subsets so that you do not see repeat ranges from 
-    having split it already on (A[1], 1)
+    # Sol 2:
+    
+    # iteratively, in-order traversal
+    # O(n) time and O(n)+O(lgn) space
+    class Solution:
+    # @param root, a tree node
+    # @return a boolean
+    def isValidBST(self, root):
+        pre, cur, stack = None, root, []
+        while stack or cur:
+            while cur:
+                stack.append(cur)
+                cur = cur.left
+            s = stack.pop()
+            if pre and s.val <= pre.val:
+                return False
+            pre, cur = s, s.right
+        return True
 
-    Search with index 1 on S1 because S2 does not contain index 1.
-    You will process [0, 1] -> give min value 2. 
-    Then finally compute answer like so. 
+    
+1.53) Dynamic programming -> check if they want permutations or combinations.  
+    The DP needs to change so that this invarient is 
+    maintained such as in Coin Change 2,
+    
+    THIS IS A COMBINATIONS DP PROBLEM. 
+    Input: amount = 5, coins = [1, 2, 5]
+    Output: 4
+    Explanation: there are four ways to make up the amount
+    with the denominations. 
+    DONT DO PERMUTATIONS DP. 
+    2 + 2 + 1 IS THE SAME AS 2 + 1 + 2, so forloop over coins first
+    so we dont reuse the same denomiation twice aka:
 
+    class Solution(object):
+        def change(self, amount, coins):
+            dic = {0: 1}
+            for coin in coins:
+                for j in range(amount + 1):
+                    dic[j] = dic.get(j, 0) +  dic.get(j - coin, 0)
+            return dic.get(amount, 0)
+    
+    THIS IS A PERMUATIONS DP PROBLEM, DONT DO COMBINATIONS:
 
 
+    Given an integer array with all positive numbers and no duplicates, 
+    find the number of possible combinations that add up to a positive integer target.
+    (the abvoe description is part of leetcode problem, they misuse word combinations)
+    nums = [1, 2, 3]
+    target = 4
 
--41) Insert interval into a sorted set of intervals using 2 binary searches:
-    Binary search the start time on the end times (bisect_right), 
-    and the end time on the start times (bisect_left)
-    if same value you can insert, otherwise cant
-    Works on open close start end intervals. 
-    Review BookingTimes in Most important problems. 
+    The possible combination ways are:
+    (1, 1, 1, 1), (1, 1, 2), (1, 2, 1), (1, 3), (2, 1, 1), (2, 2), (3, 1)
 
+    def combinationSum4(self, nums: List[int], target: int) -> int:        
+        amounts = [0 for _ in range(target + 1)]
+        amounts[0] = 1 # When you reach amount 0, yield 1, for the coin, base case
+        
+        for amt in range(1, target+1):
+            for coin in nums: 
+                if coin <= amt: 
+                    amounts[amt] += amounts[amt-coin]
+                    
+        return amounts[target]
 
+    What if negative numbers are allowed in the given array?
+    How does it change the problem?
+    What limitation we need to add to the question to allow negative numbers?
+    We should bound the length because solutions can have infinite length!!!
+    Code to follow up: 
+ 
+    def combinationSum4WithLength(self, nums, target, length, memo=collections.defaultdict(int)):
+        if length <= 0: return 0
+        if length == 1: return 1 * (target in nums)
+        if (target, length) not in memo: 
+            for num in nums:
+                memo[target, length] += self.combinationSum4(nums, target - num, length - 1)
+        return memo[target, length]
 
--40) CIRCULAR BUFFERS: Implementation Stack and Queue 
-     Declare an array with enough space!
-     
-    7.1: Push / pop function — O(1).
-    1   stack = [0] * N
-    2   size = 0
-    3   def push(x):
-    4       global size
-    5       stack[size] = x
-    6       size += 1
-    7   def pop():
-    8       global size
-    9       size -= 1
-    10      return stack[size]
-
-    7.2: Push / pop / size / empty function — O(1).
-    1   queue = [0] * N
-    2   head, tail = 0, 0
-    3   def push(x):
-    4       global tail
-    5       tail = (tail + 1) % N
-    6       queue[tail] = x
-    7   def pop():
-    8       global head
-    9       head = (head + 1) % N
-    10      return queue[head]
-    11  def size():
-    12      return (tail - head + N) % N
-    13  def empty():
-    14      return head == tail
+    
+1.54) CONTINUE TO PUSH FACTS AND DETAILS INTO A SOLUTION, ABUSE TO MAKE IT FASTER. 
+    Longest increasing subsequence can be solved with patience sort using NlogN. 
+    logN time to find pile and insert in pile. To come up with this method, 
+    look at your algorithm, realize what facts its using, realize if there 
+    are facts that you know the algorithm is not using but are true, 
+    then use those facts to ENHANCE YOUR SOLUTION, permutate the facts, look
+    for directionality in the facts, force it in with datastructures, and try to 
+    be clean as you do so. 
+    
+    # Lacks bin search below but one after adds it. 
+    The idea is to make piles as you traverse the array. The first pile is the 
+    first number in the array. As you iterate over the array, you check from 
+    the left most pile and if the current number is <= to the pile it can be 
+    placed there (greedy if I fits I sits rule) Otherwise, continue down the pile. 
+    If it can not fit on any pile you create a new one.
 
+    class Solution:
+        def lengthOfLIS(self, nums: List[int]) -> int:
+            if not nums:
+                return 0
+            # start with first pile as first num
+            piles = [nums[0]]
+            
+            for num in range(1, len(nums)):
+                # keep track if current number is placed
+                placed= False
+                # traverse the piles being greedy left to right. If it fits it sits
+                for x in range(len(piles)):
+                    if nums[num] <= piles[x]:
+                            piles[x] = nums[num]
+                            placed = True
+                            break
+                # Make home for the number if it didn't find one :(
+                if not placed:
+                    piles.append(nums[num])
+            return len(piles)
+            
+    # SOLUTION WITH BINSEARCH      
+    def lengthOfLIS(self, l: List[int]) -> int:
+        if not l: return 0
+        
+        # Create a placeholder for each pile. In the worst case, 
+        # the number of piles is the number of items in the list.
+        topOfEachPile = [0] * len(l)
+        
+        # From the deck/videos, we should know that  the Patience Algorithm is Greedy. 
+        # This results in the fewest number of piles possible.
+        # The LIS is then the number of piles that exist.
+        # Here we create a variable that describes the number 
+        # of piles that we have initialised from our placeholder above.
+        numberOfPiles = 0
+        
+        # Iterate over each number. For each number, do binary 
+        # search to figure out which of the piles to place the number.
+        for n in l:
+            # These variables set the range of the binary search. 
+            # We only want to do BS on the piles that have been initialised.
+            # We include, at the very right, a new pile. This is useful 
+            # because if the n can't fit into any of the existing 
+            # piles we have to add it into this new pile.
+            beg, end = 0, numberOfPiles
+        
+            # This BS is where we are greedy. If n is the same as l[middle] or less, we go left. 
+            while beg != end:
+                middle = (beg + end) // 2
+                if n > topOfEachPile[middle]:
+                    beg = middle + 1
+                else:
+                    end = middle
+            
+            # Update the top card at this pile.
+            topOfEachPile[beg] = n
+            
+            # If we did end up using a new pile, then beg == numberOfPiles. 
+            if beg == numberOfPiles: numberOfPiles += 1
+        
+        return numberOfPiles
 
+1.55) Review linked list 2, reversing a linked list between integers m and n 
+   and how to use recursive stack and nonlocal variables to
+   access backpointers in singly linked list. 
+   Also how to use dummy pointers to simplify code 
+   at the start.
+   and always check before doing .next to stop null errors. 
+   Iterative soln:
 
--39) LEADER ALGORITHM: 
-    Let us consider a sequence a0, a1, . . . , an−1. The leader of this sequence is the element whose
-    value occurs more than n/2 times.
+        '''
+        When we are at the line pre.next.next = cur 
+        the LL looks like this for [1,2,3,4,5] m = 2, n = 4
+        we want: 1->4->3->2->5
+        we have: 1 -> 2 <- 3 <- 4 5
+ 
+        Note that there is no connection between 4 and 5, 
+        here pre is node 1, reverse is node 4, cur is node 5; 
+        So pre.next.next = cur is basically linking 2 with 5; 
+        pre.next = reverse links node 1 with node 4.
+        '''
+        
+        def reverseBetween(self, head, m, n):
+            if m == n:
+                return head
+            p = dummy = ListNode(0)
+            dummy.next = head
+            for _ in range(m - 1):
+                p = p.next
+            cur = p.next
+            pre = None
+            for _ in range(n - m + 1):
+                cur.next, pre, cur = pre, cur, cur.next
+            p.next.next = cur # 2's next is 5
+            p.next = pre # connect 1 to 4. 
+            return dummy.next
 
-    Notice that if the sequence a0, a1, . . . , an−1 
-    contains a leader, then after removing a pair of
-    elements of different values, the remaining sequence 
-    still has the same leader. Indeed, if we
-    remove two different elements then only one of them 
-    could be the leader. The leader in the
-    new sequence occurs more than (n/2) − 1 = (n−2)/2 times. 
-    Consequently, it is still the leader of the new sequence of n − 2 elements.
+1.56) Linked List Palindrome Question:
+    Solution 1:
+        def isPalindrome(self, head):
+            rev = None
+            slow = fast = head
+            while fast and fast.next:
+                fast = fast.next.next
+                rev, rev.next, slow = slow, rev, slow.next
+            if fast:
+                slow = slow.next
+            while rev and rev.val == slow.val:
+                slow = slow.next
+                rev = rev.next
+            return not rev
+        
+        Expand rev, rev.next, slow = slow, rev, slow.next in C++ for easier understanding.
+
+        ListNode* tmp = rev;
+        rev = slow;
+        slow = slow -> next;
+        rev -> next = tmp;
+
+    Solution 2: Play Nice
+
+    Same as the above, but while comparing the two halves, restore the 
+    list to its original state by reversing the first half back. 
+
+    def isPalindrome(self, head):
+        rev = None
+        fast = head
+        while fast and fast.next:
+            fast = fast.next.next
+            rev, rev.next, head = head, rev, head.next
+        tail = head.next if fast else head
+        isPali = True
+        while rev:
+            isPali = isPali and rev.val == tail.val
+            head, head.next, rev = rev, head, rev.next
+            tail = tail.next
+        return isPali
+
+
+    Solution 3:
+    How to use nonlocals in python3 to make code easier:
+    (check if palindrome exists in singly linked list)
+        def isPalindrome(self, head):
+            """
+            :type head: ListNode
+            :rtype: bool
+            """
+            
+            if(head == None):
+                return True
+            
+            n = head
+            l = 0      
+            while n:
+                n = n.next
+                l += 1
+            
+            lp = head
+            rp = head        
+            rpCounter = (l+1)//2
+            lpCounter = (l//2 -1)
+            left_counter = 0
+            
+            for i in range(rpCounter):
+                rp = rp.next
+                
+            def check_palin(lp): 
+                # We only need these 2 as nonlocals. 
+                # because we modify in the closure. 
+                # Also cant use rp as argument 
+                # to function call. unless you wrap in []. Why?
 
-    1 def goldenLeader(A):
-    2   n = len(A)
-    3   size = 0
-    4   for k in xrange(n):
-    5       if (size == 0):
-    6           size += 1
-    7           value = A[k]
-    8       else:
-    9           if (value != A[k]):
-    10              size -= 1
-    11          else:
-    12              size += 1
-    13  candidate = -1
-    14  if (size > 0):
-    15      candidate = value
-    16  leader = -1
-    17  count = 0
-    18  for k in xrange(n):
-    19      if (A[k] == candidate):
-    20          count += 1
-    21  if (count > n // 2):
-    22      leader = candidate
-    23  return leader
+                nonlocal rp 
+                nonlocal left_counter
 
+                if (left_counter < lpCounter):
+                    left_counter += 1
+                    result = check_palin(lp.next)
+                    if result == False:
+                        return False
+                
+                if(rp == None):
+                    return True
+                
+                if(rp.val == lp.val):
+                    rp = rp.next # check next rp. 
+                    return True # needed when there are only 2 nodes in linked list. 
+                else:
+                    return False
+            return check_palin(lp)
 
-    After removing all pairs of different
-    elements, we end up with a sequence containing all the same values. 
-    This value is not necessarily the leader; it is only a candidate for the leader. 
-    Finally, we should iterate through all
-    the elements and count the occurrences of the candidate; 
-    if it is greater than n/2 then we have
-    found the leader; otherwise the sequence does not contain a leader.
 
+1.57) Python generator for converting binary to value, but 
+    binary is encoded as a linked list:
+    
+    class Solution(object):
+        def yield_content(self, head):
+            current = head
+            yield current.val
+            while current.next != None:
+                current = current.next
+                yield current.val
 
+        def getDecimalValue(self, head):
+            bin_number = ''
+            generator = self.yield_content(head)
+            while True:
+                try:
+                    bin_number += str(next(generator))
+                except StopIteration:
+                    break
+            return int(bin_number, 2)
 
--38) A comparison of Forward and Backward DP illustrated:
+1.58) WHEN GIVEN CONSTRAINTS TO A PROBLEM
+    NEGATE THE CONsTRAINTS TO EXPLOIT PROBLEM STRUCTURE. think combinatorically 
+    about how to use constraints, whether that means to do there exists, or there 
+    doesnt exist such that the constrain is satisfied. especially for greedy questions. 
+    think in positive space and negative space.
 
+1.59) For sliding window, remember that you can do optimized sliding window 
+    by skipping multiple indexes ahead instead of skipping one at a time. 
+    COMPRESS THE STEPS TO FURTHER OPTIMIZE SLIDING WINDOW!
+    OR USE MULTIPLE POINTERS. 
 
-    A game for one player is played on a board consisting of N consecutive squares, 
-    numbered from 0 to N − 1. There is a number written on each square. 
-    A non-empty array A of N integers contains the numbers written on the squares. 
-    Moreover, some squares can be marked during the game.
+1.6)     DFS, BFS + COLORS IS POWERFUL!
+        Another way to check if graph is bipartionable. 
+        ALGORITHM:
+        CAN DO BIPARTITION WITH DFS AND 2 COLORING. 
 
-    At the beginning of the game, there is a pebble on square number 0 and this 
-    is the only square on the board which is marked. The goal of the game is to
-    move the pebble to square number N − 1.
+        For each connected component, we can check whether 
+        it is bipartite by 
+        just trying to coloring it with two colors. How to do this is as follows: 
+        color any node red, then all of it's neighbors blue, 
+        then all of those neighbors 
+        red, and so on. If we ever color a red node blue 
+        (or a blue node red), then we've reached a conflict.
 
-    During each turn we throw a six-sided die, with numbers from 1 to 6 on 
-    its faces, and consider the number K, which shows on the upper face after 
-    the die comes to rest. Then we move the pebble standing on square number 
-    I to square number I + K, providing that square number I + K exists. If 
-    square number I + K does not exist, we throw the die again until we obtain 
-    a valid move. Finally, we mark square number I + K.
 
-    After the game finishes (when the pebble is standing on square number N − 1), 
-    we calculate the result. The result of the game is the sum of the numbers 
-    written on all marked squares.
+1.61) Coin Change Bottom Up DP:
+        You are given coins of different denominations and a total amount of money amount. 
+        Write a function to compute the fewest number of coins that you need to 
+        make up that amount. If that amount of money cannot be made 
+        up by any combination of the coins, return -1.
 
-    For example, given the following array:
+        Example 1:
 
-        A[0] = 1
-        A[1] = -2
-        A[2] = 0
-        A[3] = 9
-        A[4] = -1
-        A[5] = -2
-
-    The marked squares are 0, 3 and 5, so the result of the 
-    game is 1 + 9 + (−2) = 8. This is the maximal possible result 
-    that can be achieved on this board.
-
-    Write a function:
-
-    def solution(A)
-
-    that, given a non-empty array A of N integers, returns the 
-    maximal result that can be achieved on the board represented by array A.
-    
-    SOLUTION:
-    from collections import deque
+        Input: coins = [1, 2, 5], amount = 11
+        Output: 3 
+        Explanation: 11 = 5 + 5 + 1
+        Example 2:
 
-    def backwardDP(A):
-        '''
-        Backward dp.
-            
-        Start with idx 0
-        update with max value, by using 6 behind you!
-            
-        OPT[i] = A[i] + max(OPT[i-1], OPT[i-2],..., OPT[i-5])
-            
-        do we ever double add...
-        nah
-        Just need array of size 6; to space optimize
-        '''
-        # the states represent the last 6 updated states. 
-        states = deque([float("-inf"),
-                        float("-inf"),
-                        float("-inf"),
-                        float("-inf"),
-                        float("-inf"),
-                        0])
-        
-        for i in range(1, len(A)):
-            
-            # We are always guranteed a link to something before us
-            # because we always sum in max states, unlike forward dp, 
-            # where you have to force it to use previous states, by 
-            # setting your own state to something really shitty, so
-            # relaxation forces you to pick up a state
-            maxVal = A[i] + max(states)
-            states.popleft()
-            states.append(maxVal)
-            # latestVal = maxVal
-        
-        # WE HAVE TO ALWAYS INCLUDE A[0] because its marked. 
-        return maxVal + A[0]
-    
-    '''
-    Forward DP 
-    Do 6 RELAXATIONS FORWARD. 
-        
-    OPT[i+1] -> max(OPT[i+1], A[i+1] + OPT[i])?
-    OPT[i+2] -> A[i+2] + A[i]?
-    '''
-    def forwardDP(A):
-        N = len(A)
-        OPT = [float("-inf") for i in range(N)]
-        
-        # YOU ALSO HAVE TO ENSURE THAT THE PIECES THAT ARE FURTHER THAN 
-        # 6 AWAY HAVE ACCESS TO SOMETHING that was used to reach it. 
-        # so FIRST 6 ARE ACCESSIBLE!
-        
-        # In other words, set the first 6 to the value of A[i]
-        OPT[0] = 0
-        
-        for i in range(N):
-            for k in range(1, 7):
-                if i + k < len(A):
-                    OPT[i+k] = max(OPT[i] + A[i+k], OPT[i+k]) 
-        
-        # WE HAVE TO ALWAYS INCLUDE A[0] because its marked. 
-        return OPT[-1] + A[0]
-        
-    def solution(A):
-        # FORWARD DP WORKS 100%
-        # return forwardDP(A)
-        return backwardDP(A)
+        Input: coins = [2], amount = 3
+        Output: -1
+        Note:
+        You may assume that you have an infinite number of each kind of coin.  
         
+        class Solution(object):
+            def coinChange(self, coins, amount):
+                """
+                :type coins: List[int]
+                :type amount: int
+                :rtype: int
+                """
+                rs = [amount+1] * (amount+1)
+                rs[0] = 0
+                for i in xrange(1, amount+1):
+                    for c in coins:
+                        if i >= c:
+                            rs[i] = min(rs[i], rs[i-c] + 1)
 
+                if rs[amount] == amount+1:
+                    return -1
+                return rs[amount]
 
 
+1.7) Sliding window: Common problems you use the sliding window pattern with:
+        -> Maximum sum subarray of size ‘K’ (easy)
+        -> Longest substring with ‘K’ distinct characters (medium)
+        -> String anagrams (hard)
 
--37) MAKING SURE YOUR DFS IS CORRECT! And the DP is being resolved 
-     in the DFS tree properly. 
-
-    For a given array A of N integers and a sequence S of N integers 
-    from the set {−1, 1}, we define val(A, S) as follows:
+1.75) Transpose matrix:
+      Switch (i, j) with (j,i) either by 
+      iterating over upper triangle or lower triangle:
 
-    val(A, S) = |sum{ A[i]*S[i] for i = 0..N−1 }|
+        n = len(A)
+        for i in range(n):
+            for j in range(i):
+                A[i][j], A[j][i] = A[j][i], A[i][j]
 
-    (Assume that the sum of zero elements equals zero.)
-    For a given array A, we are looking for such a sequence S that minimizes val(A,S).
 
-    Write a function:
-    def solution(A)
+1.8) Two Pointers is often useful when searching pairs in a 
+        sorted array or linked list; for example, 
+        when you have to compare each element 
 
-    that, given an array A of N integers, computes the minimum value of val(A,S) 
-    from all possible values of val(A,S) for all 
-    possible sequences S of N integers from the set {−1, 1}.
+        Here are some problems that feature the Two Pointer pattern:
+        of an array to its other elements.
+        Squaring a sorted array (easy)
+        Triplets that sum to zero (medium)
+        Comparing strings that contain backspaces (medium)
 
-    For example, given array:
+1.9) Fast and slow pointer:
+        The Fast and Slow pointer approach, also known as the Hare & Tortoise algorithm, 
+        is a pointer algorithm that uses two pointers which move through the array 
+        (or sequence/linked list) at different speeds. This approach is quite useful 
+        when dealing with cyclic linked lists or arrays.
+        By moving at different speeds (say, in a cyclic linked list), the 
+        algorithm proves that the two pointers are bound to meet. The fast 
+        pointer should catch the slow pointer once both the pointers are in a cyclic loop.
+        
+        Linked List Cycle (easy)
+        Linked List Cycle || (medium)
+        Palindrome Linked List (medium)
+        Cycle in a Circular Array (hard)
 
-    A[0] =  1
-    A[1] =  5
-    A[2] =  2
-    A[3] = -2
-    
-    your function should return 0, since for S = [−1, 1, −1, 1], 
-    val(A, S) = 0, which is the minimum possible value.
 
-    def solution(A):
-        # THIS FAILS DUE TO MAX RECURSION DEPTH REACHED!
-        # BUT IT IS 100% CORRECT
-        @lru_cache(None)
-        def recurseB(i,s):
-            
-            if len(A) == i:
-                return s
-                
-            add = recurseB(i+1, s + A[i])
-            sub = recurseB(i+1, s - A[i])
-            print("CORRECT ADD AND SUB FOR I IS", i, add, sub)
+1.95) Use pointer on the fly construction !!
+      Combining running 2 pointers, running 2 container concepts, and space-efficient
+      dynamic programming concepts to get O(N) speed, O(1) space except for output container.
+      Think in terms of containers to implement fast 2 pointer solution!
+      Then think in terms of DP to reduce to a 1 pointer solution!
+      
 
-            # print("ADD and sub are", add, sub)
-            if abs(add) < abs(sub):
-                return add
-            else:
-                return sub
-        
-        correct_val = abs(recurseB(0, 0))
-        print("CORRECT VALU IS", correct_val)
+        FOR THIS PROBLEM, TRY LAGGING YOUR RUNNING VARIABLES AND INSERTIONS TO MAKE THE ALGO WORK.
         
-        # BELOW WAY IS WRONG!
-        # DO YOU KNOW WHY?
-        # IT GENERATES DIFF ANSWERS FROM ABOVE. 
-        # BECAUSE IN THE RECURSIVE CALLS CLOSE TO THE 
-        # BASE CASE, WE ARENT ABLE TO FINE TUNE THE SOLUTION
-        # TO THE INCOMING SUM, BECAUSE YOU NEVER SEE THE INCOMING
-        # SUM LIKE ABOVE. 
-        # SO INSTEAD, YOU GREEDILY CHOOSE 
-        # IN THE ABOVE RECURSION, HELPER SEES INCOMING SUM, 
-        # AND THEN RETURNS AN OPTIMIZED SUM BASED ON THE INCOMING SUM!
-        # THERE IS COMMUNICATION!
-        def recurseA(i):
-            if len(A) == i:
-                return 0
-                
-            add = A[i] + recurseA(i+1)
-            sub = -A[i] + recurseA(i+1)
-            print("INC ADD AND SUB FOR I IS", i, add, sub)
-            # print("ADD and sub are", add, sub)
-            if abs(add) < abs(sub):
-                return add
-            else:
-                return sub
-
-        incorrect_val = abs(recurseA(0))
-        return correct_val
+        238. Product of Array Except Self
 
--36.5) Reasoning about hard states in DP: MinAbsSum
-       Coming up with bottom up solution with MinAbsSum by rephrasing problem.
-       Question above. 
+        Given an array nums of n integers where n > 1,  
+        return an array output such that output[i] is 
+        equal to the product of all the elements of nums except nums[i].
 
-    Since we can arbitrarily choose to take the element or its negative, we can simplify the
-    problem and replace each number with its absolute value. Then the problem becomes dividing
-    the numbers into two groups and making the difference between the sums of the two groups
-    as small as possible. It is a classic dynamic programming problem.
-    Assume the sum of absolute values of all the numbers is S. We want to choose some of
-    the numbers (absolute values) to make their 
-    sum as large as possible without exceeding S/2.
+        Example:
 
-    Let M be the maximal element in the given array A. We create an array dp of size S.
-    
-    Slow DP:
-    Let dpi equal 1 if it is possible to achieve the 
-    sum of i using elements of A, and 0 otherwise.
-    Initially dpi = 0 for all of i (except dp0 = 1). 
-    For every successive element in A we update the
-    array taking this element into account. We simply go through all the 
-    cells, starting from the
-    top, and if dpi = 1 then we also set dpi+Aj
-    to 1. The direction in which array dp is processed
-    is important, since each element of A can be used only once. 
-    After computing the array dp, P is the largest index such that P <= S/2
-    and dpP = 1.
+        Input:  [1,2,3,4]
+        Output: [24,12,8,6]
+        Note: Please solve it without division and in O(n).
 
-    The time complexity of the above solution is O(N^2· M), since S = O(N · M).
-
-    1 def slow_min_abs_sum(A):
-    2   N = len(A)
-    3   M = 0
-    4   for i in xrange(N):
-    5       A[i] = abs(A[i])
-    6       M = max(A[i], M)
-    7   S = sum(A)
-    8   dp = [0] * (S + 1)
-    9   dp[0] = 1
-    10  for j in xrange(N):
-    11      for i in xrange(S, -1, -1):
-    12          if (dp[i] == 1) and (i + A[j] <= S):
-    13              dp[i + A[j]] = 1
-    14  result = S    
-    15  for i in xrange(S // 2 + 1):
-    16      if dp[i] == 1:
-    17          result = min(result, S - 2 * i)
-    18  return result
+        Follow up:
+        Could you solve it with constant space complexity? 
 
+        class Solution:
+            # @param {integer[]} nums
+            # @return {integer[]}
+            def productExceptSelf(self, nums):
+                p = 1
+                n = len(nums)
+                output = []
+                for i in range(0,n):
+                    output.append(p)
+                    p = p * nums[i]
+                p = 1
+                for i in range(n-1,-1,-1):
+                    output[i] = output[i] * p
+                    p = p * nums[i]
+                return output
 
-    Notice that the range of numbers is quite small (maximum 100). 
-    Hence, there must be a lot of duplicated numbers. 
-    Let count[i] denote the number of occurrences of the value i. 
-    We can process all occurrences of the same value at once. 
-    First we calculate values count[i] Then we create array dp such that:
+2) Back tracking
+    => For permutations, need some intense recursion 
+        (recurse on all kids, get all their arrays, and append our chosen element to everyones array, return) 
+        and trying all posibilities
+    => For combinations, use a binary tree. Make the following choice either: CHOOSE ELEMENT. DONT CHOOSE ELEMENT. 
+        Recurse on both cases to get all subsets
+    => To get all subsets, count from 0 to 2^n, and use bits to choose elements.
+    => When doing DP, check to see if you are dealing with permutations or combinations type solutions, and 
+        adjust your DP CAREFULLY ACCORDING TO THAT -> AKA CHECK COIN CHANGE 2
 
-    dp[j] = −1 if we cannot get the sum j,
-    dp[j] >= ­ 0 if we can get sum j.
-    Initially, dp[j] = -1 for all of j (except dp[0] = 0). Then we scan 
-    through all the values a appearing in A; we consider all a such that 
-    count[a]>0. For every such a we update dp that dp[j] denotes 
-    how many values a remain (maximally) after achieving sum j. 
-    Note that if the previous value at dp[j] >= 0 then we can 
-    set dp[j] = count[a] as no value a is needed to obtain the sum j. 
-    
-    Otherwise we must obtain sum j-a first and then use a 
-    number a to get sum j. In such a situation 
-    dp[j] = dp[j-a]-1. Using this algorithm, we can mark all the 
-    sum values and choose the best one (closest to half of S, the sum of abs of A).
+2.3) Graphs =>
+    Try BFS/DFS/A star search
+    Use dist/parent/visited maps to get values
+    -> Cycle detection -> use visited map. 
+        Actually need to carry parent in param as well in dfs 
+        for undirected graph
+    -> shortest path = BFS
+    -> Do parent stuff with parents map (such as common ancestors).
+    -> Cool graph techniques is coloring nodes, or flagging nodes 
+        if you are trying to get multiple paths in graph and looking for path intersections. 
+    -> To do topological sort, USE DFS and get start end times. also can count in-nodes and out-nodes to sort them !
+    -> Reverse the graph to get the shortest path starting from all other nodes to your node!
+    -> Sometimes in a problem, you cant bfs/dfs once. you need to bfs/dfs every vertex!
+    -> Minimum spanning tree -> use prims algorithm or kruskals algorithm
+    -> Find strongly connected components => use kosarju's algo which does dfs on graph and the reverse of the graph from a vertex.
+    -> Topological SORT: dfs, process nodes children first, then add node to list. then reverse entire list at end
+     -> REMOVING CYCLES, DFS, AND BFS using colors: DONE IN GRAPHA ALGO REVIEW SECTION BELOW. 
 
-    def MinAbsSum(A):
-        N = len(A)
-        M = 0
-        for i in range(N):
-            A[i] = abs(A[i])
-            M = max(A[i], M)
-        S = sum(A)
-        count = [0] * (M + 1)
-        for i in range(N):
-            count[A[i]] += 1
-        dp = [-1] * (S + 1)
-        dp[0] = 0
-        for a in range(1, M + 1):
-            if count[a] > 0:
-                for j in range(S):
-                    if dp[j] >= 0:
-                        dp[j] = count[a]
-                    elif (j >= a and dp[j - a] > 0):
-                        dp[j] = dp[j - a] - 1
-        result = S
-        for i in range(S // 2 + 1):
-            if dp[i] >= 0:
-                result = min(result, S - 2 * i)
-        return result
-    
-    The time complexity of the above solution is O(N · M^2), 
-    where M is the maximal element,
-    since S = O(N · M) and there are at most M different values in A.
 
+2.31) KRUSKALS WITH AND WITHOUT Disjoint set union
+        Creating Minimum Spanning Tree Using Kruskal Algorithm
+        You will first look into the steps involved in Kruskal’s Algorithm to generate a minimum spanning tree:
 
+        Step 1: Sort all edges in increasing order of their edge weights.
+        Step 2: Pick the smallest edge.
+        Step 3: Check if the new edge creates a cycle or loop in a spanning tree.
+        Step 4: If it doesn’t form the cycle, then include that edge in MST. Otherwise, discard it.
+        Step 5: Repeat from step 2 until it includes |V| - 1 edges in MST.
 
+    Kruskal's algorithm initially places all the nodes of the original graph isolated from each other, 
+    to form a forest of single node trees, and then gradually merges these trees, combining at each 
+    iteration any two of all the trees with some edge of the original graph. Before the execution of 
+    the algorithm, all edges are sorted by weight (in non-decreasing order). 
 
--36) DO COMPLEX SET MEMOIZATION ON GRID VS DJIKSTRA.  
+    Then begins the process of unification: pick all edges from the first to 
+    the last (in sorted order), and if the ends of the currently picked edge 
+    belong to different subtrees, these subtrees are combined, 
+    and the edge is added to the answer. After iterating through 
+    all the edges, all the vertices will belong to the same sub-tree, 
+    and we will get the answer.
 
-    You have a grid, and you can go up down, left or right. 
-     Find min cost to go from top left to bottom right: 
-        board = [[42, 51, 22, 10,  0 ],
-                [2,  50, 7,  6,   15],
-                [4,  36, 8,  30,  20],
-                [0,  40, 10, 100, 1 ]]
+    The simplest implementation
+    The following code directly implements the algorithm described above, 
+    and is having O(MlogM+N^2) time complexity. Sorting edges requires O(MlogN) 
+    (which is the same as O(MlogM)) operations. Information regarding the subtree to 
+    which a vertex belongs is maintained with the help of an array tree_id[] - 
+    for each vertex v, tree_id[v] stores the number of the tree , to which v belongs. 
+    For each edge, whether it belongs to the ends of different trees, 
+    can be determined in O(1). Finally, the union of the two trees is carried 
+    out in O(N) by a simple pass through tree_id[] array. Given that the 
+    total number of merge operations is N−1, we obtain 
+    the asymptotic behavior of O(MlogN+N^2).
 
-    # Below uses DP but its not fast enough. 
-    # Need to use Djikstra to pass the TLE test cases
-    def orienteeringGame(board):
-        '''
-        COMPLEX SET MEMOIZATION GRID PROBLEM: 
-        THIS IS A DP PROBLEM
-        SINCE WE CAN GO UP AND LEFT AS WELL AS DOWN AND RIGHT, 
-        IN OUR MEM TABLE, WE HAVE TO SAVE THE SET OF NODES
-        WE TRAVERSED SO FAR. 
-        SO ITS LIKE TRAVELLING SALESMAN PROBLEM DP.
-        RMBR WHEN YOU HAVE TO MEM IT!
-        '''
-        
-        R = len(board)
-        C = len(board[0])
-        
-        visited = set()
-        m = {}
-        
-        # Using a cumulative sum is a way to hash the nodes traversed so far in the 
-        # path which is important for the cache table.
-        @lru_cache(None)
-        def dfs(i, j, cum_sum):
-            if(i == R-1 and j == C-1):
-                return cum_sum # board[R-1][C-1]    
-            
-            visited.add((i,j))
-            
-            val = board[i][j]
-            cost = float("inf")
+    NON DSU IMPL:
+        struct Edge {
+            int u, v, weight;
+            bool operator<(Edge const& other) {
+                return weight < other.weight;
+            }
+        };
 
-            if i + 1 < R and (i+1, j) not in visited:
-                cost = min(cost, dfs(i + 1, j, cum_sum + val))            
-        
-            if j+1 < C and (i, j+1) not in visited:
-                cost = min(cost, dfs(i, j+1, cum_sum + val))  
+        int n;
+        vector<Edge> edges;
 
-            if i - 1 >=0 and (i-1, j) not in visited:
-                cost = min(cost, dfs(i - 1, j, cum_sum + val))      
+        int cost = 0;
+        vector<int> tree_id(n);
+        vector<Edge> result;
+        for (int i = 0; i < n; i++)
+            tree_id[i] = i;
 
-            if j-1 >= 0 and (i, j-1) not in visited:
-                cost = min(cost, dfs(i, j-1, cum_sum + val))     
-                    
-            visited.remove((i,j))    
-            return cost
-        
-        return dfs(0,0, 0) 
+        sort(edges.begin(), edges.end());
 
+        for (Edge e : edges) {
+            if (tree_id[e.u] != tree_id[e.v]) {
+                cost += e.weight;
+                result.push_back(e);
 
+                int old_id = tree_id[e.u], new_id = tree_id[e.v];
+                for (int i = 0; i < n; i++) {
+                    if (tree_id[i] == old_id)
+                        tree_id[i] = new_id;
+                }
+            }
+        }
 
--35) Find duplicate subtrees, Caching trees with UNIQUE IDS
-    Given a binary tree, return all duplicate subtrees. 
-    For each kind of duplicate subtrees, you only need to 
-    return the root node of any one of them.
-    
-    Normal soln -> create merkel hash with strings and postorder/preorder trav O(N^2)
-    This soln -> dont create those long strings. 
-    O(N) time and space. 
+    DSU implementation:
 
-    def findDuplicateSubtrees(self, root):
-        self.type_id_gen = 0
-        duplicated_subtrees = []
-        type_to_freq = defaultdict(int)
-        type_to_id = {}
-        
-        def dfs(node):
-            if not node:
-                return -1
-            type_id_left, type_id_right = (dfs(ch) for ch in (node.left, node.right))
-            tree_type = (node.val, type_id_left, type_id_right)
-            freq = type_to_freq[tree_type]
-            if freq == 0:
-                type_id = self.type_id_gen
-                self.type_id_gen += 1
-                type_to_id[tree_type] = type_id
-            elif freq == 1:
-                type_id = type_to_id[tree_type]
-                duplicated_subtrees.append(node)
-            else:
-                type_id = type_to_id[tree_type] 
-            type_to_freq[tree_type] += 1
-            return type_id
-            
-        dfs(root)
-        return duplicated_subtrees 
-    
-    Stefans version:
+    Just as in the simple version of the Kruskal algorithm, we 
+    sort all the edges of the graph in non-decreasing order of weights. 
+    Then put each vertex in its own tree (i.e. its set) via calls to the make_set 
+    function - it will take a total of O(N). We iterate through all the edges (in sorted order) 
+    and for each edge determine whether the ends belong to different trees (with two find_set 
+    calls in O(1) each). Finally, we need to perform the union of the two trees (sets), for 
+    which the DSU union_sets function will be called - also in O(1). So we get the total 
+    time complexity of O(MlogN+N+M) = O(MlogN).
 
+    Here is an implementation of Kruskal's algorithm with Union by Rank:
 
-    def findDuplicateSubtrees(self, root, heights=[]):
-        def getid(root):
-            if root:
-                # get the id of tree and if there isnt one, assign it with a default value 
-                id = treeid[root.val, getid(root.left), getid(root.right)] 
-                trees[id].append(root) 
-                return id
-
-        trees = collections.defaultdict(list)
-        treeid = collections.defaultdict()
-        treeid.default_factory = treeid.__len__
-        getid(root)
-        return [roots[0] for roots in trees.values() if roots[1:]]
-
-    The idea is the same as Danile's: Identify trees by numbering them. 
-    The first unique subtree gets id 0, the next unique subtree gets 
-    id 1, the next gets 2, etc. Now the dictionary keys aren't deep 
-    nested structures anymore but just ints and triples of ints.
+        vector<int> parent, rank;
 
+        void make_set(int v) {
+            parent[v] = v;
+            rank[v] = 0;
+        }
 
+        int find_set(int v) {
+            if (v == parent[v])
+                return v;
+            return parent[v] = find_set(parent[v]);
+        }
 
--34) How to do transition functions and states for DP: 
-     Think of all the states, and transition functions you need
-     if its hard to precalculate a state, add another state!
-     
-     Also if you cant do backward DP, try Forward DP and relaxing states!
+        void union_sets(int a, int b) {
+            a = find_set(a);
+            b = find_set(b);
+            if (a != b) {
+                if (rank[a] < rank[b])
+                    swap(a, b);
+                parent[b] = a;
+                if (rank[a] == rank[b])
+                    rank[a]++;
+            }
+        }
 
-     METHOD 1: Think in terms of Finite state machines!!
-     METHOD 2: The states may seem wierd BECAUSE YOU NEED TO CONSIDER MORE PREVIOUS LAYERS 
-               of i to come up with the solution, not just the last layer like usual DP.
+        struct Edge {
+            int u, v, weight;
+            bool operator<(Edge const& other) {
+                return weight < other.weight;
+            }
+        };
 
-     1.   House Robber
-     def rob(self, nums: List[int]) -> int:      
-         '''
-         Transition function: 
-         FREE state + ROB action -> FROZEN 
-         Free state + DONT ROB -> Free State
-         FROZEN state + Dont Rob -> Free State.  
-         '''
-         
-         COUNT = len(nums)
-         
-         FROZEN = 0
-         FREE = 0 
-         
-         NXT_FROZEN = 0
-         NXT_FREE = 0
-         
-         for val in nums:
-             NXT_FROZEN = FREE  + val
-             NXT_FREE = max(FREE, FROZEN)
-             
-             FROZEN = NXT_FROZEN
-             FREE = NXT_FREE
-         
-         return max(FREE, FROZEN)
+        int n;
+        vector<Edge> edges;
 
-    The other way you can think of this, is we are dealing 
-    with 3 layers at a time given the following recurrent relation:
-    rob(i) = Math.max( rob(i - 2) + currentHouseValue, rob(i - 1) )
-    States are: i, i-1, i-2
-    
+        int cost = 0;
+        vector<Edge> result;
+        parent.resize(n);
+        rank.resize(n);
+        for (int i = 0; i < n; i++)
+            make_set(i);
 
-    Understanding the number of layers you are dealing with tell you
-    how many states you will need to compute the current state!
+        sort(edges.begin(), edges.end());
 
+        for (Edge e : edges) {
+            if (find_set(e.u) != find_set(e.v)) {
+                cost += e.weight;
+                result.push_back(e);
+                union_sets(e.u, e.v);
+            }
+        }
 
+        Notice: since the MST will contain exactly N−1 edges, 
+        we can stop the for loop once we found that many.
 
 
--33) For some grid problems that require mapping numbers to new numbers while 
-    keeping order with right neighbor, down neighbor, up neighbor and left neighbor 
-    (Abiscus interview).And you have to use as few numbers for the mapping as possible
-    Remember that to maintain multiple orderings in different directions
-    you should be using a GRAPH!! and do BFS to generate those new numbers (and not 
-    try to do grid DP like what i did in that interview). 
+2.312) Prims Impl:
+    minimum spanning tree is built gradually by adding edges one at a time. 
+    At first the spanning tree consists only of a single vertex (chosen arbitrarily). Then the 
+    minimum weight edge outgoing from this vertex is selected and added to the spanning tree. 
+    After that the spanning tree already consists of two vertices. Now select and add the edge 
+    with the minimum weight that has one end in an already selected vertex (i.e. a vertex 
+    that is already part of the spanning tree), and the other end in an 
+    unselected vertex. And so on, i.e. every time we select and add the edge 
+    with minimal weight that connects one selected vertex with one unselected vertex. 
+    The process is repeated until the spanning tree contains all vertices (or equivalently until we have n−1 edges).
 
--32) An example of both forward and backward DP is 
-    -> 931. Minimum Falling Path Sum. Check it out! 
+    In the end the constructed spanning tree will be minimal. If 
+    the graph was originally not connected, then there doesn't 
+    exist a spanning tree, so the number of selected edges will be less than n−1.
 
+    Two impls discussed: O(N^2) and O(mlogn)
 
 
--31) FINITE STATE MACHINES PROCESSING, AND BOTTOM UP DP TECHNIQUE. 
-     1.   Best Time to Buy and Sell Stock with Cool Down
-     Thinking about the problem as a finite state machine can be helpful
-     to figure out:
-        -> STATES 
-        -> HOW THE TRANSITION FUNCTION WORKS. MAKE SURE YOU GET ALL THE TRANSITIONS IN!
-        -> THE RECURENCE FOR THE PROBLEM OR MULTIPLE RECURRENCES FOR EACH STATE. 
+    Dense Graph Implementation: O(N^2)
 
-     You need to figure out how many possible states there are for the DP, 
-     and create a grid for each state. 
-     
-    TO BUY OR SELL STOCK WITH COOLDOWN DP THOUGHT PROCESS O(1) SPACE:
+    We approach this problem for a different side: for every not yet 
+    selected vertex we will store the minimum edge to an already selected vertex.
 
-    Design an algorithm to find the maximum profit. You may
-    complete as many transactions as you like (ie, buy one and 
-    sell one share of the stockmultiple times) 
-    After you sell your stock, you cannot buy stock on next day. (ie, cooldown 1 day)
-    Example:
-    Input: [1,2,3,0,2]
-    Output: 3 
-    Explanation: transactions = [buy, sell, cooldown, buy, sell]
-     
-     In STOCK COOLDOWN problem (LEET 309), 
-     you tried to solve the DP with 2 states -> IS Cooldown/Not Cooldown.
-     
-     There is a solution where you create 3 Grids -> BUY/SELL/REST GRID. 
-     The grid comes from the fact that there are 3 states if you look 
-     at the finite state machine. 
+    Then during a step we only have to look at these 
+    minimum weight edges, which will have a complexity of O(n).
 
-    3 GRID SOLUTION -> O(1) SPACE:
+    After adding an edge some minimum edge pointers have to be recalculated. 
+    Note that the weights only can decrease, i.e. the minimal weight edge of 
+    every not yet selected vertex might stay the same, or it will be 
+    updated by an edge to the newly selected vertex. 
+    Therefore this phase can also be done in O(n).
 
-    def maxProfit(self, prices):
-        free = 0
-        have = cool = float('-inf')
-        for p in prices:
-            free, have, cool = max(free, cool), max(have, free - p), have + p
-        return max(free, cool)
-    
-    '''
-    free is the maximum profit I can have while being free to buy.
-    have is the maximum profit I can have while having stock.
-    cool is the maximum profit I can have while cooling down.
+    Thus we received a version of Prim's algorithm with the complexity O(n^2).
 
-    free = max(free, cool)
-    have = max(have, free - p)  # if we were free last round and just bought, 
-                                # then our profit(in balance) need to 
-                                # adjust because buying cost money
-                        
-    cool = have + p # to be in cool-down, 
-                    # we just sold in last round (realizing profit), 
-                    # then profit would increase by the current price
-        
-    '''
+    In particular this implementation is very convenient for the Euclidean Minimum Spanning 
+    Tree problem: we have n points on a plane and the distance between each pair 
+    of points is the Euclidean distance between them, and we want to find a minimum 
+    spanning tree for this complete graph. This task can be solved by the described 
+    algorithm in O(n^2) time and O(n) memory, which is not possible with Kruskal's algorithm.
 
+    The adjacency matrix adj[][] of size n×n stores the weights of the edges, and it 
+    uses the weight INF if there doesn't exist an edge between two vertices. The 
+    algorithm uses two arrays: the flag selected[], which indicates which vertices 
+    we already have selected, and the array min_e[] which stores the edge with minimal 
+    weight to an selected vertex for each not-yet-selected vertex (it stores the weight and the end vertex). 
+    The algorithm does n steps, in each iteration the vertex with the smallest 
+    edge weight is selected, and the min_e[] of all other vertices gets updated.
 
--30) To create bottom up -> think of recursive solution. The parameters it needs!
-     Start bottom up with these parameter dimensions. Now we have to build 
-     forward from base case. So figure out base case and direction.  
-     
-     When bottom up DP isnt working, you are usually missing a case in your recurrence!
 
-     Then create recurrence/thinking of the grid 
-     Does greater space optimization mean more performance or same performance because
-     its still the same amount of cache hits either way?  
-     
-     -> Greater space optimization may lead to higher performance, if there are fewer steps in 
-        the algorithm. 
-     -> An easy space optimization is using only the previous/next rather than saving all the states 
-        because the recurrence formula may only require the previous versions of all the states. 
+    int n;
+    vector<vector<int>> adj; // adjacency matrix of graph
+    const int INF = 1000000000; // weight INF means there is no edge
 
-    
+    struct Edge {
+        int w = INF, to = -1;
+    };
 
+    void prim() {
+        int total_weight = 0;
+        vector<bool> selected(n, false);
+        vector<Edge> min_e(n);
+        min_e[0].w = 0;
 
--29) 3 POINTER PERFORMANCE OPTIMIZATION FOR O(N^2)
+        for (int i=0; i<n; ++i) {
+            int v = -1;
+            for (int j = 0; j < n; ++j) {
+                if (!selected[j] && (v == -1 || min_e[j].w < min_e[v].w))
+                    v = j;
+            }
 
-     3SUM LEETCODE QUESTION/TRIANGLE NUMBERS LEETCODE 
-    -> You can use 3 pointers, with middle pointer iterating through array, 
-       and other 2 pointers moving left and right to find different numbers
-       to GET AN O(N^2) SOLUTION INSTEAD OF AN O(N^3) SOLUTION.
-                
+            if (min_e[v].w == INF) {
+                cout << "No MST!" << endl;
+                exit(0);
+            }
 
+            selected[v] = true;
+            total_weight += min_e[v].w;
+            if (min_e[v].to != -1)
+                cout << v << " " << min_e[v].to << endl;
 
--28) REVIEW BIDIRECTIONAL BFS PYTHON SOLUTION FOR Open the Lock in important questions. 
+            for (int to = 0; to < n; ++to) {
+                if (adj[v][to] < min_e[to].w)
+                    min_e[to] = {adj[v][to], v};
+            }
+        }
 
--27) 2 Pointers to delimit sequence ranges, and enforce loop invariants: 
-     Use pointers to delimit correct and incorrect regions in sequences, and swap elements/process
-     to correct the incorrect sequence
+        cout << total_weight << endl;
+    }
 
-     MOVE ZEROS:
-     Given an array nums, write a function to move all 0's to the end of it while 
-     maintaining the relative order of the non-zero elements.
-     OPTIMAL:
-     
-     the code will maintain the following invariant:
-     All elements before the slow pointer (lastNonZeroFoundAt) are non-zeroes.
-     All elements between the current and slow pointer are zeroes.
- 
-     Therefore, when we encounter a non-zero element, we need to swap elements 
-     pointed by current and slow pointer, then advance both pointers. 
-     If it's zero element, we just advance current pointer.
- 
-     void moveZeroes(vector<int>& nums) {
-         for (int lastNonZeroFoundAt = 0, cur = 0; cur < nums.size(); cur++) {
-             if (nums[cur] != 0) {
-                 swap(nums[lastNonZeroFoundAt++], nums[cur]);
-             }
-         }
-     }
-                
 
--26) LINKED LIST CHANGE VALUES INSTEAD OF NODE RELATIONSHIPS STRATEGY 
-
-     Delete a linked list node you have access to, but linked list is 
-     singly linked and you dont have access to  parent. 
-     
-     Soln: copy the value of the next node to our node. Then delete the next node. 
+2.313) Prims With PriorityQueue C++:
 
+        // STL implementation of Prim's algorithm for MST
+        #include<bits/stdc++.h>
+        using namespace std;
+        # define INF 0x3f3f3f3f
+        
+        // iPair ==>  Integer Pair
+        typedef pair<int, int> iPair;
+        
+        // This class represents a directed graph using
+        // adjacency list representation
+        class Graph
+        {
+            int V;    // No. of vertices
+        
+            // In a weighted graph, we need to store vertex
+            // and weight pair for every edge
+            list< pair<int, int> > *adj;
+        
+        public:
+            Graph(int V);  // Constructor
+        
+            // function to add an edge to graph
+            void addEdge(int u, int v, int w);
+        
+            // Print MST using Prim's algorithm
+            void primMST();
+        };
+        
+        // Allocates memory for adjacency list
+        Graph::Graph(int V)
+        {
+            this->V = V;
+            adj = new list<iPair> [V];
+        }
+        
+        void Graph::addEdge(int u, int v, int w)
+        {
+            adj[u].push_back(make_pair(v, w));
+            adj[v].push_back(make_pair(u, w));
+        }
+        
+        // Prints shortest paths from src to all other vertices
+        void Graph::primMST()
+        {
+            // Create a priority queue to store vertices that
+            // are being preinMST. This is weird syntax in C++.
+            // Refer below link for details of this syntax
+            // http://geeksquiz.com/implement-min-heap-using-stl/
+            priority_queue< iPair, vector <iPair> , greater<iPair> > pq;
+        
+            int src = 0; // Taking vertex 0 as source
+        
+            // Create a vector for keys and initialize all
+            // keys as infinite (INF)
+            vector<int> key(V, INF);
+        
+            // To store parent array which in turn store MST
+            vector<int> parent(V, -1);
+        
+            // To keep track of vertices included in MST
+            vector<bool> inMST(V, false);
+        
+            // Insert source itself in priority queue and initialize
+            // its key as 0.
+            pq.push(make_pair(0, src));
+            key[src] = 0;
+        
+            /* Looping till priority queue becomes empty */
+            while (!pq.empty())
+            {
+                // The first vertex in pair is the minimum key
+                // vertex, extract it from priority queue.
+                // vertex label is stored in second of pair (it
+                // has to be done this way to keep the vertices
+                // sorted key (key must be first item
+                // in pair)
+                int u = pq.top().second;
+                pq.pop();
+                
+                //Different key values for same vertex may exist in the priority queue.
+                //The one with the least key value is always processed first.
+                //Therefore, ignore the rest.
+                if(inMST[u] == true){
+                    continue;
+                }
+            
+                inMST[u] = true;  // Include vertex in MST
+        
+                // 'i' is used to get all adjacent vertices of a vertex
+                list< pair<int, int> >::iterator i;
+                for (i = adj[u].begin(); i != adj[u].end(); ++i)
+                {
+                    // Get vertex label and weight of current adjacent
+                    // of u.
+                    int v = (*i).first;
+                    int weight = (*i).second;
+        
+                    //  If v is not in MST and weight of (u,v) is smaller
+                    // than current key of v
+                    if (inMST[v] == false && key[v] > weight)
+                    {
+                        // Updating key of v
+                        key[v] = weight;
+                        pq.push(make_pair(key[v], v));
+                        parent[v] = u;
+                    }
+                }
+            }
+        
+            // Print edges of MST using parent array
+            for (int i = 1; i < V; ++i)
+                printf("%d - %d\n", parent[i], i);
+        }
+        
 
--25) Check cycle in directed graph (REMEMBER TO PUSH AND POP OFF THE RUNNING
-     RECURISIVE STACK/VISITED SET TO BE ABLE TO REPROCESS NODES ON DIFFERNT PATHS IN GRAPH):
-     (TREASURY PRIME QUIZ)
+2.314) PRIM VS KRUSKAL
+    If you implement both Kruskal and Prim, in their optimal form : with a union find and a 
+    finbonacci heap respectively, then you will note how Kruskal is easy to implement compared to Prim.
 
-    def isThereCycle(self, node, visited=set()):        
-        visited.add(node)          
-        kids = self.graph.get(node)
-        if kids: 
-            for kid in kids:
-                # print("For parent, examining child", (node, kid))
-                if kid in visited:
-                    return True
-                else:
-                    result = self.isThereCycle(kid, visited)
-                    if result == True:
-                        return True 
-        visited.remove(node)
-        return False
+    Prim is harder with a fibonacci heap mainly because you have to maintain a book-keeping 
+    table to record the bi-directional link between graph nodes and heap nodes. With a Union Find, 
+    it's the opposite, the structure is simple and can even produce directly the mst at almost no additional cost.
 
+    Use Prim's algorithm when you have a graph with lots of edges.
 
+    For a graph with V vertices E edges, Kruskal's algorithm runs in O(E log V) time 
+    and Prim's algorithm can run in O(E + V log V) amortized time, if you use a Fibonacci Heap.
 
--24) Different ways to backtrack:
-    1) Use colors, either 2 with visited set, or 3 when you need to record times in DFS, 
-    2) 3 colors is also similar to pushing and popping off a recursive stack to reprocess elements 
-       you saw. This is used when you want to get all paths from source to target, so you need to
-       reuse nodes/detect all cycles for instance.  
+    Prim's algorithm is significantly faster in the limit when you've got a 
+    really dense graph with many more edges than vertices. Kruskal performs better in 
+    typical situations (sparse graphs) because it uses simpler data structures.
 
-    ALL Paths from source to target:
-    Given a directed, acyclic graph of N nodes.  
-    Find all possible paths from node 0 to node N-1, and return them in any order.
-    
-    # DYNAMIC PROGRAMMING SOLUTION TOP-DOWN!! BY USING @lru_cache(maxsize=None)
-    # THIS SOLUTION IS BAD BECAUSE WE ARE NOT USING DEQUE AND APPENDLEFT, 
-    # LIST MERGING AND INSERTION TO FRONT IS O(N)!!!
-    
-    #The two approach might have the same asymptotic time 
-    #complexity. However, in practice the DP approach is 
-    #slower than the backtracking approach, since we copy the intermediate paths over and over.
+    Kruskal's algorithm will grow a solution from the cheapest edge by 
+    adding the next cheapest edge, provided that it doesn't create a cycle.
 
-    #Note that, the performance would be degraded further, 
-    #if we did not adopt the memoization technique here.
+    Prim's algorithm will grow a solution from a random vertex by adding 
+    the next cheapest vertex, the vertex that is not currently in the 
+    solution but connected to it by the cheapest edge.    
 
-    class Solution:
-        def allPathsSourceTarget(self, graph: List[List[int]]) -> List[List[int]]:
-            
-            # apply the memoization
-            @lru_cache(maxsize=None)
-            def dfs(node):
-                
-                if node == len(graph) - 1:
-                    return [[len(graph) - 1]]
-                
-                kids  = graph[node]
-                
-                # all paths from node to target. 
-                paths = []
-                
-                for kid in graph[node]:
-                    res = dfs(kid)
-                    # add node to front of each result!
-                    for result in res:
-                        paths.append([node] + result)
-                
-                return paths
-            return dfs(0)
+2.32) ORDERED SET/BST IN ACITION: (optimally done with fibonnaci heaps however) 
+    PRIMS ALGORITHM WITH RED BLACK TREES + SET!
+    (usally done with HEAP)
 
-    # BETTER, ALSO USES A DIFF APPROACH OF PUSHING AND POPPING EACH PATH PIECE IN FOR LOOP
-    class Solution:
-        def allPathsSourceTarget(self, graph: List[List[int]]) -> List[List[int]]:
+    n the above described algorithm it is possible to interpret the 
+    operations of finding the minimum and modifying some values as set 
+    operations. These two classical operations are supported by many 
+    data structure, for example by set in C++ (which are implemented via red-black trees).
 
-            target = len(graph) - 1
-            results = []
+    The main algorithm remains the same, but now we can find the minimum 
+    edge in O(logn) time. On the other hand recomputing the pointers 
+    will now take O(nlogn) time, which is worse than in the previous algorithm.
 
-            def backtrack(currNode, path):
-                # if we reach the target, no need to explore further.
-                if currNode == target:
-                    results.append(list(path))
-                    return
-                # explore the neighbor nodes one after another.
-                for nextNode in graph[currNode]:
-                    path.append(nextNode)
-                    backtrack(nextNode, path)
-                    path.pop()
-            # kick of the backtracking, starting from the source node (0).
-            path = deque([0])
-            backtrack(0, path)
+    But when we consider that we only need to update O(m) times in total, 
+    and perform O(n) searches for the minimal edge, then the total 
+    complexity will be O(mlogn). For sparse graphs this is better 
+    than the above algorithm, but for dense graphs this will be slower.
 
-            return results
+    Here the graph is represented via a adjacency list adj[], where adj[v] 
+    contains all edges (in form of weight and target pairs) for the vertex v. 
+    min_e[v] will store the weight of the smallest edge from vertex v to an 
+    already selected vertex (again in the form of a weight and target pair). 
+    In addition the queue q is filled with all not yet selected vertices in 
+    the order of increasing weights min_e. The algorithm does n steps, on each 
+    of which it selects the vertex v with the smallest weight min_e (by extracting 
+    it from the beginning of the queue), and then looks through all the edges 
+    from this vertex and updates the values in min_e (during an update we also 
+    need to also remove the old edge from the queue q and put in the new edge).
 
 
 
--23) Work with differences and gradients instead of RAW VALUES!!
-    It helps to solve the problem. Simplify problems by allocating 
-    everything to one group, then pulling the correct ones to the other group. 
-    Use slopes, intercepts, and think of problems geometrically when 
-    preprocessing AKA two city scheduling
+    const int INF = 1000000000;
 
+    struct Edge {
+        int w = INF, to = -1;
+        bool operator<(Edge const& other) const {
+            return make_pair(w, to) < make_pair(other.w, other.to);
+        }
+    };
 
--22) Flatten binary tree to linked list. 
-     Given a binary tree, flatten it to a linked list in-place.
-     Use right nodes when creating linked list. 
-     CAN DO THIS WITH O(1) SPACE LIKE SO:
-  
-     So what this solution is basically doing is putting the 
-     right subtree next to the rightmost node on the left subtree 
-     and then making the left subtree the right subtree and 
-     then making the left one null. Neat!
-     
-    class Solution:
-        # @param root, a tree node
-        # @return nothing, do it in place
-        def flatten(self, root):
-            if not root:
-                return
-            
-            # using Morris Traversal of BT
-            node=root
-            
-            while node:
-                if node.left:
-                    pre=node.left
-                    while pre.right:
-                        pre=pre.right
-                    pre.right=node.right
-                    node.right=node.left
-                    node.left=None
-                node=node.right
+    int n;
+    vector<vector<Edge>> adj;
 
+    void prim() {
+        int total_weight = 0;
+        vector<Edge> min_e(n);
+        min_e[0].w = 0;
+        set<Edge> q;
+        q.insert({0, 0});
+        vector<bool> selected(n, false);
+        for (int i = 0; i < n; ++i) {
+            if (q.empty()) {
+                cout << "No MST!" << endl;
+                exit(0);
+            }
 
+            int v = q.begin()->to;
+            selected[v] = true;
+            total_weight += q.begin()->w;
+            q.erase(q.begin());
 
+            if (min_e[v].to != -1)
+                cout << v << " " << min_e[v].to << endl;
 
--21) THE DUTCH PARTITIONING ALGORITHM WITH 3 POINTERS. 
-    Using 3 pointers Algorithm  + Abusing LOOP invariants 
-    The trick is to move the MIDDLE POINTER FROM LEFT TO RIGHT AND 
-    use the left and right pointers to delimit the correctly processed sequence!
+            for (Edge e : adj[v]) {
+                if (!selected[e.to] && e.w < min_e[e.to].w) {
+                    q.erase({min_e[e.to].w, e.to});
+                    min_e[e.to] = {e.w, v};
+                    q.insert({e.w, e.to});
+                }
+            }
+        }
 
-    Otherwise, try moving the left pointer right to left or the left pointer, 
-    or try adding another pointer. Add as many pointers until the problem seems simple 
-    and we have untangled all the SEPERATE CONCERNS. 
+        cout << total_weight << endl;
+    }
 
-    Given an array with n objects colored red, white or blue, 
-    sort them in-place so that objects of the same color 
-    are adjacent, with the colors in the order red, white and blue.
+2.33) Storing 2 integer values at same index in an array:
 
-    Here, we will use the integers 0, 1, and 2 to represent the 
-    color red, white, and blue respectively.
+    First we have to find a value greater than 
+    all the elements of the array. Now we can store the 
+    original value as modulus and the second value as division. 
+    Suppose we want to store arr[i] and arr[j] both at index 
+    i(means in arr[i]). First we have to find a ‘maxval’ 
+    greater than both arr[i] and arr[j]. Now we can store 
+    as arr[i] = arr[i] + arr[j]*maxval. Now arr[i]%maxval 
+    will give the original value of arr[i] and arr[i]/maxval 
+    will give the value of arr[j].
 
-    Note: One pass algorithm with constant space only. 
+2.34) Modified Bin Search: Find Minimum in Rotated Sorted Array
+    
+    Suppose an array sorted in ascending order is rotated at some pivot unknown to you beforehand.
+    (i.e.,  [0,1,2,4,5,6,7] might become  [4,5,6,7,0,1,2]).
+    Find the minimum element.
+    You may assume no duplicate exists in the array.
+    
+    This soln is abusing the fact that 
+    left side is bigger than right side,
+    for all rotated cases. 
+    [3,4,5,1,2]
 
-    Example:
-    Input: [2,0,2,1,1,0]
-    Output: [0,0,1,1,2,2]    
-
-
-    def sortColors(self, nums: List[int]) -> None:
-        i = 0
-        l = 0         
-        j = len(nums) - 1
-        
-        while l != len(nums):
-            if nums[l] == 1:
-                l += 1
-            elif nums[l] == 0 and i == l:
-                l += 1
-            elif nums[l] == 0:
-                nums[l], nums[i] = nums[i], nums[l]
-                i += 1 
-            elif nums[l] == 2 and l >= j:
-                l += 1
-            elif nums[l] == 2:
-                nums[l], nums[j] = nums[j], nums[l]
-                j -= 1
-        return nums
-
-
-    INVARIANTS ABUSE FOR SIMPLIFICATION: 
-
-    nums[0:red] = 0, nums[red:white] = 1, nums[white:blue + 1] = unclassified, 
-    nums[blue + 1:] = 2.
-    The code is written so that either 
-    (red < white and nums[red] == 1) or (red == white) at all times.
-    Think about the first time when white separates from red. 
-    That only happens when nums[white] == 1, 
-    so after the white += 1, 
-    we have nums[red] == 1, and notice that nums[red] 
-    will continue to be 1 as long as 
-    red != white. This is because red only gets 
-    incremented in the first case 
-    (nums[white] == 0), so we know that we are swapping nums[red] == 1 with nums[white] == 0.
-
- 
-    def sortColors(self, nums):
-        red, white, blue = 0, 0, len(nums)-1
-        while white <= blue:
-            if nums[white] == 0:
-                nums[red], nums[white] = nums[white], nums[red]
-                white += 1
-                red += 1
-            elif nums[white] == 1:
-                white += 1
+    def findMin(self, nums: List[int]) -> int:
+        left, right = 0, len(nums) - 1
+        while left < right:
+            middle  = (left + right) // 2
+            if nums[middle] < nums[right]:
+                right = middle
             else:
-                nums[white], nums[blue] = nums[blue], nums[white]
-                blue -= 1
-
-
--20) Hill finding part 1: Best time to buy and sell stock I
-    def maxProfit(self, prices: List[int]) -> int:
-        if not prices:
-            return 0
-        min_i = prices[0]
-        max_profit = 0
-        for i,x in enumerate(prices):
-            min_i = min(min_i, x)
-            profit = x - min_i
-            max_profit = max(max_profit, profit)
-        return max_profit
+                left = middle + 1
+        return nums[left]
 
-    CAN ALSO SOLVE WITH KADANES ALGORITHM (Max subarray sum):
-    if the interviewer twists the question slightly by giving the difference 
-    array of prices, Ex: for {1, 7, 4, 11}, 
-    if he gives {0, 6, -3, 7}, you might end up being confused. Do this:
+    My soln didnt use this fact. it instead took the first 
+    element as a reference, and then cut the middle, check left
+    and right element for pivot, and binary searched left or right
+    based on comparing referenced element to middle element. 
+    In other words. I gutta SLOW DOWN, UNDERSTAND PROBLEM,
+    EXPLOIT MORE CONSTRAINTS, LOOK AT PROBLEM STRUCTURE,
+    IDENTIFY CORE TRUTHS FOR ALL CASES!!!
 
-        public int maxProfit(int[] prices) {
-        int maxCur = 0, maxSoFar = 0;
-        for(int i = 1; i < prices.length; i++) {
-            maxCur = Math.max(0, maxCur += prices[i] - prices[i-1]);
-            maxSoFar = Math.max(maxCur, maxSoFar);
-        }
-        return maxSoFar;
-    }
 
+    # MAKE SURE TO DO PART 2, WHERE THERE ARE DUPLICATES IN ARRAY!
 
--19)VISULIZING PROBLEMS, GET GEOMETRIC UNDERSTANDING OF TEST CASES, AND DO NOT 
-    RUSH THE ALGORITHM DESIGN PHASE. TEST YOUR ALGO ON TEST CASES BEFORE WRITING. 
-    ESP IF YOU ARE UNSURE!!
 
-    BEST TIME TO BUY AND SELL STOCK 2
-    ALWAYS TRY TO TEST YOUR ALGORITHM AGAINST TEST CASES!!!! for UNDERSTANDING
-    before coding out!! YOUR ALGORITHM WILL BE INCORRECT SOMETIMES. 
-    ALSO think of invarients that should be true, and dont break invarients you invent. 
+    
+2.35) Wierd~Modified~Customized Memoization / Tree Memoization Pattern:      
+     Path Sum III
+     You are given a binary tree in which 
+     each node contains an integer value.
+     Find the number of paths that sum to a given value.
+     The path does not need to start or end at the root or 
+     a leaf, but it must go downwards 
+     (traveling only from parent nodes to child nodes).
      
-    When you design an algo, make sure you understand 
-    all the details of algo before you code it out. It may look like a hill finder, 
-    but is actually a RIEMAN SUM INTEGRAL algorithm!! 
-    Like with this qustion which you
-    messed up the first time, doing. correct soln under it. 
+    IDEA 1: You need two recursive functions. SEPERATE CONCERNS. 
+          DONT TRY TO DO IT ALL IN ONE RECURSIVE FUNCTION!
+          WATCH FOR WEIRD BASE CASES -> ESP when you get errors
+          When debugging look at base cases -> think about if you
+          need more recursive functions -> because having it all in 
+          one recursive function may lead 4 cases and 2 cases are undesirable
+    
+        class Solution:
+            def verifySum(self, node, val):         
+                if node is None:
+                    return 0
+                count = 0
+                if node.val == val:
+                    count = 1    
+                verifyRight = self.verifySum(node.right, val - node.val)
+                verifyLeft = self.verifySum(node.left, val - node.val)
+                count += (verifyRight + verifyLeft)    
+                return count
+            
+            def pathSum(self, root: TreeNode, sum: int) -> int: 
+                if root is None:
+                    return 0   
+                count = 0
+                count = self.verifySum(root, sum)
+                right = self.pathSum(root.right, sum)
+                left =  self.pathSum(root.left, sum)
+                count += right
+                count += left
+                return count     
+        
+    IDEA 2: Memoization -> When do tree recursion, check for repeat solutions.
+            Here solution is like 2-SUM, and hash map abuse. 
+            The 50% Top 50 % Bottom Memoization Pattern
 
-    Say you have an array prices for which the ith element is the price of a given stock on day i.
-    Design an algorithm to find the maximum profit. You may complete as many transactions as you like
+         why initialize cache = {0:1} why not just empty dictionary?
+            Initializing the cache to {0:1} allows us to consider the path starting 
+            from root. Another way to consider this path 
+            would be to check the value of currPathSum directly:
 
-    class Solution:
-        def maxProfitWRONG(self, prices: List[int]) -> int:
-            '''
-            IF YOU WERE SMART, YOU WOULD realized you have to consider 
-            every peak and valley to create a profit value. And this realization
-            comes from playing around with test cases and writing out problem ideas,
-            and then testing problem ideas. 
-            '''
+        class Solution:
+            def dfs(self,node,isum,target):
+                if node ==None:
+                    return
+                nxtSum = isum + node.val
+                
+                # THIS IS EXACTLY 2 SUM. WE ARE LOOKING FOR THE DIFFERENCE!
+                # BECAUSE WE WANT TO TRY THE SUMS BETWEEN ANY 2 NODES, SO WE 
+                # GUTTA COUNT EM!
+                if nxtSum - target in self.map:
+                    self.count += self.map[nxtSum - target]
+                
+                if nxtSum not in self.map:
+                    self.map[nxtSum] = 1
+                else:    
+                    self.map[nxtSum] += 1
+                
+                self.dfs(node.left,nxtSum,target)
+                self.dfs(node.right,nxtSum,target)
+                
+                # WE NO LONGER HAVE THIS NODE TO CREATE A PATH SEGMENT, SUBTRACT IT OUT. 
+                # BECAUSE WE SWITCHED BRANCHES
+                self.map[nxtSum] -= 1
+    
+            def pathSum(self, root: TreeNode, sum: int) -> int:
+                self.map = {}
+                self.map[0] = 1
+                self.count = 0
+                self.dfs(root,0,sum)
+                return self.count
 
-            i = 0
-            buyPrice = None
-            sellPrice = None            
-            profit = 0
 
-            while i < len(prices):
-                if buyPrice is None:
-                    buyPrice = prices[i]
-                elif prices[i] < buyPrice:
-                    if sellPrice:
-                        profit += (sellPrice - buyPrice)                    
-                    buyPrice = prices[i]
-                    sellPrice = None
+2.36) Learn to use iterators: Serialize and Deserialize bin tree preorder style:
+
+    class Codec:
+        def serialize(self, root):
+            def doit(node):
+                if node:
+                    vals.append(str(node.val))
+                    doit(node.left)
+                    doit(node.right)
                 else:
-                    if not sellPrice:
-                        sellPrice = prices[i]
-                    elif sellPrice < prices[i]:
-                        sellPrice = prices[i]
-                i += 1
-            if buyPrice and sellPrice:
-                profit += (sellPrice - buyPrice)
-            return profit
-        
-        def maxProfit(self, prices: List[int]) -> int:
-                # CORRECT WAY WITH INTEGRAL SUM INSTEAD OF HILL FINDING
-                profit = 0
-                prev = prices[0]
-                for i in range(1, len(prices)):
-                    if prices[i] > prev:
-                        profit += (prices[i] - prev)
-                    prev = prices[i]
-                return profit
+                    vals.append('#')
+            vals = []
+            doit(root)
+            return ' '.join(vals)
 
+        def deserialize(self, data):
+            def doit():
+                val = next(vals)
+                if val == '#':
+                    return None
+                node = TreeNode(int(val))
+                node.left = doit()
+                node.right = doit()
+                return node
+            vals = iter(data.split())
+            return doit()
 
 
--18) Sorting algorithms and true space complexity. 
+2.37) GREEDY HILL FINDING WITH REVERSE POINTERS, 
+     AKA MOST IMPORTANT INDEXES ONLY FINDING AND USING SMARTLY 
+     AKA MONOQUEUE EXTENSION
 
-    Quicksort: For quicksort, your intuition about recursion requiring O(log(n)) space is correct. 
-    Since quicksort calls itself on the order of log(n) times (in the average case, worst 
-    case number of calls is O(n)), at each recursive call a new stack frame of constant 
-    size must be allocated. Hence the O(log(n)) space complexity.
+    Some problems require you to find optimal hills, to get answer. 
+    These hills are valid for certain indexes, and then you have to use new hills
+    They have a sort of max min aura to them, and seem similar to monoqueue type 
+    problems.
+    When you see a max-min type optimization pattern, then you have to find HILLS:
+    
+    For instance:
+    Input a = [21,5,6,56,88,52], output = [5,5,5,4,-1,-1] . 
 
-    Mergesort: Since mergesort also calls itself on the order of log(n) times, 
-    why the O(n) space requirement? The extra space comes from the merge operation. 
-    Most implementations of merge use an auxiliary array with length equal to the 
-    length of the merged result, since in-place merges are very complicated. 
-    In other words, to merge two sorted arrays of length n/2, most merges will 
-    use an auxiliary array of length n. The final step of mergesort 
-    does exactly this merge, hence the O(n) space requirement.
-
-
-    Merge sort on linked lists can be executed using only O(1) extra space if 
-    you take a bottom-up approach by counting where the boundaries of 
-    the partitions are and merging accordingly.
+    Output array values is made up of indices of the 
+    element with value greater than the current element 
+    but with largest index. So 21 < 56 (index 3), 
+    21 < 88 (index 4) but also 21 < 52 (index 5) 
+    so we choose index 5 (value 52). 
+    Same applies for 5,6 and for 56 its 88 (index 4).
+    
+    Algorithm 1: Find the hills, and binsearch the indexes: 
 
+    need to keep track of biggest element on right side. 
+    on the right side, keep the hills!
+    52, is a hill, 
+    then 88, because its bigger than 52,
+    not 56, not 6, not 5, not 21, because you can just use 52, or 88 
+    so elements check against 52 first, then against 88. 
+    
+    import bisect
+    def soln(arr):
+        hills = []
+        hill_locations = []
+        running_max = float("-inf")
+        for i in range(len(arr)-1, -1, -1):
+            if running_max < arr[i]:
+                running_max = arr[i]
+                hills.append(arr[i])
+                hill_locations.append(i)
+        hill_locations_pop_idx = hill_locations[-1]
+        ans = []
 
--17.9)  For the GREEDY CANDY PROBLEM. You are given constraints to respect. 
-        The constraints are hard unless you break them up!
-        ALSO try to understand the problem before you start:
-        review it in most important problems.
+        def bin_search(arr, val):
+            l = 0
+            r = len(arr) 
+            mid = None
+            while l != r:
+                mid = l + (r-l)//2
+                if arr[mid]  == val:
+                    return mid 
+                elif arr[mid] > val:
+                    r = mid 
+                else:
+                    l = mid  + 1
+            return l # what happens if you returned mid here would that still work?
+                     # we check below. 
+                     # but i think it would be incorrect
+                     # because we always want the one index left of mid at the very end. 
         
-        There are N children standing in a line. 
-        Each child is assigned a rating value.
+        for i in range(len(arr)):
+            if i == hill_locations_pop_idx:
+                # you have to invalidate indexes because you dont want to 
+                # invalid indexes to be found in bin search.
+                hill_locations.pop()
+                hills.pop()
+                hill_locations_pop_idx = -1 if len(hill_locations) == 0 else hill_locations[-1]
+            # Locate the insertion point for x in a to maintain sorted order.
+            x = bisect.bisect_left(hills, arr[i], lo=0, hi=len(hills))
+            y = bin_search(hills, arr[i])
+            print("x, y", (x, y)) # will be same
+            if y < len(hill_locations):
+                ans.append(hill_locations[x])
+            else:
+                ans.append(-1)
+        return ans  
 
-        You are giving candies to these children 
-        subjected to the following requirements:
+    Algorithm 2: Insert everything in pq. Pop off 1 by 1, check running max idx. and assign idx.
+    -> i dont get how this method works actually...  
+    // do you pop it off and push it back in or some shit?
+    // pq based on index?
+    if max val is too big its aight kepe it,
+    If its smaller, at a lower idx, throw it away, otherwise keep it?
 
-        Each child must have at least one candy.
-        Children with a higher rating get more candies than their neighbors.
-        What is the minimum candies you must give?
-        Input: [1,0,2] 
-        Output: 2, 1, 2  -> 5
-        Input: [1,2,2]
-        Output: 1, 2, 1 -> 4
 
-        def candy(self, ratings):
-            if not ratings:
-                return 0
 
-            n = len(ratings)
-            candy = [1] * n
-            for i in range(1, n):
-                if ratings[i] > ratings[i - 1]:
-                    candy[i] = candy[i - 1] + 1
-                
-            for i in range(n - 2, -1, -1):
-                if ratings[i] > ratings[i + 1] and candy[i] <= candy[i + 1]:
-                    candy[i] = candy[i + 1] + 1
+2.38) SIMULATE BINARY SEARCH INSERTION POINT FINDER  
+     AKA bisect.bisect_left(arr, val, lo=0, hi=len(arr)) PART 1
+    -> 
+    The returned insertion point i partitions the array a into two halves so that 
+    all(val < x for val in a[lo:i]) for the left side and all(val >= x for val in a[i:hi]) 
+    for the right side.
 
-            return sum(candy)
+    # BTW THIS CODE LOOKS DIFFERENT FROM THE BINARY SEARCH TEMPLATE SECTION BELOW
 
-        You can also solve with constant space by 
-        looking at rising and falling slopes
-        
-        class Solution:
-            def candy(self, ratings):
-                if not ratings:
-                    return 0
+    # Locate the insertion point for x in a to maintain sorted order.
+    # REMEMBER THAT THE FINAL ANSWER IS LOW NOTTTTT MID
 
-                count = up = down = 1
+    # HERE WE INITIALIZED RIGHT AS LEN(NUMS) - 1
+    def searchInsert(self, nums, target):
+        low = 0
+        high = len(nums) - 1
+        while low <= high:
+            mid = (low + high) / 2
+            if nums[mid] == target:
+                return mid
+            elif nums[mid] < target:
+                low = mid + 1
+            else:
+                high = mid - 1
+        return low
+    # THE ABOVE SOLUTION WORKS ONLY IF WE RETURN LOW, NOT MEDIUM OR HIGH
 
-                for i in range(1, len(ratings)):
-                    if ratings[i] >= ratings[i - 1]:
-                        if down > 1:
-                            count -= min(down, up) - 1
-                            up, down = 1, 1
-                        up = ratings[i] == ratings[i - 1] or up + 1
-                        count += up
-                    else:
-                        down += 1
-                        count += down
+    # IN OTHER WORDS, WHAT YOU RETURN LOW/MID/HIGH IS PROBLEM SPECFIC!
 
-                if down > 1:
-                    count -= min(down, up) - 1
+    Wrong Answer
+    Details 
+    Input
+    [1,3,5,6], 2
+    Output: 0
+    Expected: 1
 
-                return count
+2.385) SIMULATE BINARY SEARCH INSERTION POINT FINDER  PART 2
+    # BTW THIS CODE LOOKS DIFFERENT FROM THE BINARY SEARCH TEMPLATE SECTION BELOW
+    Logic Flow of Solving Binary Search Problems
 
--17.8)  BE SMART ABOUT GRAPH ROOT FINDING, AND ITERATING:
-        
-        1.   Longest Consecutive Sequence
-        
-        Given an unsorted array of integers, find the length of the 
-        longest consecutive elements sequence.
-        Your algorithm should run in O(n) complexity.
+        Choose lo & hi
 
+        Always double check what is the maximum range of possible values. For example, 
+        <LeetCode 35>, since it's possible to insert a value at the very end, 
+        the boundary for this problem is actually 0 - n.
 
-        def longestConsecutive(self, nums):
-            nums = set(nums)
-            best = 0
-            for x in nums:
-                if x - 1 not in nums:
-                    y = x + 1
-                    while y in nums:
-                        y += 1
-                    best = max(best, y - x)
-            return best
+        Calculate mid
+        Always use the following, since it avoids overflow.
 
+        // when odd, return the only mid
+        // when even, return the lower mid
+        int mid = lo + ((hi - lo)/2);
 
--17.7) Intersection of 2 linked lists. 
-    Write a program to find the node at which the 
-    intersection of two singly linked lists begins.
-    (Constant space)
+        // when odd, return the only mid
+        // when even, return the upper mid
+        int mid2 = lo + ((hi - lo + 1) / 2);
 
-    Find the different in 2 lists, then traverse longer one 
-    shifted by difference, and other, one node at a time.
-    When nodes are equal that is the intersection node. 
 
-    Other soln:
-        def getIntersectionNode(self, headA, headB):
-            if headA is None or headB is None:
-                return None
+        How to move lo and hi?
+        Always use a condition we are 100% sure of. It's always easier to eliminate 
+        options when we are 100% sure of something. For eample, if we are we are looking 
+        for target <= x, then for target>nums[mid] , we are 100% sure that our mid should 
+        never be considered. Thus we can type lo = mid + 1 with all the confidence.
 
-            pa = headA # 2 pointers
-            pb = headB
+                if (100% sure logic) {
+                    left = mid + 1; // 100% sure target is to the right of mid
+                } else {
+                    right = mid; 
+                }
+                
+                if (100% sure logic) {
+                    right = mid - 1; // 100% sure target is to the left of mid
+                } else {
+                    left = mid;
+                }
+        while Condition
+        Always use while (lo < hi) so when the loop breaks, we are 100% sure that lo == hi
+        If it's possible that target doesn't exist, extra check needs to be performed.
+        🔥Avoid Infinite loop
+        // ❌ The following code results in inifite loop
+        let mid = lo + ((hi - lo)/2); // aka the lower mid
+        // We should use:
+        // let mid = lo + ((hi - lo + 1)/2) // aka the upper mid
+
+        if (100% sure logic) {
+            right = mid - 1
+        } else {
+            left = mid // <-- note here
+        }
 
-            while pa is not pb:
-                # if either pointer hits the end, 
-                # switch head and continue the second traversal, 
-                # if not hit the end, just move on to next
-                pa = headB if pa is None else pa.next
-                pb = headA if pb is None else pb.next
+        Consider when there's only 2 elements left, if the if condition goes to the else statement, 
+        since left = mid, our left boundary will not shrink, 
+        this code will loop for ever. Thus, we should use the upper mid.
 
-            return pa 
-            # only 2 ways to get out of the loop, 
-            # they meet or the both hit the end=None
+        // ❌ The following code results in inifite loop
+        let mid = lo + ((hi - lo + 1)/2); // aka the upper mid
+        // We should use:
+        // let mid = lo + ((hi - lo)/2) // aka the lower mid
 
-    the idea is if you switch head, the possible difference 
-    between length would be countered. On the second traversal, 
-    they either hit or miss. if they meet, pa or pb would 
-    be the node we are looking for, 
-    if they didn't meet, they will hit the end at 
-    the same iteration, pa == pb == None, 
-    return either one of them is the same,None
+        if (100% sure logic) {
+            left = mid + 1;
+        } else {
+            right = mid // <-- note here
+        }
+        
+        Consider when there's only 2 elements left, if the if condition goes to the else statement, 
+        since right = mid our right boundary will not shrink, this code will loop for ever. 
+        Thus, we should use the lower mid.
+
+        Take Away
+        * Always think of the situation where there's only 2 elements left!
+
+    ANSWER 1:
+        var searchInsert = function(nums, target) {
+            let lo = 0, hi = nums.length; // we might need to inseart at the end
+            while(lo < hi) { // breaks if lo == hi
+                let mid = lo + Math.floor((hi-lo)/2); // always gives the lower mid
+                if (target > nums[mid]) {
+                    lo = mid + 1 // no way mid is a valid option
+                } else {
+                    hi = mid // it might be possibe to inseart @ mid
+                }
+            }
+            return lo;
+        };
 
+2.39) SIMULATE BINARY SEARCH INSERTION POINT FINDER  PART 3 (Binary search with post processing)
+    First of all, we assume [left, right] is the possible answer range(inclusive) for this question. 
+    So initially left = 0; and right = n - 1;
 
+    we calculate int mid = left + (right - left)/2; rather than int mid = (left + right)/2; to avoid overflow.
 
+    Clearly, if A[mid] = target; return mid;
 
--17.6) Copy list with random pointer 
-       (associate input structure with output structure)
-       then recover both after trick. 
-    
-    A linked list is given such that each node contains an 
-    additional random pointer which could point to any node in the list or null.
+    if A[mid] < target, then since we can insert target into mid + 1, so the minimum 
+    possible index is mid + 1. That's the reason why we set left = mid + 1;(1)
 
-    Return a deep copy of the list.
+    if A[mid] > target, then notice here(important!) that: we can insert
+    target into mid, so mid can be the potential candidate. For example:
 
-    We need a hash map here to map to random nodes in 
-    our new linked list. This requires O(n) space
+    Then how to determine the while loop condition?
+    left < right, left <= right，left < right - 1 are probally 
+    all the possible writings for a binary search problem.
 
-    We can use constant space (if we do not consider space
-    for output)
-    
-    The idea is to associate the original node with its 
-    copy node in a single linked list. In this way, 
-    we don't need extra space to keep track of the new nodes.
+    Then how to determine the while loop condition?
+    left < right, left <= right，left < right - 1 are probally all the possible writings 
+    for a binary search problem.
 
-    The algorithm is composed of the follow three steps which are also 3 iteration rounds.
+    The answer is that we need to test it out by ourselves with our left/right operation:
 
-    Iterate the original list and duplicate each node. The duplicate
-    of each node follows its original immediately.
-    Iterate the new list and assign the random pointer for each
-    duplicated node.
-    Restore the original list and extract the duplicated nodes.
+    left = mid + 1;
+    right = mid;
+    You may find it very difficult and time consuming to figure it out. 
+    But if you are familiar with this analysis for while loop, 
+    you can give the answer very quickly, piece of cake.
 
-    def copyRandomList(self, head):
+    Let's assume there are 3 elements left at last
 
-        # Insert each node's copy right after it, already copy .label
-        node = head
-        while node:
-            copy = RandomListNode(node.label)
-            copy.next = node.next
-            node.next = copy
-            node = copy.next
+    5 	7 	9
+    l	m   h
+    we can see that left = mid + 1 and right = mid can shrink the size by 2 and 1, 
+    so 3 elements will not result in dead loop.
 
-        # Set each copy's .random
-        node = head
-        while node:
-            node.next.random = node.random and node.random.next
-            node = node.next.next
+    So we reduce it to 2 elements:
 
-        # Separate the copied list from the original, (re)setting every .next
-        node = head
-        copy = head_copy = head and head.next
-        while node:
-            node.next = node = copy.next
-            copy.next = copy = node and node.next
+    5 	  7
+    l/m   h
+    Same way, we can see that left = mid + 1 and right = mid can both shrink the size by 1, no dead loop as well.
 
-        return head_copy
+    So we can safely reduce it to only 1 element:
 
+    5
+    l/m/h
+    we can see that left = mid + 1 will not cause dead loop, but with right = mid 
+    we cannot shrink the size, so we will enter a dead loop if we goes to the case: right = mid.
 
-    @DrFirestream OMG is that a mindfuck :-). But a nice thing is that the original 
-    list's next structure is never changed, so I can write a helper generator to 
-    visit the original list with a nice for loop encapsulating the while loop 
-    and making the loop bodies a little simpler:
+    So we can determine that we need break/jump out of the loop when there is 
+    only 1 element left, i.e. while(left < right)
 
-    '''
-    def copyRandomList(self, head: 'Node') -> 'Node':
-        def nodes():
-            node = head
-            while node:
-                yield node
-                node = node.next
-        # create new nodes
-        for node in nodes():
-            node.random = Node(node.val, node.random, None)
-        # populate random field of the new node
-        for node in nodes():
-            node.random.random = node.random.next and node.random.next.random
-        # restore original list and build new list
-        head_copy = head and head.random
-        for node in nodes():
-            node.random.next, node.random = node.next and node.next.random, node.random.next
-        return head_copy
+    At the end, we need to check the last element: nums[left/right] which has not 
+    been checked in binary search loop with target to determine the index. We call it the post processing part.
 
--17.5) AVOID LINKED LIST LOOPS IN YOUR CODE. ALWAYS 
-       NULLIFY YOUR POINTERS IF YOU ARE REUSING THE 
-       DATASTRUCTURE/ DOING THINGS IN PLACE!!!!!!
-       SUCH AS HERE by saving nxt pointer as tmp
+    ANSWER:
+    class Solution {
+	public int searchInsert(int[] nums, int target) {
+		if(nums == null || nums.length == 0) return 0;
+		
+		int n = nums.length;
+		int left = 0;
+		int right = n - 1;
+		while(left < right){
+			int mid = left + (right - left)/2;
+			
+			if(nums[mid] == target) return mid;
+			else if(nums[mid] > target) right = mid; // right could be the result
+			else left = mid + 1; // mid + 1 could be the result
+		}
+		
+		// 1 element left at the end
+		// post-processing
+		return nums[left] < target ? left + 1: left;
+        }
+    }
 
-       1.   Odd Even Linked List
-       Given a singly linked list, group all odd nodes 
-       together followed    by the even nodes. 
-   
-       You should try to do it in place. The program should run in O(1)    
-       space complexity and O(nodes) time complexity.
+2.40)SIMULATE BINARY SEARCH INSERTION POINT FINDER 
+     AKA bisect.bisect_left(arr, val, lo=0, hi=len(arr))  PART 4
 
-        def oddEvenList(self, head: ListNode) -> ListNode:
-            oddH = ListNode(0)
-            evenH = ListNode(0)
-            
-            odd = oddH
-            even = evenH
-            
-            isOdd = True
-            node = head
-            
-            while node:
-                nxt = node.next
-                node.next = None # STOP THE LOOPS
-                if isOdd:
-                    odd.next = node
-                    odd = odd.next
-                    isOdd = False
-                else:
-                    even.next = node
-                    even = even.next
-                    isOdd = True
-                node = nxt
+    # HERE WE INITIALIZED RIGHT AS LEN(NUMS) KNOW THE DIFFERENCE. 
+    def searchInsert(self, nums: List[int], target: int) -> int:
+        
+        l = 0
+        r = len(nums)
+        mid = None
+        
+        while l != r:            
+            mid = l + (r-l)//2  # calculates lower mid/not upper mid
             
-            odd.next = evenH.next
-            return oddH.next
+            if nums[mid] == target:
+                return mid
+            elif nums[mid] < target:
+                l = mid + 1
+            else:
+                r = mid
 
+        # DO NOT RETURN MID, RETURN L
+        return l
 
 
 
--17.4) IMPLEMENTED QUICK SORT FOR LINKED LISTS:
-            
-    # USE MORE DUMMY NODES TO SEPERATE CONCERNS, AND REDUCE MISTAKES
-    # I HAD A PROBLEM WITH CYCLES BECAUSE I WAS REUSING NODES.
+2.55) MATRIX Problems Tips: (REDO ROTATIONS PROBLEM!)
+      Try reversing. Try transposing. Try circular sorting. 
+      Flipping on x axis or y axis is just reversing. 
 
-    def sortList(self, head: ListNode) -> ListNode:
-        '''
-        random.randint(a, b)¶
-        Return a random integer N such that a <= N <= b. Alias for randrange(a, b+1).
-        '''
-        
-        node = head
-        l = 0
-        while node:
-            l += 1
-            node = node.next
-            
-        def partition(head, start, end, pivot):
-            if start == end:
-                return head
-            if head is None:
-                return None
-            
-            pivotVal = pivot.val
-            before = ListNode(0)
-            after = ListNode(0)
-            afterCopy = after
-            beforeCopy = before
-            
-            temp = head
-            left_len = 0
+      MATRIX ROTATION:
+        HARMAN SOLN:
+
+        def rotate(self, matrix):
+            n = len(matrix)
+            N = len(matrix)
+            indexN = N - 1
             
-            while temp:       
-                # print("processing temp", temp.val)
-                if temp == pivot:
-                    temp = temp.next
-                    continue
+            for d in range(n//2):
+                swaps_to_do_this_layer = len(matrix) - 2*d - 1
+                # Swap everything except the last element. that is 
+                # automatically swapped on the first swap in the loop
+                for i in range( swaps_to_do_this_layer ):              
+                    # CONSIDER D AS THE BOUNDARY (with the help of indexN) AND 
+                    # I AS THE OFFSET TO THE ELEMENTS WITHIN BOUNDARY
+                    # I should only be offsetting one side, either a row, or a column
                     
-                if temp.val < pivotVal: 
-                    left_len += 1
-                    before.next = temp
-                    before = before.next
-                    temp = temp.next
-                else:
-                    after.next = temp
-                    after = after.next
-                    temp = temp.next
-                        
-            before.next = None
-            after.next = None
-            return beforeCopy.next, left_len, afterCopy.next
- 
-        def quicksort(head, start, end):
-            if head is None:
-                return None
-            
-            if end-start <= 1:
-                return head 
-            
-            pivotLoc = random.randint(start, end-1)            
-            pivot = head
-            i = 0
-            while i < pivotLoc:
-                pivot = pivot.next
-                i += 1
-                
-            if pivot is None:
-                return None
-               
-            left, left_len, right = partition(head, start, end, pivot) 
-            sorted_left = quicksort(left, 0, left_len)
-            sorted_right = quicksort(right, 0, end - left_len - 1)
-            
-            if sorted_left:
-                temp = sorted_left
-                while temp and temp.next:
-                    temp = temp.next
-                temp.next = pivot
-            else:
-                sorted_left = pivot
+                    northR, northC = d, i+d
+                    eastR, eastC = i + d, indexN - d
+                    southR, southC = indexN - d, indexN - d - i
+                    westR, westC = indexN - d - i, d
+                    
+                    matrix[northR][northC], matrix[eastR][eastC], matrix[southR][southC], matrix[westR][westC] =\
+                        matrix[westR][westC], matrix[northR][northC], matrix[eastR][eastC], matrix[southR][southC]
+        SMARTER WAY:
+        def rotate(self, matrix):
+            n = len(matrix)
+            for l in xrange(n / 2):
+                r = n - 1 - l
+                for p in xrange(l, r):
+                    q = n - 1 - p
+                    cache = matrix[l][p]
+                    matrix[l][p] = matrix[q][l]
+                    matrix[q][l] = matrix[r][q]
+                    matrix[r][q] = matrix[p][r]
+                    matrix[p][r] = cache     
 
-            pivot.next = sorted_right
-            return sorted_left
-        
-        return quicksort(head, 0, l)
+        REVERSE - TRANSPOSE:
 
+        def rotate(self, matrix):
+            n = len(matrix)
+            matrix.reverse()
+            for i in xrange(n): # top half triangle transpose
+                for j in xrange(i + 1, n): 
+                    matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]
+        
+        # walks over the "top-left quadrant" 
+        # of the matrix and directly rotates each element with the 
+        # three corresponding elements in the other three quadrants. 
+        # Note that I'm moving the four elements in 
+        # parallel and that [~i] is way nicer than [n-1-i].
 
--17.3 Bottom Up Merge Sort for Linked List (O(1) space )
-    class Solution {
-    public:
-        ListNode *sortList(ListNode *head) {
-            if(!head || !(head->next)) return head;
-            //get the linked list's length
-            ListNode* cur = head;
-            int length = 0;
-            while(cur){
-                length++;
-                cur = cur->next;
-            }
-            
-            ListNode dummy(0);
-            dummy.next = head;
-            ListNode *left, *right, *tail;
-            for(int step = 1; step < length; step <<= 1){
-                cur = dummy.next;
-                tail = &dummy;
-                while(cur){
-                    left = cur;
-                    right = split(left, step);
-                    cur = split(right,step);
-                    tail = merge(left, right, tail);
-                }
-            }
-            return dummy.next;
-        }
-    private:
-        ListNode* split(ListNode *head, int n){
-            //if(!head) return NULL;
-            for(int i = 1; head && i < n; i++) head = head->next;
-            
-            if(!head) return NULL;
-            ListNode *second = head->next;
-            head->next = NULL;
-            return second;
-        }
-        ListNode* merge(ListNode* l1, ListNode* l2, ListNode* head){
-            ListNode *cur = head;
-            while(l1 && l2){
-                if(l1->val > l2->val){
-                    cur->next = l2;
-                    cur = l2;
-                    l2 = l2->next;
-                }
-                else{
-                    cur->next = l1;
-                    cur = l1;
-                    l1 = l1->next;
-                }
-            }
-            cur->next = (l1 ? l1 : l2);
-            while(cur->next) cur = cur->next;
-            return cur;
-        }
-    };
+        class Solution:
+            def rotate(self, A):
+                n = len(A)
+                for i in range(n/2):
+                    for j in range(n-n/2):
+                        A[i][j], A[~j][i], A[~i][~j], A[j][~i] = \
+                                A[~j][i], A[~i][~j], A[j][~i], A[i][j]
 
+        # Flip Flip, all by myself - 48 ms
 
+        # Similar again, but I first transpose and then flip 
+        # left-right instead of upside-down, and do it all 
+        # by myself in loops. This one is 100% in-place 
+        # again in the sense of just moving the elements.
 
--17) Storing 2 integer values at same index in an array:
+        class Solution:
+            def rotate(self, A):
+                n = len(A)
+                for i in range(n): # bottom half triangle transpose
+                    for j in range(i):
+                        A[i][j], A[j][i] = A[j][i], A[i][j]
+                for row in A:
+                    for j in range(n/2):
+                        row[j], row[~j] = row[~j], row[j]
 
-    First we have to find a value greater than 
-    all the elements of the array. Now we can store the 
-    original value as modulus and the second value as division. 
-    Suppose we want to store arr[i] and arr[j] both at index 
-    i(means in arr[i]). First we have to find a ‘maxval’ 
-    greater than both arr[i] and arr[j]. Now we can store 
-    as arr[i] = arr[i] + arr[j]*maxval. Now arr[i]%maxval 
-    will give the original value of arr[i] and arr[i]/maxval 
-    will give the value of arr[j].
 
+2.57) To find the root nodes in a directed graph (NOT DAG):
+      Reverse graph and find nodes with 0 children.
+      However, there may not be root nodes!
 
--16) Modified Bin Search: Find Minimum in Rotated Sorted Array
-    
-    Suppose an array sorted in ascending order is rotated at some pivot unknown to you beforehand.
-    (i.e.,  [0,1,2,4,5,6,7] might become  [4,5,6,7,0,1,2]).
-    Find the minimum element.
-    You may assume no duplicate exists in the array.
-    
-    This soln is abusing the fact that 
-    left side is bigger than right side,
-    for all rotated cases. 
-    [3,4,5,1,2]
+2.575) REMEMBER CYCLE DETECING ON DIRECTED GRAPH ALWAYS NEEDS AT LEAST 3 COLORS!!!
+     WHILE ON UNDIRECTED YOU COULD JUST USE A VISTED SET. (OR FOR DIRECTED,
+     JUST REMEMBER TO POP THE PROCESSED ELEMENT FROM THE VISITED PATH, SO THAT A 
+     DIFFERENT DIRECTED PATH CAN VISIT THE PROCESSED ELEMENT)
+     
+2.58) Cycle finding in directed graph and undirected graph is 
+      completely different! Memorize details of each way. 
 
-    def findMin(self, nums: List[int]) -> int:
-        left, right = 0, len(nums) - 1
-        while nums[left] > nums[right]:
-            middle  = (left + right) // 2
-            if nums[middle] < nums[right]:
-                right = middle
-            else:
-                left = middle + 1
-        return nums[left]
+    Directed graph cycle finding: Course Schedule (LC):
+    There are a total of n courses you have to take, 
+    labeled from 0 to n-1.
 
-    My soln didnt use this fact. it instead took the first 
-    element as a reference, and then cut the middle, check left
-    and right element for pivot, and binary searched left or right
-    based on comparing referenced element to middle element. 
-    In other words. I gutta SLOW DOWN, UNDERSTAND PROBLEM,
-    EXPLOIT MORE CONSTRAINTS, LOOK AT PROBLEM STRUCTURE,
-    IDENTIFY CORE TRUTHS FOR ALL CASES!!!
+    Some courses may have prerequisites, for example 
+    to take course 0 you have to first take course 1, 
+    which is expressed as a pair: [0,1]
 
+    Given the total number of courses and a list of prerequisite 
+    pairs, is it possible for you to finish all courses?
     
+    Method 1 COLORED DFS:
+        def canFinishWithColoredDFS(self, numCourses, prerequisites):        
+            g = defaultdict(set)
 
-
-
-
--15) Wierd~Modified~Customized Memoization / Tree Memoization Pattern:      
-     Path Sum III
-     You are given a binary tree in which 
-     each node contains an integer value.
-     Find the number of paths that sum to a given value.
-     The path does not need to start or end at the root or 
-     a leaf, but it must go downwards 
-     (traveling only from parent nodes to child nodes).
-     
-    IDEA 1: You need two recursive functions. SEPERATE CONCERNS. 
-          DONT TRY TO DO IT ALL IN ONE RECURSIVE FUNCTION!
-          WATCH FOR WEIRD BASE CASES -> ESP when you get errors
-          When debugging look at base cases -> think about if you
-          need more recursive functions -> because having it all in 
-          one recursive function may lead 4 cases and 2 cases are undesirable
-    
-        class Solution:
-            def verifySum(self, node, val):         
-                if node is None:
-                    return 0
-                count = 0
-                if node.val == val:
-                    count = 1    
-                verifyRight = self.verifySum(node.right, val - node.val)
-                verifyLeft = self.verifySum(node.left, val - node.val)
-                count += (verifyRight + verifyLeft)    
-                return count
+            for req in prerequisites:
+                g[req[1]].add(req[0])
             
-            def pathSum(self, root: TreeNode, sum: int) -> int: 
-                if root is None:
-                    return 0   
-                count = 0
-                count = self.verifySum(root, sum)
-                right = self.pathSum(root.right, sum)
-                left =  self.pathSum(root.left, sum)
-                count += right
-                count += left
-                return count     
-        
-    IDEA 2: Memoization -> When do tree recursion, check for repeat solutions.
-            Here solution is like 2-SUM, and hash map abuse. 
-            The 50% Top 50 % Bottom Memoization Pattern
+            def has_cycle_directed(node, g, colors):
+                colors[node] = "G" # Grey being processed
+                
+                for c in g[node]:
+                    if colors.get(c) is None and has_cycle_directed(c, g, colors):
+                        return True
+                    elif colors.get(c) == "G":
+                        # We are processing this node but we looped back around somehow
+                        # so cycle
+                        return True
+                    else: 
+                        # The node we are processing has already been processed. 
+                        continue  
+                colors[node] = "B" # Black
+                return False
+            
+            colors = {}  # None -> white, Black -> Done, Grey -> Processing 
+            for i in range(numCourses):
+                # process each forest seperately
+                # print("DFS ON", i)
+                if(colors.get(i) is None and has_cycle_directed(i, g, colors)):
+                    print("COLORS ARE, ", colors)
+                    return False     
+            return True
 
-         why initialize cache = {0:1} why not just empty dictionary?
-            Initializing the cache to {0:1} allows us to consider the path starting 
-            from root. Another way to consider this path 
-            would be to check the value of currPathSum directly:
+    METHOD 2 BFS + TOPOSORT WITH INORDER OUTORDER:
+        def canFinish(self, numCourses, prerequisites):
 
-        class Solution:
-            def dfs(self,node,isum,target):
-                if node ==None:
-                    return
-                nxtSum = isum + node.val
-                
-                # THIS IS EXACTLY 2 SUM. WE ARE LOOKING FOR THE DIFFERENCE!
-                # BECAUSE WE WANT TO TRY THE SUMS BETWEEN ANY 2 NODES, SO WE 
-                # GUTTA COUNT EM!
-                if nxtSum - target in self.map:
-                    self.count += self.map[nxtSum - target]
+            g = defaultdict(set)
+            inorder_count = defaultdict(int)    
+            # Init
+            for c in range(numCourses):
+                inorder_count[c] = 0
                 
-                if nxtSum not in self.map:
-                    self.map[nxtSum] = 1
-                else:    
-                    self.map[nxtSum] += 1
+            for req in prerequisites:
+                g[req[1]].add(req[0])
+                inorder_count[req[0]] += 1
+            
+            print("inorder count")
+            
+            root_nodes = [k for (k,v) in  inorder_count.items() if v == 0]
+            print("root nodes", root_nodes)
+            
+            print("G", g)
+            print("Inorder count", inorder_count)
+            
+            d = deque(root_nodes)
+            visited = set()
+            while d:
+                node = d.popleft()
                 
-                self.dfs(node.left,nxtSum,target)
-                self.dfs(node.right,nxtSum,target)
+                visited.add(node)
                 
-                # WE NO LONGER HAVE THIS NODE TO CREATE A PATH SEGMENT, SUBTRACT IT OUT. 
-                # BECAUSE WE SWITCHED BRANCHES
-                self.map[nxtSum] -= 1
-    
-            def pathSum(self, root: TreeNode, sum: int) -> int:
-                self.map = {}
-                self.map[0] = 1
-                self.count = 0
-                self.dfs(root,0,sum)
-                return self.count
+                children = g[node]
+                for c in children:
+                    inorder_count[c] -= 1
+                    if(inorder_count[c] == 0):
+                        d.append(c)
+                               
+            # If you cant visit all nodes from root nodes, then there is a cycle 
+            # in directed graph.      
+            return len(visited) == numCourses
 
 
--14) Learn to use iterators: Serialize and Deserialize bin tree preorder style:
+2.59) Cycle finding in undirected graph: 
 
-    class Codec:
-        def serialize(self, root):
-            def doit(node):
-                if node:
-                    vals.append(str(node.val))
-                    doit(node.left)
-                    doit(node.right)
-                else:
-                    vals.append('#')
-            vals = []
-            doit(root)
-            return ' '.join(vals)
+        def undirected_has_cycle(G):
+            color = {v: WHITE for v in G}
+            cycle = False
 
-        def deserialize(self, data):
-            def doit():
-                val = next(vals)
-                if val == '#':
-                    return None
-                node = TreeNode(int(val))
-                node.left = doit()
-                node.right = doit()
-                return node
-            vals = iter(data.split())
-            return doit()
+            def visit(u, p):
+                nonlocal cycle
+                if cycle:
+                    return
 
+                color[u] = GREY
+                for v in G[u]:
+                    if color[v] == WHITE:
+                        visit(v, u)
+                    elif v != p and color[v] == GREY:
+                        cycle = True
+                color[u] = BLACK
 
+            for s in G:
+                if color[s] == WHITE:
+                    visit(s, None)
+                    if cycle:
+                        return True
 
+            return cycle
 
--13) GREEDY HILL FINDING WITH REVERSE POINTERS, 
-     AKA MOST IMPORTANT INDEXES ONLY FINDING AND USING SMARTLY 
-     AKA MONOQUEUE EXTENSION
 
-    Some problems require you to find optimal hills, to get answer. 
-    These hills are valid for certain indexes, and then you have to use new hills
-    They have a sort of max min aura to them, and seem similar to monoqueue type 
-    problems.
-    When you see a max-min type optimization pattern, then you have to find HILLS:
-    
-    For instance:
-    Input a = [21,5,6,56,88,52], output = [5,5,5,4,-1,-1] . 
+2.6) LRU Cache learnings and techniques=>
+    Circular Doubly linked lists are better than doubly linked lists if you set up dummy nodes
+    so you dont have to deal with edge cases regarding changing front and back pointers
+    -> With doubly linked lists and maps, You can remove any node in O(1) time as well as append to front and back in O(1) time 
+       which enables alot of efficiency
 
-    Output array values is made up of indices of the 
-    element with value greater than the current element 
-    but with largest index. So 21 < 56 (index 3), 
-    21 < 88 (index 4) but also 21 < 52 (index 5) 
-    so we choose index 5 (value 52). 
-    Same applies for 5,6 and for 56 its 88 (index 4).
-    
-    Algorithm 1: Find the hills, and binsearch the indexes: 
+    -> You can also use just an ordered map for this question to solve it fast!! 
+       (pop items and put them back in to bring them to the front technique to do LRU)
 
-    need to keep track of biggest element on right side. 
-    on the right side, keep the hills!
-    52, is a hill, 
-    then 88, because its bigger than 52,
-    not 56, not 6, not 5, not 21, because you can just use 52, or 88 
-    so elements check against 52 first, then against 88. 
-    
-    import bisect
-    def soln(arr):
-        hills = []
-        hill_locations = []
-        running_max = float("-inf")
-        for i in range(len(arr)-1, -1, -1):
-            if running_max < arr[i]:
-                running_max = arr[i]
-                hills.append(arr[i])
-                hill_locations.append(i)
-        hill_locations_pop_idx = hill_locations[-1]
-        ans = []
-
-        def bin_search(arr, val):
-            l = 0
-            r = len(arr) 
-            mid = None
-            while l != r:
-                mid = l + (r-l)//2
-                if arr[mid]  == val:
-                    return mid 
-                elif arr[mid] > val:
-                    r = mid 
-                else:
-                    l = mid  + 1
-            return l
-        
-        for i in range(len(arr)):
-            if i == hill_locations_pop_idx:
-                # you have to invalidate indexes because you dont want to 
-                # invalid indexes to be found in bin search.
-                hill_locations.pop()
-                hills.pop()
-                hill_locations_pop_idx = -1 if len(hill_locations) == 0 else hill_locations[-1]
-            # Locate the insertion point for x in a to maintain sorted order.
-            x = bisect.bisect_left(hills, arr[i], lo=0, hi=len(hills))
-            y = bin_search(hills, arr[i])
-            print("x, y", (x, y)) # will be same
-            if y < len(hill_locations):
-                ans.append(hill_locations[x])
-            else:
-                ans.append(-1)
-        return ans  
-
-    Algorithm 2: Insert everything in pq. Pop off 1 by 1, check running max idx. and assign idx. 
+        OrderedDict key properties:
 
+            popitem(last=True)¶
+            The popitem() method for ordered dictionaries returns and removes a (key, value) pair. 
+            The pairs are returned in LIFO order if last is true or FIFO order if false.
 
+            move_to_end(key, last=True)
+            Move an existing key to either end of an ordered dictionary. The item is 
+            moved to the right end if last is true (the default) or to the beginning if 
+            last is false. Raises KeyError if the key does not exist:
 
+            >>>
+            >>> d = OrderedDict.fromkeys('abcde')
+            >>> d.move_to_end('b')
+            >>> ''.join(d.keys())
+            'acdeb'
+            >>> d.move_to_end('b', last=False)
+            >>> ''.join(d.keys())
+            'bacde'
 
+    from collections import OrderedDict
+    class LRUCache:
 
-
--12) SIMULATE BINARY SEARCH INSERTION POINT FINDER 
-     AKA bisect.bisect_left(arr, val, lo=0, hi=len(arr)) 
-    # Locate the insertion point for x in a to maintain sorted order.
-    # REMEMBER THAT THE FINAL ANSWER IS LOW NOTTTTT MID
-
-    # HERE WE INITIALIZED RIGHT AS LEN(NUMS) - 1
-    def searchInsert(self, nums, target):
-        low = 0
-        high = len(nums) - 1
-        while low <= high:
-            mid = (low + high) / 2
-            if nums[mid] == target:
-                return mid
-            elif nums[mid] < target:
-                low = mid + 1
-            else:
-                high = mid - 1
-        return low
-
-    # HERE WE INITIALIZED RIGHT AS LEN(NUMS) KNOW THE DIFFERENCE. 
-    def searchInsert(self, nums: List[int], target: int) -> int:
-        
-        l = 0
-        r = len(nums)
-        mid = None
-        
-        while l != r:            
-            mid = l + (r-l)//2
+        def __init__(self, capacity: int):
+            self.max_capacity = capacity
+            self.lru_cache = OrderedDict()
             
-            if nums[mid] == target:
-                return mid
-            elif nums[mid] < target:
-                l = mid + 1
+        def get(self, key: int) -> int:
+            key = str(key)
+            if(key not in self.lru_cache):
+                return -1
+            value = self.lru_cache[key]
+            del self.lru_cache[key]
+            self.lru_cache[key] = value
+            return value
+
+        def put(self, key: int, value: int) -> None:
+            key = str(key)
+            if(key not in self.lru_cache):
+                if(len(self.lru_cache) < self.max_capacity):
+                    self.lru_cache[key] = value
+                else:
+                    # last=False signals you want to delete first instead
+                    # of last entry. 
+                    self.lru_cache.popitem(last=False)
+                    self.lru_cache[key] = value
             else:
-                r = mid
+                del self.lru_cache[key]
+                self.lru_cache[key] = value
 
-        # DO NOT RETURN MID, RETURN L
-        return l
+    # WITH A DOUBLY LINKED CIRCULAR LIST:
+    class LRUCache:
+        def __init__(self, capacity):
+            self.capacity = capacity
+            self.dic = dict()
+            self.head = Node(0, 0)
+            self.tail = Node(0, 0)
+            self.head.next = self.tail
+            self.tail.prev = self.head
 
+        def get(self, key):
+            if key in self.dic:
+                n = self.dic[key]
+                self._remove(n)
+                self._add(n)
+                return n.val
+            return -1
 
+        def set(self, key, value):
+            if key in self.dic:
+                self._remove(self.dic[key])
+            n = Node(key, value)
+            self._add(n)
+            self.dic[key] = n
+            if len(self.dic) > self.capacity:
+                n = self.head.next
+                self._remove(n)
+                del self.dic[n.key]
 
+        def _remove(self, node):
+            p = node.prev
+            n = node.next
+            p.next = n
+            n.prev = p
 
--11) Merkle Hashing and Tree to String Methods:
+        def _add(self, node):
+            p = self.tail.prev
+            p.next = node
+            self.tail.prev = node
+            node.prev = p
+            node.next = self.tail
 
-    Given two non-empty binary trees s and t, check whether tree 
-    t has exactly the same structure and node values with a subtree of s.
-    A subtree of s is a tree consists of a node in s and all of this node's 
-    descendants. The tree s could also be considered as a subtree of itself.
 
-    Normal way runtime is O(|s| * |t|)
-    Runtime O(|s| + |t|) (Merkle hashing):
+2.7) When you DFS/BACKTRACK, one way to reduce space usage, is using grid itself
+     as the visited set, and assigning and reverting it.  
+     Additionally, RETURN ASAP. PRUNE, PRUNE PRUNE. 
+     Do not aggregrate all the results then return.
+     NO UNNECESSARY SEARCHING. Look at Word Search in leet folder. 
 
-    For each node in a tree, we can create node.merkle, 
-    a hash representing it's subtree. This hash is formed by hashing the 
-    concatenation of the merkle of the left child, the node's value, 
-    and the merkle of the right child. Then, two trees are identical if 
-    and only if the merkle hash of their roots are equal (except when 
-    there is a hash collision.) From there, finding the answer is straightforward: 
-    we simply check if any node in s has node.merkle == t.merkle
+    Given a 2D board and a word, find if the word exists in the grid.
 
-    def isSubtree(self, s, t):
-        from hashlib import sha256
-        def hash_(x):
-            S = sha256()
-            S.update(x)
-            return S.hexdigest()
+    Harman Soln:
+    class Solution(object):
+        def exist(self, board, word):
+            R = len(board)
+            C = len(board[0])
+            def dfs(word, idx, row, col, visited):
+                if((row, col) in visited):
+                    return False
+                
+                visited.add((row, col))
+                
+                if(idx == len(word)):
+                    return True
+                
+                if(row + 1 < R and board[row + 1][col] == word[idx] ):
+                    up = dfs(word, idx+1, row+1, col, visited)
+                    # THIS IS PRUNING BELOW. RETURN FAST!
+                    if up: 
+                        return True
+                
+                if(row - 1 >= 0 and board[row-1][col] == word[idx]):
+                    down = dfs(word, idx+1, row-1, col, visited)
+                    if down:
+                        return True
+                
+                if(col + 1 < C and board[row][col+1] == word[idx]):
+                    right = dfs(word, idx+1, row, col+1, visited)
+                    if right: 
+                        return True
+                    
+                if(col - 1 >= 0 and board[row][col-1] == word[idx]):
+                    left = dfs(word, idx+1, row, col-1, visited)
+                    if left: 
+                        return True
+                
+                # By doing this, we can reuse set for all brute forcing,
+                # because it is automatically emptied. 
+                visited.remove((row, col))
+                # Dont aggregrate, return True asap. DO PRUNING, AND NO 
+                # UNNCESSARY SEARCH!
+                # return any([up, down, left, right])
+                return False
             
-        def merkle(node):
-            if not node:
-                return '#'
-            m_left = merkle(node.left)
-            m_right = merkle(node.right)
-            node.merkle = hash_(m_left + str(node.val) + m_right)
-            return node.merkle
+            # Can you memoize failure?
+            # m[idx, row, col] stores whether suffix of word was found at that location. 
+            visited = set()        
             
-        merkle(s)
-        merkle(t)
-        def dfs(node):
-            if not node:
-                return False
-            return (node.merkle == t.merkle or 
-                    dfs(node.left) or dfs(node.right))
-                        
-        return dfs(s)
-    
-    QA below:
-    Soln doesnt check for hash collisions but we use hash resistant function:
-    For practical purposes, we can assume that there will not be a hash collision, 
-    as the probability of a collision will be in the order of |S|^2 / 2^256. 
-    A computer can do a sha256 hash in about 1 microsecond, 
-    but sha256 hashes are technically proportional to their input length, 
-    and you would be hashing hex digest (32 bytes each) as well as the node.val strings.
-
-    For this problem though, collision resistant hash functions like sha256 
-    are not necessary, from performance perspective. You can use some 
-    computationally cheaper hash functions. With an addition of O(|T|) 
-    checking every time hash values match, correctness is also made sure.
+            for i in range(len(board)):
+                for j in range(len(board[0])):              
+                    if(board[i][j] == word[0] and dfs(word, 1, i, j, visited)):
+                        return True
+            
+            return False
 
-    Convert Trees to Strings Method F strings:
-    Basically we convert our tree into string representation, 
-    then just check whether substring exists in target string.
-    
-    >>> f"Hello, {name}. You are {age}."
-    'Hello, Eric. You are 74.'
 
     class Solution:
-        def isSubtree(self, s: TreeNode, t: TreeNode) -> bool:
-            string_s = self.traverse_tree(s)
-            string_t = self.traverse_tree(t)
-            if string_t in string_s:
-                return True
-            return False
-        
+        def exist(self, board: List[List[str]], word: str) -> bool:
+            def CheckLetter(row, col, cur_word):
+            #only the last letter remains
+                if len(cur_word) == 1:
+                    return self.Board[row][col] == cur_word[0]
+                else:
+                #mark the cur pos as explored -- None so that other can move here
+                    self.Board[row][col] = None
+                    if row+1<self.max_row and self.Board[row+1][col] == cur_word[1]:
+                        if CheckLetter(row+1, col, cur_word[1:]):
+                            return True
+                    if row-1>=0 and self.Board[row-1][col] == cur_word[1]:
+                        if CheckLetter(row-1, col, cur_word[1:]):
+                            return True
+                    if col+1<self.max_col and self.Board[row][col+1] == cur_word[1]:
+                        if CheckLetter(row, col+1, cur_word[1:]):
+                            return True
+                    if col-1>=0 and self.Board[row][col-1] == cur_word[1]:
+                        if CheckLetter(row, col-1, cur_word[1:]):
+                            return True
+                    #revert changes made
+                    self.Board[row][col] = cur_word[0]
+                    return False                  
         
-        def traverse_tree(self, s):
-            if s:
-                return f"#{s.val} {self.traverse_tree(s.left)} {self.traverse_tree(s.right)}"
-            return None
-
+            self.Board = board
+            self.max_row = len(board)
+            self.max_col = len(board[0])
+            if len(word)>self.max_row*self.max_col:
+                return False
+            for i in range(self.max_row):
+                for j in range(self.max_col):
+                    if self.Board[i][j] == word[0]:
+                        if CheckLetter(i, j, word):return True
+            return False
 
 
+2.8) ROLLING HASH USAGE: 
+    Consider the string abcd and we have to find the hash values of 
+    substrings of this string having length 3 ,i.e., abc and bcd.
+    
+    For simplicity let us take 5 as the base but in actual scenarios we should mod it 
+    with a large prime number to avoid overflow.For the exponent, or the base, The highest 
+    power of base is calculated as (len-1) where len is length of substring.
 
--10) Learn how to index for binsearch. 
-     Left index, getting mid, and right index is always boundary (so len(arr))
+    H(abc) => a*(5^2) + b*(5^1) + c*(5^0) 
+    = 97*25 + 98*5 + 99*1 = 3014
 
-    # Given an array where elements are sorted in ascending order, 
-    # convert it to a height balanced BST.
+    H(bcd) => b*(5^2) + c*(5^1) + d*(5^0) 
+    = 98*25 + 99*5 + 100*1 = 3045
+    
+    So, we do not need to rehash the string again. Instead, we can subtract 
+    the hash code corresponding to the first character from 
+    the first hash value,multiply the result by the considered 
+    prime number and add the hash code corresponding to the next character to it.
+    
+    H(bcd)=(H(abc)-a*(5^2))*5 + d*(5^0)=(3014-97*25)*5 + 100*1 = 3045
 
-    class Solution:
-        def sortedArrayToBST(self, nums: List[int]) -> TreeNode:            
-            def build_tree(l, r):
-                if(l == r):
-                    return None
-                
-                mid =  l + (r-l)//2
-                root = nums[mid]
-                
-                # you never include right value
-                left = build_tree(l, mid)
-                right = build_tree(mid+1, r)
-                return TreeNode(val=root, left=left, right=right)
-                
-            return build_tree(0, len(nums))
+    In general,the hash H can be defined as:-
 
+    H=( c1a^{k-1} + c2a^{k-2} + c3a^{k-3}. . . . + cka^0 ) % m
+    
+    where a is a constant, c1,c2, ... ck are the input characters 
+    and m is a large prime number, since the probability of 
+    two random strings colliding is about ≈ 1/m.
 
+    Then, the hash value of next substring, Hnxt using rolling hash can be defined as:-
 
--9 Remember that you can do in-order and post-order to help you do
-   tree problems such as validate bst: 
-   (i did it pre-order, by also keep track of the range)
+    Hnxt=( ( H - c1a^k-1 ) * a + ck+1a0 ) % m
 
-    def isValidBST(self, root):
-        res, self.flag = [], True
-        self.helper(root, res)
-        return self.flag
-    
-    def helper(self, root, res):
-        if root:
-            self.helper(root.left, res)
-            if res and root.val <= res[-1]:
-                self.flag = False
-                return
-            res.append(root.val)
-            self.helper(root.right, res)
+    // computes the hash value of the input string s
+    long long compute_hash(string s) {
+        const int p = 31;   // base 
+        const int m = 1e9 + 9; // large prime number
+        long long hash_value = 0;
+        long long p_pow = 1;
+        for (char c : s) {
+            hash_value = (hash_value + (c - 'a' + 1) * p_pow) % m;
+            p_pow = (p_pow * p) % m;  
+        }
+        return hash_value;
+    }
+    // finds the hash value of next substring given nxt as the ending character 
+    // and the previous substring prev 
+    long long rolling_hash(string prev,char nxt)
+    {
+        const int p = 31;
+        const int m = 1e9 + 9;
+        long long H=compute_hash(prev);
+        long long Hnxt=( ( H - pow(prev[0],prev.length()-1) ) * p + (int)nxt ) % m;
+        return Hnxt;
+    }
 
-    
--8) Dynamic programming -> check if they want permutations or combinations.  
-    The DP needs to change so that this invarient is 
-    maintained such as in Coin Change 2,
-    
-    THIS IS A COMBINATIONS DP PROBLEM. 
-    Input: amount = 5, coins = [1, 2, 5]
-    Output: 4
-    Explanation: there are four ways to make up the amount
-    with the denominations. 
-    DONT DO PERMUTATIONS DP. 
-    2 + 2 + 1 IS THE SAME AS 2 + 1 + 2, so forloop over coins first
-    so we dont reuse the same denomiation twice aka:
+    The various applications of Rolling Hash algorithm are:
 
-    class Solution(object):
-        def change(self, amount, coins):
-            dic = {0: 1}
-            for coin in coins:
-                for j in range(amount + 1):
-                    dic[j] = dic.get(j, 0) +  dic.get(j - coin, 0)
-            return dic.get(amount, 0)
-    
-    THIS IS A PERMUATIONS DP PROBLEM, DONT DO COMBINATIONS:
-    Given an integer array with all positive numbers and no duplicates, 
-    find the number of possible combinations that add up to a positive integer target.
+    Rabin-Karp algorithm for pattern matching in a string in O(n) time
+    Calculating the number of different substrings of a string in O(n2logn)
+    Calculating the number of palindromic substrings in a str
 
-    nums = [1, 2, 3]
-    target = 4
 
-    The possible combination ways are:
-    (1, 1, 1, 1), (1, 1, 2), (1, 2, 1), (1, 3), (2, 1, 1), (2, 2), (3, 1)
 
-    def combinationSum4(self, nums: List[int], target: int) -> int:        
-        amounts = [0 for _ in range(target + 1)]
-        amounts[0] = 1 # When you reach amount 0, yield 1, for the coin, base case
-        
-        for amt in range(1, target+1):
-            for coin in nums: 
-                if coin <= amt: 
-                    amounts[amt] += amounts[amt-coin]
-                    
-        return amounts[target]
+    Determine the number of different substrings in a string
+    Problem: Given a string s of length n, consisting only of lowercase English letters, 
+    find the number of different substrings in this string.
 
-    What if negative numbers are allowed in the given array?
-    How does it change the problem?
-    What limitation we need to add to the question to allow negative numbers?
-    We should bound the length because solutions can have infinite length!!!
-    Code to follow up: 
- 
-    def combinationSum4WithLength(self, nums, target, length, memo=collections.defaultdict(int)):
-        if length <= 0: return 0
-        if length == 1: return 1 * (target in nums)
-        if (target, length) not in memo: 
-            for num in nums:
-                memo[target, length] += self.combinationSum4(nums, target - num, length - 1)
-        return memo[target, length]
+    To solve this problem, we iterate over all substring lengths l = 1...n. For every substring length l we construct an array 
+    of hashes of all substrings of length l multiplied by the same power of p. 
+    The number of different elements in the array is equal to the number of distinct substrings of length l in the string. 
+    This number is added to the final answer.
 
+    For convenience, we will use h[i] as the hash of the prefix with i characters, and define h[0] = 0.
 
 
+    int count_unique_substrings(string const& s) {
+        int n = s.size();
 
-    
--7) CONTINUE TO PUSH FACTS AND DETAILS INTO A SOLUTION, ABUSE TO MAKE IT FASTER. 
-    Longest increasing subsequence can be solved with patience sort using NlogN. 
-    logN time to find pile and insert in pile. To come up with this method, 
-    look at your algorithm, realize what facts its using, realize if there 
-    are facts that you know the algorithm is not using but are true, 
-    then use those facts to ENHANCE YOUR SOLUTION, permutate the facts, look
-    for directionality in the facts, force it in with datastructures, and try to 
-    be clean as you do so. 
-    
-    # Lacks bin search below but one after adds it. 
-    The idea is to make piles as you traverse the array. The first pile is the 
-    first number in the array. As you iterate over the array, you check from 
-    the left most pile and if the current number is <= to the pile it can be 
-    placed there (greedy if I fits I sits rule) Otherwise, continue down the pile. 
-    If it can not fit on any pile you create a new one.
+        const int p = 31;
+        const int m = 1e9 + 9;
+        vector<long long> p_pow(n);
+        p_pow[0] = 1;
+        for (int i = 1; i < n; i++)
+            p_pow[i] = (p_pow[i-1] * p) % m;
 
-    class Solution:
-        def lengthOfLIS(self, nums: List[int]) -> int:
-            if not nums:
-                return 0
-            # start with first pile as first num
-            piles = [nums[0]]
-            
-            for num in range(1, len(nums)):
-                # keep track if current number is placed
-                placed= False
-                # traverse the piles being greedy left to right. If it fits it sits
-                for x in range(len(piles)):
-                    if nums[num] <= piles[x]:
-                            piles[x] = nums[num]
-                            placed = True
-                            break
-                # Make home for the number if it didn't find one :(
-                if not placed:
-                    piles.append(nums[num])
-            return len(piles)
-            
-    # SOLUTION WITH BINSEARCH      
-    def lengthOfLIS(self, l: List[int]) -> int:
-        if not l: return 0
-        
-        # Create a placeholder for each pile. In the worst case, 
-        # the number of piles is the number of items in the list.
-        topOfEachPile = [0] * len(l)
-        
-        # From the deck/videos, we should know that  the Patience Algorithm is Greedy. 
-        # This results in the fewest number of piles possible.
-        # The LIS is then the number of piles that exist.
-        # Here we create a variable that describes the number 
-        # of piles that we have initialised from our placeholder above.
-        numberOfPiles = 0
-        
-        # Iterate over each number. For each number, do binary 
-        # search to figure out which of the piles to place the number.
-        for n in l:
-            # These variables set the range of the binary search. 
-            # We only want to do BS on the piles that have been initialised.
-            # We include, at the very right, a new pile. This is useful 
-            # because if the n can't fit into any of the existing 
-            # piles we have to add it into this new pile.
-            beg, end = 0, numberOfPiles
-        
-            # This BS is where we are greedy. If n is the same as l[middle] or less, we go left. 
-            while beg != end:
-                middle = (beg + end) // 2
-                if n > topOfEachPile[middle]:
-                    beg = middle + 1
-                else:
-                    end = middle
-            
-            # Update the top card at this pile.
-            topOfEachPile[beg] = n
-            
-            # If we did end up using a new pile, then beg == numberOfPiles. 
-            if beg == numberOfPiles: numberOfPiles += 1
-        
-        return numberOfPiles
+        vector<long long> h(n + 1, 0);
+        for (int i = 0; i < n; i++)
+            h[i+1] = (h[i] + (s[i] - 'a' + 1) * p_pow[i]) % m;
+
+        int cnt = 0;
+        for (int l = 1; l <= n; l++) {
+            set<long long> hs;
+            for (int i = 0; i <= n - l; i++) {
+                long long cur_h = (h[i + l] + m - h[i]) % m;
+                cur_h = (cur_h * p_pow[n-i-1]) % m;
+                hs.insert(cur_h);
+            }
+            cnt += hs.size();
+        }
+        return cnt;
+    }
 
--6) Review linked list 2, reversing a linked list between integers m and n 
-   and how to use recursive stack and nonlocal variables to
-   access backpointers in singly linked list. 
-   Also how to use dummy pointers to simplify code 
-   at the start.
-   and always check before doing .next to stop null errors. 
-   Iterative soln:
+    Improve no-collision probability
+    Quite often the above mentioned polynomial hash is good enough, and no collisions will happen during tests. 
+    Remember, the probability that collision happens is only 1/m. For m = 10^9 + 9 the prob is 10^-9 which is quite low.
+    But notice, that we only did one comparison. What if we compared a string  with 
+    different strings. The probability that at least one collision happens is now 
+    . And if we want to compare 
+    different strings with each other (e.g. by counting how many unique strings exists), then the probability of at least one collision happening is already . It is pretty much guaranteed that this task will end with a collision and returns the wrong result.
 
-        '''
-        When we are at the line pre.next.next = cur 
-        the LL looks like this for [1,2,3,4,5] m = 2, n = 4
-        we want: 1->4->3->2->5
-        we have: 1 -> 2 <- 3 <- 4 5
- 
-        Note that there is no connection between 4 and 5, 
-        here pre is node 1, reverse is node 4, cur is node 5; 
-        So pre.next.next = cur is basically linking 2 with 5; 
-        pre.next = reverse links node 1 with node 4.
-        '''
-        
-        def reverseBetween(self, head, m, n):
-            if m == n:
-                return head
-            p = dummy = ListNode(0)
-            dummy.next = head
-            for _ in range(m - 1):
-                p = p.next
-            cur = p.next
-            pre = None
-            for _ in range(n - m + 1):
-                cur.next, pre, cur = pre, cur, cur.next
-            p.next.next = cur # 2's next is 5
-            p.next = pre # connect 1 to 4. 
-            return dummy.next
+    There is a really easy trick to get better probabilities. We can just compute two different hashes for each string (by using two different , and/or different , and compare these pairs instead. If  is about 
+    for each of the two hash functions than this is more or less equivalent as having one hash function with 
+    . When comparing 
+    strings with each other, the probability that at least one collision happens is now reduced to 
+    .
 
--5) How to use nonlocals in python3 to make code easier:
-    (check if palindrome exists in singly linked list)
-        def isPalindrome(self, head):
-            """
-            :type head: ListNode
-            :rtype: bool
-            """
-            
-            if(head == None):
-                return True
-            
-            n = head
-            l = 0      
-            while n:
-                n = n.next
-                l += 1
+
+
+
+
+
+    EXAMPLE:
+
+    187. Repeated DNA Sequences
+    Write a function to find all the 10-letter-long sequences 
+    (substrings) that occur more than once in a DNA molecule.
+
+    Example:
+
+    Input: s = "AAAAACCCCCAAAAACCCCCCAAAAAGGGTTT"
+
+    Output: ["AAAAACCCCC", "CCCCCAAAAA"]
+
+    def findRepeatedDnaSequences(self, s):
+        # We can use rolling hash to effeciently 
+        # compute hash values of the pattern
+        # hsh as counter for hash value => string
+        hsh = {}
+        def cal_hsh(string):
+            assert(len(string) == 10)
+            hsh_val = 0
+            for i in range(10):
+                hsh_val += ord(string[i]) * 7**i
+            return hsh_val    
+        def update_hsh(prev_val, drop_idx, add_idx):
+            return (prev_val - ord(s[drop_idx]))//7 + ord(s[add_idx]) * 7 ** 9
+        
+        n = len(s)
+        if n < 10: return []
+        hsh_val = cal_hsh(s[:10])
+        hsh[hsh_val] = s[:10]
+        ret = set()
+        # Notice this is n-9 since we want the last substring of length 10
+        for i in range(1, n-9):
+            hsh_val = update_hsh(hsh_val, i-1, i+9)
+            if hsh_val in hsh:
+                ret.add(s[i:i+10])
+            else:
+                hsh[hsh_val] = s[i:i+10]
+        return list(ret)
+
+3) 0-1 BFS
+    we can use BFS to solve the SSSP (single-source shortest path) 
+    problem in O(|E|), if the weights of each edge is either 0 or 1.
+
+    append new vertices at the beginning if the corresponding edge 
+    has weight 0, i.e. if d[u] = d[v], or at the end if the edge 
+    has weight 1, i.e. if d[u]=d[v]+1. This way the queue still remains sorted at all time.
+
+    vector<int> d(n, INF);
+    d[s] = 0;
+    deque<int> q;
+    q.push_front(s);
+    while (!q.empty()) {
+        int v = q.front();
+        q.pop_front();
+        for (auto edge : adj[v]) {
+            int u = edge.first;
+            int w = edge.second;
+            if (d[v] + w < d[u]) {
+                d[u] = d[v] + w;
+                if (w == 1)
+                    q.push_back(u);
+                else
+                    q.push_front(u);
+            }
+        }
+    }
+
+    Dial's algorithm
+    We can extend this even further if we allow the weights of the edges to be even bigger. 
+    If every edge in the graph has a weight ≤k, than the distances of vertices 
+    in the queue will differ by at most k from the distance of v to the source. 
+    So we can keep k+1 buckets for the vertices in the queue, and
+    whenever the bucket corresponding to the smallest distance gets 
+    empty, we make a cyclic shift to get the bucket with the next higher 
+    distance. This extension is called Dial's algorithm.
+
+
+
+4) To do things inplace, such as inplace quick sort, or even binary search, 
+    it is best to operate on index values in your recursion 
+    instead of slicing and joining arrays.
+    Always operate on the pointers for efficiency purposes.
+
+5) If you need to keep track of a list of values instead of just 1 values 
+    such as a list of maxes, instead of 1 max, 
+    and pair off them off, use an ordered dictionary! 
+    They will keep these values ordered for pairing purposes. 
+    pushing and poping an element in an ordered map brings it to the front. 
+
+6)  If you need to do range searches, you need a range tree. 
+    if you dont have time to get a range tree, or a kd tree 
+    use binary searching as the substitute!
+
+
+7) if the problem is unsorted, try sorting and if you need to keep
+    track of indexes, use reverse index map, to do computations. 
+
+7.5) If the problem is already sorted, try binary search. 
+
+8) Do preprocessing work before you start solving problem to improve efficiency
+
+9) Use Counter in python to create a multiset. 
+
+10) Use dynamic programming for optimal substructure, subsequence questions
+    -> Top down is easier to reason because you just memoize solutions youve seen before. 
+    -> Check for optimal substructure ( A given problems has Optimal Substructure Property 
+                                       if optimal solution of the given problem can be obtained 
+                                       by using optimal solutions of its subproblems.)
+    
+    -> Check of overlapping solutions. Make problems overlap by processing it in a certian way!!! Look at directionality!!! 
+        (DP cant help binary search because no overlapping)
+
+    -> TO DO IT: Define Subproblems. Dynamic programming algorithms usually involve a recurrence involving
+            some quantity OPT(k₁, …, kₙ) over one or more variables (usually, these variables
+            represent the size of the problem along some dimension). Define what this quantity represents
+            and what the parameters mean. This might take the form “OPT(k) is the maximum
+            number of people that can be covered by the first k cell towers” or “OPT(u, v, i) is the
+            length of the shortest path from u to v of length at most i.”
+            • Write a Recurrence. Now that you've defined your subproblems, you will need to write
+            out a recurrence relation that defines OPT(k₁, …, kₙ) in terms of some number of subproblems.
+            Make sure that when you do this you include your base cases.
+
+    -> The other key property is that there
+            should be only a polynomial number of different subproblems. These two properties together allow
+            us to build the optimal solution to the final problem from optimal solutions to subproblems.
+            In the top-down view of dynamic programming, the first property above corresponds to being
+            able to write down a recursive procedure for the problem we want to solve. The second property
+            corresponds to making sure that this recursive procedure makes only a polynomial number of
+            different recursive calls. In particular, one can often notice this second property by examining
+            the arguments to the recursive procedure: e.g., if there are only two integer arguments that range
+            between 1 and n, then there can be at most n^2 different recursive calls.
+            Sometimes you need to do a little work on the problem to get the optimal-subproblem-solution
+            property. For instance, suppose we are trying to find paths between locations in a city, and some
+            intersections have no-left-turn rules (this is particulatly bad in San Francisco). Then, just because
+            the fastest way from A to B goes through intersection C, it doesn’t necessarily use the fastest way
+            to C because you might need to be coming into C in the correct direction. In fact, the right way
+            to model that problem as a graph is not to have one node per intersection, but rather to have one
+            node per <Intersection, direction> pair. That way you recover the property you need.
+
+
+10.5) DP Construction:
+        DP problems typically show up at optimization or counting problems 
+        (or have an optimization/counting component). Look for words like 
+        "number of ways", "minimum", "maximum", "shortest", "longest", etc.
+
+        Start by writing your inputs. Identify which inputs are variable and which are constant.
+
+        Now write your output. You output will be whatever you are optimizing or 
+        counting. Because of this, the output might not match exactly what you
+        are solving for (if counting / optimizing is only a component of the problem).
+
+        Write a recurrence using your output as the function, your inputs
+        as inputs to the function, and recursive calls in the function body. 
+        The recursive calls will represent the "choices" that you can make, 
+        so that means you'll have one recursive call per "choice". (You are usually optimizing 
+        over choices are counting different types of choices). Think of ways to split up 
+        your input space into smaller components. The type of input will dictate how this 
+        might look. Array/string inputs usually peel one or two elements from the front 
+        or back of the array and recurse on the rest of the array. Binary tree inputs 
+        usually peel the root off and recurse on the two subtrees. Matrix inputs 
+        usually peel an element off and recurse in both directions (up or down and right or left).
+
+        Come up with base case(s) for the recurrence. When you make the recursive calls, 
+        you decrease the problem size by a certain amount, x. You will probably need about x base cases.
+
+        Write your code. I recommend top-down for interviews since you 
+        don't have to worry about solving subproblems in the right order. 
+        Your cache will have one dimension per non-constant input.
+
+        After writing code, think about whether bottom-up is possible 
+        (can you come up with an ordering of subproblems where smaller 
+        subproblems are visited before larger subproblems?). If so, you 
+        can decide whether it is possible to reduce space complexity by 
+        discarding old answers to subproblems. If it's possible to reduce 
+        space, mention it in the interview (and explain). You probably won't 
+        have to code it. If you have time, feel free to code it bottom-up.
+
+10.7) Memorize 0-1 Knapsack and strategy
+      and space efficiency strategy:
+    
+    -> LEARN HOW TO USE A PARENTS {} MAP TO REVISIT THE OPTIMIZED DP STATES!
+        -> And return the optimized solution
+    -> Learn how to seperate concerns when creating DP GRIDS. 
+    -> LEARN how to space optimize with PREV/NEXT Rolling optimizer,
+        -> Learn how to also JUST have PREV without Next space optimization
+           by being smart about how you iterate over data
+
+    -> Learn how to do DP with states, like Finite automata DP (stock trading leet with cooldown).
+    -> When doing DP bottom up -> think about what output looks like, then inputs, then recurrence,
+        THEN think about the grid, then think about how the grid should be filled directionality wise,
+        and which for loops to put first before the other for loops (based on how recurrence would work)
+        When thinking of recurrence think of base cases to help, and think of grid filling technique!
+
+    # n is number of items. 
+    # K[i][w] represents the maximum value captured after seeing all items up to i, 
+    # and for every integer weight possibiity up to W    
+    def knapSack(W, wt, val, n): 
+        K = [[0 for x in range(W + 1)] for x in range(n + 1)] 
+        
+        # Build table K[][] in bottom up manner 
+        '''
+        In bottom for loop, we compute how processing the item looks like for every weight integer value
+        before processing the next item. 
+        '''
+        for i in range(n + 1): # i goes thru every item we have seen so far
+            for w in range(W + 1):  # w goes through every weight
+                if i == 0 or w == 0: 
+                    K[i][w] = 0
+                elif wt[i-1] <= w: 
+                    K[i][w] = max(val[i-1] + K[i-1][w-wt[i-1]],  K[i-1][w]) 
+                else: 
+                    K[i][w] = K[i-1][w] 
+    
+        return K[n][W] 
+
+    # SPACE EFFICIENT (make sure you understand bottom 2 sentences as well as possible. 
+    We are reusing the container to contain prev item results for current item results, 
+    and the directionality of doing it backwards is really important for this reusability!)
+    
+    You can reduce the 2d array to a 1d array saving the values for the current iteration. 
+    For this to work, we have to iterate capacity (inner for-loop) in the 
+    opposite direction so we that we don't use the values that 
+    were updated in the same iteration. 
+
+    TO REMEMBER HOW TO DO BOTTOM PROBLEM, FOR DP REMEMBER THAT YOU ARE FILLING 
+    A 2D GRID. HOW SHOULD THE GRID BE FILLED WITH PENCIL AND PAPER? 
+    THATS HOW YOU FIGURE IT OUT 
+    (aka what are the entries in the map if you did topdown?)
+    
+    from collections import namedtuple
+
+    def knapsack(capacity, items):
+        # A DP array for the best-value that could be achieved for each weight.
+        best_value = [0] * (capacity + 1)
+        # The previous item used to achieve the best-value for each weight.
+        previous_item = [None] * (capacity + 1)
+        for item in items:
+            for w in range(capacity, item.weight - 1, -1):
+                value = best_value[w - item.weight] + item.value
+                if value > best_value[w]:
+                    best_value[w] = value
+                    previous_item[w] = item
+
+        # Get selected choices
+        cur_weight = capacity
+        taken = []
+        while cur_weight > 0:
+            taken.append(previous_item[cur_weight])
+            cur_weight -= previous_item[cur_weight].weight
+
+        return best_value[capacity], taken
+
+
+1)  Know how to write BFS with a deque, and DFS explicitely with a list. 
+    Keep tracking of function arguments in tuple for list. 
+
+2)  If you need a priority queue, use heapq. Need it for djikistras. 
+    Djikstras is general BFS for graphs with different sized edges. 
+
+12.5) Know expand around center to find/count palindroms in a string:
+    class Solution(object):
+        def countSubstrings(self, s):
+            # Find all even and odd substrings. 
+            '''
+            THis is also known as the expand around center solution.        
+            '''
+            
+            i = 0
+            count = 0
+            for i in range(len(s)):            
+                left = i
+                right = i
+                
+                # Count odd palins
+                def extend(left, right, s):
+                    count = 0
+                    while True:
+                        if left < 0 or right >= len(s) or s[left] != s[right]:
+                            break   
+                        count += 1
+                        left = left - 1
+                        right = right + 1
+                    return count
+                
+                count += extend(left, right, s)
+                count += extend(left, right+1, s)
+            
+            return count
+        
+
+13) TOPO SORT -> if you dont know which node to start this from, start from any node.
+                    topo sort will still figure out the sorting. keep visited set. 
+                    
+                    result = deque()
+                    def topo_sort(node, visited):
+
+                        visited.add(node)
+                        children = g[node]
+                        
+                        for c in children:
+                            if(c in visited):
+                                continue
+
+                            topo_sort(c, visited)
+                        result.appendleft(node)
+                    
+                    for node in g.keys():
+                        if node not in visited:
+                            topo_sort(node, visited)
+
+
+
+14) Use stacks/queues to take advantage of push/pop structure in problems 
+    such as parentheses problems. Or valid expression problems.
+
+15) When you have a problem and it gives you a Binary search tree, 
+    make sure to exploit that structure and not treat it as a normal
+    binary tree!!!
+
+
+16) Diviide and conquer
+
+17) Greedy algorithms => requires smart way of thinking about things
+
+18) Bit magic -> Entire section done in math notes.
+
+19) Dynamic programming with bitmasking
+
+20) GRIDS THOUGHT PROCESS AND DP:
+    When you do DP bottom up think of GRIDS. How many dimensions are your grid?
+    How would you fill a grid if you were to do it by pencil? Which direction?
+    
+    In terms of direction, determining direction is actually based on how much space optimized your current grid is.
+    If it isnt space optimized at all, and you are taking every input coming your way, I think you can usually just go forward.
+    you only need to go backward if youre doing some space optimization and getting rid of a seemingly not required input variable
+    but that input variable keeps track of previous RESULT, and you need the previous result to compute the current result, 
+    so to reuse the grid, you have to compute backwards so that you dont use the current state as the previous state, aka reusing 
+    variables DP!
+
+    Think about top down case -> HOW DOES THE MAP FILL UP. OK HOW SHOULD the GRID FILL UP
+    Whats the base cases in the GRID? 
+    Whats the recurrence relation?
+    What locations need to be filled in GRID before other spots. 
+
+21) 4. Merge Intervals
+        The Merge Intervals pattern is an efficient technique to deal with 
+        overlapping intervals. In a lot of problems involving intervals, you 
+        either need to find overlapping intervals or merge intervals if they overlap. 
+        The pattern works like this:
+        Given two intervals (‘a’ and ‘b’), there will be six different ways the 
+        two intervals can relate to each other:
+         => a consumes b, b consumes a, b after a, a after b, b after a no overlap, a after b no overlap
+
+        How do you identify when to use the Merge Intervals pattern?
+            If you’re asked to produce a list with only mutually exclusive intervals
+            If you hear the term “overlapping intervals”.
+        Merge interval problem patterns:
+            Intervals Intersection (medium)
+            Maximum CPU Load (hard)
+
+
+22) Cyclic Sort: 
+        This pattern describes an interesting 
+        approach to deal with problems involving arrays containing
+        numbers in a given range. The Cyclic Sort pattern iterates over the array 
+        one number at a time, and if the current number you are iterating is not 
+        at the correct index, you swap it with the number at its correct index. You could 
+        try placing the number in its correct index, but this will produce a complexity 
+        of O(n^2) which is not optimal, hence the Cyclic Sort pattern.
+
+        How do I identify this pattern?
+        They will be problems involving a sorted array with numbers in a given range
+        If the problem asks you to find the: 
+        -> missing/duplicate/smallest number in an sorted/rotated array
+           
+        We one by one consider all cycles. We first consider the cycle that 
+        includes first element. We find correct position of first element, 
+        place it at its correct position, say j. We consider old value of arr[j] 
+        and find its correct position, we keep doing this till all elements of current 
+        cycle are placed at correct position, i.e., we don’t come back to cycle starting point.
+    
+        Problems featuring cyclic sort pattern:
+        Find the Missing Number (easy)
+        Find the Smallest Missing Positive Number (medium)
+
+22.5) CYCLIC SORT EXAMPLE:
+
+    class Solution(object):
+        def rotate(self, nums, k):
+            
+            start = 0
+            val = nums[start]
+            
+            i = start
+            N = len(nums)
+            swaps = 0
+            
+            while True:
+                pivot = i + k
+                pivot %= N
+                
+                temp = nums[pivot]
+                nums[pivot] = val
+                val = temp
+                i = pivot
+                
+                swaps += 1
+                if(swaps == N):
+                    return 
+                if pivot == start:
+                    i = start + 1             
+                    val = nums[start + 1]
+                    start += 1        
+            return nums
+            
+    Another Solution:
+    def solution(A, K):
+        N = len(A)
+        
+        if N == 0:
+            return []
+        
+        i = 0
+        nxtVal = A[0]
+        swaps = 0
+        lastLoc = 0
+
+        while True:
+            A[(i + K) % N], nxtVal = nxtVal, A[(i + K) % N]
+            i = (i + K) % N
+            
+            swaps += 1
+            if swaps == N:
+                break 
+            if i == lastLoc:
+                lastLoc += 1
+                i += 1
+                nxtVal = A[i]
+                # did we do all swaps?
+        return A
+
+
+
+
+22.6) Know in-place reverse linked list (MEMORIZE)
+        # Function to reverse the linked list 
+            def reverse(self): 
+                prev = None
+                current = self.head 
+                while(current is not None): 
+                    next = current.next
+                    current.next = prev 
+                    prev = current 
+                    current = next
+                self.head = prev 
+        
+        Reverse a Sub-list (medium)
+        Reverse every K-element Sub-list (medium)
+
+22.61) Math & HashMap counting:
+    You are given n points in the plane that are all distinct,
+     where points[i] = [xi, yi]. A boomerang is a tuple of points (i, j, k) 
+     such that the distance between i and j equals the distance between 
+     i and k (the order of the tuple matters).
+    Return the number of boomerangs.
+
+ 
+
+    Example 1:
+
+    Input: points = [[0,0],[1,0],[2,0]]
+    Output: 2
+    Explanation: The two boomerangs are [[1,0],[0,0],[2,0]] 
+                 and [[1,0],[2,0],[0,0]].
+
+    Solution
+    for each point, create a hashmap and count all points with same distance. If for a point p, there are k points with distance d, number of boomerangs corresponding to that are k*(k-1). Keep adding these to get the final result.
+
+        res = 0
+        for p in points:
+            cmap = {}
+            for q in points:
+                f = p[0]-q[0]
+                s = p[1]-q[1]
+                cmap[f*f + s*s] = 1 + cmap.get(f*f + s*s, 0)
+            for k in cmap:
+                res += cmap[k] * (cmap[k] -1)
+        return res
+
+
+22.62) Question that doesnt look like DP but is
+    1048. Longest String Chain
+
+    You are given an array of words where each word consists of 
+    lowercase English letters.
+
+    wordA is a predecessor of wordB if and only if we can insert 
+    exactly one letter anywhere in wordA without changing the order 
+    of the other characters to make it equal to wordB.
+
+    For example, "abc" is a predecessor of "abac", while "cba" 
+    is not a predecessor of "bcad".
+
+    A word chain is a sequence of words [word1, word2, ..., wordk]
+    with k >= 1, where word1 is a predecessor of word2, word2 is a 
+    predecessor of word3, and so on. A single word is 
+    trivially a word chain with k == 1.
+
+    Return the length of the longest possible word chain with 
+    words chosen from the given list of words.
+
+    Input: words = ["a","b","ba","bca","bda","bdca"]
+    Output: 4
+    Explanation: One of the longest word chains is ["a","ba","bda","bdca"].
+
+    Soln)
+    Sort the words by word's length. (also can apply bucket sort)
+    For each word, loop on all possible previous word with 1 letter missing.
+    If we have seen this previous word, update the longest chain for the current word.
+    Finally return the longest word chain.
+
+    Succint:
+    def longestStrChain(self, words):
+        dp = {}
+        for w in sorted(words, key=len):
+            dp[w] = max(dp.get(w[:i] + w[i + 1:], 0) + 1 for i in xrange(len(w)))
+        return max(dp.values())
+
+    class Solution:
+        def longestStrChain(self, words: List[str]) -> int:
+            dp = {}
+            result = 1
+
+            for word in sorted(words, key=len):
+                dp[word] = 1
+
+                for i in range(len(word)):
+                    prev = word[:i] + word[i + 1:]
+
+                    if prev in dp:
+                        dp[word] = max(dp[prev] + 1, dp[word])
+                        result = max(result, dp[word])
+
+            return result
+    
+    3 other solns TopDown/bottomup/LIS
+
+    LIS idea:
+    class Solution:
+        def longestStrChain(self, words: List[str]) -> int:
+            def isPredecessor(word1, word2):
+                if len(word1) + 1 != len(word2): return False
+                i = 0
+                for c in word2:
+                    if i == len(word1): return True
+                    if word1[i] == c:
+                        i += 1
+                return i == len(word1)
+            
+            words.sort(key=len)
+            n = len(words)
+            dp = [1] * n
+            ans = 1
+            for i in range(1, n):
+                for j in range(i):
+                    if isPredecessor(words[j], words[i]) and dp[i] < dp[j] + 1:
+                        dp[i] = dp[j] + 1
+                ans = max(ans, dp[i])
+            return ans
+
+
+    TOPDOWN (SEEMS to be fastest)
+
+    Let dp(word) be the length of the longest possible word chain end at word word.
+    To calculate dp(word), we try all predecessors of word
+    word and get the maximum length among them.
+
+    class Solution:
+        def longestStrChain(self, words: List[str]) -> int:
+            wordSet = set(words)
+
+            @lru_cache(None)
+            def dp(word):
+                ans = 1
+                for i in range(len(word)):
+                    predecessor = word[:i] + word[i + 1:]
+                    if predecessor in wordSet:
+                        ans = max(ans, dp(predecessor) + 1)
+                return ans
+
+            return max(dp(w) for w in words)
+
+
+
+22.69) Floyd's Loop detection algorithm:
+    Find cycle in linkedlist through tortoise and hare pointers.
+    If they meet again, there is a loop in the list.
+
+
+    For showing that they eventually must meet, 
+    consider the first step at which the tortoise enters the loop. If the hare is on that node, that 
+    is a meeting and we are done. If the hare is not on that node, note that on each subsequent step the distance the hare is ahead of the 
+    tortoise increases by one, which means that since they are on a loop the d
+    istance that the hare is BEHIND the tortoise decreases by one. 
+    Hence, at some point the distance the hare is behind the tortoise becomes zero and the meet
+
+    More detailed proof (modulus):
+
+    If the preliminary tail is length T and the cycle is length C (so in your picture, T=3, C=6), 
+    we can label the tail nodes (starting at the one farthest from the cycle) 
+    as −T,−(T−1),...,−1 and the cycle nodes 0,1,2,...,C−1 (with the cycle node 
+    numbering oriented in the direction of travel).
+
+    We may use the division algorithm to write T=kC+r where 0≤r<C.
+
+    After T clicks the tortoise is at node 0 and the hare is at node r (since hare has gone 2T 
+    steps, of which the first T were in the tail, leaving T steps in the cycle, and T≡r(modC)).
+
+    Assuming r≠0, after an additional C−r clicks, the tortoise is at node C−r; and the hare is at 
+    node congruent (modC) to r+2(C−r)=2C−r≡C−r(modC). Hence both critters are at node C−r. 
+    [In the r=0 case, you can check that the animals meet at the node 0.]
+
+    The distance from the start at this meeting time is thus T+C−r=(kC+r)+C−r=(k+1)C, a multiple of the cycle length, 
+    as desired. We can further note, this occurrence is at the first multiple of the cycle length that is greater than or equal to the tail length.
+
+
+22.7) Find the start of a loop in a linked list:
+
+       Consider the following linked list, where E is the cylce entry and X, the crossing point of fast and slow.
+        H: distance from head to cycle entry E
+        D: distance from E to X
+        L: cycle length
+                          _____
+                         /     \
+        head_____H______E       \
+                        \       /
+                         X_____/   
+        
+    
+        If fast and slow both start at head, when fast catches slow, slow has traveled H+D and fast 2(H+D). 
+        Assume fast has traveled n loops in the cycle, we have:
+        2H + 2D = H + D + L  -->  H + D = nL  --> H = nL - D
+        Thus if two pointers start from head and X, respectively, one first reaches E, the other also reaches E. 
+        In my solution, since fast starts at head.next, we need to move slow one step forward in the beginning of part 2
+
+        Algorithm
+        Use two references slow, fast, initialized to the head
+        Increment slow and fast until they meet
+        fast is incremented twice as fast as slow
+        If fast.next is None, we do not have a circular list
+        When slow and fast meet, move slow to the head
+        Increment slow and fast one node at a time until they meet
+        Where they meet is the start of the loop
+
+        class MyLinkedList(LinkedList):
+
+            def find_loop_start(self):
+                if self.head is None or self.head.next is None:
+                    return None
+                slow = self.head
+                fast = self.head
+                while fast.next is not None:
+                    slow = slow.next
+                    fast = fast.next.next
+                    if fast is None:
+                        return None
+                    if slow == fast:
+                        break
+                slow = self.head
+                while slow != fast:
+                    slow = slow.next
+                    fast = fast.next
+                    if fast is None:
+                        return None
+                return slow
+
+22.8) Find kth to last element of linked list
+        Algorithm
+        Setup two pointers, fast and slow
+        Give fast a headstart, incrementing it once if k = 1, twice if k = 2, ...
+        Increment both pointers until fast reaches the end
+        Return the value of slow
+
+
+1)  TREE DFS:
+    Decide whether to process the current node now (pre-order), 
+    or between processing two children (in-order) 
+    or after processing both children (post-order).
+    Make two recursive calls for both the children 
+    of the current node to process them.
+    -> You can also just use Tree DFS to process in bfs order
+
+23.5) 2 STACKS == QUEUE TECHNIQUE!
+      push onto one, if you pop and empty, 
+      dump first one into second one!
+
+24) TWO HEAPS TECHNIQUE!!!
+
+        In many problems, we are given a set of elements such that we can divide them
+        into two parts. To solve the problem, we are interested in knowing 
+        the smallest element in one part and the biggest element in the other 
+        part. This pattern is an efficient approach to solve such problems.
+
+        This pattern uses two heaps; A Min Heap to find the smallest element 
+        and a Max Heap to find the biggest element. The pattern works by 
+        storing the first half of numbers in a Max Heap, this is because 
+        you want to find the largest number in the first half. You then 
+        store the second half of numbers in a Min Heap, as you want to 
+        find the smallest number in the second half. At any time, the 
+        median of the current list of numbers can be calculated from 
+        the top element of the two heaps.
+
+        Ways to identify the Two Heaps pattern:
+        Useful in situations like Priority Queue, Scheduling
+        If the problem states that you need to find the 
+        -> smallest/largest/median elements of a set
+        Sometimes, useful in problems featuring a binary tree data structure
+        Problems featuring
+        -> Find the Median of a Number Stream (medium)
+
+
+25) BFS CREATION OF SUBSETS! (instead of dfs choose/dont choose strat. 
+    Can this strat also be used to do TOP DOWN DP with BFS ?)
+
+    A huge number of coding interview problems involve 
+    dealing with Permutations and Combinations of a 
+    given set of elements. The pattern Subsets describes 
+    an efficient Breadth First Search (BFS) approach to 
+    handle all these problems.
+
+    The pattern looks like this:
+    Given a set of [1, 5, 3]
+    Start with an empty set: [[]]
+    Add the first number (1) to all the existing subsets to create new subsets: [[], [1]];
+    Add the second number (5) to all the existing subsets: [[], [1], [5], [1,5]];
+    Add the third number (3) to all the existing subsets: [[], [1], [5], [1,5], [3], [1,3], [5,3], [1,5,3]].
+
+    Problems featuring Subsets pattern:
+    Subsets With Duplicates (easy)
+    String Permutations by changing case (medium)
+
+25.3) Given an array of numbers and an array of integer pairs, [i,j], increment the array of numbers by one for each index between interval [i,j]
+        e.g.
+        a = [1,2,3,4]
+        intervals = [[1,3]]
+        output [1,3,4,5]
+        You're incrementing everything from index 1 to index 3.
+
+        a = [1,2,3,4]
+        intervals = [[1,3],[2,3]]
+        output [1,3,5,6]
+        You're incrementing everything from index 1 to index 3 then index 2 to index 3.
+
+
+
+25.31) How does mod work on negatives?? whats binary/ternary representation of negative numbers?
+        
+        Python modulo operator always return the remainder having the same sign as the divisor. 
+        This can lead to some confusion with the output.
+
+        >>> -5 % 3
+        1
+        >>> 5 % -3
+        -1
+        >>> -10 % 3
+        2
+        >>> 
+
+        -5 % 3 = -5 + 3 + 3 % 3 == 1
+        
+        -5 % 3 = (1 -2*3) % 3 = 1
+        5 % -3 = (-1 * -2*-3) % 3 = -1
+        -10 % 3 = (2 -4*3) % 3 = 2
+
+
+        If, according to 2's Complement any binary string can be converted to it's negative counterpart by flipping each digit to it's 
+        opposite number (eg. 10012→01102) and then add 1, then how would you implement a "3's Complement"? So to speak.
+
+        Like, lets say I have 29, and want to write it as −29 in binary.
+        First I convert it into binary: 11101. And now to make it negative, we use 2's Complement. 
+        We change the binary number to 00010 and add 1→00011.
+
+        Now we have −29 in binary form.
+
+        But how to do for ternary?
+
+25.4) Covert Decimal to binary/ternary:
+
+        Similar to converting decimal to binary/or ternary?
+            -> 
+                i mean you can just find leftmost set bits...
+                how about ternary?
+                
+                find largest 3^x that can divide number. 
+                number // 3 -> remaineder
+                number = 3*q + r
+                divide by 3 -> remainder. 
+
+                10 in tern
+
+                1*3^2 + 0*3^1 + 1*3^0 -> 10 (101)
+                10 = 3*3 + 1
+
+                YOU ARE OVER COMPLICATING IT!
+                FIND THE least significant SET BIT first, then find the bigger bits!
+
+                Steps to Convert Decimal to Ternary: 
+
+                Divide the number by 3.
+                Get the integer quotient for the next iteration.
+                Get the remainder for the ternary digit.
+                Repeat the steps until the quotient is equal to 0.
+
+                How do you represent -3 decimal? how does mod work for negatives? (Research it and post it here)
+
+                    def convertToTernary(N):
+                        
+                        # Base case
+                        if (N == 0):
+                            return;
+                    
+                        # Finding the remainder
+                        # when N is divided by 3
+                        x = N % 3;
+                        N //= 3;
+                        if (x < 0):
+                            N += 1;
+                    
+                        # Recursive function to
+                        # call the function for
+                        # the integer division
+                        # of the value N/3
+                        convertToTernary(N);
+                    
+                        # Handling the negative cases
+                        if (x < 0):
+                            print(x + (3 * -1), end = "");
+                        else:
+                            print(x, end = "");
+                    
+                    
+                    # Function to convert the
+                    # decimal to ternary
+                    def convert(Decimal):
+                        
+                        print("Ternary number of ", Decimal,
+                            " is: ", end = "");
+                    
+                        # If the number is greater
+                        # than 0, compute the
+                        # ternary representation
+                        # of the number
+                        if (Decimal != 0):
+                            convertToTernary(Decimal);
+                        else:
+                            print("0", end = "");
+
+25.5) Counting and Similar to Next Permutation: Number plate
+
+        The number on the number plate of a vehicle has alphanumeric characters. The number is a string of 6 characters of 
+        which first 2 characters are alphabets while last 4 are digits. The first number generated is AA0000 while the last 
+        number generated is ZZ9999. Find the kth number generated.
+
+        Be greedy. subtract as much as possibly to get the leftmost letter, then get rest of letters. 
+
+        Subtract 26 * 9999 -> 
+        go up 10000 -> shifts the letter.
+
+        AA0000 -> AB0000
+
+        Can you divide by 10000 first, -> check the remainder. Set that. 
+        then use the rest to figure out the other 2 letters. 
+
+
+        260,004 -> Correct answer:
+        
+        BA0004
+        
+
+        -> 260,004 % 10,000 =   4
+        260,004//10000 = 26
+
+        ok now divide by 26? 
+
+        26 % 26 == 0 
+        26/26 = 1
+
+        1 % 26 = 1
+        1//26 == 0
+        done!
+
+        so we got
+
+        26^2 * 1  + 26^1 * 0 + 4*10,0000^0
+        
+        0 ->a, 1 -> B, ..., 25 -> Z
+        BA0004
+        (I think this soln works...)
+    
+
+
+25.55) Counting Plate 2:
+    Given below pattern of license plates (Pattern only, not the actual list of license plates), Find the nth license plate
+    All license plates no are of size 5 chars
+    Eg, if n is 3, ans is - 00002
+
+    00000
+    00001
+    00002
+    ........
+    ........
+    99999
+    0000A
+    0001A
+    0002A
+    ........
+    .........
+    9999A
+    0000B
+    0001B
+    0002B
+    .........
+    .........
+    9999B
+    0000C
+    ........
+    ........
+    9999Z
+    000AA
+    001AA
+    .........
+    .........
+    999AA
+    000AB
+    ..........
+    ..........
+    999ZZ
+    00AAA
+    ........
+    ........
+    ZZZZZ
+
+        Soln: Idea:
+        Example there are n = 5 charaters and find no-th license plate
+        All licenses can be listed and devided into 6 region:
+
+        Region 1	Region 2	Region 3	Region 4	Region 5	Region 6
+        00000	0000A	000AA	00AAA	0AAAAA	AAAAA
+        00001	0001A	001AA	01AAA	1AAAAA	AAAAB
+        ...	...	...	...	...	...
+        99999	9999Z	999ZZ	99ZZZ	9ZZZZZ	ZZZZZ
+        The first region has $10^5$ elements
+        The second region has $10^4*26$ elements
+        The third region has $10^3*26^2$ elements
+        The fourth region has $10^2*26^3$ elements
+        The fifth region has $10 * 26^4$ elements
+        The sixth region has $26^5$ elements\
+
+        We will find no-th license that belongs which region by compare no with the order of the first element in each region
+        After that, we find the pattern of this license.
+        Can see that each license has 2 part: left part only has number (like '123') and right part has only alphabet (like 'ABC').
+        If the no-th license belongs to Region X, left part has (5 - X + 1) numbers (call it by num0s) and (X - 1) alphabets.
+
+        Calculate the order from the first element in this region, call it distance
+        The left part is remainder of distance modulo $10^{num0s}$.
+        The right part is calculated from the quotient of distance devide $10^{num0s}$.
+
+25.57)  BFS VS Brute force:
+
+        Given a 2D grid with n rows and m columns. Some cells are blocked which you cannot pass through. From each cell you can go either up, 
+        down, left or right. Find the shortest path from (0, 0) to (n-1, m-1).
+
+        Followup:
+
+        Now assume that there exists no path from (0, 0) to (n-1, m-1) (All paths are blocked). Find the minimum number of cells that you need to 
+        unblock such that there exists a path from (0, 0) to (n-1, m-1). Can you solve it in O(n+m)
+
+        First part: BFS,
+
+        Second part: 
+
+        Brute force:
+            Try to dfs from start to other nodes. Then allow 1 crossing, and see if you make it. If you dont, try 2 crossings, until you get to N
+
+        Better:
+
+
+
+25.58) Cycle in linked list. One node moves 1 step at a time and the other node moves 2 steps at a time. If they meet, there is a cycle. 
+    If a pointer reaches theend of the linkedlist before the pointers are the same, then there is no cycle. Actually, the pointers need not move one and two nodes at a 
+    time; it is only necessaary that thepointers move at different rates. Sketch otu the proof for this. 
+
+
+25.59) Without a calculator, how many zeros are at the end of 100! (100 factorial)
+    factor out 100, factor out 10?
+    100 *90*80*70*60*50*40*30*20*10
+    
+    2*5 -> 10 
+
+    atleast 12....
+    
+    Answer:Whatyoudon'twanttodoisstartmultiplyingitallout!Thetrickis
+    rememberingthatthenumberofzerosattheendofanumberisequaltothe
+    numberoftimes"10"(or"2*5")appearswhenyoufactorthenumber.Therefore
+    thinkabouttheprimefactorizationof100!andhowmany2sand5sthereare.
+    Thereareabunchmore2sthan5s,sothenumberof5sisalsothenumberof10sin
+    thefactorization.Thereisone5foreveryfactorof5inourfactorialmultiplication
+    (1*2*...*5*...*10*...*15*...)andanextra5for25,50,75,and100.Thereforewehave
+    20+4=24zerosattheendof100!.
+    
+    Review Prime factorization
+
+25.6) Min cost to make string palindrome:
+    Given a string S and a cost matrix C.
+
+    C[i][j] denotes the cost to convert character i to character j. 
+
+    Goal is to convert the string into a palindromic string. In one operation you can choose a character of string and convert 
+    that character to any other character. You can do this operation any number of times. The cost to convert one character to another character 
+    is determined by the cost matrix. Find the minimum cost to convert a given string to a palindrome. 
+
+        The idea is to start comparing from the two ends of string. Let i be initialized as 0 index and j initialized as length – 1.
+        If characters at two indices are not same, a cost will apply. To make the cost minimum replace the character 
+        which is smaller. Then increment i by 1 and decrement j by 1. Iterate till i less than j. 
+
+        Also find the shortest cost from one character to anotehr using all pair shortest paths graph algo
+
+
+25.7) Efficient strategy for round robin?
+
+        Fair log pickups:
+        A log is defined as:
+
+        class Log {
+            String text;
+            String serverId;
+        }
+
+        You are given a list of logs and a number k. You need to pick up k logs in total from the servers. But while picking 
+        one must ensure that the pickup strategy is as fair as possible. By fair it means that it should not happen that all the logs 
+        are picked up from the same machine. Return list of log files. Implement the following method:
+
+        List<Log> optimalLogPickup(List<Log> logs, int k) {
+
+        }
+
+        Eg:
+
+
+        logs = [{"hello", "server#1"}, {"world", "server#1"}, {"Rishika Sinha", "server#2"}, {"best PM", "server#2"}], k = 2
+
+        possible output: 
+        logs = [{"hello", "server#1"}, {"Rishika Sinha", "server#2"}]
+        incorrect output:
+        logs = [{"hello", "server#1"}, {"world", "server#1"}] // Since I am picking both the logs from the same server (server#1) while being unfair to server#2.
+
+
+        Create map of server -> logs
+        
+        Use priority queue and pick one item at a time. 
+        
+        What if we want to pick more items at a time?
+
+        Determine min amount for particular server. 
+        Exhaust it, then keep track of min amount for next server.
+        Exhuast it, until you run out of servers. 
+
+        Count total logs in each server.
+        Sort it. 
+        [2,4,5,7,8] [5 servers]
+
+        Now check if k > 2*5, if it is, take 2 logs from each server. and kill off the exhausted server. 
+        Subtract 2 from every element in list and pop front. 
+
+        [2,3,5,6]
+        Repeat process, but if k <2 * 4 then just do round robin pick 1 at a time. 
+
+25.8) LAZY COMPUTING, PARTIAL SUMS,  AND Increment Intervals:
+
+    Given an array of numbers and an array of integer pairs, [i,j], increment the array of numbers by one for each index between interval [i,j]
+    e.g.
+    a = [1,2,3,4]
+    intervals = [[1,3]]
+    output [1,3,4,5]
+    You're incrementing everything from index 1 to index 3.
+
+    a = [1,2,3,4]
+    intervals = [[1,3],[2,3]]
+    output [1,3,5,6]
+    You're incrementing everything from index 1 to index 3 then index 2 to index 3.
+
+    Ok in a seperate LAZY array, put 1 and -1 in the locations where we are incrementing (1 for increment, and put -1 in the location 1 after the end of interval).
+    Lazy array will have to be 1 size bigger, to deal with end intervals. 
+
+    Process all the intervals, then at the end, do a cumulative sum array with that table. 
+    Cumulative sum array will include all your incrementing!
+
+    So for  [[1,3],[2,3]] we create the following:
+    [0, 1, 1, 0, -2]
+    -> Cum sum is:
+    [0,1,2,2,0]
+    Then sum it with original array a (ignore last element in lazy):
+
+    [1,3,5,6] -> which is our answer. 
+
+    Soln Code:
+        partial sum technique
+        we will increment the start position with 1 and decrease the (end + 1) position then will perform a prefix sum
+
+        vector<int> incrementIntervals(vector <int> array , vector<vector<int>> intervals) {
+        int n = (int)array.size();
+        vector <int> partialSum(n + 1 , 0);
+        for(auto index : intervals){
+        partialSum[index[0]]++;
+        partialSum[index[1] + 1]--;
+        }
+        for(int i = 1;i <= n;i++){
+            partialSum[i] += partialSum[i - 1];
+        }
+        vector <int> answer(n , 0);
+        for(int i = 0;i < n;i++){
+            answer[i] = array[i] + partialSum[i];
+        }
+        return answer;
+        }
+        hope this helps you
+        https://codeforces.com/blog/entry/15729 
+
+
+
+25.9)  SQRT Decomposition
+        Suppose we have an array a1, a2, ..., an and . We partition this array into k pieces each containing k elements of a.
+
+        Doing this, we can do a lot of things in . Usually we use them in the problems with modify and ask queries.
+
+        Problems : Holes, DZY Loves Colors, RMQ (range minimum query) problem
+
+25.95) Sparse Table
+        The main problem that we can solve is RMQ problem, we have an array a1, a2, ..., an and some queries. Each query gives you numbers 
+        l and r (l ≤ r) and you should print the value of min(al, al + 1, ..., ar) .
+
+        Solving using Sparse Table : For each i that 1 ≤ i ≤ n and for each j that 0 ≤ j and i + 2^j - 1 ≤ n, we keep the value 
+        of min(ai, ai + 1, ..., ai + (2^j - 1) ) in st[i][j] (preprocess) : (code is 0-based)
+
+        for(int j = 0;j < MAX_LOG; j++)
+            for(int i = 0; i < n; i ++) if(i + (1 << j) - 1 < n)
+                st[i][j] = (j ?   min(st[i][j-1], st[i + (1 << (j-1)) - 1][j-1])    :    a[i]);
+
+
+        And then for each query, first of all, find the maximum x such that 2^x ≤ r - l + 1 and answer is min(st[l][x], st[r - 2^x + 1][x]) .
+
+        So, the main idea of Sparse Table, is to keep the value for each interval of length 2^k (for each k).
+
+        You can use the same idea for LCA problem and so many other problems.
+        So preprocess will be in O(n.log(n)) and query will be in O(1)
+
+25.96) Median of Medians
+
+    The task is to find a median (the element with central index) in a sorted set of elements storing on 
+    multiple (here assuming the number is 1000) servers.
+
+    It’s pointless to do a full sort of set - it won’t fit in memory :) The algorithm is to sort arrays on each server and take a 
+    median from each other. Now we get a set of 1000 medians and it’s easy to find the result here.
+
+    More information: http://en.wikipedia.org/wiki/Selection_algorithm#Linear_general_selection_algorithm_-_Median_of_Medians_algorithm
+
+
+25.97) XOR Double Linked Lists:
+        Sometimes you implement linked list and think whether it’s needed to store 1 or 2 pointers in each node. 
+        The space really matters, especially if you store millions of records but sometimes it’s good to have a way to 
+        traverse back from a given node. There is one hack how to store two pointers using just half of the size 
+        (meaning that you’ll use size like for a single-linked list).
+
+        You store previous XOR next pointers.
+
+        Usage: when you traverse front (or back) the linked list, you just get the value and XOR it with the last element, taking the next value.
+
+        
+        A <-> B <-> C <-> D <-> E
+             A^C   B^D   C^E
+ 
+25.98) Recursively convert number to base x
+
+    Solution is incredibly simple and uses recursion:
+
+    //convert number to base X
+    public String convertToBase(int a, int x) {
+    if (a < x) return a;
+    return convertToBase(a/x, x) + (a%x);
+    }
+
+25.99) Matrix block (REMEMBER TO USE PRIORITY QUEUE VS DP ANALYSIS!)
+        Given a 2D grid with n rows and m columns. Some cells are blocked which you cannot pass through. From each cell you can go either up, 
+        down, left or right. Find the shortest path from (0, 0) to (n-1, m-1).
+        -> bfs
+
+        Followup:
+
+        Now assume that there exists no path from (0, 0) to (n-1, m-1) (All paths are blocked).
+        Find the minimum number of cells that you need to 
+        unblock such that there exists a path from (0, 0) to (n-1, m-1). Can you solve it in O(n+m)
+
+        Can follow up be solved with DP. I think so
+        
+        Also can we also just go right and down, why woudl we go up and left if we are starting at (0, 0)
+
+        To do follow up,
+        write dfs code that tries all paths to go from (0,0) to destination, and also passes through obstacles!
+        Keep track of path that took min # of obstacles to remove and memoize this in dfs
+
+        Then return min of left and down!
+
+        @lru_cache(None)
+        def helper(i, j)
+
+            if i == N-1 and J == M-1:
+                return 0
+            
+            isObstacle = 0
+            if maze[i][j] == "obstacle":
+                isObstacle = 1
+
+
+            return isObstacle + min(helper(i+1, j), helper(i, j+1)) 
+
+        This is linear time right!
+
+        Follow up can also be solved with PQ and exhausting all paths!, and priority is # of blocks you touched so far.
+
+
+
+
+
+
+25.999) FUNCTOOLS CACHE:
+
+    functools.cache was newly added in version 3.9.
+
+    The documentation states:
+
+    Simple lightweight unbounded function cache. Sometimes called “memoize”.
+
+    Returns the same as lru_cache(maxsize=None), creating a thin wrapper around a dictionary lookup for the 
+    function arguments. Because it never needs to evict old values, this is smaller and faster than lru_cache() with a size limit.
+
+    Example from the docs:
+
+    @cache
+    def factorial(n):
+        return n * factorial(n-1) if n else 1
+                
+
+
+26) Modified Binary Search  
+        First, find the middle of start and end. 
+        An easy way to find the middle would be: 
+        middle = (start + end) / 2.
+        
+        But this has a good chance of producing an integer overflow 
+        so it’s recommended that you represent the middle as: 
+        middle = start + (end — start) / 2
+        -> Also rmbr there are 2 types of mids, Left mid and right mid. Add 1 for right mid. 
+
+        Problems featuring the Modified Binary Search pattern:
+        Order-agnostic Binary Search (easy)
+        Search in a Sorted Infinite Array (medium)
+
+
+
+26.5) Basic Calculator 1,2,3 (I havent personally done this yet): [study other solutions too, and do it again.]
+
+
+    This algorithm works for Basic Calculator (BC I) problem, where we can have only + - ( ) operations, for Basic Calculator II (BC II), 
+    where we can have only + - * / operations and also for Basic Calculator III (BC III), where we can have all + - * / ( ) operations.
+
+    Stack of monomials
+    The idea is to use both stack and recursion (which can be seen as 2 stack, because recursion use implicit stack). First, let us consider, 
+    that we do not have any brackets. Then let us keep the stack of monomial, consider the example s = 1*2 - 3\4*5 + 6. 
+    Then we want our stack to be equal to [1*2, -3\4*5, 6], let us do it step by step:
+
+    Put 1 into stack, we have stack = [1].
+    We can see that operation is equal to *, so we pop the last element from our stack and put new element: 1*2, now stack = [1*2].
+    Now, operation is equal to -, so we put -3 to stack and we have stack = [1*2, -3] now
+    Now, operation is equal to \, so we pop the last element from stack and put -3\4 instead, stack = [1*2, -3\4]
+    Now, operation is equal to *, so we pop last element from stack and put -3\4*5 instead, stack = [1*2, -3\4*5].
+    Finally, operation is equal to +, so we put 6 to stack: stack = [1*2, -3\4*5, 6]
+    Now, all we need to do is to return sum of all elements in stack.
+
+    How to deal with brackets
+    If we want to be able to process the brackets properly, all we need to do is to call our calculator recursively! 
+    
+    When we see the open bracket (, we call calculator with the rest of our string, and when we see closed bracket ')', we give back 
+    the value of expression inside brackets and the place where we need to start when we go out of recursion.
+
+    Complexity
+    Even though we have stack and also have recursion, we process every element only once, so time complexity is O(n). However 
+    we pass slice of string as argument each time we meet bracket, so time complexity can go upto O(n^2) on example like (1+(1+(... +))) 
+    with O(n) open brackets. Space complexity is potentially O(n), because we need to keep stacks, but each element not more than once.
+
+    class Solution:
+        def calculate(self, s):
+            def update(op, v):
+                if op == "+": stack.append(v)
+                if op == "-": stack.append(-v)
+                if op == "*": stack.append(stack.pop() * v)           #for BC II and BC III
+                if op == "/": stack.append(int(stack.pop() / v))      #for BC II and BC III
+                
+            # the cool trick here is we assign + as our first sign, the operator becomes "post fix"        
+            it, num, stack, sign = 0, 0, [], "+"
+            
+            while it < len(s):
+                if s[it].isdigit():
+                    num = num * 10 + int(s[it])
+                elif s[it] in "+-*/":
+                    update(sign, num)
+                    num, sign = 0, s[it]
+                elif s[it] == "(":                                        # For BC I and BC III
+                    num, j = self.calculate(s[it + 1:])
+                    it = it + j
+                elif s[it] == ")":                                        # For BC I and BC III
+                    update(sign, num)
+                    return sum(stack), it + 1
+                it += 1
+            update(sign, num)
+            return sum(stack)
+        
+
+    Solution 2
+    The problem of previous code is that we pass slice of string as parameter. In python it works quite fast, because function is 
+    implemented in C and it works very fast. If we want to have honest linear time, we need to pass index as parameter. 
+    (there is alternative way like I used in problem 1896 https://leetcode.com/problems/minimum-cost-to-change-the-final-value-of-expression/discuss/1267304/Python-Recursion-dfs-solution-explained, 
+    where we can precalculate pairs of open and closing brackets)
+
+    Complexity
+    Now time complexity it is O(n), space is still O(n).
+
+    class Solution:
+        def calculate(self, s):    
+            def calc(it):
+                def update(op, v):
+                    if op == "+": stack.append(v)
+                    if op == "-": stack.append(-v)
+                    if op == "*": stack.append(stack.pop() * v)
+                    if op == "/": stack.append(int(stack.pop() / v))
+            
+                num, stack, sign = 0, [], "+"
+                
+                while it < len(s):
+                    if s[it].isdigit():
+                        num = num * 10 + int(s[it])
+                    elif s[it] in "+-*/":
+                        update(sign, num)
+                        num, sign = 0, s[it]
+                    elif s[it] == "(":
+                        num, j = calc(it + 1)
+                        it = j - 1
+                    elif s[it] == ")":
+                        update(sign, num)
+                        return sum(stack), it + 1
+                    it += 1
+                update(sign, num)
+                return sum(stack)
+
+            return calc(0)
+
+    Note:
+
+    Awsome solution, but it needs a little fix to pass this test case "14-3/2" in python (haven't tried in python3 tho), Update the function for -ve integer division as follows
+
+    if operation == "/":
+                    prev_value = stack.pop()
+                    if prev_value <0:
+                        prev_value = abs(prev_value)
+                        stack.append(-(int(prev_value/value)))
+                    else:
+                        stack.append(int(prev_value/value))
+
+921) Minimum Add to Make Parentheses Valid
+        Medium
+
+        2403
+
+        139
+
+        Add to List
+
+        Share
+        A parentheses string is valid if and only if:
+
+        It is the empty string,
+        It can be written as AB (A concatenated with B), where A and B are valid strings, or
+        It can be written as (A), where A is a valid string.
+        You are given a parentheses string s. In one move, you can insert a parenthesis at any position of the string.
+
+        For example, if s = "()))", you can insert an opening parenthesis to be "(()))" or a closing parenthesis to be "())))".
+        Return the minimum number of moves required to make s valid.
+
+
+        class Solution:
+            def minAddToMakeValid(self, s: str) -> int:
+            
+            
+                invalid_opens = 0
+                invalid_closes = 0
+                for i in s:
+                    if i == "(":
+                        invalid_opens += 1         
+                    elif i == ")":
+                        if(invalid_opens > 0):
+                            invalid_opens -= 1
+                        else:
+                            invalid_closes += 1
+                
+                return invalid_opens + invalid_closes 
+                 
+Given an m x n matrix mat, return an array of all the elements of the array in a diagonal order.\
+        Hey guys, super easy solution here, with NO DIRECTION CHECKS!!!
+        The key here is to realize that the sum of indices on all diagonals are equal.
+            -> Exploit property
+
+        class Solution(object):
+            def findDiagonalOrder(self, matrix):
+                """
+                :type matrix: List[List[int]]
+                :rtype: List[int]
+                """
+                d={}
+                #loop through matrix
+                for i in range(len(matrix)):
+                    for j in range(len(matrix[i])):
+                        #if no entry in dictionary for sum of indices aka the diagonal, create one
+                        if i + j not in d:
+                            d[i+j] = [matrix[i][j]]
+                        else:
+                        #If you've already passed over this diagonal, keep adding elements to it!
+                            d[i+j].append(matrix[i][j])
+                # we're done with the pass, let's build our answer array
+                ans= []
+                #look at the diagonal and each diagonal's elements
+                for entry in d.items():
+                    #each entry looks like (diagonal level (sum of indices), [elem1, elem2, elem3, ...])
+                    #snake time, look at the diagonal level
+                    if entry[0] % 2 == 0:
+                        #Here we append in reverse order because its an even numbered level/diagonal. 
+                        [ans.append(x) for x in entry[1][::-1]]
+                    else:
+                        [ans.append(x) for x in entry[1]]
+                return ans  
+
+
+26.6) Graph algo question series of queries:
+    You are given a weighted graph G that contains N nodes and M edges. 
+    Each edge has weight(w) associated to it. You are given Q queries of the following type:
+
+    -> x y W. Find if there exists a path in G between nodes x and y such that the weight of each edge in the path is at most W. If such a path exists print 1, otherwise print 0.
+
+    Constraints:
+    1<=N,Q,M,<=10^5
+    1<=w,W<=10^5
+    1<=x,y<=N
+        Here is my solution with complexity: O(MlogN+QlogN)
+        Idea: sort the edges and queries by weights then join nodes and check if the nodes are connected i.e. have the same parent 
+        node in disjoint-sets.n the very beginning all nodes are disconnected. Then starting from edges with smallest weight the nodes are 
+        connected (Union) while the weight of edge is less or equal to the weight in the current query.
+        If the nodes have the same parent node for the current query then the query is counted.
+
+        Ex. edges = [
+        [0, 1, 5],
+        [1, 2, 6],
+        [2, 3, 7],
+        [0, 3, 4]
+        ]
+        queries = [
+        [0, 3, 5],
+        [1, 0, 3]
+        ]
+
+        Answer - 1,0
+
+        def solve(edges, queries):
+            def find(a):
+                if par[a] < 0:
+                    return a
+                par[a] = find(par[a])
+                return par[a]
+
+            def merge(a,b):
+                if a!=b:
+                    if rank[a]>rank[b]:
+                        par[b]=a
+                        rank[a]+=rank[b]
+                    else:
+                        par[a]=b;
+                        rank[b]+=rank[a]
+
+            n = len(edges)
+            if not edges or not queries:
+                return 0
+                        
+            par=[-1 for i in range(n+10)]
+            rank=[1 for i in range(n+10)]
+
+            edges.sort(key = lambda x:  x[2])
+            queries.sort(key = lambda x:    x[2])
+
+            pos = 0
+            for i,j,w in queries:
+                while pos < len(edges) and edges[pos][2] <= w:
+                    k = edges[pos]
+                    a = find(k[0])
+                    b = find(k[1])
+                    merge(a,b)
+                    pos+=1
+                print(1) if find(i) == find(j) else print(0)
+    
+
+
+26.7) MIN-MAX DP CARDS GOOGLE (same as stone game 3)
+        Two players are playing a card game where the deck of cards are layed out in a straight line and each card value is visible to both the players.
+        The value of each card can range from a reasonable [-ve to +ve] number and the length of deck in n.
+
+        The rules of the game are such:
+
+        Player 1 starts the game
+        Each player has 3 option:
+        (Option 1: Pick 1st card)
+        (Option 2: Pick 1st two cards)
+        (Option 3: Pick 1st three cards)
+        You're only allowed to pick cards from the left side of the deck
+        Both players have to play optimally.
+        Return the maximum sum of cards Player 1 can obtain by playing optimally.
+
+        Example 1:
+
+        Input: cards = [1, 2, -3, 8]
+        Output: 3
+        Explanation:
+        Turn 1: Player 1 picks the first 2 cards: 1 + 2 = 3 points
+        Turn 2: Player 2 gets the rest of the deck: -3 + 8 = 5 points
+        Example 2:
+
+        Input: cards = [1, 1, 1, 1, 100]
+        Output: 101
+        Explanation:
+        Turn 1: Player 1 picks cards[0] = 1 point
+        Turn 2: Player 2 picks cards[1] + cards[2] + cards[3] = 3 points
+        Turn 3: Player 1 picks cards[4] = 100 points
+
+        from functools import lru_cache
+        def max_score(cards):
+            @lru_cache(maxsize=None)
+            def minimax(idx, player1):
+                if idx >= len(cards):
+                    return 0
+                if player1:
+                    return max([sum(cards[idx:idx + o]) + minimax(idx + o, not player1) \
+                                for o in range(1, 4)])
+                else:
+                    return min([minimax(idx + o, not player1) for o in range(1, 4)])
+
+            return minimax(0, True)
+
+        Space O(N)
+        // dp[i] means the max possible score the 1st player can get starting from index i
+        // best strategy means we take the option that minimizes the max possible score for our opponent
+
+        def max_score_iterative(cards):
+            total, n = 0, len(cards)
+            dp = [0] * (n + 3)
+            
+            for i in range(n - 1, -1, -1):
+                total += cards[i]
+                // we then get (total - the minimized possible score for our opponent)
+                // we maximize our own score, by minning opponent, 
+                // but on the next iteration, the thing we compute now will be used as part of the "min"
+                dp[i] = total - min([dp[i + o] for o in range(1, 4)])
+            
+            return dp[0]
+
+        Optimized bottom-up:
+        Time: O(n); space: O(1).
+        from collections import deque
+        def max_score_iterative_opt(cards):
+            total, n = 0, len(cards)
+            dp = deque([0] * 3)
+            
+            for i in range(n - 1, -1, -1):
+                total += cards[i]
+                head = total - min(dp)
+                dp.pop()
+                dp.appendleft(head)
+            
+            return dp[0]
+
+
+
+
+26.8) Problems that seemingly cant improve but do (always attempt bin search theory!):
+
+        You are given a string that is grouped together by characters. For example a sample input could be: "hhzzzzaaa", 
+        and we need to output the most frequently occuring character so for our example we would output 'z'.
+
+        I was only asked this question on the phone screen.
+
+        Optimization 1:
+
+        Since the characters are kept in groups, we need to find the index where the character changes.
+        To get the count of a specific character, we need to subtract i - pivot.
+        Linear Time and Constant Space
+
+
+
+        I thought Linear time and constant space was the optimal solution, but it turns out the interviewer wanted me to optimize 
+        further into Log N time and constant space. This is where I struggled. 
+        After a hint I was able to code out the binary search solution.
+
+        Get the start from skipping and binary search for the end, k * log(n) but since k is capped at the number of 
+        different characters which should be a fixed amount. k is constant so log(n). Thanks for the detailed post, 
+        I think someone else mentioned this problem, but the description was very vague.
+
+        public class Main {
+            //returns position after the last instance of c, end variable is not needed but I just put it in for clarity
+            private static int findEnd(String s, char c, int start, int end){
+                while(start<=end){
+                    int mid = start+(end-start)/2;
+                    if(s.charAt(mid) == c){
+                        start = mid+1;
+                    }else{
+                        end = mid-1;
+                    }
+                }
+                return start;
+            }
+            private static char findMostFrequent(String s){
+                int i = 0;
+                int mostFreqCount = 0;
+                //assuming s is not blank
+                char mostFreq = ' ';
+                while(i<s.length()){
+                    char c = s.charAt(i);
+                    int end = findEnd(s, c, i, s.length()-1);
+                    int start = i;
+                    int count = end-start;
+                    if(count> mostFreqCount){
+                        mostFreqCount = count;
+                        mostFreq = c;
+                    }
+                    i = end;
+                }
+                return mostFreq;
+            }
+            public static void main(String[] args) {
+                System.out.println(findMostFrequent("hhzzzzaaa"));
+            }
+        }
+
+
+26.7) Creating a stock exchange:
+        1801. Number of Orders in the Backlog
+        Medium
+
+        166
+
+        176
+
+        Add to List
+
+        Share
+        You are given a 2D integer array orders, where each orders[i] = [pricei, amounti, orderTypei] denotes that amounti orders have been placed of type orderTypei at the price pricei. The orderTypei is:
+
+        0 if it is a batch of buy orders, or
+        1 if it is a batch of sell orders.
+        Note that orders[i] represents a batch of amounti independent orders with the same price and order type. All orders represented by orders[i] will be placed before all orders represented by orders[i+1] for all valid i.
+
+        There is a backlog that consists of orders that have not been executed. The backlog is initially empty. When an order is placed, the following happens:
+
+        If the order is a buy order, you look at the sell order with the smallest price in the backlog. If that sell order's price is smaller than or equal to the current buy order's price, they will match and be executed, and that sell order will be removed from the backlog. Else, the buy order is added to the backlog.
+        Vice versa, if the order is a sell order, you look at the buy order with the largest price in the backlog. If that buy order's price is larger than or equal to the current sell order's price, they will match and be executed, and that buy order will be removed from the backlog. Else, the sell order is added to the backlog.
+        Return the total amount of orders in the backlog after placing all the orders from the input. Since this number can be large, return it modulo 109 + 7.
+
+        class Solution:
+            def getNumberOfBacklogOrders(self, orders):
+                b, s = [], []
+                
+                for p,a,o in orders:
+                    if o == 0:
+                        heapq.heappush(b, [-p, a])
+                        
+                    elif o == 1:
+                        heapq.heappush(s, [p, a])
+                    
+                    # Check "good" condition
+                    while s and b and s[0][0] <= -b[0][0]:
+                        a1, a2 = b[0][1], s[0][1]
+                        
+                        if a1 > a2:
+                            b[0][1] -= a2
+                            heapq.heappop(s)
+                        elif a1 < a2:
+                            s[0][1] -= a1
+                            heapq.heappop(b)
+                        else:
+                            heapq.heappop(b)
+                            heapq.heappop(s)
+                            
+                count = sum([a for p,a in b]) + sum([a for p,a in s])
+                return count % (10**9 + 7)
+
+
+26.8) Common Prefixes
+
+        The distance between 2 binary strings is the sum of their lengths after removing the common prefix. 
+        For example: the common prefix of 1011000 and 1011110 is 1011 so the distance is len("000") + len("110") = 3 + 3 = 6.
+
+        Given a list of binary strings, pick a pair that gives you maximum distance 
+        among all possible pair and return that distance.
+
+
+
+26.9)  904. Fruit Into Baskets
+        Medium
+
+        897
+
+        67
+
+        Add to List
+
+        Share
+        You are visiting a farm that has a single row of fruit trees arranged from left to right. The trees are represented by an integer array fruits where fruits[i] is the type of fruit the ith tree produces.
+
+        You want to collect as much fruit as possible. However, the owner has some strict rules that you must follow:
+
+        You only have two baskets, and each basket can only hold a single type of fruit. There is no limit on the amount of fruit each basket can hold.
+        Starting from any tree of your choice, you must pick exactly one fruit from every tree (including the start tree) while moving to the right. The picked fruits must fit in one of your baskets.
+        Once you reach a tree with fruit that cannot fit in your baskets, you must stop.
+        Given the integer array fruits, return the maximum number of fruits you can pick.
+
+        
+
+        Example 1:
+
+        Input: fruits = [1,2,1]
+        Output: 3
+        Explanation: We can pick from all 3 trees.
+        Example 2:
+
+        Input: fruits = [0,1,2,2]
+        Output: 3
+        Explanation: We can pick from trees [1,2,2].
+        If we had started at the first tree, we would only pick from trees [0,1].
+        Example 3:
+
+        Input: fruits = [1,2,3,2,2]
+        Output: 4
+        Explanation: We can pick from trees [2,3,2,2].
+        If we had started at the first tree, we would only pick from trees [1,2].
+        
+        Soln:
+            # slide the window!
+            '''  
+            take a fruit, 
+            take another fruit type,
+            extend window untily oucant.
+            
+            throw away fruit until one fruit is there. 
+            
+            then move right pointer to incldue a new fruit.
+            Repeat
+            record max.
+            '''
+
+        Soln 2: O(1) space doing Longest Subarray With 2 Elements
+
+            class Solution {
+                public int totalFruit(int[] tree) {
+                    // track last two fruits seen
+                    int lastFruit = -1;
+                    int secondLastFruit = -1;
+                    int lastFruitCount = 0;
+                    int currMax = 0;
+                    int max = 0;
+                    
+                    for (int fruit : tree) {
+                        if (fruit == lastFruit || fruit == secondLastFruit)
+                            currMax++;
+                        else
+                            currMax = lastFruitCount + 1; // last fruit + new fruit
+                        
+                        if (fruit == lastFruit)
+                            lastFruitCount++;
+                        else
+                            lastFruitCount = 1; 
+                        
+                        if (fruit != lastFruit) {
+                            secondLastFruit = lastFruit;
+                            lastFruit = fruit;
+                        }
+                        
+                        max = Math.max(max, currMax);
+                    }
+                    
+                    return max;
+                }
+            }
+
+26.95) Heap Vs Binary Search Vs Quick Select -> Super important bin search technique
+
+        973. K Closest Points to Origin
+        Medium
+        Given an array of points where points[i] = [xi, yi] represents a point on the X-Y plane and an integer k, return the k closest points to the origin (0, 0).
+
+        The distance between two points on the X-Y plane is the Euclidean distance (i.e., √(x1 - x2)2 + (y1 - y2)2).
+
+        You may return the answer in any order. The answer is guaranteed to be unique (except for the order that it is in).
+
+        Soln:
+
+        Max heap priority soln is easy (keep track of k furthest points)
+            class Solution:
+                def kClosest(self, points: List[List[int]], k: int) -> List[List[int]]:
+                    # Since heap is sorted in increasing order,
+                    # negate the distance to simulate max heap
+                    # and fill the heap with the first k elements of points
+                    heap = [(-self.squared_distance(points[i]), i) for i in range(k)]
+                    heapq.heapify(heap)
+                    for i in range(k, len(points)):
+                        dist = -self.squared_distance(points[i])
+                        if dist > heap[0][0]:
+                            # If this point is closer than the kth farthest,
+                            # discard the farthest point and add this one
+                            heapq.heappushpop(heap, (dist, i))
+                    
+                    # Return all points stored in the max heap
+                    return [points[i] for (_, i) in heap]
+                
+                def squared_distance(self, point: List[int]) -> int:
+                    """Calculate and return the squared Euclidean distance."""
+                    return point[0] ** 2 + point[1] ** 2
+
+        Binary Search Soln (Time Complexity O(N) space O(N))
+            
+            It would be NlogN but we elimiate our search space as we iterate the bin search!
+
+            In this case, however, we can improve upon the time complexity of this modified binary search by eliminating 
+            one set of points at the end of each iteration. If the target distance yields fewer than kk closer points, 
+            then we know that each of those points belongs in our answer and can then be ignored in later iterations. 
+            If the target distance yields more than kk closer points, on the other hand, we know that 
+            we can discard the points that fell outside the target distance.
+            
+            
+            Since we're going to be using the midpoint of the range of distances for each iteration of our binary search, we should
+            calculate the actual Euclidean distance for each point, rather than using the squared distance as in the other approaches. 
+            An even distribution of the points in the input array will yield an even distribution of
+            distances, but an uneven distribution of squared distances.
+            Complexity = N + N/2 + N/4 ... = 2N
+            
+            
+            class Solution:
+                def kClosest(self, points: List[List[int]], k: int) -> List[List[int]]:
+                    # Precompute the Euclidean distance for each point
+                    distances = [self.euclidean_distance(point) for point in points]
+                    # Create a reference list of point indices
+                    remaining = [i for i in range(len(points))]
+                    # Define the initial binary search range
+                    low, high = 0, max(distances)
+                    
+                    # Perform a binary search of the distances
+                    # to find the k closest points
+                    closest = []
+                    while k:
+                        mid = (low + high) / 2
+                        closer, farther = self.split_distances(remaining, distances, mid)
+                        if len(closer) > k:
+                            # If more than k points are in the closer distances
+                            # then discard the farther points and continue
+                            remaining = closer
+                            high = mid
+                        else:
+                            # Add the closer points to the answer array and keep
+                            # searching the farther distances for the remaining points
+                            k -= len(closer)
+                            closest.extend(closer)
+                            remaining = farther
+                            low = mid
+                            
+                    # Return the k closest points using the reference indices
+                    return [points[i] for i in closest]
+
+                def split_distances(self, remaining: List[int], distances: List[float],
+                                    mid: int) -> List[List[int]]:
+                    """Split the distances around the midpoint
+                    and return them in separate lists."""
+                    closer, farther = [], []
+                    for index in remaining:
+                        if distances[index] <= mid:
+                            closer.append(index)
+                        else:
+                            farther.append(index)
+                    return [closer, farther]
+
+                def euclidean_distance(self, point: List[int]) -> float:
+                    """Calculate and return the squared Euclidean distance."""
+                    return point[0] ** 2 + point[1] ** 2
+
+
+
+        Quick Select Soln (with partiail sorting partition function):
+            Lets reduce space to O(1) by modifying in place
+            Try to understand the partition function!!
+
+            1.Return the result of a QuickSelect algorithm on the points array to kk elements.
+            2. In the QuickSelect function:
+                Repeatedly partition a range of elements in the given array while homing in on the k^{th}kth element.
+            3. In the partition function:
+                Choose a pivot element. The pivot value will be squared Euclidean distance from the origin to the pivot element and will be compared to the 
+                    squared Euclidean distance of all other points in the partition.
+                Start with pointers at the left and right ends of the partition, then while the two pointers have not yet met:
+                    If the value of the element at the left pointer is smaller than the pivot value, increment the left pointer.
+                    Otherwise, swap the elements at the two pointers and decrement the right pointer.
+            Make sure the left pointer is past the last element whose value is lower than the pivot value.
+            Return the value of the left pointer as the new pivot index.
+            4. Return the first kk elements of the array.
+
+
+
+            class Solution:
+                def kClosest(self, points: List[List[int]], k: int) -> List[List[int]]:
+                    return self.quick_select(points, k)
+                
+                def quick_select(self, points: List[List[int]], k: int) -> List[List[int]]:
+                    """Perform the QuickSelect algorithm on the list"""
+                    left, right = 0, len(points) - 1
+                    pivot_index = len(points)
+                    while pivot_index != k:
+                        # Repeatedly partition the list
+                        # while narrowing in on the kth element
+                        pivot_index = self.partition(points, left, right)
+                        if pivot_index < k:
+                            left = pivot_index
+                        else:
+                            right = pivot_index - 1
+                    
+                    # Return the first k elements of the partially sorted list
+                    return points[:k]
+                
+                def partition(self, points: List[List[int]], left: int, right: int) -> int:
+                    """Partition the list around the pivot value"""
+                    pivot = self.choose_pivot(points, left, right)
+                    pivot_dist = self.squared_distance(pivot)
+                    while left < right:
+                        # Iterate through the range and swap elements to make sure
+                        # that all points closer than the pivot are to the left
+                        if self.squared_distance(points[left]) >= pivot_dist:
+                            points[left], points[right] = points[right], points[left]
+                            right -= 1
+                        else:
+                            left += 1
+                    
+                    # Ensure the left pointer is just past the end of
+                    # the left range then return it as the new pivotIndex
+                    if self.squared_distance(points[left]) < pivot_dist:
+                        left += 1
+                    return left
+                
+                def choose_pivot(self, points: List[List[int]], left: int, right: int) -> List[int]:
+                    """Choose a pivot element of the list"""
+                    return points[left + (right - left) // 2]
+                
+                def squared_distance(self, point: List[int]) -> int:
+                    """Calculate and return the squared Euclidean distance."""
+                    return point[0] ** 2 + point[1] ** 2
+
+
+26.97)  1509. Minimum Difference Between Largest and Smallest Value in Three Moves
+
+        You are given an integer array nums. In one move, you can choose one element of nums and change it by any value.
+
+        Return the minimum difference between the largest and smallest value of nums after performing at most three moves.
+
+        
+
+        Example 1:
+
+        Input: nums = [5,3,2,4]
+        Output: 0
+        Explanation: Change the array [5,3,2,4] to [2,2,2,2].
+        The difference between the maximum and minimum is 2-2 = 0.
+        Example 2:
+
+        Input: nums = [1,5,0,10,14]
+        Output: 1
+        Explanation: Change the array [1,5,0,10,14] to [1,1,0,1,1]. 
+        The difference between the maximum and minimum is 1-0 = 1.
+
+        class Solution:
+            def minDifference(self, nums: List[int]) -> int:
+                '''
+                get top 3 mins,
+                get top 3 maxes
+                
+                Ok remove the worst offenders. 
+                compare min and max. 
+                
+                try every possibility with these 3. 
+                i guess!
+                We have 4 plans:
+
+                kill 3 biggest elements
+                kill 2 biggest elements + 1 smallest elements
+                kill 1 biggest elements + 2 smallest elements
+                kill 3 smallest elements
+                '''
+                pass
+            
+        import heapq
+        class Solution:
+            def minDifference(self, nums: List[int]) -> int:
+                
+                if len(nums) <= 3:
+                    return 0
+                
+                top_4 = []
+                for x in nums:
+                    heapq.heappush(top_4,x)
+                    if len(top_4) > 4:
+                        heapq.heappop(top_4)
+                top_4.sort()
+                down_4 = []
+                for x in nums:
+                    heapq.heappush(down_4,-x)
+                    if len(down_4) > 4:
+                        heapq.heappop(down_4)
+                down_4.sort()
+                down_4 = [-x for x in down_4]
+                
+                
+                res = float('inf')
+                for i in range(4):
+                    if abs(top_4[i] - down_4[3-i]) < res:
+                        res = abs(top_4[i] - down_4[3-i])
+                
+                return res
+
+
+26.98)  Do good tracking as you iterate left to right
+
+        1525. Number of Good Ways to Split a String
+        You are given a string s.
+
+        A split is called good if you can split s into two non-empty strings sleft and sright where their concatenation is equal to 
+        s (i.e., sleft + sright = s) and the number of distinct letters in sleft and sright is the same.
+
+        Return the number of good splits you can make in s.
+
+        Have two dicionaries to track the frequency of letters for the left partition and the right partition. Initially, 
+        left partion will be empty. For each loop, update both dictionaries to reflect the frequency on the left and right 
+        partition. If the length of both partitions are equal, we found the good ways, so increment the result.
+
+
+        class Solution:
+            def numSplits(self, s: str) -> int:
+                left_count = collections.Counter()
+                right_count = collections.Counter(s)
+                res = 0
+                for c in s:
+                    left_count[c] += 1
+                    right_count[c] -= 1
+                    if right_count[c] == 0:
+                        del right_count[c]
+                    
+                    if len(left_count) == len(right_count):
+                        res += 1
+                        
+                return res
+
+26.99) DP or something else?
+
+        A pizza shop offers n pizzas along with m toppings. A customer plans to spend around x coins. 
+        The customer should order exactly one pizza, and may order zero, one or two toppings. Each topping may be order only once.
+
+        Given the lists of prices of available pizzas and toppings, what is the price closest to x of possible orders? 
+        Here, a price said closer to x when the difference from x is the smaller. 
+        Note the customer is allowed to make an order that costs more than x.
+
+        Example 1:
+
+        Input: pizzas = [800, 850, 900], toppings = [100, 150], x = 1000
+        Output: 1000
+        Explanation:
+        The customer can spend exactly 1000 coins (two possible orders).
+        Example 2:
+
+        Input: pizzas = [850, 900], toppings = [200, 250], x = 1000
+        Output: 1050
+        Explanation:
+        The customer may make an order more expensive than 1000 coins.
+        Example 3:
+
+        Input: pizzas = [1100, 900], toppings = [200], x = 1000
+        Output: 900
+        Explanation:
+        The customer should prefer 900 (lower) over 1100 (higher).
+        Example 4:
+
+        Input: pizzas = [800, 800, 800, 800], toppings = [100], x = 1000
+        Output: 900
+        Explanation:
+        The customer may not order 2 same toppings to make it 1000. 
+
+
+        def closestPrice(pizzas, toppings, x):
+            import bisect
+            closest = float('inf')
+            new_toppings = [0]
+            
+            # Generate combinations for 0, 1, and 2 toppings
+            for i in range(len(toppings)):
+                new_toppings.append(toppings[i])
+                for j in range(i+1, len(toppings)):
+                    new_toppings.append(toppings[i] + toppings[j])
+            new_toppings.sort()
+            for pizza in pizzas:
+                idx = bisect.bisect_left(new_toppings, x - pizza)
+                for j in range(idx-1, idx+2):
+                    if 0 <= j < len(new_toppings):
+                        diff = abs(pizza + new_toppings[j] - x)
+                        if diff == abs(closest - x):
+                            closest = min(closest, pizza + new_toppings[j]) # When two are equal, take the lowest one according to example 3
+                        elif diff < abs(closest - x):
+                            closest = pizza + new_toppings[j]
+            return closest
+
+26.999) BFS TOPOLOGICAL SORT TECHNIQUE/MEET IN THE MIDDLE
+
+        310. Minimum Height Trees
+
+        Share
+        A tree is an undirected graph in which any two vertices are connected by exactly one path. 
+        In other words, any connected graph without simple cycles is a tree.
+
+        Given a tree of n nodes labelled from 0 to n - 1, and an array of n - 1 edges where edges[i] = [ai, bi] indicates 
+        that there is an undirected edge between the two nodes ai and bi in the tree, you can choose any node of the tree as the root. 
+        When you select a node x as the root, the result tree has height h. Among all possible rooted trees, those with minimum height (i.e. min(h))  are called minimum height trees (MHTs).
+
+        Return a list of all MHTs' root labels. You can return the answer in any order.
+
+        The height of a rooted tree is the number of edges on the longest downward path between the root and a leaf.
+
+        Soln:
+            We start from every end, by end we mean vertex of degree 1 (aka leaves). We let the pointers move the same speed. 
+            When two pointers meet, we keep only one of them, until the last two pointers 
+            meet or one step away we then find the roots.
+
+            It is easy to see that the last two pointers are from the two ends of the longest path in the graph.
+
+            The actual implementation is similar to the BFS topological sort. Remove the leaves, update the degrees of inner vertexes. 
+            Then remove the new leaves. Doing so level by level until there are 2 or 1 nodes left. What's left is our answer!
+
+            The time complexity and space complexity are both O(n).
+
+            Note that for a tree we always have V = n, E = n-1.
+
+        def findMinHeightTrees(self, n, edges):
+            if n == 1: return [0] 
+            adj = [set() for _ in xrange(n)]
+            for i, j in edges:
+                adj[i].add(j)
+                adj[j].add(i)
+
+            leaves = [i for i in xrange(n) if len(adj[i]) == 1]
+
+            while n > 2:
+                n -= len(leaves)
+                newLeaves = []
+                for i in leaves:
+                    j = adj[i].pop()
+                    adj[j].remove(i)
+                    if len(adj[j]) == 1: newLeaves.append(j)
+                leaves = newLeaves
+            return leaves
+            
+        # Runtime : 104ms
+
+26.99999) Trees and leaf removal
+    You are given a tree-shaped undirected graph consisting of n nodes labeled 1...n and n-1 edges. The i-th edge connects nodes edges[i][0] and edges[i][1] together.
+    For a node x in the tree, let d(x) be the distance (the number of edges) from x to its farthest node. Find the min value of d(x) for the given tree.
+    The tree has the following properties:
+
+    It is connected.
+    It has no cycles.
+    For any pair of distinct nodes x and y in the tree, there's exactly 1 path connecting x and y.
+    Example 1:
+    Input: n = 6, edges = [[1, 4], [2, 3], [3, 4], [4, 5], [5, 6]]
+        1
+        |
+    2-3-4-5-6
+
+    Output: 2
+
+    Input: n = 2, edges = [[1, 2]]
+    Output: 1
+
+    Input: n = 10, edges = [[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10]]
+    Output: 5
+
+
+    Imagine a spider with many legs, and each leg has multiple sections.
+
+    In each iteration, you're going to pull out the outermost section of each of its legs.
+
+    In the context of a graph, you're removing the leaf nodes (nodes with exactly 1 adjacent edge) at every iteration.
+
+    The number of iterations at the end (when you've finished pulling out all its legs) gives min([d(node) for node in graph])
+
+
+    from collections import defaultdict
+    from typing import List
+
+
+    def min_dist_to_furthest_node(n: int, edges: List[List[int]]) -> int:
+        """
+        Time  : O(N)
+        Space : O(N),
+        """
+
+        # SETUP THE GRAPH
+        g = defaultdict(list)
+
+        # SETUP A SET OF NODES WITH IN-DEGREE = 0
+        id0 = set([i for i in range(1, n + 1)])
+
+        # COUNT THE IN-DEGREE OF EACH NODE
+        id = [0] * (n + 1)
+
+        # TRACK THE DIST
+        dist = 0
+
+        for e in edges:
+            g[e[0]].append(e[1])
+            g[e[1]].append(e[0])
+            id[e[0]] += 1
+            id[e[1]] += 1
+            if id[e[0]] > 1 and e[0] in id0: id0.remove(e[0])
+            if id[e[1]] > 1 and e[1] in id0: id0.remove(e[1])
+
+        # LOOP TILL WE ONLY HAVE 0 - 1 NODE WITH ID = 0
+        while len(id0) > 1:
+
+            # TRACK THE NEW ID0
+            new_id0 = set()
+
+            # REMOVE ALL LEAVES AND THEIR EDGES
+            for leaf in id0:
+                for nb in g.get(leaf):
+                    id[nb] -= 1
+                    if id[nb] == 1: new_id0.add(nb)
+
+            id0 = new_id0
+            dist += 1
+
+        return dist
+
+
+27) Backtracking Example:
+    282. Expression Add Operators
+    Share
+    Given a string num that contains only digits and an integer target, return all possibilities to insert the binary 
+    operators '+', '-', and/or '*' between the digits of num so that the resultant expression evaluates to the target value.
+
+    Note that operands in the returned expressions should not contain leading zeros.
+
+    Example 1:
+
+    Input: num = "123", target = 6
+    Output: ["1*2*3","1+2+3"]
+    Explanation: Both "1*2*3" and "1+2+3" evaluate to 6.
+    Example 2:
+
+    Input: num = "232", target = 8
+    Output: ["2*3+2","2+3*2"]
+    Explanation: Both "2*3+2" and "2+3*2" evaluate to 8.
+    Example 3:
+
+    Input: num = "3456237490", target = 9191
+    Output: []
+    Explanation: There are no expressions that can be created from "3456237490" to evaluate to 9191.
+
+    Soln 1
+
+    class Solution:
+        def addOperators(self, num: 'str', target: 'int') -> 'List[str]':
+
+            def backtracking(idx=0, path='', value=0, prev=None):            
+                if idx == len(num) and value == target:
+                    rtn.append(path)
+                    return
+                
+                for i in range(idx+1, len(num) + 1):
+                    tmp = int(num[idx: i])
+                    if i == idx + 1 or (i > idx + 1 and num[idx] != '0'):
+                        if prev is None :
+                            backtracking(i, num[idx: i], tmp, tmp)
+                        else:
+                            backtracking(i, path+'+'+num[idx: i], value + tmp, tmp)
+                            backtracking(i, path+'-'+num[idx: i], value - tmp, -tmp)
+                            backtracking(i, path+'*'+num[idx: i], value - prev + prev*tmp, prev*tmp)
+            
+            rtn = []
+            backtracking()
+            
+            return rtn    
+
+
+
+    Soln 2 (Official Leetcode)
+
+    class Solution:
+        def addOperators(self, num: 'str', target: 'int') -> 'List[str]':
+
+            N = len(num)
+            answers = []
+            def recurse(index, prev_operand, current_operand, value, string):
+
+                # Done processing all the digits in num
+                if index == N:
+
+                    # If the final value == target expected AND
+                    # no operand is left unprocessed
+                    if value == target and current_operand == 0:
+                        answers.append("".join(string[1:]))
+                    return
+
+                # Extending the current operand by one digit
+                current_operand = current_operand*10 + int(num[index])
+                str_op = str(current_operand)
+
+                # To avoid cases where we have 1 + 05 or 1 * 05 since 05 won't be a
+                # valid operand. Hence this check
+                if current_operand > 0:
+
+                    # NO OP recursion
+                    recurse(index + 1, prev_operand, current_operand, value, string)
+
+                # ADDITION
+                string.append('+'); string.append(str_op)
+                recurse(index + 1, current_operand, 0, value + current_operand, string)
+                string.pop();string.pop()
+
+                # Can subtract or multiply only if there are some previous operands
+                if string:
+
+                    # SUBTRACTION
+                    string.append('-'); string.append(str_op)
+                    recurse(index + 1, -current_operand, 0, value - current_operand, string)
+                    string.pop();string.pop()
+
+                    # MULTIPLICATION
+                    string.append('*'); string.append(str_op)
+                    recurse(index + 1, current_operand * prev_operand, 0, value - prev_operand + (current_operand * prev_operand), string)
+                    string.pop();string.pop()
+            recurse(0, 0, 0, 0, [])    
+            return answers
+
+
+
+27.5) Top K elements
+        -> CAN BE SOLVED IN O(N) WITH BUCKET SORT, AND QUICK SELECT. CHECK IT OUT
+        -> TOP K MOST FREQUENT ELEMENTS QUESTION TO SEE THIS. 
+
+        Any problem that asks us to find the top/smallest/top most frequently occuring ‘K’ 
+        elements among a given set falls under this pattern.
+
+        The best data structure to keep track of ‘K’ elements is Heap. 
+        This pattern will make use of the Heap to solve multiple 
+        problems dealing with ‘K’ elements at a time from 
+        a set of given elements. The pattern looks like this:
+
+        Insert ‘K’ elements into the min-heap or max-heap based on the problem.
+
+        Iterate through the remaining numbers and if you find one that is 
+        larger than what you have in the heap, 
+        then remove that number and insert the larger one.
+
+        There is no need for a sorting algorithm because the heap will keep track of the elements for you.
+        How to identify the Top ‘K’ Elements pattern:
+        If you’re asked to find the top/smallest/frequent ‘K’ elements of a given set
+        If you’re asked to sort an array to find an exact element
+        Problems featuring Top ‘K’ Elements pattern:
+        Top ‘K’ Numbers (easy)
+        Top ‘K’ Frequent Numbers (medium)
+
+        # Top K Frequent Elements
+
+        class Solution(object):
+            def topKFrequent(self, nums, k):
+                """
+                :type nums: List[int]
+                :type k: int
+                :rtype: List[int]
+                """
+
+                num_of_items_to_return = k
+                m = collections.defaultdict(int)
+                
+                for i in nums:
+                    m[i] += 1
+
+                pq = [] # heapq
+                counter = itertools.count()
+                
+                # entry_finder = {} Used for deleting other elements in heapq!
+
+                for k, v in m.items():
+                
+                    if len(pq) < num_of_items_to_return:
+                        count = next(counter)
+                        i = [v, count, k] #[priority, count, task]
+                        heappush(pq, i)
+                    else:
+                        top =  pq[0][0] # get priority
+                        print("TOP IS", top)
+
+                        if v > top:
+                            _ = heappop(pq)
+                            count = next(counter)
+                            i = [v, count, k] #[priority, count, task]
+                            heappush(pq, i)     
+                return map(lambda x: x[-1], pq)
+
+        # BUCKET SOLN:
+        There are solution, using quickselect with O(n) complexity in average, but I think they are 
+        overcomplicated: actually, there is O(n) solution, using bucket sort. The idea, is that frequency 
+        of any element can not be more than n. So, the plan is the following:
+
+        Create list of empty lists for bucktes: for frequencies 1, 2, ..., n.
+        Use Counter to count frequencies of elements in nums
+        Iterate over our Counter and add elements to corresponding buckets.
+
+        buckets is list of lists now, create one big list out of it.
+
+        Finally, take the k last elements from this list, these elements will be top K frequent elements.
+
+        Complexity: time complexity is O(n), because we first iterate over nums once and create buckets, then we 
+        flatten list of lists with total number of elements O(n) and finally 
+        we return last k elements. Space complexity is also O(n).
+
+        class Solution:
+            def topKFrequent(self, nums, k):
+                bucket = [[] for _ in range(len(nums) + 1)]
+                Count = Counter(nums).items()  
+                for num, freq in Count: bucket[freq].append(num) 
+                flat_list = list(chain(*bucket))
+                return flat_list[::-1][:k]
+                
+
+28) K way Merge:
+
+K-way Merge helps you solve problems that involve a set of sorted arrays.
+
+        Whenever you’re given ‘K’ sorted arrays, you can use a
+        Heap to efficiently perform a sorted traversal of all 
+        the elements of all arrays. You can push the smallest 
+        element of each array in a Min Heap to get the overall minimum. 
+        After getting the overall minimum, push the next element 
+        from the same array to the heap. Then, repeat this process 
+        to make a sorted traversal of all elements.
+
+        The pattern looks like this:
+        Insert the first element of each array in a Min Heap.
+        After this, take out the smallest (top) element from the heap and add it to the merged list.
+        After removing the smallest element from the heap, insert the next element of the same list into the heap.
+        Repeat steps 2 and 3 to populate the merged list in sorted order.
+        How to identify the K-way Merge pattern:
+        The problem will feature sorted arrays, lists, or a matrix
+        If the problem asks you to merge sorted lists, find the smallest element in a sorted list.
+        Problems featuring the K-way Merge pattern:
+        Merge K Sorted Lists (medium)
+        K Pairs with Largest Sums (Hard)
+
+29) Questions you can solve with XOR can also probably be done with other operators such as +, -, *, /. Make
+    sure you check for integer overflow. thats why xor method is always better.
+
+29.5)  You are given an array A of n - 2 integers 
+    which are in the range between 1 and n. All numbers 
+    appear exactly once, except two numbers, which are 
+    missing. Find these two missing numbers.
+
+    Ok so go through range of numbers between 1 and n.
+    XOR all those numbers,
+    ex:
+
+    def soln(ans):
+        val = 0
+        for i in range(0, N):
+            val ^= (i+1)
+
+        # then xor with ever number in ans. 
+        for i in A:
+            val ^= i
+
+        # ok now val is   a ^ b where both a and b are different 
+        # how to extract a, and b?
+        '''
+
+        you could run  a ^ b and try to xor it with 
+        a number between 1 and n -> the result would be the other number, 
+        b. 
+
+        then check if the other number is between 1 and N and if it is,
+        keep it. -> could you also check if the a and b you found is 
+        also the same as the sum of the 2 missing numbers, which you can 
+        get by subtracting N(n+1)/2 - sum(A). 
+        so if it passes both tests then its more likely to be that rite!!
+        but could 2 seperate 'a, 'b pairs still pass both sum and xor test?
+        
+        ABOVE SOLUTION IS HACKY!!
+        '''
+
+        BETTER SOLUTION: 
+        # ok now val is   a ^ b where both a and b are different 
+        # how to extract a, and b?
+        '''
+        well if the value is 10001. 
+
+        The 0 means they were both either 0 bit, or both 1 bit.
+        if its 1, then either the a has a 1 bit and b has 0 bit or 
+        vice versa. 
+
+        Partitioning based on inspecting u ^ v
+        Luckily, we can figure out what to do by using what we 
+        already stated earlier. Let’s think about this:
+
+        If the two bits XOR takes as input are the same, the result is 0, otherwise it is 1.
+
+        If we analyze the individual bits in u ^ v, then every 0 means that the 
+        bit had the same value in both u and v. Every 1 means that the bits differed.
+
+        Using this, we find the first 1 in u ^ v, i.e. the first position i where u and v 
+        have to differ. Then we partition A as well as the numbers from 1 to n according to that bit.
+        We end up with two partitions, each of which contains two sets:
+
+        Partition 0
+        The set of all values from 1 to n where the i-th bit is 0
+        The set of all values from A where the i-th bit is 0
+        
+        Partition 1
+        The set of all values from 1 to n where the i-th bit is 1
+        The set of all values from A where the i-th bit is 1
+        
+        Since u and v differ in position i, we know that they have to be in different partitions.
+
+        Reducing the problem
+        Next, we can use another insight described earlier:
+
+        While we worked on integers from 1 to n so far, this is not required. In fact, the 
+        previous algorithm works in any situation where there is (1) some set of potential 
+        elements and (2) a set of elements actually appearing. The sets may only differ 
+        in the one missing (or duplicated) element.
+
+        These two sets correspond exactly to the sets we have in each partition. 
+        We can thus search for u by applying this idea to one of the partitions 
+        and finding the missing element, and then find v by applying it to the other partition.
+
+        This is actually a pretty nice way of solving it: We effectively 
+        reduce this new problem to the more general version of the problem we solved earlier.
+
+
+30.1)  Use loop invarients when doing 2 pointer solutions, greedy solutions, etc. to think about, and help
+    interviewer realize that your solution works!!!
+
+30.2)  Derieive mathematical relationships between numbers in array, and solve for a solution. Since
+    there was a mathematical relationship, xor can prolly be used for speedup. 
+    For instance: Find the element that appears once
+
+        Given an array where every element occurs three times, except one element which occurs only once. 
+
+        public int singleNumber(int[] A) {
+            int ones = 0, twos = 0;
+            for(int i = 0; i < A.length; i++){
+                ones = (ones ^ A[i]) & ~twos;
+                twos = (twos ^ A[i]) & ~ones;
+            }
+            return ones;
+        }
+
+        Here's my Python solution and explanation, inspired by this post and others.
+
+        The trick is to keep a counter of the numbers. If we see one number the counter should be 1, 
+        if we see two numbers the counter should be 2, and if we see 3 numbers the counter should loop 
+        back to 0. In order to have these 3 states we need 2 bits, hence a and b. Below is the transition 
+        table, and the code follows from it. It should be obvious if we figure it out for a single bit we 
+        can apply to 32-bits. Note that the order of operations matter, we calculate b first and then a. 
+        Since we're guaranteed three numbers and a single lone number, we can just return b (ab will never end up as 10).
+
+        a b num -> a b
+        0 0 0   -> 0 0 
+        0 1 0   -> 0 1
+        1 0 0   -> 1 0
+        0 0 1   -> 0 1
+        0 1 1   -> 1 0
+        1 0 1   -> 0 0
+
+        class Solution(object):
+            def singleNumber(self, nums):
+                a = b = 0
+                for n in nums:
+                    b = (b^n)&~a
+                    a = (a^n)&~b
+                return b
+
+
+        Here is some intuition to help understand this nice and concise solution:
+
+        First of all, consider the (set^val) as one of the following:
+        1. adding "val" to the "set" if "val" is not in the "set" => A^0 = A
+        2. removing "val" from the "set" if "val" is already in the "set" => A^A = 0
+
+        Assume "ones" and "twos" to be sets that are keeping track of which numbers have 
+        appeared once and twice respectively;
+
+        "(ones ^ A[i]) & ~twos" basically means perform the above mentioned operation if and only if 
+        A[i] is not present in the set "twos". So to write it in layman:
+
+        IF the set "ones" does not have A[i]
+            Add A[i] to the set "ones" if and only if its not there in set "twos"
+        ELSE
+            Remove it from the set "ones"
+        So, effectively anything that appears for the first time will be in the set. Anything that appears a second 
+        time will be removed. We'll see what happens when an element appears a third time (thats handled by the set "twos").
+
+        After this, we immediately update set "twos" as well with similar logic:
+        "(twos^ A[i]) & ~ones" basically means:
+
+        IF the set "twos" does not have A[i]
+            Add A[i] to the set "twos" if and only if its not there in set "ones"
+        ELSE
+            Remove it from the set "twos"
+        So, effectively, any number that appears a first time will be in set "ones" so it will not be added to "twos". 
+        Any number appearing a second time would have been removed from set "ones" in the previous step and 
+        will now be added to set "twos". Lastly, any number appearing a third time will simply be removed 
+        from the set "twos" and will no longer exist in either set.
+
+        Finally, once we are done iterating over the entire list, set "twos" would be empty and set "ones"
+        will contain the only number that appears once.
+
+
+30.3)  DP is like traversing a DAG. it can have a parents array, dist, and visited set. SOmetimes you need to backtrack
+    to retrieve parents so remember how to do that!!!!. 
+
+30.4)  Do bidirectional BFS search if you know S and T and you are finding the path! 
+    (i think its good for early termination in case there is no path)
+
+30.5)  For linked list questions, draw it out. Dont think about it. Then figur eout how you are rearranging the ptrs.
+    and how many new variables you need. ALSO USE DUMMY POINTERS to not deal with modifying head pointer case. 
+
+
+30.6)  Linear Algorithms:
+    Bracket Matching => Use stack
+    Postfix Calculator and Conversion
+        Prefix calculator => 2 + 6 * 3 => this needs binary tree to do i think! with extra mem
+        Prefix: + 2 * 6 3, * + 2 6 3
+        Postfix: 2 6 3 * +, 2 6 + 3 *
+        We can evaluate postfix in O(n). Push elements in stack. when you see operator, 
+        pop 2 elements right, do compute, put back into stack.
+
+    (Static) selection problem
+        Given unchanged array of n elements. can we find kth smallest element of A in O(n). yeah prlly
+        A = {2, 8, 7, 1, 5, 4, 6, 3} 
+        4th smallest is 4. 
+        4 solutions: 
+        sort and get k-1 element O(nlogn)
+        Do heap-select USING MIN HEAP. create min heap of given n element and call extractMin() k times.
+            O(n + kLogn) => because heapify is O(n)
+        Method 3 (Using Max-Heap)
+            We can also use Max Heap for finding the k’th smallest element. Following is algorithm.
+            1) Build a Max-Heap MH of the first k elements (arr[0] to arr[k-1]) of the given array. O(k)
+
+            2) For each element, after the k’th element (arr[k] to arr[n-1]), compare it with root of MH.
+            ……a) If the element is less than the root then make it root and call heapify for MH
+            ……b) Else ignore it.
+            // The step 2 is O((n-k)*logk)
+
+            1) Finally, root of the MH is the kth smallest element.
+
+            Time complexity of this solution is O(k + (n-k)*Logk)
+
+        METHOD 4(BEST METHOD QUICK SELECT): -> DO MEDIAN OF MEDIANS TO GET O(N) NOT WORST AVERAGE CASE? worst time!!!
+           The idea is, not to do complete quicksort, but stop at the point where pivot itself is k’th         
+            smallest element. Also, not to recur for both left and right sides of pivot, 
+            but recur for one of them according to the position of pivot. The worst case time          
+            complexity of this method is O(n^2), but it works in O(n) on average.
+
+    Sorting in linear time
+        Given array, each int between [0, 100] can we sort in O(n). yeah counting sort.
+        What if given arry has range of 32 bit unsigned ints [0, 2^32 -1] => radix sort
+
+    Sliding window
+        -> Given an array of n elements, can we find a smallest sub-array size so that the sum of the sub-array is greater 
+        than or equal to a constant S in O(n)
+        
+        2 pointers both start at index 0. move end pointer 
+        to right until you have S. then keep that as current_min_running_length_of_subarray.
+        move start pointer to right to remove elements, then fix by extending end pointer if sum falls below S. 
+        get new subarrays and update current_min_running_length_of_subarray. 
+
+30.7)  Heapify is cool. Python heapify implementation that is O(N) implemented below: 
+       UNDERSTAND IT.
+       # Single slash is simple division in python. 2 slashes is floor division in python
+       # only the root of the heap actually has depth log2(len(a)). Down at the nodes one above a leaf - 
+       # where half the nodes live - a leaf is hit on the first inner-loop iteration.
+
+        def heapify(A):
+            for root in xrange(len(A)//2-1, -1, -1):
+                rootVal = A[root]
+                child = 2*root + 1
+                while child < len(A):
+                    # we pick the smaller child to sort?
+                    # makes sense because the smaller child is the one
+                    # that has to fight with the parent in a min heap.
+                    if child+1 < len(A) and A[child] > A[child+1]:
+                        child += 1
+                    if rootVal <= A[child]:
+                        break
+                    A[child], A[(child-1)//2] = A[(child-1)//2], A[child]
+                    child = child *2 + 1
+
+30.75) Write some notes here on how to implement update-key for heaps well!
+
+
+30.8)  Understand counting sort, radix sort.
+        Counting sort is a linear time sorting algorithm that sort in O(n+k) 
+        time when elements are in range from 1 to k.        
+        What if the elements are in range from 1 to n^2? 
+        We can’t use counting sort because counting sort will take O(n^2) which is worse 
+        than comparison based sorting algorithms. Can we sort such an array in linear time?
+        Radix Sort is the answer. The idea of Radix Sort is to do digit by digit 
+        sort starting from least significant digit to most significant digit. 
+        Radix sort uses counting sort as a subroutine to sort.
+        Look at section below for impls.
+
+
+30.9)  To do post order traversal or inorder traversal 
+    on a binary tree iteratively (or doing any dfs, where you want to vist root node last). 
+    you need to USE A FLAG!! (LOOK at morris traversal for cool funs!)
+
+        def postorderTraversal(self, root):
+            traversal, stack = [], [(root, False)]
+            while stack:
+                node, visited = stack.pop()
+                if node:
+                    if visited:
+                        # add to result if visited
+                        traversal.append(node.val)
+                    else:
+                        # post-order
+                        stack.append((node, True))
+                        stack.append((node.right, False))
+                        stack.append((node.left, False))
+
+            return traversal
+
+        def inorderTraversal(self, root):
+            result, stack = [], [(root, False)]
+
+            while stack:
+                cur, visited = stack.pop()
+                if cur:
+                    if visited:
+                        result.append(cur.val)
+                    else:
+                        stack.append((cur.right, False))
+                        stack.append((cur, True))
+                        stack.append((cur.left, False))
+
+            return result
+        
+        def preorderTraversal(self, root):
+            ret = []
+            stack = [root]
+            while stack:
+                node = stack.pop()
+                if node:
+                    ret.append(node.val)
+                    stack.append(node.right)
+                    stack.append(node.left)
+            return ret
+
+
+31.1) When you need to keep a set of running values such as mins, and prev mins, 
+    you can keep all the runnign mins in a datastructre and as your algorithm traverses the datastructure, 
+    update the datastructure for the running value as well in the same way to maintaing consistency!
+    For instance, min stack: 
+    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.
+
+    push(x) -- Push element x onto stack.
+    pop() -- Removes the element on top of the stack.
+    top() -- Get the top element.
+    getMin() -- Retrieve the minimum element in the stack.
+
+    have 2 stacks, one for the actual stack, and another that simulates the same operations to 
+    maintain the running min.
+
+
+31.11) In some questions you can 
+    do DFS or BFS from a root node to a specific 
+    child node and you end up traversing a tree, 
+    either the DFS tree or BFS Tree. 
+    HOWEVER, AS AN O(1) space optimization, you might be able 
+    to go backward from the child node to the root node,
+    and only end up traversing a path rather than a tree!
+    Go up the tree for SPEED. 
+
+    Optimize by going from child to root before going from root to child
+
+
+
+31.5) DFS ANALYSIS START AND END TIMES!
+    The parenthesis theorem says that the discovery 
+    and finish time intervals are either disjoint or nested.
+
+    With the graph version of DFS, only some edges 
+    (the ones for which visited[v] is false) will be traversed. 
+    These edges will form a tree, called the depth-first-search 
+    tree of G starting at the given root, and the edges in this
+    tree are called tree edges. The other edges of G can be 
+    divided into three categories:
+
+    Back edges point from a node to one of its ancestors in the DFS tree.
+    Forward edges point from a node to one of its descendants.
+    Cross edges point from a node to a previously visited 
+    node that is neither an ancestor nor a descendant.
+
+    AnnotatedDFS(u, parent):
+        parent[u] = parent
+        start[u] = clock; clock = clock + 1
+        visited[u] = true
+        for each successor v of u:
+            if not visited[v]:
+            AnnotatedDFS(v, u)
+        end[u] = clock; clock = clock + 1
+
+    we will show in a moment that a graph is acyclic if and 
+    only if it has no back edges. But first: how do we tell 
+    whether an edge is a tree edge, a back edge, a forward edge, 
+    or a cross edge? We can do this using the clock mechanism 
+    we used before to convert a tree into a collection of intervals.
+
+
+    Tree edges are now easy to recognize; uv is a tree edge 
+    if parent[v] = u. For the other types of edges, 
+    we can use the (start,end) intervals to tell 
+    whether v is an ancestor, descendant, or distant cousin of u:
+
+    Edge type of uv | start times         | end times
+    Tree edge       | start[u] < start[v] | end[u] > end[v]
+    Back edge       | start[u] > start[v] | end[u] < end[v]
+    Forward edge    | start[u] < start[v] | end[u] > end[v]
+    Cross edge      | start[u] > start[v] | end[u] > end[v]
+
+
+
+32) In head recursion , the recursive call, when it happens, comes 
+      before other processing in the function (think of it happening at the top, 
+      or head, of the function). In tail recursion , it's the 
+      opposite—the processing occurs before the recursive call.
+
+40.2) Heap
+    -> Given a node k, easy to compute indices for
+        parent and children
+        - Parent Node: floor(k/2)
+        - Children: 2k, 2k+1
+    You must refer to the definition of a Binary Heap:
+
+        A Binary heap is by definition a complete binary tree ,that is, all levels of the       
+        tree, 
+        except possibly the last one (deepest) are fully filled, and, if the last     
+        level of the tree is not complete, the nodes of that level are filled from left to        
+        right.
+        
+        It is by definition that it is never unbalanced. The maximum difference in balance      
+        of the two subtrees is 1, when the last level is partially filled with nodes only       
+        in the left subtree.
+
+    -> To insert node: (running time O(lgn)) (SIFT UP)
+    1) make a new node at last level as far left as possible. 
+    2) if node breaks heap property, swap with its parent node. 
+    3) new node moves up tree. repeat 1) to 3) until all conflicts resolved.
+
+    -> Deleting root node: (SIFT DOWN)
+    1) Remove the root, and bring the last node (rightmost node 
+    in the last leve) to the root. 
+    2) If the root breaks the heap property, look at its children
+    and swap it with the larger one. 
+    3) Repeat 2 until all conflicts resolved
+
+
+41) AVOID LINKED LIST LOOPS IN YOUR CODE. ALWAYS 
+       NULLIFY YOUR POINTERS IF YOU ARE REUSING THE 
+       DATASTRUCTURE/ DOING THINGS IN PLACE!!!!!!
+       SUCH AS HERE by saving nxt pointer as tmp
+
+       1.   Odd Even Linked List
+        Given the head of a singly linked list, group all the nodes 
+        with odd indices together followed by the nodes with even 
+        indices, and return the reordered list.
+
+        The first node is considered odd, and the second node is even, and so on.
+
+        Note that the relative order inside both the even and odd
+        3groups should remain as it was in the input.
+
+        You must solve the problem in O(1) extra space complexity and O(n) time complexity.
+   
+       You should try to do it in place. The program should run in O(1)    
+       space complexity and O(nodes) time complexity.
+
+        def oddEvenList(self, head: ListNode) -> ListNode:
+            oddH = ListNode(0)
+            evenH = ListNode(0)
+            
+            odd = oddH
+            even = evenH
+            
+            isOdd = True
+            node = head
+            
+            while node:
+                nxt = node.next
+                node.next = None # IMPORTANT STOP THE LOOPS
+                if isOdd:
+                    odd.next = node
+                    odd = odd.next
+                    isOdd = False
+                else:
+                    even.next = node
+                    even = even.next
+                    isOdd = True
+                node = nxt
+            
+            odd.next = evenH.next
+            return oddH.next
+
+
+42) Copy list with random pointer 
+       (associate input structure with output structure)
+       then recover both after trick. 
+    
+    A linked list is given such that each node contains an 
+    additional random pointer which could point to any node in the list or null.
+
+    Return a deep copy of the list.
+    
+    The deep copy should consist of exactly n brand new nodes, 
+    where each new node has its value set to the value of its 
+    corresponding original node. Both the next and random 
+    pointer of the new nodes should point to new nodes in the 
+    copied list such that the pointers in the original list and 
+    copied list represent the same list state.
+
+    # Definition for a Node.
+    class Node:
+        def __init__(self, x: int, next: 'Node' = None, random: 'Node' = None):
+            self.val = int(x)
+            self.next = next
+            self.random = random
+    """
+
+    We need a hash map here to map to random nodes in 
+    our new linked list. This requires O(n) space
+
+    We can use constant space (if we do not consider space
+    for output)
+    
+    The idea is to associate the original node with its 
+    copy node in a single linked list. In this way, 
+    we don't need extra space to keep track of the new nodes.
+
+    The algorithm is composed of the follow three steps which are also 3 iteration rounds.
+
+    Iterate the original list and duplicate each node. The duplicate
+    of each node follows its original immediately.
+    Iterate the new list and assign the random pointer for each
+    duplicated node.
+    Restore the original list and extract the duplicated nodes.
+
+    def copyRandomList(self, head):
+
+        # Insert each node's copy right after it, already copy .label
+        node = head
+        while node:
+            copy = RandomListNode(node.label)
+            copy.next = node.next
+            node.next = copy
+            node = copy.next
+
+        # Set each copy's .random
+        node = head
+        while node:
+            node.next.random = node.random and node.random.next
+            node = node.next.next
+
+        # Separate the copied list from the original, (re)setting every .next
+        node = head
+        copy = head_copy = head and head.next
+        while node:
+            node.next = node = copy.next
+            copy.next = copy = node and node.next
+
+        return head_copy
+
+
+    @DrFirestream OMG is that a mindfuck :-). But a nice thing is that the original 
+    list's next structure is never changed, so I can write a helper generator to 
+    visit the original list with a nice for loop encapsulating the while loop 
+    and making the loop bodies a little simpler: (May not be worth trying to understand this)
+
+    '''
+    def copyRandomList(self, head: 'Node') -> 'Node':
+        def nodes():
+            node = head
+            while node:
+                yield node
+                node = node.next
+        # create new nodes
+        for node in nodes():
+            node.random = Node(node.val, node.random, None)
+        # populate random field of the new node
+        for node in nodes():
+            node.random.random = node.random.next and node.random.next.random
+        # restore original list and build new list
+        head_copy = head and head.random
+        for node in nodes():
+            node.random.next, node.random = node.next and node.next.random, node.random.next
+        return head_copy
+
+
+43) Intersection of 2 linked lists. 
+    Write a program to find the node at which the 
+    intersection of two singly linked lists begins.
+    (Constant space)
+    If the two linked lists have no intersection at all, return null.
+    After they intersect they cant diverge!
+
+    Find the different in 2 lists, then traverse longer one 
+    shifted by difference, and other, one node at a time.
+    When nodes are equal that is the intersection node. 
+
+    Other soln:
+        def getIntersectionNode(self, headA, headB):
+            if headA is None or headB is None:
+                return None
+
+            pa = headA # 2 pointers
+            pb = headB
+
+            while pa is not pb:
+                # if either pointer hits the end, 
+                # switch head and continue the second traversal, 
+                # if not hit the end, just move on to next
+                pa = headB if pa is None else pa.next
+                pb = headA if pb is None else pb.next
+
+            return pa 
+            # only 2 ways to get out of the loop, 
+            # they meet or the both hit the end=None
+
+    the idea is if you switch head, the possible difference 
+    between length would be countered. On the second traversal, 
+    they either hit or miss. if they meet, pa or pb would 
+    be the node we are looking for, 
+    if they didn't meet, they will hit the end at 
+    the same iteration, pa == pb == None, 
+    return either one of them is the same,None
+
+44) BE SMART ABOUT GRAPH ROOT FINDING, AND ITERATING:
+        
+        1.   Longest Consecutive Sequence        
+        Given an unsorted array of integers, find the length of the 
+        longest consecutive elements sequence.
+        Your algorithm should run in O(n) complexity.
+
+        def longestConsecutive(self, nums):
+            nums = set(nums)
+            best = 0
+            for x in nums:
+                if x - 1 not in nums: # this indicates you are at root
+                    y = x + 1
+                    while y in nums:
+                        y += 1
+                    best = max(best, y - x)
+            return best
+
+
+
+45) Hill finding part 1: Best time to buy and sell stock I
+
+    You are given an array prices where prices[i] is the 
+    price of a given stock on the ith day.
+
+    You want to maximize your profit by choosing a 
+    single day to buy one stock and choosing a different 
+    day in the future to sell that stock.
+
+    Return the maximum profit you can achieve from this transaction. 
+    If you cannot achieve any profit, return 0.
+
+    def maxProfit(self, prices: List[int]) -> int:
+        if not prices:
+            return 0
+        min_i = prices[0]
+        max_profit = 0
+        for i,x in enumerate(prices):
+            min_i = min(min_i, x)
+            profit = x - min_i
+            max_profit = max(max_profit, profit)
+        return max_profit
+
+    CAN ALSO SOLVE WITH KADANES ALGORITHM (Max subarray sum):
+    if the interviewer twists the question slightly by giving the difference 
+    array of prices, Ex: for {1, 7, 4, 11}, 
+    if he gives {0, 6, -3, 7}, you might end up being confused. Do this:
+
+        public int maxProfit(int[] prices) {
+        int maxCur = 0, maxSoFar = 0;
+        for(int i = 1; i < prices.length; i++) {
+            maxCur = Math.max(0, maxCur += prices[i] - prices[i-1]);
+            maxSoFar = Math.max(maxCur, maxSoFar);
+        }
+        return maxSoFar;
+    }
+
+
+46)VISULIZING PROBLEMS, GET GEOMETRIC UNDERSTANDING OF TEST CASES, AND DO NOT 
+    RUSH THE ALGORITHM DESIGN PHASE. TEST YOUR ALGO ON TEST CASES BEFORE WRITING. 
+    ESP IF YOU ARE UNSURE!!
+
+    BEST TIME TO BUY AND SELL STOCK 2
+    ALWAYS TRY TO TEST YOUR ALGORITHM AGAINST TEST CASES!!!! for UNDERSTANDING
+    before coding out!! YOUR ALGORITHM WILL BE INCORRECT SOMETIMES. 
+    ALSO think of invarients that should be true, and dont break invarients you invent. 
+     
+    When you design an algo, make sure you understand 
+    all the details of algo before you code it out. It may look like a hill finder, 
+    but is actually a RIEMAN SUM INTEGRAL algorithm!! 
+    Like with this qustion which you
+    messed up the first time, doing. correct soln under it. 
+
+    Say you have an array prices for which the ith element is the price of a given stock on day i.
+    Design an algorithm to find the maximum profit. You may complete as many transactions as you like
+
+    class Solution:
+        def maxProfitWRONG(self, prices: List[int]) -> int:
+            '''
+            IF YOU WERE SMART, YOU WOULD realized you have to consider 
+            every peak and valley to create a profit value. And this realization
+            comes from playing around with test cases and writing out problem ideas,
+            and then testing problem ideas. 
+            '''
+
+            i = 0
+            buyPrice = None
+            sellPrice = None            
+            profit = 0
+
+            while i < len(prices):
+                if buyPrice is None:
+                    buyPrice = prices[i]
+                elif prices[i] < buyPrice:
+                    if sellPrice:
+                        profit += (sellPrice - buyPrice)                    
+                    buyPrice = prices[i]
+                    sellPrice = None
+                else:
+                    if not sellPrice:
+                        sellPrice = prices[i]
+                    elif sellPrice < prices[i]:
+                        sellPrice = prices[i]
+                i += 1
+            if buyPrice and sellPrice:
+                profit += (sellPrice - buyPrice)
+            return profit
+        
+        def maxProfit(self, prices: List[int]) -> int:
+                # CORRECT WAY WITH INTEGRAL SUM INSTEAD OF HILL FINDING
+                profit = 0
+                prev = prices[0]
+                for i in range(1, len(prices)):
+                    if prices[i] > prev:
+                        profit += (prices[i] - prev)
+                    prev = prices[i]
+                return profit
+
+47) 2 Pointers to delimit sequence ranges, and enforce loop invariants: 
+     Use pointers to delimit correct and incorrect regions in sequences, and swap elements/process
+     to correct the incorrect sequence
+    while the slow and fast ptrs delimit regions, they also are pointing at critcal elements that can be 
+    swapping in and out, or sticking to a loop invariant, this makes writing the code easier. 
+
+     MOVE ZEROS:
+     Given an array nums, write a function to move all 0's to the end of it while 
+     maintaining the relative order of the non-zero elements.
+     OPTIMAL:
+     
+     the code will maintain the following invariant:
+     All elements before the slow pointer (lastNonZeroFoundAt) are non-zeroes.
+     All elements between the current and slow pointer are zeroes.
+ 
+     Therefore, when we encounter a non-zero element, we need to swap elements 
+     pointed by current and slow pointer, then advance both pointers. 
+     If it's zero element, we just advance current pointer.
+ 
+     void moveZeroes(vector<int>& nums) {
+         for (int lastNonZeroFoundAt = 0, cur = 0; cur < nums.size(); cur++) {
+             if (nums[cur] != 0) {
+                 swap(nums[lastNonZeroFoundAt++], nums[cur]);
+             }
+         }
+     }
+                
+
+48) LINKED LIST CHANGE VALUES INSTEAD OF NODE RELATIONSHIPS STRATEGY 
+
+     Delete a linked list node you have access to, but linked list is 
+     singly linked and you dont have access to  parent. 
+     
+     Soln: copy the value of the next node to our node. Then delete the next node. 
+
+
+49) Check cycle in directed graph (REMEMBER TO PUSH AND POP OFF THE RUNNING
+     RECURISIVE STACK/VISITED SET TO BE ABLE TO REPROCESS NODES ON DIFFERNT PATHS IN GRAPH):
+     (TREASURY PRIME QUIZ, DO IT THIS WAY OR WITH COLORS.)
+
+    def isThereCycle(self, node, visited=set()):        
+        visited.add(node)          
+        kids = self.graph.get(node)
+        if kids: 
+            for kid in kids:
+                # print("For parent, examining child", (node, kid))
+                if kid in visited:
+                    return True
+                else:
+                    result = self.isThereCycle(kid, visited)
+                    if result == True:
+                        return True 
+        visited.remove(node)
+        return False
+
+
+50) Different ways to backtrack:
+    1) Use colors, either 2 with visited set, or 3 when you need to record times in DFS, 
+    2) 3 colors is also similar to pushing and popping off a recursive stack to reprocess elements 
+       you saw. This is used when you want to get all paths from source to target, so you need to
+       reuse nodes/detect all cycles for instance.  
+
+    ALL Paths from source to target:
+    Given a directed, acyclic graph of N nodes.  
+    Find all possible paths from node 0 to node N-1, and return them in any order.
+    
+    # DYNAMIC PROGRAMMING SOLUTION TOP-DOWN!! BY USING @lru_cache(maxsize=None)
+    # THIS SOLUTION IS BAD BECAUSE WE ARE NOT USING DEQUE AND APPENDLEFT, 
+    # LIST MERGING AND INSERTION TO FRONT IS O(N)!!!
+    
+    #The two approach might have the same asymptotic time 
+    #complexity. However, in practice the DP approach is 
+    #slower than the backtracking approach, since we copy the intermediate paths over and over.
+
+    #Note that, the performance would be degraded further, 
+    #if we did not adopt the memoization technique here.
+
+    class Solution:
+        def allPathsSourceTarget(self, graph: List[List[int]]) -> List[List[int]]:
+            
+            # apply the memoization
+            @lru_cache(maxsize=None)
+            def dfs(node):
+                
+                if node == len(graph) - 1:
+                    return [[len(graph) - 1]]
+                
+                kids  = graph[node]
+                
+                # all paths from node to target. 
+                paths = []
+                
+                for kid in graph[node]:
+                    res = dfs(kid)
+                    # add node to front of each result!
+                    for result in res:
+                        paths.append([node] + result)
+                
+                return paths
+            return dfs(0)
+
+    # BETTER, ALSO USES A DIFF APPROACH OF PUSHING AND POPPING EACH PATH PIECE IN FOR LOOP
+    class Solution:
+        def allPathsSourceTarget(self, graph: List[List[int]]) -> List[List[int]]:
+
+            target = len(graph) - 1
+            results = []
+
+            def backtrack(currNode, path):
+                # if we reach the target, no need to explore further.
+                if currNode == target:
+                    results.append(list(path))
+                    return
+                # explore the neighbor nodes one after another.
+                for nextNode in graph[currNode]:
+                    path.append(nextNode)
+                    backtrack(nextNode, path)
+                    path.pop()
+            # kick of the backtracking, starting from the source node (0).
+            path = deque([0])
+            backtrack(0, path)
+
+            return results
+
+
+51) Work with differences and gradients instead of RAW VALUES!!
+    It helps to solve the problem. Simplify problems by allocating 
+    everything to one group, then pulling the correct ones to the other group. 
+    Use slopes, intercepts, and think of problems geometrically when 
+    preprocessing AKA two city scheduling
+    (Please review two city scheduling . py now)
+
+51.5) DP -> if its too hard, sketch out top down soln before attempting bot up!!
+     Then use recursive arguments for OPT[][] -> create your OPT definition and 
+     write out when the finite state machine changes, as well as directionality on 
+     input. You can also take a look at space optimization after sketching out a first soln:
+
+        801. Minimum Swaps To Make Sequences Increasing
+        Hard
+
+        You are given two integer arrays of the same length nums1 and nums2. In one operation, 
+        you are allowed to swap nums1[i] with nums2[i].
+
+        For example, if nums1 = [1,2,3,8], and nums2 = [5,6,7,4], you can swap the element at i = 3 to 
+        obtain nums1 = [1,2,3,4] and nums2 = [5,6,7,8].
+        Return the minimum number of needed operations to make nums1 and nums2 strictly increasing. 
+        The test cases are generated so that the given input always makes it possible.
+
+        An array arr is strictly increasing if and only if arr[0] < arr[1] < arr[2] < ... < arr[arr.length - 1].
+
+        Example 1:
+
+        Input: nums1 = [1,3,5,4], nums2 = [1,2,3,7]
+        Output: 1
+        Explanation: 
+        Swap nums1[3] and nums2[3]. Then the sequences are:
+        nums1 = [1, 3, 5, 7] and nums2 = [1, 2, 3, 4]
+        which are both strictly increasing.
+        Example 2:
+
+        Input: nums1 = [0,3,5,8,9], nums2 = [2,1,4,6,9]
+        Output: 1
+
+    Soln:
+
+        from collections import defaultdict
+        class Solution:
+            '''
+            might be easier to think of it top down first for hard questions like this...
+            '''
+            def minSwapTD(self, nums1: List[int], nums2: List[int]) -> int:
+                @lru_cache(None)
+                def helper(swapped_prev, i):
+                    
+                    if i == len(nums1):
+                        return 0
+                    prev1 = None
+                    prev2 = None
+                    if swapped_prev == False:
+                        prev1 = float("-inf") if (i-1) < 0 else nums1[i-1]
+                        prev2 = float("-inf") if (i-1) < 0 else nums2[i-1]
+                    else:
+                        prev1 = float("-inf") if (i-1) < 0 else nums2[i-1]
+                        prev2 = float("-inf") if (i-1) < 0 else nums1[i-1]
+                    
+                    res1, res2 = float("inf"), float("inf")
+                    if(prev1 < nums1[i] and prev2 < nums2[i]):
+                        res1 = helper(False, i+1) 
+                    
+                    if(prev1 < nums2[i] and prev2 < nums1[i]):
+                        res2 = helper(True, i+1) + 1
+                    
+                    return min(res1, res2)
+                    
+                nums1.append(float("inf"))
+                nums2.append(float("inf"))
+                return helper(False, 0)
+            
+            '''
+            BOTTOM UP SOLN:
+            (There is a forward and backward version!)
+            
+            DP[swapped][i] = Min num of ops to make strictly increasing up to i
+                            swapped indicates given that we had swapped on index i to make it work!
+                            Consider swapped state when computing next state!
+            
+            # there might not even be certain states alowed -> set them to infinite for being invalid!
+            
+            State automata: 
+            
+            DP[false][i] = float("inf")    
+            DP[true][i] = float("inf")
+                
+            if nums1[i-1] < nums1[i] and nums2[i-1] < nums2[i]:
+                DP[false][i] = DP[false][i-1]    
+                DP[true][i] = DP[false][i-1] + 1
+                
+            if nums2[i-1] < nums1[i] and nums1[i-1] < nums2[i]:
+                DP[false][i] = min(DP[false][i], DP[true][i-1])
+                DP[true][i] = min(DP[true][i], DP[true][i-1], DP[false][i-1] + 1)
+            
+            DP[false][i] = DP[false][i-1]  # if we didnt swap in prev 
+            
+            # Does this mean the min operations if we consider the 
+            DP[true][i]   = (DP[true][i-1] + 1) VS   DP[false][i-1]
+            
+            We also have nums1[i], nums2[i]
+            Base Cases:
+            DP[true][0] = 0
+            DP[false][0] = 0
+            DP[][1]
+            '''
+            def minSwap(self, nums1: List[int], nums2: List[int]) -> int:
+                OPT = defaultdict()
+                OPT[True] = {}
+                OPT[False] = {}
+                
+                OPT[True][0] = 1 # incase you swapped the first index?
+                OPT[False][0] = 0
+
+                N = len(nums1)
+                for i in range(1, N):
+                    OPT[False][i] = float("inf")
+                    OPT[True][i] = float("inf")
+                    # The greatest difficulty came below where we have to think about 
+                    # state changes! There is a logical, creativity part to that. 
+                    if(nums1[i-1] < nums1[i] and nums2[i-1] < nums2[i]):
+                        OPT[False][i] = OPT[False][i-1] # it worked!
+                        # For the following line below we cant gurantee the swap would work! (wrong harman!)
+                        # OPT[True][i] = OPT[False][i-1] + 1 
+                        # if we are swapping again below, 
+                        # OPT[True][i] = OPT[True][]
+                        # if we swap below, to gurantee the order works, we have to cancel out the swap by swapping again
+                        OPT[True][i] = OPT[True][i-1] + 1
+                    if nums2[i-1] < nums1[i] and nums1[i-1] < nums2[i]:
+                        OPT[False][i] = min(OPT[False][i], OPT[True][i-1])
+                        OPT[True][i] = min(OPT[True][i], OPT[False][i-1] + 1) 
+
+                return min(OPT[True][N-1], OPT[False][N-1])
+                    
+        Another Soln:
+
+        @Acker help explain:
+
+        A[i - 1] < A[i] && B[i - 1] < B[i].
+        In this case, if we want to keep A and B increasing before the index i, can only have two choices.
+        -> 1.1 don't swap at (i-1) and don't swap at i, we can get not_swap[i] = not_swap[i-1]
+        -> 1.2 swap at (i-1) and swap at i, we can get swap[i] = swap[i-1]+1
+        if swap at (i-1) and do not swap at i, we can not guarantee A and B increasing.
+
+        A[i-1] < B[i] && B[i-1] < A[i]
+        In this case, if we want to keep A and B increasing before the index i, can only have two choices.
+        -> 2.1 swap at (i-1) and do not swap at i, we can get notswap[i] = Math.min(swap[i-1], notswap[i] )
+        -> 2.2 do not swap at (i-1) and swap at i, we can get swap[i]=Math.min(notswap[i-1]+1, swap[i])
+
+        def minSwap(self, A, B):
+            N = len(A)
+            not_swap, swap = [N] * N, [N] * N
+            not_swap[0], swap[0] = 0, 1
+            for i in range(1, N):
+                if A[i - 1] < A[i] and B[i - 1] < B[i]:
+                    swap[i] = swap[i - 1] + 1
+                    not_swap[i] = not_swap[i - 1]
+                if A[i - 1] < B[i] and B[i - 1] < A[i]:
+                    swap[i] = min(swap[i], not_swap[i - 1] + 1)
+                    not_swap[i] = min(not_swap[i], swap[i - 1])
+            return min(swap[-1], not_swap[-1])
+
+        In the above soln you can continue to optimize by only keeping the last state for swap and not_swap btw!!!
+        
+        def minSwap(self, A, B):
+            N = len(A)
+            not_swap, swap = 0, 1
+            for i in range(1, N):
+                not_swap2 = swap2 = N
+                if A[i - 1] < A[i] and B[i - 1] < B[i]:
+                    swap2 = swap + 1
+                    not_swap2 = not_swap
+                if A[i - 1] < B[i] and B[i - 1] < A[i]:
+                    swap2 = min(swap2, not_swap + 1)
+                    not_swap2 = min(not_swap2, swap)
+                swap, not_swap = swap2, not_swap2
+            return min(swap, not_swap)
+
+
+52) Flatten binary tree to linked list. 
+     Given a binary tree, flatten it to a linked list in-place.
+     Use right nodes when creating linked list. 
+     CAN DO THIS WITH O(1) SPACE LIKE SO:
+  
+     So what this solution is basically doing is putting the 
+     right subtree next to the rightmost node on the left subtree 
+     and then making the left subtree the right subtree and 
+     then making the left one null. Neat!
+     
+    class Solution:
+        # @param root, a tree node
+        # @return nothing, do it in place
+        def flatten(self, root):
+            if not root:
+                return
+            
+            # using Morris Traversal of BT
+            node=root
+            
+            while node:
+                if node.left:
+                    pre=node.left
+                    while pre.right:
+                        pre=pre.right
+                    pre.right=node.right
+                    node.right=node.left
+                    node.left=None
+                node=node.right
+
+
+53) Flattening a multilevel doubly linked list using a stack:
+        def flatten(self, head):
+            if not head:
+                return
+            
+            dummy = Node(0,None,head,None)     
+            stack = []
+            stack.append(head)
+            prev = dummy
+            
+            while stack:
+                root = stack.pop()
+
+                root.prev = prev
+                prev.next = root
+                
+                if root.next:
+                    stack.append(root.next)
+                    root.next = None
+                if root.child:
+                    stack.append(root.child)
+                    root.child = None
+                prev = root        
+                
+            # disengage dummy node
+            dummy.next.prev = None
+            return dummy.next
+
+54) Boyer moore voting algortihm:
+    given an array of n elements, tell me if there is an 
+    element that appears more than n/2 times.
+
+    Obviously this has a huge amount of uses.
+
+    The trivial solution would be to sort the array in O(n * log(n)) time and then
+
+    Boyer Moore Algorithm
+    This will require two passes, the first to find a 
+    possible candidate, and the second to verify that 
+    it is a candidate. The second part is 
+    trivial so we will not focus on it. The first sweep
+    however is a little bit more tricky.
+
+    We initialize a count to 0. Then as we proceed in the list, 
+    if the count is 0, we make the current value being
+    looked at the candidate. If the value we’re looking at 
+    is the candidate, then we increment the count by 1, 
+    otherwise we decrement the count.
+
+    Distributed Boyer-Moore
+    Determine how many cores/processors you have, and call it t. 
+    Now, split your array into t positions and run Boyer-Moore 
+    on each of these sections. You will get a candidate 
+    and a count from each of these sections. Now, 
+    recursively run Boyer-Moore on the list of 
+    [candidate1 * count1] + [candidate2 * count2] … . Pretty cool right!
+
+    Generalization
+    The generalized problem is given a list, 
+    find all elements of the list that occur more 
+    than n/k times. We simply have to carry 
+    the proof from the last case over and it applies directly.
+
+    Have a set of possible candidates, and have an associated count with them.
+
+    Iterate through the list, and if the item is in 
+    the dictionary, increment the count. If not and 
+    the number of elements in the dictionary is less 
+    than k, then just add it to the dictionary with count 1. 
+    Otherwise, decrement all the counters by 1, and delete 
+    any candidates with a counter 1.
+
+
+53) The art of segment trees and monoqueues:
+    PLEASE REVIEW SEGMENT TREES IN DATA STRUCTURES NOTES!!
+
+    Previously we saw segment trees.
+    That data structure was able to answer the question
+
+    reduce(lambda x,y: operator(x,y), arr[i:j], default)
+    and we were able to answer it in O(\log(j - i)) time. 
+    Moreover, construction of this data structure only took O(n) time. 
+    Moreover, it was very generic as operator and 
+    default could assume be any values.
+
+    This obviously had a lot of power, but we can use something a lot 
+    simpler if we want to answer easier problems. 
+    Suppose instead, we wanted to ask the question
+
+    reduce(lambda x,y: operator(x,y), arr[i:i + L])
+    with the caveat that operator(x,y) will return 
+    either x or y and that L remains fixed.
+
+    Some examples of this is to find the minimum of some 
+    fixed length range, or the maximum in some fixed length range.
+
+    Introducing, the Monotonic Queue, with the handy name Monoqueue.
+
+    The code for this guy is pretty self explanatory, but the basic idea 
+    is to maintain a sliding window that sweeps across. 
+    Moreover, the contents of the Monoqueue are sorted 
+    with respect to the comparator Operator, so to 
+    find the “best” in a range one only need look at the front.
+
+    from collections import deque
+    class Monoqueue:
+        def __init__(self, operator):
+            self.q = deque()
+            self.op = operator
+        
+        def get_best(self):
+            if not self.q:
+                return None
+            return self.q[0][0]
+        
+        '''
+
+        if q has elements, look at back of queue. 
+        pop the elements off that cannot be best possible (i think? WTF??)
+        Ok sure. What the count does is it shows the range for which 
+        it is the best possible value. once you exit the range, remove the front
+        of the queue, and go to the next best, which will be the best for a certain sized window
+        before another thing is the best. 
+        So we keep track of the bests at each step only, and keep the best even if we "pop" because
+        its located a lil to the right, of the thing you popped on the main stream. 
+        '''
+        def push(self, val):
+            count = 0
+            while self.q and self.op(val, self.q[-1][0]):
+                count += 1 + self.q[-1][1]
+                self.q.pop()
+            self.q.append([val, count])
+        '''
+        Pop front. only if count is == 0.
+        Otherwise, decrement the count. Why is the count important?
+        I guess the count keeps track of the range you are sliding across
+        so if you pop it, and slide to the right, its still THE BEST POSSIBLE VALUE 
+        (because the best possible value is located somewhere a lil to the right), 
+        because it was not actually popped. just some garbage element on the main list 
+        was popped. 
+        '''
+        def pop(self):
+            if not self.q:
+                return None
+            if self.q[0][1] > 0:
+                self.q[0][1] -= 1
+            else:
+                self.q.popleft()
+
+54) 3 POINTER PERFORMANCE OPTIMIZATION FOR O(N^2)
+     3SUM LEETCODE QUESTION/TRIANGLE NUMBERS LEETCODE 
+    -> You can use 3 pointers, with middle pointer iterating through array, 
+       and other 2 pointers moving left and right to find different numbers
+       to GET AN O(N^2) SOLUTION INSTEAD OF AN O(N^3) SOLUTION.
+
+
+55) Counting all subarrays trick with prefixes:
+     
+     1.   Subarray Sums Divisible by K
+    
+    Given an array A of integers, return the number of 
+    (contiguous, non-empty) subarrays that have a sum divisible by K.
+
+    Example 1:
+
+    Input: A = [4,5,0,-2,-3,1], K = 5
+    Output: 7
+    Explanation: There are 7 subarrays with a sum divisible by K = 5:
+    [4, 5, 0, -2, -3, 1], [5], [5, 0], [5, 0, -2, -3], [0], [0, -2, -3], [-2, -3]
+
+
+    class Solution(object):
+        def subarraysDivByK(self, A, K):
+            P = [0]
+            for x in A:
+                P.append((P[-1] + x) % K)
+
+            count = collections.Counter(P)
+            return sum(v*(v-1)/2 for v in count.values())
+
+
+-62) RECURSION AND ENUMERATION WITH FROZENSET AND DP:
+
+    You have a collection of coins, and you know the values of the 
+    coins and the quantity of each type of coin in it. You want to 
+    know how many distinct sums you can make from non-empty 
+    groupings of these coins.
+
+    Example
+
+    For coins = [10, 50, 100] and quantity = [1, 2, 1], the output should be
+    possibleSums(coins, quantity) = 9.
+
+    # RECURSIVE SOLUTION WITH DP. 
+    def possibleSums(coins, quantity):
+        @lru_cache(None)
+        def recursive(i):
+            if i == len(coins):
+                return frozenset([0])
+                
+            coinType = coins[i]
+            tot = quantity[i]
+            amts = recursive(i+1)
+            res = set()
+            for amt in amts:
+                for k in range(tot+1):
+                    res.add(amt + k*coinType)
+            return frozenset(res)
+            
+        s = recursive(0)
+        return len(s) - 1
+
+
+-81)MONTONIC QUEUE/STACK + CRITICAL ELEMENTS + LEFT RIGHT, THEN RIGHT LEFT TRICK:
+    Sometimes you have to look at critically ordered elements left to right, then 
+    right to left like product of array except self
+
+    Given an array of integers a, return a new array b using the following guidelines:
+
+    For each index i in b, the value of bi is the index of the aj 
+    nearest to ai and is also greater than ai.
+    If there are two options for bi, put the leftmost one in bi.
+    If there are no options for bi, put -1 in bi.
+    Example
+
+    For a = [1, 4, 2, 1, 7, 6], the output should bbe
+    nearestGreater(a) = [1, 4, 1, 2, -1, 4].
+
+
+    def nearestGreater(a):
+        # n log n solution with binary search, on sorted array!
+        '''
+        Can do with sorting + keeping track of index + binary search
+        Faster soln (MONTONIC QUEUE/STACK + CRITICAL ELEMENTS + LEFT RIGHT, THEN RIGHT LEFT TRICK): 
+        
+        process left to right. when i use word queue below, i mean stack.  
+        
+        keep elements in queue. 
+        go left to right. 
+        
+        pick up elements as you go left to right.
+        
+        when you see smaller element, check queue. if queue has smaller element, remove it 
+        because it is no longer a critical point, the element we just saw is a critical point 
+        that can be a larger element. 
+        
+        to get nearest! -> we redo algo right to left, 
+        after doing it left to right, and overwrite the soln 
+        when we find a better one aka closer one!   
+        '''
+        result = [None for i in range(len(a))]
+        
+        stack = [] 
+        
+        # left to right
+        for idx, el in enumerate(a):
+            while len(stack) > 0:    
+                if stack[-1][0] <= el:
+                    stack.pop()
+                else:
+                    break
+                    
+            if len(stack) > 0:    
+                result[idx] = stack[-1][1]
+            
+            stack.append([el, idx])
+        
+        # generator
+        def enumerate_reversed(L):
+            for index in reversed(range(len(L))):
+                yield index, L[index]
+
+        stack = []
+        # right to left
+        for idx, el in enumerate_reversed(a):
+            while len(stack) > 0:    
+                if stack[-1][0] <= el:
+                    stack.pop()
+                else:
+                    break
+                    
+            if len(stack) > 0:
+                if result[idx] is None or abs(idx - result[idx]) > abs(idx - stack[-1][1]):
+                    result[idx] = stack[-1][1] 
+            
+            if result[idx] is None:
+                result[idx] = -1
+            
+            stack.append([el, idx])
+        return result
+
+
+
+-72) Getting tripped up by doordash challanege:
+     WHEN TO USE DP VS SORTING+GREEDY+MAXIMALMUNCH+HEAPQ SOLUTION/HILLFINDING. 
+
+    Question: 
+    So given drivers, they have speed, and professionalism such as:
+    5 drivers and [100, 12, 4, 23, 5], [20, 30, 50, 12, 12]
+
+    We can only select a maximum of 3 drivers and a minium of 1. 
+    We want to get the max quality of a set of drivers 
+    where quality = (Sum of drivers speed ) * min(of all drivers professionalism)
+
+    What we can do is sort by professionals, so we can always take the best drivers first
+    and then the worse drivers next. And we should take maximal because its sum for the speed.
+    HOWEVER WE ARE LIMITED IN THE NUMBER OF MAX DRIVERS WE CAN TAKE.
+    TO DEAL WITH THAT USE A HEAPQ TO STORE THE CURRENT SUM OF DRIVERS, AND POP THE SMALLEST
+    VALUE DRIVER FROM SET OF DRIVERS.
+    and keep track of max sum as you do this. 
+    
+
+    Initially i tried to solve with DP because thinking through the problem was hard.
+    You should know when to use dp and when not too. YOU MUST START BY EXPLOITING PROBLEM 
+    STRUCTURE AND THINKING GREEDY IN ALL DIRECTONS. Then when you figure that out, 
+    TRY HILL FINDING WITH A DEQUE/HEAPQ/SEGMENT TREE. 
+
+    THAT IS THE WAY!!!!
+    SOLUTION BELOW: 
+
+
+    from heapq import heappush, heappop
+
+    def maximumTeamQuality(speed, professionalism, maxDashers):
+        '''
+        sort by professionalism.
+        
+        keep taking ppl, and update max?
+        as we reduce professionalism -> speed increases. 
+        and we should always take everyone thats more professional
+        '''  
+        
+        zipped = sorted(zip(professionalism, speed), key=lambda x: x[0], reverse=True)
+                
+        # pop the lowest sum element each time when we go over maxDashers!
+        # since the professionalism doesnt matter for the chosen ones if we choosing lower
+        # professionalism one. 
+        # need minheap.
+        
+        maxQ = 0
+        curr_sum = 0
+        h = []
+        
+        for p, s in zipped: 
+            curr_sum += s
+            # check
+            if len(h) == maxDashers:
+                smallest = heappop(h)
+                curr_sum -= smallest[0]
+                
+            heappush(h, [s])    
+
+            maxQ = max(maxQ, curr_sum*p)
+        return maxQ
+
+-69) You can return a deduplicated sorted list of combinations from a 
+     sorted list that has repeated values without using the sort function, or sets.
+     When you dfs, include a limit argument, and dont include the current argument in the take/donttake 
+     if its the same as the previous argument, and the previous argument was not taken. 
+     Look at sumSubsets for more info. 
+
+
+-100) MOD TRICKS -> GET MOD IN BETWEEN [0, K]
+
+
+    /*
+    1.    Check If Array Pairs Are Divisible by k
+    Medium
+    Share
+    Given an array of integers arr of even length n and an integer k.
+    We want to divide the array into exactly n / 2 pairs such that the sum of each pair is divisible by k.
+    Return True If you can find a way to do that or False otherwise.
+
+        #include <bits/stdc++.h> 
+
+        class Solution {
+        public:
+            bool canArrange(vector<int>& arr, int k) {
+                unordered_multiset<int> s;
+                
+                for(auto & i : arr) {
+                    if(i < 0){ 
+                        // HOW TO MAKE NUMBER POSITIVE
+                        i += (abs(i)/k + (i%k != 0))*k;
+                    }
+                    // ANOTHER WAY  TO KEEP MODS BETWEEN [0, K-1 is just do following]
+                    // i = (i%k + k)%k
+                    if(s.find(k - i%k) != s.end()) {
+                        s.erase(s.find(k - i%k));
+                    } else {
+                        if(i%k == 0) {
+                            s.insert(k);
+                        }else {                
+                            s.insert(i%k);
+                        }
+                    }
+                }
+                if(s.size() == 0) {
+                    return true;
+                }
+                return false;
+            }
+        };
+
+
+    // VERY CLEAN SOLUTION
+
+    class Solution {
+    public:
+        bool canArrange(vector<int>& arr, int k) {
+            vector<int> freq(k);
+            
+            for (int x : arr)
+                freq[((x % k) + k) % k]++;
+            
+            if (freq[0] % 2)
+                return false;
+            
+            for (int i=1, j=k-1; i<j; i++, j--)
+                if (freq[i] != freq[j])
+                    return false;
+            
+            return true;
+        }
+    };
+
+    /*
+    FASTER CPP SOLUTIONS
+    */
+
+    class Solution {
+    public:
+        bool canArrange(vector<int>& arr, int k) {
+            vector<int> freq(k,0);
+            int n = arr.size();
+            for(int i = 0; i < n; ++i) {
+                if(arr[i] >= 0) {
+                    freq[arr[i] % k] = ((freq[arr[i] % k] + 1) % k);
+                }
+                else {
+                    int temp = k - abs(arr[i] % k);
+                    if(temp == k)
+                        temp = 0;
+                    freq[temp] = ((freq[temp] + 1) % k);
+                }
+            }
+
+            if(freq[0] % 2 != 0) 
+                return false;
+            for(int i = 1; i <= freq.size() / 2; i++){
+                if(freq[i] != freq[k - i]) return false;
+            }
+            return true;
+        }
+        
+    };
+
+    static const auto speedup = []() {
+            std::ios::sync_with_stdio(false); std::cin.tie(nullptr); cout.tie(nullptr); return 0;
+    }();
+
+
+
+-99) Use 2 MULTISET TREEMAPS instead of 2 Heaps for Median Finding Trick!!
+    1)   Sliding Window Median
+    (However slightly slower because of log(N) 
+    cost retrival of best elements vs PQ)
+    Window position                Median
+    ---------------               -----
+    [1  3  -1] -3  5  3  6  7       1
+    1 [3  -1  -3] 5  3  6  7       -1
+    1  3 [-1  -3  5] 3  6  7       -1
+    1  3  -1 [-3  5  3] 6  7       3
+    1  3  -1  -3 [5  3  6] 7       5
+    1  3  -1  -3  5 [3  6  7]      6
+
+        class Solution {
+        public:
+            void insertTree(int element, multiset<double> & l, multiset<double> & r) {
+                if(l.size() == r.size()) {
+                    // insert into left. 
+                    
+                    if(r.size() > 0 && *(r.begin()) < element) { 
+                        double temp = *(r.begin());
+                        
+                        // ERASING BY VALUE IS BUG FOR MULTISET BECAUSE IT REMOVES ALL COPIES
+                        // ONLY ERASE THE ITERATOR!! TO ERASE ONE. 
+                        r.erase(r.begin());
+                        r.insert(element);
+                        element = temp;
+                    }
+                    l.insert(element);
+                } else {
+                    // l is bigger, insert into right. 
+                    
+                    if( *(--l.end()) > element ) {
+                        double temp = *(--l.end()) ;
+                        l.erase(--l.end()); //COOL TIP, YOU CAN ERASE WITH EITHER VALUE OR ITERATOR
+                        l.insert(element);
+                        element = temp; 
+                    }
+                    
+                    r.insert(element);
+                }
+            }
+            
+            void deleteTree(int element, multiset<double> & l, multiset<double> & r ) {
+                // Find tree that contains element, remove, then rebalance. 
+                bool leftBigger = l.size() > r.size();
+                
+                auto leftSearch =l.find(element);  
+                if( leftSearch != l.end()) {
+                    l.erase(leftSearch);
+                    // if left is greater than right by 1 dont do anything    
+                    // if left is same size as right, move right element to left.  
+                    if(!leftBigger) {
+                        // move right to left. 
+                        auto rightEle = *(r.begin());
+                        r.erase(r.begin());
+                        l.insert(rightEle);
+                    }            
+                } else {
+                    // search right, has to contain it.  
+                    auto rightSearch = r.find(element);
+                    r.erase(rightSearch);
+                    
+                    // if left is same size as right do nothing
+                    // otherwise, move left to right. 
+                    
+                    if(leftBigger) {
+                        auto leftEle = *(--l.end());
+                        l.erase(--l.end());
+                        r.insert(leftEle);
+                    }
+                }
+            }
+            
+            
+            double calcMedian(const multiset<double> & l, const multiset<double> & r) {
+            // always ensure left has 1 more element than right. 
+            // then always return *(left.end() - 1)
+                
+                if(l.size() == r.size()) {
+                    
+                    return ( *(--l.end()) + *(r.begin()) ) / 2.0;  
+                }  else {
+                    return *(--l.end());
+                }
+            } 
+            
+            vector<double> medianSlidingWindow(vector<int>& nums, int k) {    
+                // keep 2 multsets. 
+                multiset<double> l;
+                multiset<double> r;
+                
+                int i = 0;
+                int j = 0;
+
+                while(j < k) {            
+                    insertTree(nums[j], l, r);
+                    j += 1;
+                }
+                
+                vector<double> res;
+                double med = calcMedian(l, r);
+                res.push_back(med);
+                
+                while(j != nums.size()) {            
+                    insertTree(nums[j], l, r);
+                    deleteTree(nums[i], l, r);
+                
+                    med = calcMedian(l, r);
+                    res.push_back(med);
+                    i += 1;
+                    j += 1;
+                }
+                return res;    
+            }
+        };
+
+
+-98) C++ A Priority Queue USAGE VS BINARY TREE MAP USAGE: 
+    
+    1. Find K Pairs with Smallest Sums
+
+    You are given two integer arrays nums1 and nums2 
+    sorted in ascending order and an integer k.
+
+    Define a pair (u,v) which consists of one element from the first 
+    array and one element from the second array.
+
+    Find the k pairs (u1,v1),(u2,v2) ...(uk,vk) with the smallest sums.
+
+    Example 1:
+
+    Input: nums1 = [1,7,11], nums2 = [2,4,6], k = 3
+    Output: [[1,2],[1,4],[1,6]] 
+    Explanation: The first 3 pairs are returned from the sequence: 
+                [1,2],[1,4],[1,6],[7,2],[7,4],[11,2],[7,6],[11,4],[11,6]
+    Example 2:
+
+    Input: nums1 = [1,1,2], nums2 = [1,2,3], k = 2
+    Output: [1,1],[1,1]
+    Explanation: The first 2 pairs are returned from the sequence: 
+                [1,1],[1,1],[1,2],[2,1],[1,2],[2,2],[1,3],[1,3],[2,3]
+    Example 3:
+
+    Input: nums1 = [1,2], nums2 = [3], k = 3
+    Output: [1,3],[2,3]
+    Explanation: All possible pairs are returned from the sequence: [1,3],[2,3]
+
+    C++ SOLUTION A (fastest):
+
+    class Solution {
+        public:
+        vector<pair<int, int>> kSmallestPairs(vector<int>& nums1, vector<int>& nums2, int k) {
+            vector<pair<int,int>> result;
+            if (nums1.empty() || nums2.empty() || k <= 0)
+                return result;
+            auto comp = [&nums1, &nums2](pair<int, int> a, pair<int, int> b) {
+                return nums1[a.first] + nums2[a.second] > nums1[b.first] + nums2[b.second];};
+            priority_queue<pair<int, int>, vector<pair<int, int>>, decltype(comp)> min_heap(comp);
+            min_heap.emplace(0, 0);
+            while(k-- > 0 && min_heap.size())
+            {
+                auto idx_pair = min_heap.top(); min_heap.pop();
+                result.emplace_back(nums1[idx_pair.first], nums2[idx_pair.second]);
+                if (idx_pair.first + 1 < nums1.size())
+                    min_heap.emplace(idx_pair.first + 1, idx_pair.second);
+                if (idx_pair.first == 0 && idx_pair.second + 1 < nums2.size())
+                    min_heap.emplace(idx_pair.first, idx_pair.second + 1);
+            }
+            return result;
+        }
+    };
+
+
+
+    C++ SOLUTION B (slower):
+
+    struct compare
+    {
+        bool operator() (const pair<int, int> & a, const pair<int, int> & b)
+        {
+            return a.first + a.second >= b.first + b.second;
+        }
+    };
+
+    class Solution {
+    public:
+        vector<vector<int>> kSmallestPairs(vector<int>& nums1, vector<int>& nums2, int k) {
+            
+            if (nums1.empty() || nums2.empty() || k == 0)
+                return {};
+                
+            priority_queue< pair<int, int>, vector<pair<int, int>>, compare > que;
+            
+            int N = nums1.size();
+            int M = nums2.size();
+            
+            for (int i = 0; i < N; i++)
+            {
+                for (int j = 0; j < M; j++)
+                {
+                    que.push({nums1[i], nums2[j]});       
+                }
+            }
+            
+            vector<vector<int>> ans;
+            
+            int count = min(k, (int)que.size());
+            
+            for (int s = 0; s < count; s++)
+            {
+                auto item = que.top();
+                que.pop();
+                
+                ans.push_back({});
+                ans.back().push_back(item.first);
+                ans.back().push_back(item.second);
+            }
+            
+            return ans;
+        }
+    };
+
+
+    class Solution {
+    public:
+        vector<vector<int>> kSmallestPairs(vector<int>& v1, vector<int>&v2, int k) {
+            map<int,vector<pair<int,int>>>mp;
+            int sz1=v1.size(),sz2=v2.size();
+            for(int i=0;i<sz1;++i){
+                for(int j=0;j<sz2;++j)
+                    mp[v1[i]+v2[j]].push_back({v1[i],v2[j]});
+            }
+
+            vector<vector<int>>res;
+            for(auto it=mp.begin();it!=mp.end();++it){
+                for(pair<int,int>p:it->second){
+                    if(res.size()==k)
+                    break;
+                    res.push_back({p.first,p.second});
+                }
+            }
+            return res;
+        }
+    };
+
+
+-68) Counting clouds by removing and growing as an alternative DFS:
+
+    Given a 2D grid skyMap composed of '1's (clouds) and '0's (clear sky), 
+    count the number of clouds. A cloud is surrounded by clear sky, and is 
+    formed by connecting adjacent clouds horizontally or vertically. 
+    You can assume that all four edges of the skyMap are surrounded by clear sky.
+
+    Example
+
+    For
+
+    skyMap = [['0', '1', '1', '0', '1'],
+              ['0', '1', '1', '1', '1'],
+              ['0', '0', '0', '0', '1'],
+              ['1', '0', '0', '1', '1']]
+    the output should be
+    countClouds(skyMap) = 2;
+    
+    
+    def countClouds(skyMap):
+        if not skyMap or not skyMap[0]:
+            return 0
+        m, n = len(skyMap), len(skyMap[0])
+        ones = {(i, j) for i in range(m) for j in range(n) if skyMap[i][j] == '1'}
+        cc = 0
+        while ones:
+            active = {ones.pop()}
+            while active:
+                ones -= active
+                nxt_active = set()
+                for x, y in active:
+                    for dx, dy in ((-1,0), (1,0), (0,-1), (0,1)):
+                        if 0 <= x+dx < m and 0 <= y + dy < n and \
+                            (x+dx, y+dy) in ones:
+                            nxt_active.add((x+dx, y+dy))
+                active = nxt_active
+            cc += 1
+        return cc
+
+
+2 - Given an array of integers, find the subarray with maximum XOR. 
+
+        Think of cumulatives and starting from beginning simialar to above problem. 
+
+        Similar to previous problem:
+        Cool XOR trick to solve problem:
+        -> F(L, R) is XOR subarray L to R
+        F(L, R) = F(1, R) ^ F(1, L-1)
+    */
+
+
+
+
+-67) Lazy updates to build faster data structures (aka min stack extended ):
+
+        Similar hill finding question from IMC oa: 
+        Techniques: for stack 2.0, where we create a stack
+        but we can also increment alll elements below index i 
+        by a value
+        
+        -> implement push, pop, increment(index i, value v)
+        you use 2 stacks, and we do LAZY updates. Similar to min stack.
+        When we access an element that should have been increment. 
+        add stack value + increment stack value. 
+        When we increment we only save it at index i. not [0...i] with for loop
+        to do O(1) lookup, push, pop, increment. And when we pop that index,
+        assign to index i-1.
+        
+        THE IDEA IS: -> look at the very specific constraints of problem and solve 
+        for only what it is asking. nothing more (which allows you to simplify and 
+        improve solutions).
+        
+        Try to solve by being as LAZY as possible, and keeping track of critical indexes. 
+        Do it similar to how you as a lazy human would solve it IRL. 
+        
+        By waiting to do operations until it is necessary -> and being GREEDY and smart 
+        about how to update the state of the problem for only the next state[and just the next state], 
+        and not all states, we optimized stack 2.0. 
+
+        IMPLEMENTATION OF SUPER STACK:
+    
+        def superStack(operations):
+            stack = []
+            inc = []
+            result = []
+            '''
+            Save and propogate lazy updates using inc[]
+            based on how we access stack 
+            '''
+            for op in operations:
+                
+                items = op.split()
+                cmd = items[0]  
+                if cmd == "push":
+                    stack.append(int(items[1]) )
+                    inc.append(0)
+                elif cmd == "pop":
+                    if len(stack) > 0:
+                        stack.pop()
+                        poppedInc = inc.pop()
+                        if len(inc) > 0:
+                            inc[-1] += poppedInc
+                elif cmd == "inc":
+                    # inc 2 2
+                    pos, val = int(items[1]), int(items[2])
+                    inc[pos-1] += val
+                
+                if len(stack) > 0:
+                    print(stack[-1] + inc[-1])
+                else:
+                    print("EMPTY")
+
+
+
+-66)  Hill finding w/ stacks and queues and lazy updates in data structures: 
+
+        '''
+        Given an array a composed of distinct elements, find 
+        the next larger element for each element of the array, i.e. 
+        the first element to the right that is greater than this element, 
+        in the order in which they appear in the array, and return the 
+        results as a new array of the same length. If an element does 
+        not have a larger element to its right, put -1 in the 
+        appropriate cell of the result array.
+
+        Example
+
+        For a = [6, 7, 3, 8], the output should be
+        nextLarger(a) = [7, 8, 8, -1]
+
+        '''
+        # use queue. 
+        '''
+        HILL FINDING WITH CRITICAL INDEXES + LAZINESS LECTURE.  
+        KEEP TRACK OF KEY POINTS ONLY IN QUEUE/STACK. 
+        NO WASTE IN QUEUE, JUST WHAT WE NEED. 
+        AKA hill finding.         
+        '''
+
+        def nextLarger(a):        
+            st = []
+            res = []
+
+            for i in range(len(a)-1, -1, -1):
+                val = a[i]
+                while len(st) > 0:
+                    if a[i] > st[-1]:
+                        st.pop()
+                    else:
+                        break     
+                if len(st) == 0:
+                    res.append(-1)
+                else:
+                    res.append(st[-1])
+                st.append(val)
+            return res[::-1]
+
+
+
+-65) REGEX REVIEW USAGE:
+
+    You categorize strings into three types: good, bad, or mixed. If a string has 
+    3 consecutive vowels or 5 consecutive consonants, or both, then it is categorized 
+    as bad. Otherwise it is categorized as good. Vowels in the English alphabet are 
+    ["a", "e", "i", "o", "u"] and all other letters are consonants.
+
+    The string can also contain the character ?, which can be replaced by either a 
+    vowel or a consonant. This means that the string "?aa" can be bad if ? is a 
+    vowel or good if it is a consonant. This kind of string is categorized as mixed.
+
+    Implement a function that takes a string s and returns its category: good, bad, or mixed.
+
+    def classifyStrings(s):
+        if re.search(r"[aeiou]{3}|[^aeiou?]{5}", s):
+            return "bad"
+        if "?" not in s:
+            return "good"
+        a = classifyStrings(s.replace("?", "a", 1))
+        b = classifyStrings(s.replace("?", "b", 1))
+        return "mixed" if a != b else a
+
+
+-64) Bomber DP or is the DP just precomputation below? you should check:
+    (CAN DO WITH PRECOMPUTATION BUT LETS DO WITH DP!!!)
+    
+    Each cell in a 2D grid contains either a wall ('W') or an 
+    enemy ('E'), or is empty ('0'). Bombs can destroy enemies, 
+    but walls are too strong to be destroyed. A bomb placed in 
+    an empty cell destroys all enemies in the same row and column, 
+    but the destruction stops once it hits a wall.
+
+    Return the maximum number of enemies you can destroy using one bomb.
+
+    Note that your solution should have O(field.length · field[0].length) 
+    complexity because this is what you will be asked during an interview.
+
+    Example
+    For
+    field = [["0", "0", "E", "0"],
+            ["W", "0", "W", "E"],
+            ["0", "E", "0", "W"],
+            ["0", "W", "0", "E"]]
+    the output should be
+    bomber(field) = 2.
+
+    Sol'n A Easy (Cool Top Down):
+        from functools import lru_cache
+        def bomber(q):
+            if not q or not q[0]:
+                return 0
+            a , b = len(q),len(q[0])
+            @lru_cache(maxsize=None)
+            def g(m,n,x,y):
+                return 0 if m<0 or n<0 or m>=a or n>=b or q[m][n]=="W" \
+                    else g(m + x,n + y,x,y)+(q[m][n]=="E")
+            ans = 0
+            for i in range(a):
+                for j in range(b):
+                    if q[i][j] == "0":
+                        ans = max(ans,g(i-1,j,-1,0)+g(i,j-1,0,-1)+g(i+1,j,1,0)+g(i,j+1,0,1))
+            return ans
+    Soln B:
+        def bomber(F):
+            if not F or not F[0]         :   return 0
+            row ,col = len(F) ,len(F[0]) ;   F = numpy.array(F)
+            dp = numpy.zeros((row,col))  ;   t = zip(*numpy.where(F == 'E'))
+            for x,y in t:
+                for i in range(y-1,-1,-1):   
+                    if F[x,i] == 'W'  :   break
+                    if F[x,i] == '0' :   dp[x,i]+=1 
+                for i in range(y+1,col):
+                    if F[x,i] == 'W'  :   break
+                    if F[x,i] == '0'  :   dp[x,i]+=1 
+                for i in range(x-1,-1,-1):
+                    if F[i,y] == 'W'  :   break
+                    if F[i,y] == '0'  :   dp[i,y]+=1 
+                for i in range(x+1,row):
+                    if F[i,y] == 'W'  :   break
+                    if F[i,y] == '0'  :   dp[i,y]+=1 
+            return dp.max()
+
+    Soln C:
+        def bomber(A):
+            from itertools import groupby
+            if not A or not A[0]: return 0
+            R, C = len(A), len(A[0])
+            dp = [ [0] * C for _ in xrange(R) ]
+            for r, row in enumerate(A):
+                c = 0
+                for k, v in groupby(row, key = lambda x: x != 'W'):
+                    w = list(v)
+                    if k:
+                        enemies = w.count('E')
+                        for c2 in xrange(c, c + len(w)):
+                            dp[r][c2] += enemies
+                    c += len(w)
+
+            for c, col in enumerate(zip(*A)):
+                r = 0
+                for k, v in groupby(col, key = lambda x: x != 'W'):
+                    w = list(v)
+                    if k:
+                        enemies = w.count('E')
+                        for r2 in xrange(r, r + len(w)):
+                            dp[r2][c] += enemies
+                    r += len(w)
+            
+            ans = 0
+            for r, row in enumerate(A):
+                for c, val in enumerate(row):
+                    if val == '0':
+                        ans = max(ans, dp[r][c])
+            return ans
+
+-63) IMPORTANT TRICK: 
+     PRECOMPUTING LEFT AND RIGHT INDEX SUMS WITH KADANES
+
+    Strategy:
+        Try other precomputes besides cumulative sums. 
+        Use the precomputed solution for one problem to 
+        make several other precomputes that can be used for 
+        a more difficult but similarly looking problem!!! 
+
+        For instance pre-computes of the Kadane algorithm.
+
+    WITH KADANES, YOU CAN PRECOMPUTE maximum array sum that starts at i, 
+    and max array sum that ends at j. and use these to solve a question.
+
+    Problem: max_double_slice_sum
+
+    A non-empty array A consisting of N integers is given.
+
+    A triplet (X, Y, Z), such that 0 ≤ X < Y < Z < N, is called a double slice.
+
+    The sum of double slice (X, Y, Z) is the total of 
+        A[X + 1] + A[X + 2] + ... + A[Y − 1] + A[Y + 1] + A[Y + 2] + ... + A[Z − 1].
+
+        A[0] = 3
+        A[1] = 2
+        A[2] = 6
+        A[3] = -1
+        A[4] = 4
+        A[5] = 5
+        A[6] = -1
+        A[7] = 2
+        
+    contains the following example double slices:
+
+    double slice (0, 3, 6), sum is 2 + 6 + 4 + 5 = 17,
+    double slice (0, 3, 7), sum is 2 + 6 + 4 + 5 − 1 = 16,
+    double slice (3, 4, 5), sum is 0.
+    The goal is to find the maximal sum of any double slice.
+
+    Write a function:
+
+    def solution(A)
+    that, given a non-empty array A consisting of N integers, 
+    returns the maximal sum of any double slice.
+
+    For example for above array,
+    the function should return 17, because no double 
+    slice of array A has a sum of greater than 17.
+
+    ALGORITHM:
+    You can use a modified form of Kadane's algorithm that 
+    calculates the MAX Sum subarray ending at each index.
+    
+    For each index, calculate the max_sum_ending_at[i] value 
+    by using Kadane's algorithm in forward direction.
+    
+    For each index, calculate the max_sum_starting_from[i] 
+    value by using Kadane's algorithm in reverse direction.
+    
+    Iterate these arrays simultaneously and choose the 'Y' that has the maximum value of
+
+    max_sum_ending_at[Y-1] + max_sum_starting_from[Y+1]
+
+
+    def solution(A):
+        l_max_slice_sum = [0] * len(A)
+        r_max_slice_sum = [0] * len(A)
+
+        for i in range(1, len(A)-2): # A[X + 1] + A[X + 2] + ... + A[Y − 1]
+            # Let's assume that Y is equal to i+1.
+            # If l_max_slice_sum[i-1] + A[i] is negative, we assign X to i.
+            # It means that the slice sum is 0 because X and Y are consecutive indices.
+            l_max_slice_sum[i] = max(l_max_slice_sum[i-1] + A[i], 0)
+
+        for i in range(len(A)-2, 1, -1): # A[Y + 1] + A[Y + 2] + ... + A[Z − 1]
+            # We suppose that Y is equal to i-1.
+            # As aforementioned, Z will be assigned to i if r_max_slice_sum[i+1] + A[i]
+            # is negative, and it returns 0 because Y and Z becomes consecutive indices.
+            r_max_slice_sum[i] = max(r_max_slice_sum[i+1] + A[i], 0)
+
+        max_slice_sum = l_max_slice_sum[0] + r_max_slice_sum[2]
+        for i in range(1, len(A)-1):
+            # Let's say that i is the index of Y.
+            # l_max_slice_sum[i-1] is the max sum of the left slice, and
+            # r_max_slice_sum[i+1] is the max sum of the right slice.
+            max_slice_sum = max(max_slice_sum, l_max_slice_sum[i-1]+r_max_slice_sum[i+1])
+            
+        return max_slice_sum
+
+70) Cycle detection in directed graph using BFS, and topological sort 
+     with indegree count. 
+
+    from collections import deque
+    def hasDeadlock(connections):
+        '''
+        If j is in the list connections[i], then there is a directed edge from process i to process j.
+        For connections = [[1], [2], [3, 4], [4], [0]], the output should be
+        hasDeadlock(connections) = true.
+        '''
+        N = len(connections)
+        
+        reverse_g = [[] for i in range(N)]
+        for parent, kids in enumerate(connections):
+            for k in kids:
+                reverse_g[k].append(parent)
+                
+        indegree = {}
+        q = deque([])
+        
+        for node, kids in enumerate(reverse_g):
+            indegree[node] = len(kids)
+            if indegree[node] == 0:
+                q.append(node)
+        
+        # no root nodes then cycle.
+        if len(q) == 0:
+            return True
+        
+        visited = set()
+        
+        while q:
+            print("process", q)
+            
+            node = q.popleft()
+            kids = connections[node]
+            
+            visited.add(node)
+            
+            for k in kids:
+                indegree[k] -= 1
+                
+                print("SAW KID with indg", k, indegree[k])
+                if(indegree[k] == 0):
+                    q.append(k)
+                #elif(indegree[k] <  0):
+                    # this elif was wrong because indegree will never fall below 0.
+                    # it just wont ever be added to queue if its part of cycle. 
+                    # Cycle because the indegrees dropped below 0!
+                    # return True
+
+        if len(visited) == N: # No cycle
+            return False
+        else:
+            return True # yes cycle
+
+
+-78) Maximal Square DP - DP vs cumulative array strategy?
+    
+    You have a 2D binary matrix that's filled with 0s and 1s. 
+    In the matrix, find the largest square that 
+    contains only 1s and return its area.
+
+    NOTES:
+        When a problem looks like a cumulative array problem try other accumulations,
+        rather than sum, such as 2d segment trees, or 2d maximum slice accumations.
+
+        In this probem -> we did our accumulation based on 3 other coordinates in matrix. 
+        Up your preprocessing game
+        ALWAYS USE THE DIAGONAL SOMEHOW IN 2D ARRAYS + DONT FORGET TOP-LEFT COORDINATE.
+    
+    SOLUTION:
+        def maximalSquare(matrix):
+            
+            '''
+            then do maximal rectangle. 
+            Go right and go down. 
+            question -> how many 1's below me?
+            
+            1 1 1 1
+            1 2 2 2 
+            1 2 3
+
+            Recurrence:
+            dp(i,j) = min(dp(i−1, j), dp(i−1, j−1), dp(i, j−1)) + 1
+
+            BASE CASE: 
+            matrix[i,j] == '0' THEN return 0        
+            '''
+            R = len(matrix)
+            if R == 0:
+                return 0
+            C = len(matrix[0])
+            prevRow = [0 for j in range(C+1)]
+            maxSquare = 0
+            for i in range(R):
+                # we have to zero pad. 
+                currRow = [0]
+                
+                for j in range(1, C+1):
+                    # if current value is 0, put 0.
+                    val = matrix[i][j-1]
+                    if val == "0":
+                        currRow.append(0)
+                    else:
+                        minOfTopAndLeft = min(currRow[-1], prevRow[j-1], prevRow[j])
+                        cellVal = minOfTopAndLeft + 1
+                        maxSquare = max(maxSquare, cellVal**2)
+                        currRow.append(cellVal)
+                        
+                prevRow = currRow[::]
+            return maxSquare
+            
+
+
+
+
+
+-77) Painted Ladies BACKWARD DP
+
+    In San Francisco, there is a row of several beautiful houses called 
+    the Painted Ladies. Each of the Painted Ladies can be painted with 
+    one of three colors: red, blue or green. The cost of painting each 
+    house with a certain color is different. cost[i][0] for each i is 
+    the cost of painting house i red, cost[i][1] is the cost of painting 
+    it blue, and cost[i][2] is the cost of painting it green.
+
+    You want to paint all the houses in a way such that no two adjacent 
+    Painted Ladies have the same color. Find the minimum cost to achieve this.
+
+    Example
+
+    For cost = [[1, 3, 4], [2, 3, 3], [3, 1, 4]], the output should be
+    paintHouses(cost) = 5.
+
+    def paintHouses(cost):
+        
+        '''
+        recurrence 
+        OPT[i, color] = minimum cost as a result of choosing a specific color. 
+        # compute all three! -> BACKWARD DP. 
+        OPT[i, Blue] = min(OPT[i-1, RED], OPT[i-1, GREEN])
+        OPT[i, RED] =  min(OPT[i-1, BLUE], OPT[i-1, GREEN])
+        OPT[i, GREEN] =  min(OPT[i-1, BLUE], OPT[i-1, RED])
+        answer is min(of all colors OPT[i])
+        
+        recursive
+        fn(idx, prev_color)
+            we know prev color -> choose other 2 colors. 
+            take min of choosing either color!
+        
+        Space optimize to 3 variables!        
+        '''
+        opt_b, opt_r, opt_g = cost[0][0], cost[0][1], cost[0][2]
+        IDX_b, IDX_r, IDX_g = 0, 1, 2
+        
+        for i in range(1, len(cost)):
+            blue_cost = cost[i][IDX_b]
+            red_cost = cost[i][IDX_r]
+            green_cost = cost[i][IDX_g]
+            
+            opt_b, opt_g, opt_r = \
+                min(opt_r, opt_g) + blue_cost, min(opt_r, opt_b) + green_cost, min(opt_b, opt_g) + red_cost  
+            
+        return min(opt_b, opt_g, opt_r)
+
+
+
+
+-76) Linked Lists, 2 Pointers and simplifying problems by  respecting   
+     OPEN-CLOSE 2 pointers which satisfy a <= b < c aka [X, Y) for start and end. 
+
+    Given a singly linked list of integers l and a non-negative integer n, 
+    move the last n list nodes to the beginning of the linked list.
+
+    Example
+
+    For l = [1, 2, 3, 4, 5] and n = 3, the output should be
+    rearrangeLastN(l, n) = [3, 4, 5, 1, 2];
+    For l = [1, 2, 3, 4, 5, 6, 7] and n = 1, the output should be
+    rearrangeLastN(l, n) = [7, 1, 2, 3, 4, 5, 6].
+
+    HARMAN SOLUTION WHICH USES 2POINTERS that refer to [start, end]
+    problem is both pointers can point to same node so this case 
+    has to be handled seperately!! + other edge cases.
+    
+        def rearrangeLastN(l, n):     
+            # use 2 pointers that occupy n space. 
+            # go to the  second last element. do you know why? 
+            # because we have to set None to the element we are 
+            # splitting from. 
+            i = l 
+            j = l
+            
+            if l is None:
+                return None
+            if n == 0:
+                return l
+                
+            # n-1 spaces between n nodes
+            for _ in range(n-1):
+                j = j.next
+            
+            # the whole list was chosen as n. 
+            if j.next == None:
+                return l
+            
+            # second last.
+            while j and j.next and j.next.next:
+                i = i.next
+                j = j.next
+            
+            # get last node. 
+            j.next.next = l
+            
+            # end
+            newStart = i.next            
+            # SET THE NULLS AT THE END BECAUSE WE CAN 
+            # BREAK LINKED LIST FUNCTIONALITY
+            # IF BOTH POINTERS POINT AT SAME NODE!
+            i.next = None
+            return newStart
+
+    OPEN CLOSE NOTATION SOLUTION CLEANNN:
+
+        def rearrangeLastN(l, n):
+            if n == 0:
+                return l
+            front, back = l, l
+            for _ in range(n):
+                front = front.next
+            if not front:
+                return l
+            while front.next:
+                front = front.next
+                back = back.next
+            out = back.next
+            back.next = None
+            front.next = l
+            return out
+
+
+-75) ORDERED SETS vs PRIORTIY QUEUES (Python does not have ordered set aka bst)
+
+    Since both std::priority_queue and std::set (and std::multiset) are data 
+    containers that store elements and allow you to access them in an ordered 
+    fashion, and have same insertion complexity O(log n), what are the advantages 
+    of using one over the other (or, what kind of situations call for the one or the other?)?
+
+    While I know that the underlying structures are different, I am not as much 
+    interested in the difference in their implementation as I am in the comparison 
+    their performance and suitability for various uses.
+
+    Note: I know about the no-duplicates in a set. That's why I also mentioned std::multiset 
+    since it has the exactly same behavior as the std::set but can be used 
+    where the data stored is allowed to compare as equal elements. 
+    So please, don't comment on single/multiple keys issue.
+
+    The priority queue only offers access to the largest element, while the set 
+    gives you a complete ordering of all elements. This weaker interface means that 
+    implementations may be more efficient (e.g. you can store the actual queue 
+    data in a vector, which may have better performance on account of its memory locality).
+
+
+    A priority queue only gives you access to one element in sorted order -- i.e., 
+    you can get the highest priority item, and when you remove that, you can get 
+    the next highest priority, and so on. A priority queue also allows duplicate 
+    elements, so it's more like a multiset than a set. [Edit: As @Tadeusz Kopec pointed out, 
+    building a heap is also linear on the number of items in the heap, where building a 
+    set is O(N log N) unless it's being built from a sequence that's already 
+    ordered (in which case it is also linear).]
+
+    A set allows you full access in sorted order, so you can, for example, find 
+    two elements somewhere in the middle of the set, then traverse in order from one to the other.
+
+
+-74)MULTI TIMESTAMP DP FINITE STATE MACHINE problems. Bottom up with decode ways:
+    DECODE WAYS (REVIEW in most important)
+    class Solution:
+        def numDecodings(self, s):        
+            # BOTTOM UP ONLY!
+            '''        
+            ADD UP ALL THE WAYS WE ARRIVED TO A STATE FROM OTHER STATES!!
+            USE IF STATEMENTS TO DETECT IF WE CAN ARRIVE TO THE STATE. 
+            
+            OPT[i] = OPT[i-1]   (TAKE ONE ALWAYS POSSIBLE!)
+                    + OPT[i-2]   (TAKE 2 MAY NOT BE POSSIBLE)
+            
+            s = "12"
+            "0" does not map to anything -> can only be used with 10 or 20
+            
+            226
+            2 -> 1  b
+            22 -> 1 bb 
+            2 26
+            3 ways:
+            2 2 6
+            22 6
+            2 26
+            
+            Base case empty string = 1?
+            take 1 
+            2 
+            take 2:
+            22 
+            next timestamp?
+            we take 1 
+            
+            OPT[i] -> all the ways to decode up to index i. 
+            process index 0 -> only 1 way to decode unless its 0. 
+            can take 2 charcters if OPT[i-1] exists. 
+            
+            In other words solution relies on 3 timesteps to build finite automata
+            '''
+            
+            OPT = [0 for i in range(len(s) +1)]
+            
+            # BASE CASE
+            OPT[0] = 1 
+            prevCh = None
+            seeNonezero = False
+            
+            # BTW its easy to optimize this to O(N) space, using 2 variables for 
+            # previous 2 timestamps. 
+            
+            for idx in range(1, len(s)+1):
+                # 0 cannot become anything!
+                # take current character as single. 
+                ch = int(s[idx-1])
+                if ch != 0:
+                    OPT[idx] += OPT[idx-1]    
+                # only way we can use 0 is if we see prev.                         
+                # if you see 2 zeros in a row you cant decode it -> answer is 0. 
+                if prevCh != None: 
+                    # take current character + prev char!
+                    if (prevCh == 1 and ch < 10) or (prevCh == 2 and ch < 7):
+                        OPT[idx] += OPT[idx-2]
+                # loop end set prevCharacter
+                prevCh = ch            
+                
+            return OPT[len(s)]    
+
+-90) USING TREESETS AND TREE MAPS C++
+
+    Round 1
+    Design a data structure with two operations 1. addRange(int start, int end) 
+    and 2. contains(int point)
+    Here range means an interval, so the data structure contains information 
+    of all ranges added uptil that point and you can have interleaved queries 
+    of the form contains(int point) which returns true if the point 
+    is contained in any of the ranges or false otherwise.
+
+    The solution I thought of was to store the ranges/intervals as a 
+    list of sorted disjoint intervals (i.e merge overlapping intervals). 
+    Now when we get a contains query, we can perform binary 
+    search(interval with start point equal to or less than point) 
+    to find a potential interval that may contain it. addRange would 
+    be O(n) and contains would be O(logn). I believe there is a better 
+    solution with interval trees but interviewer said this solution 
+    was okay which I ended up coding.
+
+    USE sortedcontainers in python or
+    Q1:
+    Use a treemap => amortized O(logn) merge and O(logn) contains.
+    
+    STL map is inherently a binary search tree - just use map::find. 
+    Using container member functions, where they are present, 
+    is preferable to algorithms.
+
+    How to find all elements in a range in STL map(set)
+
+    If you are using std::map, it's already sorted, your 
+    can use lower_bound/upper_bound an example from cplusplus.com:
+
+    // map::lower_bound/upper_bound
+    #include <iostream>
+    #include <map>
+
+    int main ()
+    {
+        std::map<char,int> mymap;
+        std::map<char,int>::iterator itlow,itup;
+
+        mymap['a']=20;
+        mymap['b']=40;
+        mymap['c']=60;
+        mymap['d']=80;
+        mymap['e']=100;
+
+        itlow=mymap.lower_bound ('b');  // itlow points to b
+        itup=mymap.upper_bound ('d');   // itup points to e (not d!)
+
+        mymap.erase(itlow,itup);        // erases [itlow,itup)
+
+        // print content:
+        for (std::map<char,int>::iterator it=mymap.begin(); it!=mymap.end(); ++it)
+            std::cout << it->first << " => " << it->second << '\n';
+
+        return 0;
+    }
+
+
+
+-97) INTERVAL QUESTIONS THAT CAN BE 
+     SOLVED BY EITHER SORTING BY START TIME OR END TIME
+
+    Hanging Banners
+    Question 212 of 858
+    You are given a list of list of integers 
+    intervals of the form [start, end] representing 
+    the starts and end points of banners you want to hang. 
+    Each banner needs at least one pin to stay up, and one 
+    pin can hang multiple banners. Return the smallest number 
+    of pins required to hang all the banners.
+
+    Note: The endpoints are inclusive, so if two banners are 
+    touching, e.g. [1, 3] and [3, 5], you can put a pin at 
+    3 to hang both of them.
+
+    intervals = [
+        [1, 4],
+        [4, 5],
+        [7, 9],
+        [9, 12]
+    ]
+    Output
+
+    2
+    Explanation
+
+    You can put two pins at 4 and 9 to hang all the banners..
+
+    Example 2
+    Input
+
+    intervals = [
+        [1, 10],
+        [5, 10],
+        [6, 10],
+        [9, 10]
+    ]
+    Output
+
+    1
+    Explanation
+
+    You can put one pin at 10.
+
+    // TWO WAYS TO SOLVE WOWOWO
+    // YOU CAN EITHER SORT BY START TIME LIKE BELOW
+    int solve1(vector<vector<int>>& intervals) {
+        /*
+        sort by start time, 
+
+        keep set of end times. 
+        update with smallest end time so far seen. 
+
+        if next interval is past the current smallest end time, pop all intervals and add a pin,
+        then restart algo. 
+        */
+        sort(intervals.begin(), intervals.end(), 
+             [](vector<int> a, vector<int> b)-> bool {return a[0] < b[0];} );
+        
+        int pins = 0;
+        int nearestEnd = -1;
+        
+        for(int i = 0; i != intervals.size(); ++i) {
+            
+            auto intv = intervals[i];
+            if(intv[0] > nearestEnd) {
+                pins += 1;
+                nearestEnd = intv[1];
+            } else {
+                // keep in set of intervals!
+                nearestEnd = min(nearestEnd, intv[1]);
+            }
+        }
+        return pins;
+    }
+
+    // YOU CAN SORT BY END TIME TOO LIKE BELOW: 
+
+    class Solution:
+        def solve(self, intervals):
+            intervals.sort(key=lambda i: i[1])
+            last = float("-inf")
+            ans = 0
+            for s, e in intervals:
+                if s <= last:
+                    continue
+                last = e
+                ans += 1
+            return ans
+
+
+-93) Bloomberg BINARY SEARCHING ON AN OBJECTIVE QUESTION. 
+     Calculate amt you can take out monthly that leads to balance 0
+    when balance also gets interest rate of 6%.
+
+    Just make guesses from 0 to totalamt     through binary searching,
+    and then check through math formula if 
+    taking out that specific monthly amount X will 
+    lead to balance of 0
+    when person dies. 
+
+    When do math approximations -> TRY BINARY SEARCH. 
+
+
+-92) HOW TO SORT PARTIALLY UNSORTED ARRAYS: ( SPLIT + JOIN)
+    Round 1: Given a sorted n-size array, there are k elements 
+    have been changed i.e. [1, 3, 5, 6, 4, 2, 12] (it might be changed from [1, 3, 5, 6, 7, 8, 12] with k = 2). Important to know is that k is unknown and k is much smaller than n. 
+    The task is to re-sort the entire array.
+    The interviewer wants O(n) solution. I bombed this one. In the end, the 
+    interviewer kind of fed the solution to me. What he suggested: 
+    a. break the array into two: one sorted array and one unsorted array e.g. [1, 3, 5, 12] 
+    and [6, 4, 2]. This takes O(n) 
+    b. Sort the unsorted array. This takes O(klogk) 
+    c. Merge two sorted arrays. This takes O(n). Because k is very small, so in the end O(n) + O(klogk) ~= O(n).
+        
+
+
+-91) 
+    Round 2
+    You have two arrays of odd length (same length). 
+    You should check if you can pair elements from both arrays such that 
+    xor of each pair is the same.
+    
+    Ex : [a, b, c] and [d, e, f] check we can find a pairing 
+         say (arrays actually have integers)
+    a xor e = v
+    b xor d = v
+    c xor f = v
+
+    SOLUTION:
+    O(N). XOR all => v. we can take advantage of the property that a^b=v => a^v=>b 
+        and use a hashset.
+
+
+
+
+-73) To solve weird optimization problems, write out the problem constraints in 
+     mathematical notation!  
+     + english words
+     + greedy detection/hill finding/maximization/montonic queue/segment tree optimize/binary search/quick select   
+     + As you find constraints -> think of edge cases -> can they be solved by setting the base case in a recurrence?
+     + NEGATIVE SPACE. 
+     + or through other means? 
+    
+    1.    Remove Covered Intervals: 
+
+    Given a list of intervals, remove all intervals that are covered by another interval in the list.
+
+    Interval [a,b) is covered by interval [c,d) if and only if c <= a and b <= d.
+
+    After doing so, return the number of remaining intervals.
+    
+    Example 1:
+
+    Input: intervals = [[1,4],[3,6],[2,8]]
+    Output: 2
+    Explanation: Interval [3,6] is covered by [2,8], therefore it is removed.
+    Example 2:
+
+    Input: intervals = [[1,2],[1,4],[3,4]]
+    Output: 1
+    class Solution:
+        def removeCoveredIntervals(self, intervals: List[List[int]]) -> int:
+            '''
+            Sort by start time. 
+            
+            Then check if interval after me I cover. If i do remove, 
+            otherwise keep. 
+            
+            sort intervals by start time.          
+            
+            when checking next interval, make sure its start time is after 
+            the max finish time, otherwise covered. 
+            
+            Compare end time of first one with endtime of second one, if its within its covered.
+            OTHERWISE!!,
+            
+            if you get an interval with further endtime -> update the FOCUS interval to that. 
+            because it will be able to cover more on the right. 
+            So keep the one with largest end time asthe main focus. 
+            
+            Requires sorting on start time  -> NLOGN.
+            
+            need to do 2 sorts, 
+            earliest start time,
+            then for those with same start time -> latest finish time comes first. 
+            So then the latest finish times can consume the earlier finish times and be used to consume intervals
+            without same start time. 
+            '''
+            
+            # DO A DOUBLE SORT -> MAJOR SORT ON START -> MINOR SORT ON FINISH TIME. 
+            intervals.sort(key=lambda x: (x[0], -x[1]))
+            
+            curr_fin = intervals[0][1]
+            
+            covered_count = 0
+            for i in range(1, len(intervals)):
+                nxt_fin = intervals[i][1]
+
+                if nxt_fin <= curr_fin:
+                    covered_count += 1
+                else:
+                    curr_fin = nxt_fin
+                    
+            return len(intervals) - covered_count
+
+
+-88)  You are a traveling salesperson who travels 
+      back and forth between two cities (A and B). 
+      You are given a pair of arrays (revA and revB) of length n.
+
+    You can only sell goods in one city per day.
+    At the end of each day you can choose to travel to another 
+    city but it will cost a constant amount of money (travelCost).
+
+    Ex::
+    revA[] = {3, 7,2,100};
+
+    revB[] = {1,1,1,10};
+
+    travelCost = 2;
+    Find maximum profit.
+        int MaxProfitBySalesMan ( int arr1 [] , int arr2 [] , int n )
+        {
+            int dp [ 2 ] [ n ] ; 
+            dp [ 0 ] [ 0 ]  = arr1 [ 0 ] ; 
+            dp [ 1 ] [ 0 ]  = arr2 [ 0 ] ;
+            for ( int i = 1 ; i < n ; i ++ )
+            {
+                dp [ 0 ] [ i ] = max ( dp [ 0 ] [ i -  1 ] , dp [ 1 ][ i  - 1 ] - 2  ) + arr1 [ i ]  ; 
+                dp [ 1 ] [ i ] = max ( dp [ 1 ] [ i -  1 ] , dp [ 0 ][ i  - 1 ] - 2  ) + arr2 [ i ]  ;
+            }
+            return max ( dp [ 0] [ n - 1 ] , dp [ 1 ] [ n - 1 ] ) ;
+        }
+
+
+
+-87)Optimizing binary tree questions with bottom up DP: 
+    One way to optimize these questions is to use post-order traversal.
+    Compute the value for the children then compute for parent sorta like DP:
+
+    1.   Count Univalue Subtrees
+    中文English
+    Given a binary tree, count the number of uni-value subtrees.
+    
+    A Uni-value subtree means all nodes of the subtree have the same value.
+    
+    Example
+    Example1
+    
+    Input:  root = {5,1,5,5,5,#,5}
+    Output: 4
+    Explanation:
+                  5
+                 / \
+                1   5
+               / \   \
+              5   5   5
+    Example2
+    
+    Input:  root = {1,3,2,4,5,#,6}
+    Output: 3
+    Explanation:
+                  1
+                 / \
+                3   2
+               / \   \
+              4   5   6
+
+    Solution:
+    def countUnivalSubtrees(self, root):
+        count = 0
+        def helper(node):
+            nonlocal count 
+            if node is None:
+                return None
+            left_result = helper(node.left)
+            right_result = helper(node.right)
+            if left_result == False:
+                return False
+            if right_result == False:
+                return False
+            if left_result and left_result != node.val:
+                return False
+            if right_result and right_result != node.val:
+                return False
+            count += 1
+            return node.val
+        helper(root)
+        return count
+
+
+-86.5)  HRT: 1775. Equal Sum Arrays With Minimum Number of Operations
+
+        You are given two arrays of integers nums1 and nums2, possibly of different lengths. 
+        The values in the arrays are between 1 and 6, inclusive.
+
+        In one operation, you can change any integer's value in any of the arrays 
+        to any value between 1 and 6, inclusive.
+
+        Return the minimum number of operations required to make the sum of values in nums1 
+        equal to the sum of values in nums2. Return -1​​​​​ if it is not possible 
+        to make the sum of the two arrays equal.
+
+            static const auto speedup = []() { std::ios::sync_with_stdio(false); std::cin.tie(nullptr); return 0; }();
+
+            class Solution {
+            public:
+                int minOperations(vector<int>& nums1, vector<int>& nums2) {
+                    // calculate the frequency and find the sum
+                    vector<int> cnt1(7,0), cnt2(7,0);
+                    for(auto &a:nums1) cnt1[a]++;
+                    for(auto &a:nums2) cnt2[a]++;
+                    int sum1 = accumulate(nums1.begin(), nums1.end(), 0);
+                    int sum2 = accumulate(nums2.begin(), nums2.end(), 0);
+                    
+                    // already equal
+                    if(sum1 == sum2) return 0;
+                    
+                    // reduce sum1 < sum2 to sum1 > sum2....so only one problem we have to deal wiith
+                    if(sum1 < sum2){
+                        swap(sum1, sum2);
+                        cnt1.swap(cnt2);
+                    }
+                    
+                    // since sum1 > sum2 ... we have two options 
+                            // 1) decrease val in first array 
+                            // 2) increase val in second array
+                    
+                    // if we have 6 in first array, maximum decrease of sum1 can be of 5 So, sum1-sum2 decreases by 5 
+                    // Similarly if we have 1 in second array, maximum incrase of sum2 can be 5. And hence sum1-sum2 decreases by 5. 
+                    // So, decreasing 6 in first array and increasing 1 in second lead to maximum deduction of 5 in the difference.
+                    
+                    // Similary, If we consider 5 from first array and 2 from the second array, 
+                    // it can lead to maximum deduction of 4 in the difference.
+                    
+                    // Now, cnt1[i] (i=2,3,4,5,6) will have the number of times it can decrese the difference by (i-1);
+                    for(int i=1; i<=6; i++)
+                        cnt1[i] += cnt2[7-i];
+                    
+                    int diff = sum1-sum2;
+                    int curr = 6;      // start by i=6 and go upto i=2;
+                    int ops = 0;        // to store the # of operations
+                    
+                    while(diff && (curr>1)){
+                        // count the # of substraction needs to be done where the substraction can be of (curr-1) 
+                        int needed = ceil(1.0*diff/(curr-1));
+                        
+                        // maximum operations is bounded by count of the (curr-1) substraction
+                        // As stated earlier cnt1[curr] have the count of how many (curr-1) deduction can be done
+                        // So, we can only do min(needed, cnt1[curr-1]) ops
+                        ops += min(needed, cnt1[curr]);
+                        
+                        // deacrese the difference accordingly
+                        diff -= min(needed, cnt1[curr])*(curr-1);
+                        
+                        // for last deduction diff can be -ve. E.g. diff was 3 and we deduct 5. So, we can assume that we deducted 3 only and make diff = 0
+                        if(diff < 0) diff = 0;
+                        
+                        // go for next smaller value
+                        curr--;
+                    }
+                    
+                    // if diff is non-zero, then return -1. Otherwise return the # of operations
+                    return (diff ? -1 : ops);
+                }
+            };
+
+
+
+-40) CIRCULAR BUFFERS: Implementation Stack and Queue 
+     Declare an array with enough space!
+     
+    7.1: Push / pop function — O(1).
+    1   stack = [0] * N
+    2   size = 0
+    3   def push(x):
+    4       global size
+    5       stack[size] = x
+    6       size += 1
+    7   def pop():
+    8       global size
+    9       size -= 1
+    10      return stack[size]
+
+    7.2: Push / pop / size / empty function — O(1).
+    1   queue = [0] * N
+    2   head, tail = 0, 0
+    3   def push(x):
+    4       global tail
+    5       tail = (tail + 1) % N
+    6       queue[tail] = x
+    7   def pop():
+    8       global head
+    9       head = (head + 1) % N
+    10      return queue[head]
+    11  def size():
+    12      return (tail - head + N) % N
+    13  def empty():
+    14      return head == tail
+
+-86) monotonic stack vs monotonic queue and how to build a monotonic structure
+    HRT PROBLEM: MINIMIZE THE AMPLITUDE!:
+    Given an array of N elements, remove K elements to minimize the amplitude(A_max - A_min) of the remaining array.
+
+    remove k consecutive elements from A such that amplitude is minimal which is the 
+
+
+        #include <vector>
+        #include <deque>
+        #include <bits/stdc++.h>
+        #include <iostream> 
+
+        using namespace std;
+
+
+        struct Item {
+            int idx;
+            int val;
+        };
+
+
+        int solution(vector<int> &A, int K) {
+
+            /*
+            min amplitude.
+
+            remove k consecutive elements from A, 
+            such that amplitude of remaining elements will be minimal.
+
+            Aka keep track of max and min outside of k size interval
+            use both minheap and maxheap -> too painful to do. need to use map plus internal siftup siftdown
+
+            slide window left to right.
+            + monotonic deque for max + monotonic deque for min. 
+            add values to end of queue when you process,
+
+            pop from left side which contains best max, min, and pop when the index gets crossed!
+
+            */
+
+            // montonic queue after K elements. 
+            int idx = K; 
+            int N = A.size();
+
+            deque<Item> mono_max;
+            deque<Item> mono_min; 
+
+            // initialize monotonic struture with stack operations
+            for(int idx = K; idx < N; ++idx) {
+                // pop smaller elements and keep larger elements. 
+                Item i;
+                i.idx = idx;
+                i.val = A[idx];
+                while(!mono_max.empty() && mono_max.back().val <= i.val) {
+                    mono_max.pop_back();
+                }
+                mono_max.push_back(i);
+            }
+
+            for(int idx = K; idx < N; ++idx) {
+                // pop smaller elements and keep larger elements. 
+                Item i;
+                i.idx = idx;
+                i.val = A[idx];
+                while(!mono_min.empty() && mono_min.back().val >= i.val) {
+                    mono_min.pop_back();
+                }
+                mono_min.push_back(i);
+            }
+
+            // use monotone as queue
+            // 2 pointer + runnign min + update mono queues
+            int i = 0;
+            int j = K-1;
+
+            int amp = INT_MAX;
+
+            while(j != N) {
+                
+                int temp = mono_max.front().val - mono_min.front().val;
+                std::cout << "max and min is" << mono_max.front().val << ", " << mono_min.front().val << endl;
+
+                amp = min(amp, temp);
+                // add index i max_mono and min_mono 
+                // burn through the stack from the back garabage points
+                // set index to infinite cause these points we add when we move
+                // sliding window to right cannot be invalidated. 
+
+                // add in ith item in sliding window.         
+                Item newItem;
+                newItem.val = A[i];
+                newItem.idx = INT_MAX;
+
+                while(!mono_max.empty() && mono_max.back().val <= newItem.val) {
+                    mono_max.pop_back();
+                }
+                mono_max.push_back(newItem);
+                
+                while(!mono_min.empty() && mono_min.back().val >= newItem.val) {
+                    mono_min.pop_back();
+                }
+                mono_min.push_back(newItem);
+
+                // move sliding window.
+                i += 1;
+                j += 1;
+
+                // remove j+1th item from sliding window. 
+                if(j != N) {
+                    if(mono_max.front().idx == j) {
+                        mono_max.pop_front();
+                    }   
+
+                    if(mono_min.front().idx == j) {
+                        mono_min.pop_front();
+                    }
+                }
+            }
+
+            return amp; 
+        }
+
+        int main(){
+            vector<int> a = {1,2,3,4,5,6};
+            vector<int> b = {5,3,6,1,3};
+            vector<int> c = {8,8,4,3};
+            vector<int> d = {3,5,1,6,9,8,2,5,6};
+
+            cout << solution(a,  2) << endl;
+            cout << solution(b,  2) << endl;
+            cout << solution(c,  2) << endl;
+            cout << solution(d,  4) << endl;
+        }
+
+
+-85) think of the algo to do citadel problem -> round robin ALGORITHM!!!
+    -> Also take a look at the problem consecutive numbers sum
+
+
+-84) Using cumulative array for sums in 1D and 2D case tricks:
+    1D) sum between i and j inclsuive:
+        sum(j) - sum(i-1)
+        REMEMBER TO DO I-1 to make it INCLUSIVE!
+
+    2D)
+    Have a 2D cumulative array,
+    of size N+1, M+1, for NxM array
+    top row is all 0s.
+    left column is all 0s.
+    similar to cumualtive array. 
+    
+    2 coordinates is top left and bottom right. 
+    
+    (from snap interview)
+    SUM OF LARGE RECTANGE - SUM OF TOP RIGHT - SUM OF BOTTOM LEFT + SUM OF SMALL RECTANGLE. 
+    
+
+
+    topleft -> tlx, tly
+    bottomright -> brx, bry
+    
+    # because inclusive, not sure though, do lc to check below part.
+    tlx -= 1
+    tly -= 1
+
+    arr[brx][bry] - arr[brx][tly] - arr[tlx][bry]  + arr[tlx][tly]
+
+Snap DEADLOCK QUESTION
+
+    We obtained a log file containing runtime information about all threads and mutex locks of a user program. 
+    The log file contains N lines of triplets about threads acquiring or releasing mutex locks. The format of the file 
+    is: The first line contains an integer N indicating how many more lines are in the file. Each of the following N lines 
+    contains 3 numbers separated by space. The first number is an integer representing thread_id (starting from 1). 
+    The second number is either 0 (acquiring) or 1 (releasing). The third number is an integer representing mutex_id 
+    (starting from 1). Now we want you to write a detector program that reads the logs line by line and output the line 
+    number of the trace where a deadlock happens. If there is no deadlock after reading all log traces, output 0.
+
+    Example:
+    4
+    1 0 1
+    2 0 2
+    2 0 1
+    1 0 2
+
+    Output:
+    4
+
+    Ok so create graph and check for cycle?
+    
+    t1 wants a [a taken]
+    t2 wants b  [b taken]
+
+    t1 -> a -> t2 -> b -> t1
+    Cycle right!
+
+    or lets do it like
+
+    remove edges when that line comes from 
+    t2 wants a [a wanted not released -> t2 falls asleep with b]
+    t1 wants b [b wanted not released -> t1 falls asleep with a]
+    Soooo
+    both threads are asleep
+    because
+
+    Do cycle detection on resource allocation graph sir!
+
+
+
+
+
+-37) MAKING SURE YOUR DFS IS CORRECT! And the DP is being resolved 
+     in the DFS tree properly. 
+
+    For a given array A of N integers and a sequence S of N integers 
+    from the set {−1, 1}, we define val(A, S) as follows:
+
+    val(A, S) = |sum{ A[i]*S[i] for i = 0..N−1 }|
+
+    (Assume that the sum of zero elements equals zero.)
+    For a given array A, we are looking for such a sequence S that minimizes val(A,S).
+
+    Write a function:
+    def solution(A)
+
+    that, given an array A of N integers, computes the minimum value of val(A,S) 
+    from all possible values of val(A,S) for all 
+    possible sequences S of N integers from the set {−1, 1}.
+
+    For example, given array:
+
+    A[0] =  1
+    A[1] =  5
+    A[2] =  2
+    A[3] = -2
+    
+    your function should return 0, since for S = [−1, 1, −1, 1], 
+    val(A, S) = 0, which is the minimum possible value.
+
+    def solution(A):
+        # THIS FAILS DUE TO MAX RECURSION DEPTH REACHED!
+        # BUT IT IS 100% CORRECT
+        @lru_cache(None)
+        def recurseB(i,s):
+            
+            if len(A) == i:
+                return s
+                
+            add = recurseB(i+1, s + A[i])
+            sub = recurseB(i+1, s - A[i])
+            print("CORRECT ADD AND SUB FOR I IS", i, add, sub)
+
+            # print("ADD and sub are", add, sub)
+            if abs(add) < abs(sub):
+                return add
+            else:
+                return sub
+        
+        correct_val = abs(recurseB(0, 0))
+        print("CORRECT VALU IS", correct_val)
+        
+        # BELOW WAY IS WRONG!
+        # DO YOU KNOW WHY?
+        # IT GENERATES DIFF ANSWERS FROM ABOVE. 
+        # BECAUSE IN THE RECURSIVE CALLS CLOSE TO THE 
+        # BASE CASE, WE ARENT ABLE TO FINE TUNE THE SOLUTION
+        # TO THE INCOMING SUM, BECAUSE YOU NEVER SEE THE INCOMING
+        # SUM LIKE ABOVE. 
+        # SO INSTEAD, YOU GREEDILY CHOOSE 
+        # IN THE ABOVE RECURSION, HELPER SEES INCOMING SUM, 
+        # AND THEN RETURNS AN OPTIMIZED SUM BASED ON THE INCOMING SUM!
+        # THERE IS COMMUNICATION!
+        def recurseA(i):
+            if len(A) == i:
+                return 0
+                
+            add = A[i] + recurseA(i+1)
+            sub = -A[i] + recurseA(i+1)
+            print("INC ADD AND SUB FOR I IS", i, add, sub)
+            # print("ADD and sub are", add, sub)
+            if abs(add) < abs(sub):
+                return add
+            else:
+                return sub
+
+        incorrect_val = abs(recurseA(0))
+        return correct_val
+
+-36.5) Reasoning about hard states in DP: MinAbsSum
+       Coming up with bottom up solution with MinAbsSum by rephrasing problem.
+       Question above. 
+
+    Since we can arbitrarily choose to take the element or its negative, we can simplify the
+    problem and replace each number with its absolute value. Then the problem becomes dividing
+    the numbers into two groups and making the difference between the sums of the two groups
+    as small as possible. It is a classic dynamic programming problem.
+    Assume the sum of absolute values of all the numbers is S. We want to choose some of
+    the numbers (absolute values) to make their 
+    sum as large as possible without exceeding S/2.
+
+    Let M be the maximal element in the given array A. We create an array dp of size S.
+    
+    Slow DP:
+    Let dpi equal 1 if it is possible to achieve the 
+    sum of i using elements of A, and 0 otherwise.
+    Initially dpi = 0 for all of i (except dp0 = 1). 
+    For every successive element in A we update the
+    array taking this element into account. We simply go through all the 
+    cells, starting from the
+    top, and if dpi = 1 then we also set dpi+Aj
+    to 1. The direction in which array dp is processed
+    is important, since each element of A can be used only once. 
+    After computing the array dp, P is the largest index such that P <= S/2
+    and dpP = 1.
+
+    The time complexity of the above solution is O(N^2· M), since S = O(N · M).
+
+    1 def slow_min_abs_sum(A):
+    2   N = len(A)
+    3   M = 0
+    4   for i in xrange(N):
+    5       A[i] = abs(A[i])
+    6       M = max(A[i], M)
+    7   S = sum(A)
+    8   dp = [0] * (S + 1)
+    9   dp[0] = 1
+    10  for j in xrange(N):
+    11      for i in xrange(S, -1, -1):
+    12          if (dp[i] == 1) and (i + A[j] <= S):
+    13              dp[i + A[j]] = 1
+    14  result = S    
+    15  for i in xrange(S // 2 + 1):
+    16      if dp[i] == 1:
+    17          result = min(result, S - 2 * i)
+    18  return result
+
+
+    Notice that the range of numbers is quite small (maximum 100). 
+    Hence, there must be a lot of duplicated numbers. 
+    Let count[i] denote the number of occurrences of the value i. 
+    We can process all occurrences of the same value at once. 
+    First we calculate values count[i] Then we create array dp such that:
+
+    dp[j] = −1 if we cannot get the sum j,
+    dp[j] >= ­ 0 if we can get sum j.
+    Initially, dp[j] = -1 for all of j (except dp[0] = 0). Then we scan 
+    through all the values a appearing in A; we consider all a such that 
+    count[a]>0. For every such a we update dp that dp[j] denotes 
+    how many values a remain (maximally) after achieving sum j. 
+    Note that if the previous value at dp[j] >= 0 then we can 
+    set dp[j] = count[a] as no value a is needed to obtain the sum j. 
+    
+    Otherwise we must obtain sum j-a first and then use a 
+    number a to get sum j. In such a situation 
+    dp[j] = dp[j-a]-1. Using this algorithm, we can mark all the 
+    sum values and choose the best one (closest to half of S, the sum of abs of A).
+
+    def MinAbsSum(A):
+        N = len(A)
+        M = 0
+        for i in range(N):
+            A[i] = abs(A[i])
+            M = max(A[i], M)
+        S = sum(A)
+        count = [0] * (M + 1)
+        for i in range(N):
+            count[A[i]] += 1
+        dp = [-1] * (S + 1)
+        dp[0] = 0
+        for a in range(1, M + 1):
+            if count[a] > 0:
+                for j in range(S):
+                    if dp[j] >= 0:
+                        dp[j] = count[a]
+                    elif (j >= a and dp[j - a] > 0):
+                        dp[j] = dp[j - a] - 1
+        result = S
+        for i in range(S // 2 + 1):
+            if dp[i] >= 0:
+                result = min(result, S - 2 * i)
+        return result
+    
+    The time complexity of the above solution is O(N · M^2), 
+    where M is the maximal element,
+    since S = O(N · M) and there are at most M different values in A.
+
+-36) DO COMPLEX SET MEMOIZATION ON GRID VS DJIKSTRA.  
+
+    You have a grid, and you can go up down, left or right. 
+     Find min cost to go from top left to bottom right: 
+        board = [[42, 51, 22, 10,  0 ],
+                [2,  50, 7,  6,   15],
+                [4,  36, 8,  30,  20],
+                [0,  40, 10, 100, 1 ]]
+
+    # Below uses DP but its not fast enough. 
+    # Need to use Djikstra to pass the TLE test cases
+    def orienteeringGame(board):
+        '''
+        COMPLEX SET MEMOIZATION GRID PROBLEM: 
+        THIS IS A DP PROBLEM
+        SINCE WE CAN GO UP AND LEFT AS WELL AS DOWN AND RIGHT, 
+        IN OUR MEM TABLE, WE HAVE TO SAVE THE SET OF NODES
+        WE TRAVERSED SO FAR. 
+        SO ITS LIKE TRAVELLING SALESMAN PROBLEM DP.
+        RMBR WHEN YOU HAVE TO MEM IT!
+        '''
+        
+        R = len(board)
+        C = len(board[0])
+        
+        visited = set()
+        m = {}
+        
+        # Using a cumulative sum is a way to hash the nodes traversed so far in the 
+        # path which is important for the cache table.
+        @lru_cache(None)
+        def dfs(i, j, cum_sum):
+            if(i == R-1 and j == C-1):
+                return cum_sum # board[R-1][C-1]    
             
-            lp = head
-            rp = head        
-            rpCounter = (l+1)//2
-            lpCounter = (l//2 -1)
-            left_counter = 0
+            visited.add((i,j))
             
-            for i in range(rpCounter):
-                rp = rp.next
+            val = board[i][j]
+            cost = float("inf")
+
+            if i + 1 < R and (i+1, j) not in visited:
+                cost = min(cost, dfs(i + 1, j, cum_sum + val))            
+        
+            if j+1 < C and (i, j+1) not in visited:
+                cost = min(cost, dfs(i, j+1, cum_sum + val))  
+
+            if i - 1 >=0 and (i-1, j) not in visited:
+                cost = min(cost, dfs(i - 1, j, cum_sum + val))      
+
+            if j-1 >= 0 and (i, j-1) not in visited:
+                cost = min(cost, dfs(i, j-1, cum_sum + val))     
+                    
+            visited.remove((i,j))    
+            return cost
+        
+        return dfs(0,0, 0) 
+
+
+
+
+-71) Interval Problem Type Intuition, and Line Sweeping
+     Try 2 pointer! or heap!
+     
+    1.   Interval List Intersections
+    Given two lists of closed intervals, each list of 
+    intervals is pairwise disjoint and in sorted order.
+
+    Return the intersection of these two interval lists.
+
+    (Formally, a closed interval [a, b] (with a <= b) denotes the set of real numbers x with a <= x <= b.  The intersection of two closed intervals is a set of real numbers that is either empty, or can be represented as a closed interval.  For example, the intersection of [1, 3] and [2, 4] is [2, 3].)
+
+    Example 1:
+    Input: A = [[0,2],[5,10],[13,23],[24,25]], B = [[1,5],[8,12],[15,24],[25,26]]
+    Output: [[1,2],[5,5],[8,10],[15,23],[24,24],[25,25]]
+
+    2 POINTER SOLUTION OPTIMAL: 
+        def intervalIntersection(self, A: List[List[int]], B: List[List[int]]) -> List[List[int]]:
+            '''
+            FOR INTERVAL QUESTIONS RMBR:
+            SORTS FOR INTERSECTIONS USUALLY BEST TO SORT BY START TIME.
+            
+            BUT WHENEVER WE ARE CHECKING TO REMOVE INTERVALS FROM THE ACTIVE REGION!
+            REMOVE BASED ON EARLIEST FINISH TIME, RATHER THAN OTHER METRICS:
+            
+            SOLUTION IS 2 POINTERS:
+            
+            ANOTHER INTERSECTION HINT: 
+            INTERSECTIONS HAVE THE FORM OF THE FOLLOWING:
+            [max(Astart, Bstart), min(Aend, Bend)]
+            -> intersection exists if above computation is a real interval!
+                (aka has positive length)        
+            '''
+            
+            i = 0
+            j = 0
+            res = []
+            if len(A) == 0 or len(B) == 0:
+                return []
+            
+            '''
+            You dont move pointers based on what the next earlier one was
+            but the one that finished earlier, 
+            because that one can no longer intersect with anything!
+            '''
+            while i < len(A) and j < len(B):
+                
+                a_start, a_end = A[i]
+                b_start, b_end = B[j]
+                
+                pos_int_s = max(a_start, b_start)
+                pos_int_e = min(a_end, b_end)
+                if pos_int_s <= pos_int_e:
+                    res.append([pos_int_s, pos_int_e])
+                
+                if a_end < b_end:
+                    i += 1
+                else:
+                    j += 1 
+            return res
+
+
+    LINE SWEEPING SOLUTION:
+        Remember when things are presorted, then line sweeep is not 
+        optimal because it requires sorting.
+        O(NLOGN) so it is slower than sorted variant!
+
+
+        Like every interval problem, this can be solved by line sweep. 
+        Note that, if the input is already pre-sorted, this 
+        isn't an optimal solution. But it is cool and interesting.
+
+        The general idea here is that we have a window, keyed by 
+        person A or person B. When we add/remove intervals, we just need 
+        to be careful that we're extending any existing window values, 
+        if that person already exists in our window.
+
+        Time: O(n log n)
+        Space: O(n)
+
+        class Solution:
+            def intervalIntersection(self, A: List[List[int]], B: List[List[int]]) -> List[List[int]]:
+                events = []
+                OPEN, CLOSE = 0, 1
                 
-            def check_palin(lp): 
-                # We only need these 2 as nonlocals. 
-                # because we modify in the closure. 
-                # Also cant use rp as argument 
-                # to function call. unless you wrap in []. Why?
+                for start, end in A:
+                    events.append((start, OPEN, end, "A"))
+                    events.append((end, CLOSE, end, "A"))
+                    
+                for start, end in B:
+                    events.append((start, OPEN, end, "B"))
+                    events.append((end, CLOSE, end, "B"))
+                
+                events.sort()
+                window = {}
+                ans = []
+                
+                for time, event_type, end, key in events:
+                    if event_type == OPEN:
+                        window[key] = (time, end)
+                    else:
+                        del window[key]
 
-                nonlocal rp 
-                nonlocal left_counter
+                    if len(window) > 1:
+                        start_a, end_a = window["A"]
+                        start_b, end_b = window["B"]
+                        
+                        best_start = max(start_a, start_b)
+                        best_end = min(end_a, end_b)
+                        ans.append((best_start, best_end))
+                        
+                return ans
 
-                if (left_counter < lpCounter):
-                    left_counter += 1
-                    result = check_palin(lp.next)
-                    if result == False:
-                        return False
+
+    LINE SWEEPING second method.
+
+        class Solution {
+            public int[][] intervalIntersection(int[][] A, int[][] B) {
+                List<int[]> res = new ArrayList<>();
+                int n = A.length + B.length;
+                int[] start = new int[n], end = new int[n];
+                int c = 0;
+                for (int i = 0;  i < A.length; ++i) {
+                    start[c] = A[i][0];
+                    end[c++] = A[i][1];
+                }
                 
-                if(rp == None):
-                    return True
+                for (int i = 0;  i < B.length; ++i) {
+                    start[c] = B[i][0];
+                    end[c++] = B[i][1];
+                }
                 
-                if(rp.val == lp.val):
-                    rp = rp.next # check next rp. 
-                    return True # needed when there are only 2 nodes in linked list. 
-                else:
-                    return False
-            return check_palin(lp)
+                // O(n log (n))
+                Arrays.sort(start);
+                Arrays.sort(end);
+                
+                /**
+                line sweep : go from left to right, stopping at start or end intervals.
+                if its a start the increment busy.
+                if its an end, decrement busy. before that check if 2 intervals are busy at the moment, if they are, it means A and B are indulged in the period end[e] and start[s - 1].
+                note that end[e - 1] < start[s - 1] if busy = 2 else busy < 2, so the interval of interest is start[s - 1] and end[e]. Also s cannot be 0.
+                */
+                int s = 0, e = 0, busy = 0;
+                while( e < n ) {
+                if (s < n && start[s] <= end[e]) {
+                    busy++;
+                    ++s;
+                } else {
+                    if (busy == 2) {
+                        res.add(new int[] {start[s - 1], end[e]});
+                    }
+                    busy--;
+                    ++e;
+                }
+                }
+                
+                return res.toArray(new int[0][0]); 
+            }
+        }
 
 
--4) Python generator for converting binary to value, but 
-    binary is encoded as a linked list:
-    
-    class Solution(object):
-        def yield_content(self, head):
-            current = head
-            yield current.val
-            while current.next != None:
-                current = current.next
-                yield current.val
 
-        def getDecimalValue(self, head):
-            bin_number = ''
-            generator = self.yield_content(head)
-            while True:
-                try:
-                    bin_number += str(next(generator))
-                except StopIteration:
-                    break
-            return int(bin_number, 2)
 
--3) WHEN GIVEN CONSTRAINTS TO A PROBLEM
-    NEGATE THE CONsTRAINTS TO EXPLOIT PROBLEM STRUCTURE. think combinatorically 
-    about how to use constraints, whether that means to do there exists, or there 
-    doesnt exist such that the constrain is satisfied. especially for greedy questions. 
-    think in positive space and negative space.
+-70) Example of extracting dynamic programming traversal paths 
+     after doing DP problem.
+        '''
+        CombinationSum:
 
--2) For sliding window, remember that you can do optimized sliding window 
-    by skipping multiple indexes ahead instead of skipping one at a time. 
-    COMPRESS THE STEPS TO FURTHER OPTIMIZE SLIDING WINDOW!
-    OR USE MULTIPLE POINTERS. 
+        Given an array of integers a and an integer sum, find all of the 
+        unique combinations in a that add up to sum.
+        The same number from a can be used an unlimited number of times in 
+        a combination.
+        Elements in a combination (a1 a2 … ak) must be sorted in non-descending order, 
+        while the combinations themselves must be sorted in ascending order.
 
--1)     DFS, BFS + COLORS IS POWERFUL!
-        Another way to check if graph is bipartionable. 
-        ALGORITHM:
-        CAN DO BIPARTITION WITH DFS AND 2 COLORING. 
+        If there are no possible combinations that add up to sum, 
+        the output should be the string "Empty".
+
+        Example
+
+        For a = [2, 3, 5, 9] and sum = 9, the output should be
+        combinationSum(a, sum) = "(2 2 2 3)(2 2 5)(3 3 3)(9)".
+
+
+        The DP problem is simple, done previously before HARMAN!!
+
+        Here we try to return the paths themselves, that were traversed in the DP
+        2 ways to do so:
+        A parents map OR as we save our results in the DP array, we also save our paths in a DP paths array.
+        Look at both methods and learn!!
+
+        '''
+        from collections import defaultdict, deque
+        def combinationSum(a, sum):
+            # parents map? 
+            g = defaultdict(list)
+            
+            # sort a and deduplicate. 
+            
+            a = sorted(list(set(a)))
+            
+            # we could also space optimize and just use One D array, because new 
+            # index doesnt use just previous index, but all previous indexes.
+            # so include all of em. 
+            OPT = [[0 for i in range(sum+1)]]
+            OPT[0][0] = 1
+            
+            
+            dp_paths = [[] for i in range(sum+1)]
+            dp_paths[0].append([])
+            
+            for idx, coinVal in enumerate(a):
+                # to compute for current index, 
+                # first copy previous, then operate on current. 
+                curr = OPT[-1][:]
+                '''
+                idx, coin?
+                '''
+                for i in range(sum+1):
+                    if i >= coinVal:
+                        # do we specify the coin type we used??
+                        # depends if we built from previous index, or 
+                        # coins from this index.  -> cant you use difference in amts
+                        # to determine coins -> YESS.
+                        # you dont need to save coinVal
+                        curr[i] += curr[i-coinVal]
+                        # can we save it, as we build the dp?
+                        
+                        parent_paths = dp_paths[i-coinVal]
+                        for p in parent_paths:
+                            cp = p[::]
+                            cp.append(coinVal)
+                            dp_paths[i].append(cp)
+
+                        if(curr[i-coinVal] > 0):
+                            g[i].append(i-coinVal)
+                                
+                OPT.append(curr)
+            
+            # DP PATHS WORKS HOW YOU EXPECT. IF OPT[sum] = 6, then in DP paths there is 6 paths.
+            print("DP_PATHS", dp_paths)
+            print("OPT", OPT)
+            
+            '''
+            Problem with getting all paths: we end up with all permutations instead of 
+            combinations: 
+            
+            Output: "(2 2 2 2)(2 2 4)(2 4 2)(2 6)(4 2 2)(4 4)(6 2)(8)"
+            Expected Output: "(2 2 2 2)(2 2 4)(2 6)(4 4)(8)"
+            SO WE NEED LIMIT ARGUMENT.
+            '''
+            
+            results = []
+            
+            def get_all_paths(node, path, limit):
+                kids = g[node]
+                if len(kids) == 0:
+                    # nonlocal results
+                    results.append(path)
+                
+                # USING A LIMIT ALLOWS YOU TO TURN 
+                # PERMUTATONS INTO COMBINATIONS IF ITS SORTED.
+                # BY TRAVERSING COINS FROM LARGEST TO SMALLEST ONLY. 
+                
+                for k in kids:
+                    coinVal = node-k
+                    if coinVal <= limit:
+                        cp = path.copy()
+                        cp.appendleft(coinVal)
+                        get_all_paths(k, cp, min(limit, coinVal))
+                        
+            get_all_paths(sum, deque([]), float("inf"))
+            final=[]
+            
+            # Uncomment this line and code still creates correct output!
+            # results = dp_paths[sum]
+
+            for r in results:
+                if len(r) == 0:
+                    continue
+                s = str(r[0])
+                for idx in range(1, len(r)):
+                    s += " " + str(r[idx])
+                final.append(s)
+            
+            final.sort()
+            
+            if len(final) == 0:
+                return "Empty"
+                
+            last = ")(".join(final)
+            return "(" + last + ")" 
 
-        For each connected component, we can check whether 
-        it is bipartite by 
-        just trying to coloring it with two colors. How to do this is as follows: 
-        color any node red, then all of it's neighbors blue, 
-        then all of those neighbors 
-        red, and so on. If we ever color a red node blue 
-        (or a blue node red), then we've reached a conflict.
 
 
-1)  For problems like parenthesis matching. You can use a stack to solve the matching. But you can also
-    do matching by incrementing and decrementing an integer variable. Or you can use colors or 
-    other types of INDICATOR VARIABLE TYPE SOLUTIONS that contain meta information on the problem. 
-    Also remember that as you see each element, you can push multiple times to stack, not just once
-    in case u need to keep count of something before a pop occurs. 
-    
-0.05) To solve a difficult 3D problem or 2D problem. Solve the lower dimension first, 
-     and then use it to guide your solution for higher dimensions. 
-     Such as max area of rectangle of 1's.
 
-0.1) When doing string splitting, there are helper functions 
-     but sometimes its better to for loop through the 
-     string character by character because you have more granularity 
-     which can help to solve the problem easily. 
 
-0.15)   One-line Tree in Python
-        Using Python's built-in defaultdict we can easily define a tree data structure:
 
-        def tree(): return defaultdict(tree)
-        
-        users = tree()
-        users['harold']['username'] = 'hrldcpr'
-        users['handler']['username'] = 'matthandlersux'
+###############################################################33
+###################################################
+###############################################################33
+###################################################
+###############################################################33
+###################################################
 
-0.2) Learnings from interval coloring. Sometimes we care a lot about tracking our current running value
-    such as current running intersection to generate a solution output. However it can be better to
-    focus on the negative space, and care about what will be evicted first, as our main tracking 
-    concern using a priority queue. Look at problems with both positive and negative space in mind. 
-    Know whats best to track, and track it. dont be fooled by the question. 
+ALGO README PART 2:
 
-0.25) Look to see if the question is a
-      in the negative space of questions you've 
-      seen before!
-      For instance, Non-overlapping intervals LC, where
-      you find the minimum number of intervals to remove 
-      to make the rest of the intervals non-overlapping
-      is the negative of max interval scheduling using
-      earliest finish time.
+55.5) K stack pops (Finish it up https://binarysearch.com/problems/K-Stack-Pops):
+    
+        K Stack Pops
+        Medium
 
-      But you can also solve directly:
-      Sort the intervals by their start time. 
-      If two intervals overlap, the interval 
-      with larger end time will be removed 
-      so as to have as little impact on 
-      subsequent intervals
+        You are given two-dimensional list of integers stacks and an integer k. Assuming each list in stacks represents a stack, return 
+        the maximum possible sum that can be achieved from popping off exactly k elements from any combination of the stacks.
 
-0.26) Introduce multiple running variables, if maintaining one 
-        running variable makes the updates too difficult or tricky
-        (SEPERATION OF CONCERNS USING MULTIPLE VARS OR CONTAINERS TRICK)
+        Constraints
 
-        For instance: LC -> 
-        Given an integer array nums, find the contiguous 
-        subarray within an array (containing at least one number) 
-        which has the largest product.
+        n ≤ 500 where n is the number of rows in stacks.
+        m ≤ 200 where m is the maximum number of elements in a stack.
+        k ≤ 100
 
-        Example 1:
+        Youll realize only way is DP:
 
-        Input: [2,3,-2,4]
-        Output: 6
-        Explanation: [2,3] has the largest product 6.
-        
-        Solution:
-        int maxProduct(int A[], int n) {
-            // store the result that is the max we have found so far
-            int r = A[0];
+        attempt top down, then do bottom up. Watch out for following failures:: 
 
-            // imax/imin stores the max/min product of
-            // subarray that ends with the current number A[i]
-            for (int i = 1, imax = r, imin = r; i < n; i++) {
-                // multiplied by a negative makes big number smaller, small number bigger
-                // so we redefine the extremums by swapping them
-                if (A[i] < 0)
-                    swap(imax, imin);
+        class Solution:
+            def solveSlow(self, stacks, k):
+                
+                '''
 
-                // max/min product for the current number is either the current number itself
-                // or the max/min by the previous number times the current one
-                imax = max(A[i], imax * A[i]);
-                imin = min(A[i], imin * A[i]);
+                This solution didnt pass, we didnt optimize the DP states enuff.
+                FAILURE
 
-                // the newly computed max value is a candidate for our global result
-                r = max(r, imax);
-            }
-            return r;
-        }
+                '''
+                @cache
+                def helper(i,j, remaining):
+                    # i is the list we are processing so far. 
+                    # remaining is amt of elements left.
 
+                    if remaining == 0:
+                        return 0
 
-0.27) Binary Tree Max Path Sum: the binary tree version of max subarray sum:
+                    if i == len(stacks):
+                        return float("-inf")
 
-    Given a non-empty binary tree, find the maximum path sum.
-    For this problem, a path is defined as any sequence of nodes from 
-    some starting node to any node in the tree along the parent-child connections. 
-    The path must contain at least one node and does not need to go through the root.
-    
-    def maxPathSum(self, root: TreeNode) -> int:
-        m = float(-inf)
-        def helper(node):
-            nonlocal m
-            if node is None:
-                return 0
-            maxRightPath =  helper(node.right)
-            maxLeftPath = helper(node.left)           
-            right = maxRightPath + node.val
-            left = maxLeftPath + node.val
-            connected = maxRightPath + maxLeftPath + node.val
-            m = max(m, right, left, connected, node.val)
-            maxPath = max(right, left, node.val, 0)
-            return maxPath
-        helper(root)
-        return m
+                    take = float("-inf") 
+                    dont = float("-inf")
 
+                    # print("stacks i is", stacks[i])
+                    if len(stacks[i]) - j >= 0:
+                        element = stacks[i][len(stacks[i])-j]
+                    
+                        take = helper(i, j+1, remaining - 1) + element
+                        # stacks[i].append(element)
 
-0.28) Given an unbalacned binary search tree, write a function 
-      kthSmallest to find the kth smallest element in it.
-    # GENERATOR SOLN:
-    def traverse(node):
-        if node:
-            yield from traverse(node.left)
-            yield node
-            yield from traverse(node.right)
-        
-    def kthSmallest(root, k):
-        k -= 1
-        for i, node in enumerate(traverse(root)):
-            if i == k:
-                return node.val
+                    dont = helper(i+1,1, remaining)
+                    return max(take, dont)
 
+                return helper(0,1, k)
 
-    # RECURSIVE
-    def kthSmallest(self, root: TreeNode, k: int) -> int:
-        # LETS DO INORDER THIS TIME. 
-        found = None
-        count = 0
+            def solve(self, stacks, k):
+                '''
+                A[i+1,l]=max{A[i,l−t]+(t pops from stack i+1),0≤t≤l}
+                We can compute A[m,k] in time O(k^2m).
+                
+                '''   
+                pass
 
-        def inorder(node):
-            nonlocal found
-            nonlocal count
-            
-            # Ok found left side. 
-            if node is None:
-                return 
-            
-            inorder(node.left)
-            count += 1
-            if count == k:
-                found = node.val
-                return 
-            inorder(node.right)
-        inorder(root)
-        return found
-    
-    # ITERATION:
-    def kthSmallest(self, root, k):
-        stack = []
-        while True:
-            while root:
-                stack.append(root)
-                root = root.left
-            root = stack.pop()
-            k -= 1
-            if not k:
-                return root.val
-            root = root.right
-    
-    What if the BST is modified (insert/delete operations) 
-    often and you need to find the kth smallest frequently?
-    How would you optimize the kthSmallest routine?
-    
-    Seems like a database description, isn't it? Let's use here 
-    the same logic as for LRU cache design, and combine an 
-    indexing structure (we could keep BST here) with a double linked list.
-    Such a structure would provide:
+            # Forward dp? someone elses solution
+            def solve(self, stacks, k):
+                NINF = float("-inf")
+                dp = [NINF] * (k + 1)
+                dp[0] = 0
 
-    O(H) time for the insert and delete.
-    O(K) for the search of kth smallest.
+                for stack in stacks:
+                    P = [0]
+                    for x in reversed(stack):
+                        P.append(P[-1] + x)
 
-    You could also add a count field to each node but this would make performance:
-    It's not O(log n). O(h) instead. h is the height of the BST.
+                    for j in range(k, 0, -1):
+                        for i in range(1, min(j + 1, len(P))):
+                            dp[j] = max(dp[j], dp[j - i] + P[i])
 
+                return dp[k]
 
-0.3) Granularity === Optimization. Break up variables and track everything. Structurd things like
-      for loops, and functional structures like reduction, and map, and filter 
-      that dont fit the required granlarity should be thrown away if it interferes. 
+                
+                return A[len(stacks) - 1][k]
 
-0.4) HOW TO do cieling using python floor int truncation:
 
-    def ceiling_division(n, d):
-        return -(n // -d)
 
-0.45) When you are solving a problem, and it seems like DP. 
-      take a step back and see if you can use  hash map abuse + greedy,
-      to solve the problem. DP uses hash maps too, but maybe you can
-      be smart and add direction, and running values, which will allow  
-      hash map abuse to work (try thinking of it bottom up, base case, direction,
-      to help you think of hash map abuse or a greedy soln). 
 
-0.5) Preprocess and do a running comparison between 2 containers. 
-    For instance, to do certain problems you need to sort a list and then compare the sorted list 
-    to another list to determine ways to do sliding window/2pointer type techniques. 
+56) Do N CHOOSE K. Generate all K combinations:
+     Recursively:
 
-0.55) GREEDY AND 2 POINTER SOLUTION GUIDE: 
-      
-      For an optimization problem, to do it greedily and efficiently, do not enumerate 
-      all states, only ones that you are sure could possibily be better under the problems
-      constraints. 
-      Do this first:
-      
-      DISCOVER ALL THE CONSTRIANTS INTRODUCED BY THE PROBLEM FIRST!
-      THEN THINK OF THEOREMS THAT MUST BE TRUE AS A RESULT OF THE CONSTRAINTS.
-      RUN THROUGH EXAMPLES, TO ENSURE THEOREMS ARE TRUE, and then step through a 
-      solution to see how they work: 
+     // C++ program to print all combinations of size 
+    // k of elements in set 1..n 
+    #include <bits/stdc++.h> 
+    using namespace std; 
+    
+    void makeCombiUtil(vector<vector<int> >& ans, 
+        vector<int>& tmp, int n, int left, int k) 
+    { 
+        // Pushing this vector to a vector of vector 
+        if (k == 0) { 
+            ans.push_back(tmp); 
+            return; 
+        } 
+    
+        // i iterates from left to n. First time 
+        // left will be 1 
+        for (int i = left; i <= n; ++i) 
+        { 
+            tmp.push_back(i); 
+            makeCombiUtil(ans, tmp, n, i + 1, k - 1); 
+    
+            // Popping out last inserted element 
+            // from the vector 
+            tmp.pop_back(); 
+        } 
+    } 
+    
+    // Prints all combinations of size k of numbers 
+    // from 1 to n. 
+    vector<vector<int> > makeCombi(int n, int k) 
+    { 
+        vector<vector<int> > ans; 
+        vector<int> tmp; 
+        makeCombiUtil(ans, tmp, n, 1, k); 
+        return ans; 
+    } 
+    
+    // Driver code 
+    int main() 
+    { 
+        // given number 
+        int n = 5; 
+        int k = 3; 
+        vector<vector<int> > ans = makeCombi(n, k); 
+        for (int i = 0; i < ans.size(); i++) { 
+            for (int j = 0; j < ans[i].size(); j++) { 
+                cout << ans.at(i).at(j) << " "; 
+            } 
+            cout << endl; 
+        } 
+        return 0; 
+    } 
+        
 
-      Do both 1 and 2 at same time to come up with a solution:
-      1) EXPLOT THEOREMS TO CREATE the OPTIMIZATION PATTERNS AND STEPS TO EXECUTE.
-         Thinking of the problem using DP can help with greedy creation. 
-      2) THINK OF WHAT A PROOF TO THE GREEDY PROBLEM COULD BE GIVEN THE THEREMS;
-         use proof to guide creation of greedy.
 
-      Example: Container with most water: 
-        
-        Find two lines, which together with x-axis forms a container, 
-        such that the container contains the most water.
-        Input: [1,8,6,2,5,4,8,3,7]
-        Output: 49
-        
-        class Solution:
-            def maxArea(self, height):
-                i, j = 0, len(height) - 1
-                water = 0
-                while i < j:
-                    water = max(water, (j - i) * min(height[i], height[j]))
-                    if height[i] < height[j]:
-                        i += 1
-                    else:
-                        j -= 1
-                return water
 
-0.56) SLIDING WINDOW ALGO DESIGN PATTERN:
-      Max Sum Contiguous Subarray: 
-      
-    # Function to find the maximum contiguous subarray 
-    from sys import maxint 
-    def maxSubArraySum(a,size): 
-        
-        max_so_far = -maxint - 1
-        max_ending_here = 0
-        
-        for i in range(0, size): 
-            max_ending_here = max_ending_here + a[i] 
-            if (max_so_far < max_ending_here): 
-                max_so_far = max_ending_here 
-    
-            if max_ending_here < 0: 
-                max_ending_here = 0   
-        return max_so_far 
 
 
-0.57) Interval Coloring:
+-53) Recursive Multiply:
+    Write a recursie function to multiply 2 positive integers without using the 
+    * operator. Only addition, subtraction and bit shifting but minimize ops. 
+
+    Answer:
+
+    int minProduct(int a, int b) {
+        int bigger = a< b ? b : a;
+        int smaller = a < b ? a: b;
+        return minProductHelper(a, b);
+    }
+
+    int minProdHelper(smaller, bigger) {s
+        if smaller == 0 return 0
+        elif smaller == 1 return 1
+
+        int s = smaller >> 1; //divide by 2
+        int halfPrd = minProductHelper(s, bigger);
+        if smaller % 2 == 0:
+            return halfProd + halfProd
+        else:
+            return halfProd + halfProd + bigger
+    }
+    Runtime O(log s)
     
-    from heapq import *
-    import itertools
 
-    def minMeetingRooms(self, intervals):
-        sorted_i = sorted(intervals, key=lambda x: x.start)
-        
-        pq = []
-        counter = itertools.count()
-        active_colors = 0
-        max_colors = 0
-        
-        for i in sorted_i:
-            iStart = i.start
-            iEnd = i.end
-            
-            while len(pq) != 0:
-                
-                min_end_time, _, interval_to_be_popped = pq[0]                
-                if(iStart <= min_end_time):
-                    break                
-                active_colors -= 1
-                _ = heappop(pq)
-                            
-            c = next(counter)
-            item = [iEnd, c, i]
-            heappush(pq, item)
-            print("increment active colors")
-            active_colors += 1
-            max_colors = max(active_colors, max_colors)
-        return max_colors
 
 
-0.6) To delete from a list in O(1), any index, you can swap the middle indexed element with
-    the last element in the array. then call array.pop(). This is O(1). You could also use a linked
-    list. The problem is, this will mess up the sorting of your array if you do this. 
-    so dont do it if your result needs to be sorted. 
+1) REVIEW BIDIRECTIONAL BFS PYTHON SOLUTION FOR Open the Lock in important questions. 
 
+49) Detect negative cycles with Bellman Ford:
 
-0.65) EMULATE DO WHILE IN PYTHON:
+    1) Initialize distances from source to all vertices as infinite and distance to source itself as 0. 
+    Create an array dist[] of size |V| with all values as infinite except dist[src] where src is source vertex.
 
-        i = 1
+    2) This step calculates shortest distances. Do following |V|-1 times where |V| is the number of vertices in given graph.
+    …..a) Do following for each edge u-v
+    ………………If dist[v] > dist[u] + weight of edge uv, then update dist[v]
+    ………………….dist[v] = dist[u] + weight of edge uv
 
-        while True:
-            print(i)
-            i = i + 1
-            if(i > 3):
-                break
+    3) This step reports if there is a negative weight cycle in graph. Do following for each edge u-v
+    ……If dist[v] > dist[u] + weight of edge uv, then “Graph contains negative weight cycle”
 
-0.67) PYTHON AND BINARY Enumerate all subsets:
-    class Solution:
-        def subsets(self, nums):
-            numberOfSubsets = len(nums)
-            subsets = []
-            for i in range(0, 2 ** numberOfSubsets):
-                bits = bin(i)
-                subset = []
-                for j in range(0, numberOfSubsets):
-                    if i >> j & 1:  # Check if the first bit is on, 
-                                    # then check if second bit is on, 
-                                    # then check third bit is on, and keep going
-                        subset.append(nums[j])
+    The idea of step 3 is, step 2 guarantees shortest distances if graph doesn’t 
+    contain negative weight cycle. If we iterate through all edges one more 
+    time and get a shorter path for any vertex, then 
+    there is a negative weight cycle.
 
-                subsets.append(subset)
-            return subsets
 
-        Iterate through all subsets of a 
-        subset y (not including empty set) (TODO WRITE IN PYTHON):
+55)    Common problems solved using DP on broken profile include:
 
-        given a set of numbers, we want to find the sum of all subsets.
+        finding number of ways to fully fill an area 
+        (e.g. chessboard/grid) with some figures (e.g. dominoes)
+        finding a way to fill an area with minimum number of figures
+        finding a partial fill with minimum number of unfilled space (or cells, in case of grid)
+        finding a partial fill with the minimum number of figures, such that no more figures can be added
+        Problem "Parquet"
+        
+        Problem description. Given a grid of size N×M. 
+        Find number of ways to 
+        fill the grid with figures of size 2×1 (no cell 
+        should be left unfilled, 
+        and figures should not overlap each other).
 
-            Sol: This is easy to code using bitmasks. we can use an array to store all the results.
+        Let the DP state be: dp[i,mask], where i=1,…N and mask=0,…2^(M)−1.
 
-            int sum_of_all_subset ( vector< int > s ){
-                        int n = s.size() ;
-                        int results[ ( 1 << n ) ] ;     // ( 1 << n )= 2^n
+        i respresents number of rows in the current grid, and mask is the state of 
+        last row of current grid. If j-th bit of mask is 0 then the corresponding 
+        cell is filled, otherwise it is unfilled.
 
-                    //initialize results to 0
-                        memset( results, 0, sizeof( results ) ) ;
+        Clearly, the answer to the problem will be dp[N,0].
 
-                    // iterate through all subsets
-                    // for each subset, O(2^n)
-                    for( int i = 0 ; i < ( 1 << n ) ; ++ i ) {    
-                            // check membership, O(n)
-                            for ( int j = 0; j < n ; ++ j ) {       
-                                // test bit
-                                if ( ( i & ( 1 << j ) ) ! = 0 )    
-                                    results[i] += s [j] ;          
-                                }
+        We will be building the DP state by iterating over each i=1,⋯N 
+        and each mask=0,…2^(M)−1, and for each mask we will be only transitioning forward, 
+        that is, we will be adding figures to the current grid.
+        
+        int n, m;
+        vector < vector<long long> > dp;
+        void calc (int x = 0, int y = 0, int mask = 0, int next_mask = 0)
+        {
+            if (x == n)
+                return;
+            if (y >= m)
+                dp[x+1][next_mask] += d[x][mask];
+            else
+            {
+                int my_mask = 1 << y;
+                if (mask & my_mask)
+                    calc (x, y+1, mask, next_mask);
+                else
+                {
+                    calc (x, y+1, mask, next_mask | my_mask);
+                    if (y+1 < m && ! (mask & my_mask) && ! (mask & (my_mask << 1)))
+                        calc (x, y+2, mask, next_mask);
                 }
             }
-
-0.68) When you are doing a question that requires modifying a list as you go
-      dont save pointers to the list and reprocess list and other stuff. 
-      Do all the modifications in one loop as you go.
-      Such as for Insert Interval (LC 57)
-      
-0.69) When the question has products involved. Use Logs to turn it into a sums question. 
+        }
 
 
-0.7) Iterate backwards through array using python for dp:
-    for i in range(len(arr) - 1, -1, -1):
-        print(i)
+        int main()
+        {
+            cin >> n >> m;
 
-0.71) Remember that its constant space when you are enumerating over the alphabet!!
+            dp.resize (n+1, vector<long long> (1<<m));
+            dp[0][0] = 1;
+            for (int x=0; x<n; ++x)
+                for (int mask=0; mask<(1<<m); ++mask)
+                    calc (x, 0, mask, 0);
 
-0.75) To get the fastest greedy solution possible, you must keep getting more
-     and more greedy and breaking assumptions you think you have. Only 
-     care about the answer, not the details of the question. Focus on 
-     what you REALLY NEED!!! when you keep breaking the questions rules
-     you thought were rules, find the true constraints!
-     Look at 621) Task Scheduler. It looked complicated but we just 
-     kept getting more greedy to get the most optimal MATHEMATICAL SOLUTION.
-     USE MATH AND ANALYSIS TO GET THE BEST SOLUTION!
+            cout << dp[n][0];
+        }
 
 
-0.8) Sometimes you will get TLE with the bottom up solution. 
-     
-     This is because bottom up is slower since it is performing a BFS, 
-     rather than going directly to the solution unlike DFS + memoization, 
-     that tries to solve as quickly as possible. 
 
-     => If you only need a subset of the possible outputs 
-     from the algorithm, then the answer could also be yes. 
-     You only calculate the outputs you need, and so you avoid unneeded work.
-    => Jump 
+47) Union Find Structure
+    -> Used to store disjoint sets
+    -> Can support 2 types of operations efficienty:
+    - Find(x) returns the "representative" of the set that x belongs. 
+    - Union(x, y): merges 2 sets that contain x and y
 
+    Both operations can be done in (essentially) constant time
+    Main idea: represent each set by a rooted tree
+        -> Every node maintains a link to its parent
+        -> A root node is "representative" of the corresponding set.
+    
+    Find(x) => follow the links from x until a node points itself. 
+        -> This is O(N). DO PATH COMPRESSION.
+        -> Makes tree shallower every time Find() is called. 
+        -> After Find(x) returns the root, backtrack to x and reroute
+            all the links to the root. 
 
-0.85) When their is a max or min problem. 
-      TRY GREEDY first before doing GRAPH SEARCH + DP
-      Be smart first and do 
-      GREEDY + EXPLOIT PROBLEM STRUCTURE before anything 
-      else. 
+    Union(x, y) => run Find(x) and Find(y) to find the 
+            corresponding root nodes and direct one to the other
 
-0.9) Bidirectional BFS Reasons to use:
+    Union By rank:  
+        always attaches the shorter tree to the root of the 
+        taller tree. Thus, the resulting tree 
+        is no taller than the originals unless they were of equal height, 
+        in which case the resulting tree is taller by one node.
 
-    Bi-directional BFS will yield much better 
-    results than simple BFS in most cases. Assume the 
-    distance between source and target is k, and the 
-    branching factor is B (every vertex has on average B edges).
+        To implement union by rank, each element is associated with a rank. 
+        Initially a set has one element and a rank of zero. If two sets are 
+        unioned and have the same rank, the resulting set's rank is one larger; 
+        otherwise, if two sets are unioned and have different ranks, the resulting
+        set's rank is the larger of the two. Ranks are used instead of height or 
+        depth because path compression will change the trees' heights over time.
 
-    BFS will traverse 1 + B + B^2 + ... + B^k vertices.
-    Bi-directional BFS will traverse 2 + 2B^2 + ... + 2B^(k/2) vertices.
-    For large B and k, the second is obviously much faster the the first.
+    PSEUDOCODE:
+    function MakeSet(x)
+        if x is not already present:
+            add x to the disjoint-set tree
+            x.parent := x
+            x.rank   := 0
+            x.size   := 1
 
-1) Exploit problem structure
+    function Find(x)
+        if x.parent != x
+            x.parent := Find(x.parent)
+        return x.parent
 
-    a) This means using a sliding window
-    b) This means keeping track of running values, and updating permanent values such as 
-        keeping tracking of curr_max_from_left to update overall_max when you are running through an array
-        -> running variables, running maps, running sets
-    c) Use 2 pointer solutions. Two pointers can be nodes or indexes in an array.
+    function Union(x, y)
+        xRoot := Find(x)
+        yRoot := Find(y)
+    
+        // x and y are already in the same set
+        if xRoot == yRoot            
+            return
+    
+        // x and y are not in same set, so we merge them
+        if xRoot.rank < yRoot.rank
+            xRoot, yRoot := yRoot, xRoot // swap xRoot and yRoot
+    
+        // merge yRoot into xRoot
+        yRoot.parent := xRoot
+        if xRoot.rank == yRoot.rank:
+            xRoot.rank := xRoot.rank + 1
+    
 
-1.25)   When the problem says sorted order, you can use
-        binary search or a very smart version of
-        2 pointer/2 index solutions. For instance,
-        2 SUM for ordered arrays can be 
-        solved in O(N) (OR even O(log N) if you implement 
-        binary searching 2 pointers)
 
-        # binary search        
-        def twoSum(self, numbers, target):
-            for i in xrange(len(numbers)):
-                l, r = i+1, len(numbers)-1
-                tmp = target - numbers[i]
-                while l <= r:
-                    mid = l + (r-l)//2
-                    if numbers[mid] == tmp:
-                        return [i+1, mid+1]
-                    elif numbers[mid] < tmp:
-                        l = mid+1
-                    else:
-                        r = mid-1
+48) Applications of Union Find:
+    keep track of the connected components of an undirected graph. 
+    This model can then be used to determine whether 
+    two vertices belong to the same component, 
+    or whether adding an edge between them would result in a cycle. 
+    DETECT CYCLE IN UNDIRECTED GRAPH:
+    
+        # A utility function to find the subset of an element i 
+        def find_parent(self, parent,i): 
+            if parent[i] == -1: 
+                return i 
+            if parent[i]!= -1: 
+                return self.find_parent(parent,parent[i]) 
+    
+        # A utility function to do union of two subsets 
+        def union(self,parent,x,y): 
+            x_set = self.find_parent(parent, x) 
+            y_set = self.find_parent(parent, y) 
+            parent[x_set] = y_set 
 
-1.3) Count set bits in integer:
-      (Log N!!) if N represents size of number
+        # The main function to check whether a given graph 
+        # contains cycle or not 
+        def isCyclic(self): 
+            
+            # Allocate memory for creating V subsets and 
+            # Initialize all subsets as single element sets 
+            parent = [-1]*(self.V) 
+    
+            # Iterate through all edges of graph, find subset of both 
+            # vertices of every edge, if both subsets are same, then 
+            # there is cycle in graph. 
+            for i in self.graph: 
+                for j in self.graph[i]: 
+                    x = self.find_parent(parent, i)  
+                    y = self.find_parent(parent, j) 
+                    if x == y: 
+                        return True
+                    self.union(parent,x,y) 
 
-    # Function to get no of set bits in binary 
-    # representation of positive integer n */ 
-    def  countSetBits(n): 
-        count = 0
-        while (n): 
-            count += n & 1
-            n >>= 1
-        return count 
 
-1.5) LOOK AT PROBLEM IN ALL POSSIBLE DIRECTIONS to apply your techniques, whether its 2 pointer, 
-    sliding window, or Dynamic programming
-    a) think about left to right
-    b) right to left
-    c) 2 pointer on either side and you close into the middle
-    d) 2 pointers, one that traverses even indexes, and the other that traverses odd indexes
-    e) Linked list pointers, second moves twice as fast as the first. When second gets to end, first is at halfway node. 
-    f) Be creative in how you see the DIRECTIONALITY of the solution for a given problem. 
+41) FORD FULKERSON ALGORITHM PYTHON (MAX FLOW MIN CUT):
+    class Graph: 
+    
+        def __init__(self,graph): 
+            self.graph = graph # residual graph 
+            self. ROW = len(graph)             
+    
+        '''Returns true if there is a path from source 's' to sink 't' in 
+        residual graph. Also fills parent[] to store the path '''
+        def BFS(self,s, t, parent): 
+    
+            # Mark all the vertices as not visited 
+            visited =[False]*(self.ROW) 
+            queue=[] 
+            queue.append(s) 
+            visited[s] = True
 
-1.6) Coin Change Bottom Up DP:
-        You are given coins of different denominations and a total amount of money amount. 
-        Write a function to compute the fewest number of coins that you need to 
-        make up that amount. If that amount of money cannot be made 
-        up by any combination of the coins, return -1.
+            while queue: 
+    
+                #Dequeue a vertex from queue and print it 
+                u = queue.pop(0) 
+            
+                # Get all adjacent vertices of the dequeued vertex u 
+                # If a adjacent has not been visited, then mark it 
+                # visited and enqueue it 
+                for ind, val in enumerate(self.graph[u]): 
+                    if visited[ind] == False and val > 0 : 
+                        queue.append(ind) 
+                        visited[ind] = True
+                        parent[ind] = u 
 
-        Example 1:
+            return True if visited[t] else False
+                      
+        # Returns tne maximum flow from s to t in the given graph 
+        def FordFulkerson(self, source, sink): 
+    
+            # This array is filled by BFS and to store path 
+            parent = [-1]*(self.ROW) 
+    
+            max_flow = 0 # There is no flow initially 
+    
+            # Augment the flow while there is path from source to sink 
+            while self.BFS(source, sink, parent) : 
+    
+                # Find minimum residual capacity of the edges along the 
+                # path filled by BFS. Or we can say find the maximum flow 
+                # through the path found. 
+                path_flow = float("Inf") 
+                s = sink 
 
-        Input: coins = [1, 2, 5], amount = 11
-        Output: 3 
-        Explanation: 11 = 5 + 5 + 1
-        Example 2:
+                # Get the limiting flow in the path. Traverse parents array to get path
+                while(s !=  source): 
+                    path_flow = min (path_flow, self.graph[parent[s]][s]) 
+                    s = parent[s] 
+    
+                # Add path flow to overall flow 
+                max_flow +=  path_flow 
+    
+                # update residual capacities of the edges and reverse edges along the path 
+                v = sink 
+                while(v !=  source): 
+                    u = parent[v] 
+                    self.graph[u][v] -= path_flow 
+                    self.graph[v][u] += path_flow 
+                    v = parent[v] 
+    
+            return max_flow 
 
-        Input: coins = [2], amount = 3
-        Output: -1
-        Note:
-        You may assume that you have an infinite number of each kind of coin.  
-        
-        class Solution(object):
-            def coinChange(self, coins, amount):
-                """
-                :type coins: List[int]
-                :type amount: int
-                :rtype: int
-                """
-                rs = [amount+1] * (amount+1)
-                rs[0] = 0
-                for i in xrange(1, amount+1):
-                    for c in coins:
-                        if i >= c:
-                            rs[i] = min(rs[i], rs[i-c] + 1)
+    graph = [[0, 16, 13, 0, 0, 0], 
+            [0, 0, 10, 12, 0, 0], 
+            [0, 4, 0, 0, 14, 0], 
+            [0, 0, 9, 0, 0, 20], 
+            [0, 0, 0, 7, 0, 4], 
+            [0, 0, 0, 0, 0, 0]]    
+    g = Graph(graph) 
+    source = 0; sink = 5
+    print ("The maximum possible flow is %d " % g.FordFulkerson(source, sink)) 
+  
+    Output:
+    The maximum possible flow is 23
 
-                if rs[amount] == amount+1:
-                    return -1
-                return rs[amount]
+42) Bipartite matching problem: (Max flow 1)
+    n students. d dorms. Each student wants to live in one of 
+    the dorms of his choice. 
+    Each dorm can accomodate at most one student. 
+
+    Problem: Find an assignment that maximizes the number of 
+    students who get a housing.
+    
+    Add source and sink. 
+    make edges between students and dorms. 
+    all edges weight are 1
+    S-> all students -> all dorms -> T
 
+    Find the max-flow. Then find the optimal assignment from the chosen
+    edges. 
 
-1.7) Sliding window: Common problems you use the sliding window pattern with:
-        -> Maximum sum subarray of size ‘K’ (easy)
-        -> Longest substring with ‘K’ distinct characters (medium)
-        -> String anagrams (hard)
+    If dorm j can accomodate cj students -> make edge with capacity
+    cj from dorm j to the sink.
+    
+43) Decomposing a DAG into nonintersecting paths:
+    -> Split each vertex v into vleft and vright
+    -> For each edge u->v in the DAG, make an edge from uleft to vright
 
-1.75) Transpose matrix:
-      Switch (i, j) with (j,i) either by 
-      iterating over upper triangle or lower triangle:
+44) Min Cost Max Flow:
+    A varient of max-flow problem. Each edge has capacity c(e) and
+    cost cost(e). You have to pay cost(e) amount of money per unit 
+    flow per unit flow flowing through e
+    -> Problem: Find the max flow that has the minimum total cost.
+    -> Simple algo (Slow):
+        Repeat following:
+            Take the residual graph
+            Find a negative cost cycle using Bellman Ford
+                -> If there is none, finish. 
+            Circulate flow through the cycle to decrease the total cost,
+            until one of the edges is saturated.
+                -> Total amount of flow doesnt change .
 
-        n = len(A)
-        for i in range(n):
-            for j in range(i):
-                A[i][j], A[j][i] = A[j][i], A[i][j]
+45) Segment Tree Attempt:
 
+    Question 3:
+    Given an array of +ve numbers and another array of same size with zeros.
+    Here are the operations you're allowed to perform on the second array.
 
-1.8) Two Pointers is often useful when searching pairs in a 
-        sorted array or linked list; for example, 
-        when you have to compare each element 
+    You're allowerd to increment only a subarray of values. [Subarray has to be a contiguous block]
+    You're allowerd to increment the values of the subarray by a value of 1.
+    How many increment operations does it require to transform second array of zeros to the first array?
 
-        Here are some problems that feature the Two Pointer pattern:
-        of an array to its other elements.
-        Squaring a sorted array (easy)
-        Triplets that sum to zero (medium)
-        Comparing strings that contain backspaces (medium)
+    Input:
+    [3, 4, 2, 5, 7]
 
-1.9) Fast and slow pointer:
-        The Fast and Slow pointer approach, also known as the Hare & Tortoise algorithm, 
-        is a pointer algorithm that uses two pointers which move through the array 
-        (or sequence/linked list) at different speeds. This approach is quite useful 
-        when dealing with cyclic linked lists or arrays.
-        By moving at different speeds (say, in a cyclic linked list), the 
-        algorithm proves that the two pointers are bound to meet. The fast 
-        pointer should catch the slow pointer once both the pointers are in a cyclic loop.
-        
-        Linked List Cycle (easy)
-        Linked List Cycle || (medium)
-        Palindrome Linked List (medium)
-        Cycle in a Circular Array (hard)
+    Output: 9
 
+    For Q3, All the comments are discussing O(nlogn) or O(n^2) solutions, I have O(n) solution seems straight forward
 
-1.95) Use pointer on the fly construction !!
-      Combining running 2 pointers, running 2 container concepts, and space-efficient
-      dynamic programming concepts to get O(N) speed, O(1) space except for output container.
-      Think in terms of containers to implement fast 2 pointer solution!
-      Then think in terms of DP to reduce to a 1 pointer solution!
-      
+    Logic
+    Assume we know the answer for array of size n-1 elements and now we are 
+    trying to compute array of size n elements (1 new integer got added to the array at the end)
+    if the last element in the old array is greater than or equal to the newly added element 
+    then number of operations to add will be zero.
+    if the last element in the old array is less than the newly added element then number of 
+    operations to add will be newly added element - last element of old array
 
-        FOR THIS PROBLEM, TRY LAGGING YOUR RUNNING VARIABLES AND INSERTIONS TO MAKE THE ALGO WORK.
-        
-        238. Product of Array Except Self
+    Code Soln 1:
 
-        Given an array nums of n integers where n > 1,  
-        return an array output such that output[i] is 
-        equal to the product of all the elements of nums except nums[i].
+        public int minOperations(int[] a) {
+            if(a.length == 0) return 0;
+            int res = a[0];
+            for(int i=1; i<a.length; i++) {
+                res += Math.max(0, a[i] - a[i-1]);
+            }
+            return res;
+        }
 
-        Example:
+    Segment Tree Soln 2:
 
-        Input:  [1,2,3,4]
-        Output: [24,12,8,6]
-        Note: Please solve it without division and in O(n).
+        def seg_tree(arr, i, j, cache):
+            if i == j:
+                cache[(i, j)] = [i, arr[i]]
+                
+            else:
+                k = int((i + j)/2)
+                
+                a = seg_tree(arr, i, k, cache)
+                b = seg_tree(arr, k+1, j, cache)
+                
+                cache[(i, j)] = a if a[1] < b[1] else b
+                
+            return cache[(i, j)]
 
-        Follow up:
-        Could you solve it with constant space complexity? 
+        def get_min(cache, p, q, i, j):
+            if (p, q) in cache:
+                return cache[(p, q)]
+            
+            k = int((i + j)/2)
+            
+            if q <= k:
+                return get_min(cache, p, q, i, k)
+            elif p > k:
+                return get_min(cache, p, q, k+1, j)
+            else:
+                a = get_min(cache, p, k, i, k)
+                b = get_min(cache, k+1, q, k+1, j)
+                
+                return a if a[1] < b[1] else b
+            
+        def increment_recur(cache, p, q, n, m):
+            i, v = get_min(cache, p, q, 0, n-1)
+            
+            if p == q:
+                return v-m
+            
+            a = increment_recur(cache, p, i-1, n, v) if i-1 >= p else 0
+            b = increment_recur(cache, i+1, q, n, v) if i+1 <= q else 0
+            
+            return v - m + a + b
+                
+        def increment(arr):
+            cache = {}
+            n = len(arr)
+            seg_tree(arr, 0, n-1, cache)
+            return increment_recur(cache, 0, n-1, n, 0)
 
-        class Solution:
-            # @param {integer[]} nums
-            # @return {integer[]}
-            def productExceptSelf(self, nums):
-                p = 1
-                n = len(nums)
-                output = []
-                for i in range(0,n):
-                    output.append(p)
-                    p = p * nums[i]
-                p = 1
-                for i in range(n-1,-1,-1):
-                    output[i] = output[i] * p
-                    p = p * nums[i]
-                return output
 
-2) Back tracking
-    => For permutations, need some intense recursion 
-        (recurse on all kids, get all their arrays, and append our chosen element to everyones array, return) 
-        and trying all posibilities
-    => For combinations, use a binary tree. Make the following choice either: CHOOSE ELEMENT. DONT CHOOSE ELEMENT. 
-        Recurse on both cases to get all subsets
-    => To get all subsets, count from 0 to 2^n, and use bits to choose elements.
-    => When doing DP, check to see if you are dealing with permutations or combinations type solutions, and 
-        adjust your DP CAREFULLY ACCORDING TO THAT -> AKA CHECK COIN CHANGE 2
 
-2.3) Graphs =>
-    Try BFS/DFS/A star search
-    Use dist/parent/visited maps to get values
-    -> Cycle detection -> use visited map. 
-        Actually need to carry parent in param as well in dfs 
-        for undirected graph
-    -> shortest path = BFS
-    -> Do parent stuff with parents map (such as common ancestors).
-    -> Cool graph techniques is coloring nodes, or flagging nodes 
-        if you are trying to get multiple paths in graph and looking for path intersections. 
-    -> To do topological sort, USE DFS and get start end times. also can count in-nodes and out-nodes to sort them !
-    -> Reverse the graph to get the shortest path starting from all other nodes to your node!
-    -> Sometimes in a problem, you cant bfs/dfs once. you need to bfs/dfs every vertex!
-    -> Minimum spanning tree -> use prims algorithm or kruskals algorithm
-    -> Find strongly connected components => use kosarju's algo which does dfs on graph and the reverse of the graph from a vertex.
-    -> Topological SORT: dfs, process nodes children first, then add node to list. then reverse entire list at end
-     REMOVING CYCLES, DFS, AND BFS using colors: DONE IN GRAPHA ALGO REVIEW SECTION BELOW. 
 
 
-2.31) PRIM VS KRUSKAL
-    If you implement both Kruskal and Prim, in their optimal form : with a union find and a 
-    finbonacci heap respectively, then you will note how Kruskal is easy to implement compared to Prim.
+####################################################################
+############################################
 
-    Prim is harder with a fibonacci heap mainly because you have to maintain a book-keeping 
-    table to record the bi-directional link between graph nodes and heap nodes. With a Union Find, 
-    it's the opposite, the structure is simple and can even produce directly the mst at almost no additional cost.
+COOL NOTES PART 0.0: DFS Trees, Articulation Points, CUT EDGES AND BRIDGES
 
+32.5) DFS LOW LINK!
 
+        ARTICULATION POINTS :
 
-    Use Prim's algorithm when you have a graph with lots of edges.
+        These are also called cut-vertices . When they are removed(including the edges connected to them) , 
+        the remaining graph is broken down into two or more connected components.
 
-    For a graph with V vertices E edges, Kruskal's algorithm runs in O(E log V) time 
-    and Prim's algorithm can run in O(E + V log V) amortized time, if you use a Fibonacci Heap.
+        BRIDGES:
 
-    Prim's algorithm is significantly faster in the limit when you've got a 
-    really dense graph with many more edges than vertices. Kruskal performs better in 
-    typical situations (sparse graphs) because it uses simpler data structures.
+        These are also called cut-edges . When they are removed, the graph 
+        is broken down into two or more connected components.
 
+        FORWARD EDGES:
 
-    Kruskal's algorithm will grow a solution from the cheapest edge by 
-    adding the next cheapest edge, provided that it doesn't create a cycle.
+        They are the edges taken during the dfs (or bfs) . 
+        More specifically, they are the edges present in the dfs tree.
 
-    Prim's algorithm will grow a solution from a random vertex by adding 
-    the next cheapest vertex, the vertex that is not currently in the 
-    solution but connected to it by the cheapest edge.    
+        BACK EDGES:
 
-2.311) KRUSKALS WITH AND WITHOUT Disjoint set union
+        They are the edges that connect vertices to some of its ancestors..
 
+        NOTE:  In a dfs tree there exits no cross-edge. Suppose there are 2 vertices u and v connected 
+        to each other and some same ancestor in dfs-tree say w. So u(or v) is visited before v(or u) 
+        during dfs and the edge u-v then becomes a forward edge making the edge v-w(or u-w) a back edge.
 
-    Then begins the process of unification: pick all edges from the first to 
-    the last (in sorted order), and if the ends of the currently picked edge 
-    belong to different subtrees, these subtrees are combined, 
-    and the edge is added to the answer. After iterating through 
-    all the edges, all the vertices will belong to the same sub-tree, 
-    and we will get the answer.
+        PROPERTY I :  In a tree , all edges are cut-edges. (By defination of a tree)
 
-    The simplest implementation
-    The following code directly implements the algorithm described above, 
-    and is having O(MlogM+N^2) time complexity. Sorting edges requires O(MlogN) 
-    (which is the same as O(MlogM)) operations. Information regarding the subtree to 
-    which a vertex belongs is maintained with the help of an array tree_id[] - 
-    for each vertex v, tree_id[v] stores the number of the tree , to which v belongs. 
-    For each edge, whether it belongs to the ends of different trees, 
-    can be determined in O(1). Finally, the union of the two trees is carried 
-    out in O(N) by a simple pass through tree_id[] array. Given that the 
-    total number of merge operations is N−1, we obtain 
-    the asymptotic behavior of O(MlogN+N^2).
+        PROPERTY II: For a vertex u to be a cut-vertex, there should be some vertex v in its subtree 
+        in dfs tree which has no back edge to any ancestor of u or none of its ancestors which lie in 
+        path from u to to v has a backedge to an ancestor of u.  Why? Suppose we claim vertex w is a 
+        cut vertex and u be any vertex in it’s subtree. If u has a back-edge to any ancestor of w, 
+        cutting w doesn’t break it into two components as u is still reachable from ancestor’s of w.
 
-    NON DSU IMPL:
-        struct Edge {
-            int u, v, weight;
-            bool operator<(Edge const& other) {
-                return weight < other.weight;
-            }
-        };
+        PROPERTY III: For an edge e connecting u and v  ( par[v]=u ) to be a cut-edge , none of the 
+        vertices in the subtree of v should have a backedge to u or any of its ancestors. (Same reasoning as above)
 
-        int n;
-        vector<Edge> edges;
+        Note: From now on we will be focussing on finding bridges of a graph. Finding Articulation Points would just need some trivial changes from that.
 
-        int cost = 0;
-        vector<int> tree_id(n);
-        vector<Edge> result;
-        for (int i = 0; i < n; i++)
-            tree_id[i] = i;
+        So how to find bridges in a graph ?
 
-        sort(edges.begin(), edges.end());
+        BRUTE FORCE
+        We can loop through all the edges, remove them and check if it’s a cut edge or not by running a dfs and 
+        checking the number of connected components formed. COMPLEXITY: O(E*(V+E))        
 
-        for (Edge e : edges) {
-            if (tree_id[e.u] != tree_id[e.v]) {
-                cost += e.weight;
-                result.push_back(e);
+        OPTIMIZED APPROACH
+        Let’s start by defining a new term:
 
-                int old_id = tree_id[e.u], new_id = tree_id[e.v];
-                for (int i = 0; i < n; i++) {
-                    if (tree_id[i] == old_id)
-                        tree_id[i] = new_id;
-                }
-            }
-        }
+        LOWLINKS:
 
-    DSU implementation:
+        Lowlink of a vertex v is the maximum ancestor in dfs tree to 
+        which v or any node in its subtree in dfs tree has a backedge to.
+                 ---> 1 
+                /    /\
+               /   2   5               
+               |  /    /\   
+               | 3    6  7
+               |/
+               4
 
-    Just as in the simple version of the Kruskal algorithm, we 
-    sort all the edges of the graph in non-decreasing order of weights. 
-    Then put each vertex in its own tree (i.e. its set) via calls to the make_set 
-    function - it will take a total of O(N). We iterate through all the edges (in sorted order) 
-    and for each edge determine whether the ends belong to different trees (with two find_set 
-    calls in O(1) each). Finally, we need to perform the union of the two trees (sets), for 
-    which the DSU union_sets function will be called - also in O(1). So we get the total 
-    time complexity of O(MlogN+N+M) = O(MlogN).
+        In the above example, node 1 has lowlink 1, node 2 has lowlink 1, node 3 has lowlink 1, node 4 has lowlink 1, node 5 has lowlink 5,
+        node 6 has lowlink 6, node 7, has lowlink 7
 
-    Here is an implementation of Kruskal's algorithm with Union by Rank:
 
-        vector<int> parent, rank;
+        The above figure shows the dfs tree of a graph with the lowlink values written in red. Note that node 6 
+        has a lowlink value 6 instead of being connected to 5 because the edge 5-6 is not a backedge.
 
-        void make_set(int v) {
-            parent[v] = v;
-            rank[v] = 0;
-        }
+        Now how to assign the lowlink values? An easy way is by assigning minimum height of node to which it has a
+        backedge. But we will do it similar to Euler Tour (Inorder traversal). As we know in euler tour,  ancestors get 
+        lesser value assigned . So here our lowlink  value will be the least ancestor value to which any node in the subtree 
+        has a backedge.  So now, what will be the condition for an edge to be bridge? An edge u-v (u=par[v]) becomes a 
+        bridge iff the lowlink value of node v is greater than value assigned to node u. Why? Because u will have 
+        lower value than any node in subtree of v. So a higher lowlink means there is no backedge 
+        in subtree of v to u or any ancestor of u.
 
-        int find_set(int v) {
-            if (v == parent[v])
-                return v;
-            return parent[v] = find_set(parent[v]);
-        }
+        Let’s look into some code now:
 
-        void union_sets(int a, int b) {
-            a = find_set(a);
-            b = find_set(b);
-            if (a != b) {
-                if (rank[a] < rank[b])
-                    swap(a, b);
-                parent[b] = a;
-                if (rank[a] == rank[b])
-                    rank[a]++;
+        vectorg[N];
+        int timestamp[N];
+        int best[N];
+        bool visited[N];
+        int par[N];
+        bool iscut[N];
+        int T=0;
+        void dfs(int s,int p)
+        {
+            par[s]=p;
+            timestamp[s]=T++;
+            best[s]=timestamp[s];
+            visited[s]=true;
+            for(auto v:g[s])
+            {
+                if(!visited[v.first])
+                {
+                    dfs(v.first,s);
+                    best[s]=min(best[s],best[v.first]);
+                    if(best[v.first]>timestamp[s])
+                    {
+                        iscut[v.second]=true;
+                    }
+                }
+                else if(v.first!=p)
+                {
+                    best[s]=min(best[s],best[v.first]);
+                }
             }
         }
 
-        struct Edge {
-            int u, v, weight;
-            bool operator<(Edge const& other) {
-                return weight < other.weight;
-            }
-        };
+        Let’s try understanding what’s happening:
 
-        int n;
-        vector<Edge> edges;
+        timestamp[s]=T++ : This assigns values to nodes same as in euler tour. 
+        Note that T is incremented before visiting subtree of s. 
+        So all nodes in subtree of s has higher timestamp value than s.
 
-        int cost = 0;
-        vector<Edge> result;
-        parent.resize(n);
-        rank.resize(n);
-        for (int i = 0; i < n; i++)
-            make_set(i);
+        best[s] : This is the lowlink value of s. Initially it is assigned to same value as that of s.
 
-        sort(edges.begin(), edges.end());
+        best[s]=min(best[s],best[v.first]) : We update our current lowlink value 
+        if any node in subtree of v.first has a backedge to some ancestor of s.
 
-        for (Edge e : edges) {
-            if (find_set(e.u) != find_set(e.v)) {
-                cost += e.weight;
-                result.push_back(e);
-                union_sets(e.u, e.v);
-            }
-        }
+        best[v.first]>timestamp[s]: This is the same condition we discussed above for an edge to be cut-edge. 
+        (Note: Here we are labelling v.first as a cut-edge though it is a vertex. We can always represent 
+        any edge u-v (u=par[v]) as v as every vertex has atmax one parent in a tree.
+
+
+33) Articulation Points Algorithm:
+    A cut vertex is a vertex that when removed (with its boundary edges) 
+    from a graph creates more components than previously in the graph. 
+    A recursive function that find articulation points  using DFS traversal 
+    
+    In DFS tree, a vertex u is articulation point if one of the 
+    following two conditions is true.
+    
+    1) u is root of DFS tree and it has at least two children.
+       the first case is simple to detect. For every vertex, count children. 
+       If currently visited vertex u is root (parent[u] is NIL) 
+       and has more than two children, print it.
+    
+    2) u is not root of DFS tree and it has a child v such that no vertex 
+       in subtree rooted with v has a back edge to one of the ancestors (in DFS tree) of u.
+
+        How to handle second case? The second case is trickier. 
+        We maintain an array disc[] to store discovery time of vertices. 
+        For every node u, we need to find out the earliest visited vertex 
+        (the vertex with minimum discovery time) that can be reached 
+        from subtree rooted with u. So we maintain an additional array 
+        low[] which is defined as follows.
 
-        Notice: since the MST will contain exactly N−1 edges, 
-        we can stop the for loop once we found that many.
+        low[u] = min(disc[u], disc[w]) 
+        where w is an ancestor of u and there is a back edge from 
+        some descendant of u to w.
 
+34) Articulation points and Biconnected graphs:
+    In graph theory, a biconnected component (sometimes known as a 2-connected component) 
+    is a maximal biconnected subgraph. Any connected graph decomposes into a 
+    tree of biconnected components called the block-cut tree of the graph. 
+    The blocks are attached to each other at shared vertices called 
+    cut vertices or articulation points. Specifically, a 
+    cut vertex is any vertex whose removal 
+    increases the number of connected components.
 
-2.312) Prims Impl:
-    minimum spanning tree is built gradually by adding edges one at a time. 
-    At first the spanning tree consists only of a single vertex (chosen arbitrarily). Then the 
-    minimum weight edge outgoing from this vertex is selected and added to the spanning tree. 
-    After that the spanning tree already consists of two vertices. Now select and add the edge 
-    with the minimum weight that has one end in an already selected vertex (i.e. a vertex 
-    that is already part of the spanning tree), and the other end in an 
-    unselected vertex. And so on, i.e. every time we select and add the edge 
-    with minimal weight that connects one selected vertex with one unselected vertex. 
-    The process is repeated until the spanning tree contains all vertices (or equivalently until we have n−1 edges).
+    biconnected graph -> if any one vertex were to be removed, 
+    the graph will remain connected. 
+    Therefore a biconnected graph has no articulation vertices.
+    
+    We obviously need two passes. In the first pass, we want to figure out which 
+    vertex we can see from each vertex through back edges, if any. 
+    In the second pass we want to visit vertices in the opposite 
+    direction and collect the minimum bi-component ID 
+    (i.e. earliest ancestor accessible from any descendants).
 
-    In the end the constructed spanning tree will be minimal. If 
-    the graph was originally not connected, then there doesn't 
-    exist a spanning tree, so the number of selected edges will be less than n−1.
+    AP Pseudocode:
 
-    Two impls discussed: O(N^2) and O(mlogn)
+    time = 0
+    visited[i] = false for all i
+    GetArticulationPoints(u)
+        visited[u] = true
+        u.st = time++
+        u.low = u.st    //keeps track of highest ancestor reachable from any descendants
+        dfsChild = 0    //needed because if no child then removing this node doesn't decompose graph
+        for each ni in adj[i]
+            if not visited[ni]
+                GetArticulationPoints(ni)
+                ++dfsChild
+                parents[ni] = u
+                u.low = Min(u.low, ni.low)  //while coming back up, get the lowest reachable ancestor from descendants
+            else if ni <> parent[u] //while going down, note down the back edges
+                u.low = Min(u.low, ni.st)
 
+        //For dfs root node, we can't mark it as articulation point because 
+        //disconnecting it may not decompose graph. So we have extra check just for root node.
+        if (u.low = u.st and dfsChild > 0 and parent[u] != null) or (parent[u] = null and dfsChild > 1)
+            Output u as articulation point
+            Output edges of u with v.low >= u.low as bridges
+            Output u.low as bicomponent ID
 
-    Dense Graph Implementation: O(N^2)
+35) CUT VERTEX AKA ARTICULATION POINT finding:
+        u --> The vertex to be visited next 
+        visited[] --> keeps tract of visited vertices 
+        disc[] --> Stores discovery times of visited vertices 
+        parent[] --> Stores parent vertices in DFS tree 
+        ap[] --> Store articulation points
 
-    We approach this problem for a different side: for every not yet 
-    selected vertex we will store the minimum edge to an already selected vertex.
+        def AP(self): 
+            visited = [False] * (self.V) 
+            disc = [float("Inf")] * (self.V) 
+            low = [float("Inf")] * (self.V) 
+            parent = [-1] * (self.V) 
+            ap = [False] * (self.V) #To store articulation points 
+    
+            # Call the recursive helper function 
+            # to find articulation points 
+            # in DFS tree rooted with vertex 'i' 
+            for i in range(self.V): 
+                if visited[i] == False: 
+                    self.APUtil(i, visited, ap, parent, low, disc) 
+    
+            for index, value in enumerate (ap): 
+                if value == True: print index, 
 
-    Then during a step we only have to look at these 
-    minimum weight edges, which will have a complexity of O(n).
+        def APUtil(self,u, visited, ap, parent, low, disc): 
+            #Count of children in current node  
+            children = 0
+    
+            # Mark the current node as visited and print it 
+            visited[u]= True
+    
+            # Initialize discovery time and low value 
+            disc[u] = self.Time 
+            low[u] = self.Time 
+            self.Time += 1
+    
+            #Recur for all the vertices adjacent to this vertex 
+            for v in self.graph[u]: 
+                # If v is not visited yet, then make it a child of u 
+                # in DFS tree and recur for it 
+                if visited[v] == False : 
+                    parent[v] = u 
+                    children += 1
+                    self.APUtil(v, visited, ap, parent, low, disc) 
+    
+                    # Check if the subtree rooted with v has a connection to 
+                    # one of the ancestors of u 
+                    low[u] = min(low[u], low[v]) 
+    
+                    # u is an articulation point in following cases 
+                    # (1) u is root of DFS tree and has two or more chilren. 
+                    if parent[u] == -1 and children > 1: 
+                        ap[u] = True
+    
+                    #(2) If u is not root and low value of one of its child is more 
+                    # than discovery value of u. 
+                    if parent[u] != -1 and low[v] >= disc[u]: 
+                        ap[u] = True    
+                        
+                    # Update low value of u for parent function calls     
+                elif v != parent[u]:  # found backedge!
+                    low[u] = min(low[u], disc[v]) 
 
-    After adding an edge some minimum edge pointers have to be recalculated. 
-    Note that the weights only can decrease, i.e. the minimal weight edge of 
-    every not yet selected vertex might stay the same, or it will be 
-    updated by an edge to the newly selected vertex. 
-    Therefore this phase can also be done in O(n).
 
-    Thus we received a version of Prim's algorithm with the complexity O(n^2).
+36) CUT EDGE AKA BRIDGE finding. 
+    
+    '''A recursive function that finds and prints bridges 
+    using DFS traversal 
+    low[w] is the lowest vertex reachable in a subtree rooted at w
 
-    In particular this implementation is very convenient for the Euclidean Minimum Spanning 
-    Tree problem: we have n points on a plane and the distance between each pair 
-    of points is the Euclidean distance between them, and we want to find a minimum 
-    spanning tree for this complete graph. This task can be solved by the described 
-    algorithm in O(n^2) time and O(n) memory, which is not possible with Kruskal's algorithm.
+    u --> The vertex to be visited next 
+    visited[] --> keeps tract of visited vertices 
+    disc[] --> Stores discovery times of visited vertices 
+    parent[] --> Stores parent vertices in DFS tree'''
+    def bridge(self): 
+   
+        # Mark all the vertices as not visited and Initialize parent and visited,  
+        # and ap(articulation point) arrays 
+        visited = [False] * (self.V) 
+        disc = [float("Inf")] * (self.V) 
+        low = [float("Inf")] * (self.V) 
+        parent = [-1] * (self.V) 
+  
+        # Call the recursive helper function to find bridges 
+        # in DFS tree rooted with vertex 'i' 
+        for i in range(self.V): 
+            if visited[i] == False: 
+                self.bridgeUtil(i, visited, parent, low, disc)
 
-    The adjacency matrix adj[][] of size n×n stores the weights of the edges, and it 
-    uses the weight INF if there doesn't exist an edge between two vertices. The 
-    algorithm uses two arrays: the flag selected[], which indicates which vertices 
-    we already have selected, and the array min_e[] which stores the edge with minimal 
-    weight to an selected vertex for each not-yet-selected vertex (it stores the weight and the end vertex). 
-    The algorithm does n steps, in each iteration the vertex with the smallest 
-    edge weight is selected, and the min_e[] of all other vertices gets updated.
+    def bridgeUtil(self,u, visited, parent, low, disc): 
+  
+        # Mark the current node as visited and print it 
+        visited[u]= True
+  
+        # Initialize discovery time and low value 
+        disc[u] = self.Time 
+        low[u] = self.Time 
+        self.Time += 1
+  
+        #Recur for all the vertices adjacent to this vertex 
+        for v in self.graph[u]: 
+            # If v is not visited yet, then make it a child of u 
+            # in DFS tree and recur for it 
+            if visited[v] == False : 
+                parent[v] = u 
+                self.bridgeUtil(v, visited, parent, low, disc) 
+  
+                # Check if the subtree rooted with v has a connection to 
+                # one of the ancestors of u 
+                # this value will become smaller if v has a backedge that goes to an 
+                # ancestor of u
+                low[u] = min(low[u], low[v]) 
+  
+  
+                ''' If the lowest vertex reachable from subtree 
+                under v is below u in DFS tree, then u-v is 
+                a bridge'''
+                if low[v] > disc[u]: 
+                    print ("%d %d" %(u,v)) 
+      
+                      
+            elif v != parent[u]: # Update low value of u for parent function calls. 
+                low[u] = min(low[u], disc[v]) 
+36.5) Eulerean tour:
 
+    Necessary and sufficient conditions
+        An undirected graph has a closed Euler tour iff it is connected and 
+        each vertex has an even degree.
 
-    int n;
-    vector<vector<int>> adj; // adjacency matrix of graph
-    const int INF = 1000000000; // weight INF means there is no edge
+        An undirected graph has an open Euler tour (Euler path) if it is connected, and each vertex, 
+        except for exactly two vertices, has an even degree. The two vertices of odd degree have to be the endpoints of the tour.
 
-    struct Edge {
-        int w = INF, to = -1;
-    };
+        A directed graph has a closed Euler tour iff it is strongly connected and the in-degree of each vertex is equal to its out-degree.
 
-    void prim() {
-        int total_weight = 0;
-        vector<bool> selected(n, false);
-        vector<Edge> min_e(n);
-        min_e[0].w = 0;
+        Similarly, a directed graph has an open Euler tour (Euler path) iff for each vertex the difference 
+        between its in-degree and out-degree is 0, except for two vertices, where one has difference +1 (the start of the tour) 
+        and the other has difference -1 (the end of the tour) and, if you add an edge from the
+        end to the start, the graph is strongly connected.
 
-        for (int i=0; i<n; ++i) {
-            int v = -1;
-            for (int j = 0; j < n; ++j) {
-                if (!selected[j] && (v == -1 || min_e[j].w < min_e[v].w))
-                    v = j;
-            }
+    Fleury's algorithm (Not the best one)
 
-            if (min_e[v].w == INF) {
-                cout << "No MST!" << endl;
-                exit(0);
-            }
+        Fleury's algorithm is a straightforward algorithm for finding Eulerian paths/tours. It proceeds by repeatedly 
+        removing edges from the graph in such way, that the graph remains Eulerian. A version of the algorithm, 
+        which finds Euler tour in undirected graphs follows.
 
-            selected[v] = true;
-            total_weight += min_e[v].w;
-            if (min_e[v].to != -1)
-                cout << v << " " << min_e[v].to << endl;
+        Start with any vertex of non-zero degree. Choose any edge leaving this vertex, which is not a bridge 
+        (i.e. its removal will not disconnect the graph into two or more disjoint connected components). If there is no 
+        such edge, stop. Otherwise, append the edge to the Euler tour, remove it from the graph, and 
+        repeat the process starting with the other endpoint of this edge.
 
-            for (int to = 0; to < n; ++to) {
-                if (adj[v][to] < min_e[to].w)
-                    min_e[to] = {adj[v][to], v};
-            }
-        }
+        Though the algorithm is quite simple, it is not often used, because it needs to identify bridges 
+        in the graph (which is not a trivial thing to code.) Slightly more sophisticated, but easily implementable algorithm is presented below.
 
-        cout << total_weight << endl;
-    }
+    Cycle finding algorithm (Better)
 
+        This algorithm is based on the following observation: if C is any cycle in a Eulerian graph, 
+        then after removing the edges of C, the remaining connected components will also be Eulerian graphs.
 
+        The algorithm consists in finding a cycle in the graph, removing its edges and
+        repeating this steps with each remaining connected component. It has a very compact code with recursion:
 
-2.32) ORDERED SET/BST IN ACITION: (optimally done with fibonnaci heaps however) 
-    PRIMS ALGORITHM WITH RED BLACK TREES + SET!
-    (usally done with HEAP)
+    PSUEDOCODE:
+        find_tour(u):
+            for each edge e=(u,v) in E:
+                remove e from E
+                find_tour(v)
+            prepend u to tour
 
-    n the above described algorithm it is possible to interpret the 
-    operations of finding the minimum and modifying some values as set 
-    operations. These two classical operations are supported by many 
-    data structure, for example by set in C++ (which are implemented via red-black trees).
+        where u is any vertex with a non-zero degree.  
 
-    The main algorithm remains the same, but now we can find the minimum 
-    edge in O(logn) time. On the other hand recomputing the pointers 
-    will now take O(nlogn) time, which is worse than in the previous algorithm.
+37) Lets go over that again! Cut edges, cut vertices, Eulerian tours   
 
-    But when we consider that we only need to update O(m) times in total, 
-    and perform O(n) searches for the minimal edge, then the total 
-    complexity will be O(mlogn). For sparse graphs this is better 
-    than the above algorithm, but for dense graphs this will be slower.
+    Definitions An Euler tour (or Eulerian tour) in an undirected graph is a tour that
+    traverses each edge of the graph exactly once. Graphs that have an Euler tour 
+    are called Eulerian.
 
-    Here the graph is represented via a adjacency list adj[], where adj[v] 
-    contains all edges (in form of weight and target pairs) for the vertex v. 
-    min_e[v] will store the weight of the smallest edge from vertex v to an 
-    already selected vertex (again in the form of a weight and target pair). 
-    In addition the queue q is filled with all not yet selected vertices in 
-    the order of increasing weights min_e. The algorithm does n steps, on each 
-    of which it selects the vertex v with the smallest weight min_e (by extracting 
-    it from the beginning of the queue), and then looks through all the edges 
-    from this vertex and updates the values in min_e (during an update we also 
-    need to also remove the old edge from the queue q and put in the new edge).
+    Finding cut edges -------------------
+        The code below works properly because the lemma above (first lemma):
+        h is the height of the vertex. v is the parent. u is the child.
+
+        We need compute for each subtree, the lowest node in the DFS tree that a back edge can reach. 
+        This value can either be the depth of the other end point, or the discovery time. 
+        Cut edges can, also, be seen as edges that needs to be removed 
+        to end up with strongly connected components.
 
 
 
-    const int INF = 1000000000;
+        h[root] = 0
+        par[v] = -1
+        dfs (v):
+                d[v] = h[v]
+                color[v] = gray
+                for u in adj[v]:
+                        if color[u] == white
+                                then par[u] = v and dfs(u) and d[v] = min(d[v], d[u])
+                                if d[u] > h[v]
+                                        then the edge v-u is a cut edge
+                        else if u != par[v])
+                                then d[v] = min(d[v], h[u])
+                color[v] = black
 
-    struct Edge {
-        int w = INF, to = -1;
-        bool operator<(Edge const& other) const {
-            return make_pair(w, to) < make_pair(other.w, other.to);
-        }
-    };
+        In this code, h[v] =  height of vertex v in the DFS tree and d[v] = min(h[w] where 
+                                            there is at least vertex u in subtree of v in 
+                                      the DFS tree where there is an edge between u and w).
 
-    int n;
-    vector<vector<Edge>> adj;
+    Finding cut vertices -----------------
+        The code below works properly because the lemma above (first lemma):
 
-    void prim() {
-        int total_weight = 0;
-        vector<Edge> min_e(n);
-        min_e[0].w = 0;
-        set<Edge> q;
-        q.insert({0, 0});
-        vector<bool> selected(n, false);
-        for (int i = 0; i < n; ++i) {
-            if (q.empty()) {
-                cout << "No MST!" << endl;
-                exit(0);
-            }
+        h[root] = 0
+        par[v] = -1
+        dfs (v):
+                d[v] = h[v]
+                color[v] = gray
+                for u in adj[v]:
+                        if color[u] == white
+                                then par[u] = v and dfs(u) and d[v] = min(d[v], d[u])
+                                if d[u] >= h[v] and (v != root or number_of_children(v) > 1)
+                                        then the edge v is a cut vertex
+                        else if u != par[v])
+                                then d[v] = min(d[v], h[u])
+                color[v] = black
 
-            int v = q.begin()->to;
-            selected[v] = true;
-            total_weight += q.begin()->w;
-            q.erase(q.begin());
+        In this code, h[v] =  height of vertex v in the DFS tree and d[v] = min(h[w] where 
+        there is at least vertex u in subtree of v in the DFS tree where there is an edge between u and w).
 
-            if (min_e[v].to != -1)
-                cout << v << " " << min_e[v].to << endl;
+    Finding Eulerian tours ----------------
+        It is quite like DFS, with a little change :
 
-            for (Edge e : adj[v]) {
-                if (!selected[e.to] && e.w < min_e[e.to].w) {
-                    q.erase({min_e[e.to].w, e.to});
-                    min_e[e.to] = {e.w, v};
-                    q.insert({e.w, e.to});
-                }
-            }
-        }
 
-        cout << total_weight << endl;
-    }
+        vector E
+        dfs (v):
+                color[v] = gray
+                for u in adj[v]:
+                        erase the edge v-u and dfs(u)
+                color[v] = black
+                push v at the end of e
+        e is the answer.
 
+    Python implementation
+    This is a short implementation of the Euler tour in python.
 
+        # g is a 2D adjacency matrix
+        circuit = []
+        def visit(current):
+            for x in range(MAX_N):
+                if g[current][x] > 0:
+                    g[current][x] -= 1
+                    g[x][current] -= 1
+                    visit(x)
+            circuit.append(current)
 
+        # circuit now has the circuit in reverse, if ordering matters
+        # you can start with any node for a closed tour, and an odd degree node for a open tour
 
 
 
+31.75) Construct the Rooted Tree by using start and finish time of its 
+      DFS traversal: 
+
+    Given start and finish times of DFS traversal of N vertices 
+    that are available in a Rooted tree, the task is 
+    to construct the tree (Print the Parent of each node).
 
+    Parent of the root node is 0.
 
+    Examples:
 
+    Input: Start[] = {2, 4, 1, 0, 3}, End[] = {3, 5, 4, 5, 4}
+    Output: 3 4 4 0 3
+    Given Tree is -:
+                        4(0, 5)
+                        /   \
+                (1, 4)3     2(4, 5)
+                    /  \    
+            (2, 3)1    5(3, 4)
 
 
+    The root will always have start time = 0
+    processing a node takes 1 unit time but backtracking 
+    does not consume time, so the finishing time 
+    of two nodes can be the same.
 
+    Input: Start[] = {4, 3, 2, 1, 0}, End[] = {5, 5, 3, 3, 5}
+    Output: 2 5 4 5 0
 
+    Root of the tree is the vertex whose starting time is zero.
 
+    Now, it is sufficient to find the descendants of a vertex, 
+    this way we can find the parent of every vertex.
 
+    Define Identity[i] as the index of the vertex with starting equal to i.
+    As Start[v] and End[v] are starting and ending time of vertex v.
+    The first child of v is Identity[Start[v]+1] and
+    the (i+1)th is Identity[End[chv[i]]] where chv[i] is the ith child of v.
+    Traverse down in DFS manner and update the parent of each node.
+    
+    Time Complexity : O(N)
+    where N is the number of nodes in the tree.
+    
+    def Restore_Tree(S, E): 
+    
+        # Storing index of vertex with starting 
+        # time Equal to i 
+        Identity = N*[0]   
+    
+        for i in range(N): 
+            Identity[Start[i]] = i 
+    
+        # Parent array 
+        parent = N*[-1] 
+        curr_parent = Identity[0] 
+        
+        for j in range(1, N): 
+    
+            # Find the vertex with starting time j 
+            child = Identity[j] 
+    
+            # If end time of this child is greater than  
+            # (start time + 1), then we traverse down and  
+            # store curr_parent as the parent of child 
+            if End[child] - j > 1: 
+                parent[child] = curr_parent 
+                curr_parent = child 
+    
+            # Find the parent of current vertex 
+            # over iterating on the finish time 
+            else:      
+                parent[child] = curr_parent 
+    
+                # Backtracking takes zero time 
+                while End[child]== End[parent[child]]: 
+                    child = parent[child] 
+                    curr_parent = parent[child] 
+                    if curr_parent == Identity[0]: 
+                        break
+        for i in range(N): 
+            parent[i]+= 1
+    
+        # Return the parent array 
+        return parent 
+    
+    # Driver Code  
+    if __name__=="__main__": 
+        N = 5
+    
+        # Start and End time of DFS 
+        Start = [2, 4, 1, 0, 3] 
+        End = [3, 5, 4, 5, 4] 
+        print(*Restore_Tree(Start, End)) 
 
 
+#############################################################################
+###################################################33
 
+Cool Notes Part 0.5: Sliding Window with a deque
+        -> In this question you learn about the difference between useless elements, 
+           and useful elements.
+           How to use a deque to maintain the useful elemenets as you run through the arry
+           Operating on the indexes of an array instead of the actual elements (pointers!)
+           Always try to realized how to discern useless and useful elements when sliding your window,
+           and how to keep track of them and maintain them
+           (In this case, every iteration we cull bad elements!)
 
+        -> Sliding Window Maximum (Maximum of all subarrays of size k)
+           Given an array and an integer k, find the maximum for each 
+           and every contiguous subarray of size k. O(N) algorithm
 
+           We create a Deque, Qi of capacity k, that stores only useful elements 
+           of current window of k elements. An element is useful if it is in current window 
+           and is greater than all other elements on left side of it in current window. 
+           We process all array elements one by one and maintain Qi to contain 
+           useful elements of current window and these useful elements are 
+           maintained in sorted order. The element at front of the Qi is 
+           the largest and element at rear of Qi is the smallest of current window. 
+           Time Complexity: O(n). It seems more than O(n) at first look. 
+           If we take a closer look, we can observe that every element of 
+           array is added and removed at most once. 
+           So there are total 2n operations.
+          
+            def printMax(arr, n, k): 
+                
+                """ Create a Double Ended Queue, Qi that  
+                will store indexes of array elements.  
+                The queue will store indexes of useful  
+                elements in every window and it will 
+                maintain decreasing order of values from 
+                front to rear in Qi, i.e., arr[Qi.front[]] 
+                to arr[Qi.rear()] are sorted in decreasing 
+                order"""
+                Qi = deque() 
+                
+                # Process first k (or first window)  
+                # elements of array 
+                for i in range(k): 
+                    
+                    # For every element, the previous  
+                    # smaller elements are useless 
+                    # so remove them from Qi 
+                    while Qi and arr[i] >= arr[Qi[-1]] : 
+                        Qi.pop() 
+                    
+                    # Add new element at rear of queue 
+                    Qi.append(i); 
+                    # We are storing the indexes for the biggest elements!
+                
+                # Qi contains the biggest elements in the first k so:
+                # k -> [1, 4, 6, 3, 5] (5 elements)
+                # Qi -> [2, 5] (useful elements -> 
+                #              the indexes for elements that can become a maximum)
+                # element at front of queue is maximum, in this case, it is 6 (index is 2)
 
+                # Process rest of the elements, i.e.  
+                # from arr[k] to arr[n-1] 
+                for i in range(k, n): 
+                    
+                    # The element at the front of the 
+                    # queue is the largest element of 
+                    # previous window, so print it 
+                    print(str(arr[Qi[0]]) + " ", end = "") 
+                    
+                    # Remove our really good candidates which are  
+                    # out of window now. SO SAD!! 
+                    # out of window elements are in the front of the queue. 
+                    # indexes are increasing like above -> 2 -> 5
+                    # its i-k because we want to shift our removal range to start at index 0 
+                    # and go up to n-k for the last window.
+                    while Qi and Qi[0] <= i-k: 
+                        
+                        # remove from front of deque 
+                        Qi.popleft()  
+                    
+                    # Remove all elements smaller than 
+                    # the currently being added element  
+                    # (Remove useless elements) 
+                    # we can do this because the element we are adding will always
+                    # be a candidate for the sliding window in the next iteration, 
+                    # and a better candidate, than the  "useless" elements in the sliding
+                    # window
+                    while Qi and arr[i] >= arr[Qi[-1]] : 
+                        Qi.pop() 
+                    
+                    # Add current element at the rear of Qi 
+                    Qi.append(i) 
+                
+                # Print the maximum element of last window 
+                print(str(arr[Qi[0]])) 
+        
+        -> YOU CAN ALSO ANSWER THIS QUESTION WITH A SEGMENT TREE. 
 
+        OTHER TAKEAWAYS:
+        This queue is a monoqueue
+        What does Monoqueue do here:
 
+        It has three basic options:
+        push: push an element into the queue; O (1) (amortized)
+        pop: pop an element out of the queue; O(1) (pop = remove, it can't report this element)
+        max: report the max element in queue;O(1)
 
-2.325) DFS ANALYSIS START AND END TIMES!
-    The parenthesis theorem says that the discovery 
-    and finish time intervals are either disjoint or nested.
+        It takes only O(n) time to process a N-size sliding window minimum/maximum problem.
+        Note: different from a priority queue (which takes O(nlogk) to solve this problem), 
+        it doesn't pop the max element: It pops the first element (in original order) in queue.
+###################################################################################
+##################################################################################
 
-    With the graph version of DFS, only some edges 
-    (the ones for which visited[v] is false) will be traversed. 
-    These edges will form a tree, called the depth-first-search 
-    tree of G starting at the given root, and the edges in this
-    tree are called tree edges. The other edges of G can be 
-    divided into three categories:
+Interesting/Google Problems Fun:
 
-    Back edges point from a node to one of its ancestors in the DFS tree.
-    Forward edges point from a node to one of its descendants.
-    Cross edges point from a node to a previously visited 
-    node that is neither an ancestor nor a descendant.
 
-    AnnotatedDFS(u, parent):
-        parent[u] = parent
-        start[u] = clock; clock = clock + 1
-        visited[u] = true
-        for each successor v of u:
-            if not visited[v]:
-            AnnotatedDFS(v, u)
-        end[u] = clock; clock = clock + 1
+    1) Given a zero-inexed array H of height of buildings, number of bricks b and number of ropes r. You start your journey from buiding 0 and 
+        move to adjacent building either using rope or bricks. You have limited number of bricks and ropes.
+        While moving from ith building to (i+1)th building,
 
-    we will show in a moment that a graph is acyclic if and 
-    only if it has no back edges. But first: how do we tell 
-    whether an edge is a tree edge, a back edge, a forward edge, 
-    or a cross edge? We can do this using the clock mechanism 
-    we used before to convert a tree into a collection of intervals.
+        if next building's height is less than or equal to the current buiding's height, you do not need rope or bricks.
+        if next building's height is greater than current buiding's height, you can either use one rope or (h[i+1] - h[i]) bricks.
+        So, question is How far can you reach from 0th buiding if you use bricks and ropes optimally? return index of building till which you can move.
 
+        Example 1:
 
-    Tree edges are now easy to recognize; uv is a tree edge 
-    if parent[v] = u. For the other types of edges, 
-    we can use the (start,end) intervals to tell 
-    whether v is an ancestor, descendant, or distant cousin of u:
+        Input : H = [4,2,7,6,9,11,14,12,8], b = 5, r = 2
+        Output: 8
+        Explanation: use rope to move from index 1 to index 2. 
+        use 3 bricks to move from index 3 to index 4. 
+        use 2 bricks to move from index 4 to index 5. 
+        use rope to move from index 5 to index 6. 
+        so we can reach at the end of the array using 2 ropes and 5 bricks. 
+        Example 2:
 
-    Edge type of uv | start times         | end times
-    Tree edge       | start[u] < start[v] | end[u] > end[v]
-    Back edge       | start[u] > start[v] | end[u] < end[v]
-    Forward edge    | start[u] < start[v] | end[u] > end[v]
-    Cross edge      | start[u] > start[v] | end[u] > end[v]
+        Input : H = [4,2,7,6,9,11,14,12,8], b = 5, r = 1
+        Output: 5
+        Explanation: use rope to move from index 1 to index 2. 
+        use 3 bricks to move from index 3 to index 4. 
+        use 2 bricks to move from index 4 to index 5. 
+        so we can reach at index 5 using 1 ropes and 5 bricks. 
 
-2.33) Construct the Rooted Tree by using start and finish time of its 
-      DFS traversal: 
 
+        ✔️ Solution - I (Using Min-Heap)
 
-    Given start and finish times of DFS traversal of N vertices 
-    that are available in a Rooted tree, the task is 
-    to construct the tree (Print the Parent of each node).
+        Ladders can be used anywhere even for an infinite jump to next building. We need to realise that bricks limit our jumping capacity if 
+        used at wrong jumps. So, bricks should be used only on the smallest jumps in the path and ladders should be used on the larger ones.
 
-    Parent of the root node is 0.
+        We could have sorted the jumps and used ladders on largest L jumps(where, L is number of ladders) and bricks elsewhere. 
+        But, we don't know how many jumps will be performed or what's the order of jump sequence.
 
-    Examples:
+        For this, we will assume that the first L jumps are the largest ones and store the jump heights in ascending order. 
+        We can use priority_queue / min-heap for this purpose (since we would be needing to insert and delete elements from it...explained further).
 
-    Input: Start[] = {2, 4, 1, 0, 3}, End[] = {3, 5, 4, 5, 4}
-    Output: 3 4 4 0 3
-    Given Tree is -:
-                        4(0, 5)
-                        /   \
-                (1, 4)3     2(4, 5)
-                    /  \    
-            (2, 3)1    5(3, 4)
+        Now, for any further jumps, we need to use bricks since the first L jumps have used up all the ladders. 
+        Let's call the jump height requried from now on as curJumpHeight. Now,
 
+        If curJumpHeight > min-heap top : We have the choice to use bricks on the previous jump which had less jump height. 
+        So, we will use that many bricks on previous (smaller) jump and use ladder for current (larger) jump.
 
-    The root will always have start time = 0
-    processing a node takes 1 unit time but backtracking 
-    does not consume time, so the finishing time 
-    of two nodes can be the same.
+        If curJumpHeight <= min-heap top : There's no way to minimize usage of bricks for current jump. 
+        We need to spend atleast curJumpHeight number of bricks
 
-    Input: Start[] = {4, 3, 2, 1, 0}, End[] = {5, 5, 3, 3, 5}
-    Output: 2 5 4 5 0
+        So, using the above strategy, we can find the furthest building we can reach. As soon as the available 
+        bricks are all used up, we return the current building index.
 
-    Root of the tree is the vertex whose starting time is zero.
+        Time Complexity : O(NlogL)
+        Space Complexity : O(L)
 
-    Now, it is sufficient to find the descendants of a vertex, 
-    this way we can find the parent of every vertex.
+        def furthestBuilding(self, H: List[int], bricks: int, ladders: int) -> int:
+            jumps_pq = []
+            for i in range(len(H) - 1):
+                jump_height = H[i + 1] - H[i]
+                if jump_height <= 0: continue
+                heappush(jumps_pq, jump_height)
+                if len(jumps_pq) > ladders:
+                    bricks -= heappop(jumps_pq)
+                if(bricks < 0) : return i
+            return len(H) - 1
 
-    Define Identity[i] as the index of the vertex with starting equal to i.
-    As Start[v] and End[v] are starting and ending time of vertex v.
-    The first child of v is Identity[Start[v]+1] and
-    the (i+1)th is Identity[End[chv[i]]] where chv[i] is the ith child of v.
-    Traverse down in DFS manner and update the parent of each node.
-    
-    Time Complexity : O(N)
-    where N is the number of nodes in the tree.
-    
-    def Restore_Tree(S, E): 
-    
-        # Storing index of vertex with starting 
-        # time Equal to i 
-        Identity = N*[0]   
-    
-        for i in range(N): 
-            Identity[Start[i]] = i 
-    
-        # Parent array 
-        parent = N*[-1] 
-        curr_parent = Identity[0] 
+        Dumber soln:
         
-        for j in range(1, N): 
-    
-            # Find the vertex with starting time j 
-            child = Identity[j] 
-    
-            # If end time of this child is greater than  
-            # (start time + 1), then we traverse down and  
-            # store curr_parent as the parent of child 
-            if End[child] - j > 1: 
-                parent[child] = curr_parent 
-                curr_parent = child 
-    
-            # Find the parent of current vertex 
-            # over iterating on the finish time 
-            else:      
-                parent[child] = curr_parent 
-    
-                # Backtracking takes zero time 
-                while End[child]== End[parent[child]]: 
-                    child = parent[child] 
-                    curr_parent = parent[child] 
-                    if curr_parent == Identity[0]: 
-                        break
-        for i in range(N): 
-            parent[i]+= 1
-    
-        # Return the parent array 
-        return parent 
-    
-    # Driver Code  
-    if __name__=="__main__": 
-        N = 5
-    
-        # Start and End time of DFS 
-        Start = [2, 4, 1, 0, 3] 
-        End = [3, 5, 4, 5, 4] 
-        print(*Restore_Tree(Start, End)) 
+        Time Complexity : O(NlogL)
+        Space Complexity : O(L)
 
-2.35) In head recursion , the recursive call, when it happens, comes 
-      before other processing in the function (think of it happening at the top, 
-      or head, of the function). In tail recursion , it's the 
-      opposite—the processing occurs before the recursive call.
+        from sortedcontainers import SortedDict
+        def furthestBuilding(self, H: List[int], bricks: int, ladders: int) -> int:
+            jumps = SortedDict()
+            for i in range(len(H) - 1):
+                jump_height = H[i + 1] - H[i]
+                if jump_height <= 0: continue
+                jumps[jump_height], ladders = jumps.get(jump_height, 0) + 1, ladders - 1
+                if ladders < 0:
+                    top = jumps.peekitem(0)[0]
+                    bricks -= top
+                    jumps[top] -= 1
+                    if jumps[top] == 0 : jumps.popitem(0)
+                if(bricks < 0) : return i
+            return len(H) - 1
 
-2.37) Articulation Points Algorithm:
-    A cut vertex is a vertex that when removed (with its boundary edges) 
-    from a graph creates more components than previously in the graph. 
-    A recursive function that find articulation points  using DFS traversal 
-    
-    In DFS tree, a vertex u is articulation point if one of the 
-    following two conditions is true.
-    
-    1) u is root of DFS tree and it has at least two children.
-       the first case is simple to detect. For every vertex, count children. 
-       If currently visited vertex u is root (parent[u] is NIL) 
-       and has more than two children, print it.
-    
-    2) u is not root of DFS tree and it has a child v such that no vertex 
-       in subtree rooted with v has a back edge to one of the ancestors (in DFS tree) of u.
 
-        How to handle second case? The second case is trickier. 
-        We maintain an array disc[] to store discovery time of vertices. 
-        For every node u, we need to find out the earliest visited vertex 
-        (the vertex with minimum discovery time) that can be reached 
-        from subtree rooted with u. So we maintain an additional array 
-        low[] which is defined as follows.
+    2) Topological ordering
+        Given task dependencies (x, y) denoting that to complete y one must first complete x. Find the least
+        amount of time needed to finish all the tasks given that the task that can be done in parallel can be 
+        processed together and it takes 1 unit of time to process a task. 
 
-        low[u] = min(disc[u], disc[w]) 
-        where w is an ancestor of u and there is a back edge from 
-        some descendant of u to w.
+        Inorder -> reduce by 1? Process TOPOLOGICAL ORDER BFS'ing?
 
-2.39) Articulation points and Biconnected graphs:
-    In graph theory, a biconnected component (sometimes known as a 2-connected component) 
-    is a maximal biconnected subgraph. Any connected graph decomposes into a 
-    tree of biconnected components called the block-cut tree of the graph. 
-    The blocks are attached to each other at shared vertices called 
-    cut vertices or articulation points. Specifically, a 
-    cut vertex is any vertex whose removal 
-    increases the number of connected components.
+        figure it out!
+        (https://docs.google.com/document/d/1S4osCeZjZa20sWywMq4EneHJALcUfPsPm5fXwLbwiAM/edit#heading=h.p5po8tu4jedu)
 
-    biconnected graph -> if any one vertex were to be removed, 
-    the graph will remain connected. 
-    Therefore a biconnected graph has no articulation vertices.
-    
-    We obviously need two passes. In the first pass, we want to figure out which 
-    vertex we can see from each vertex through back edges, if any. 
-    In the second pass we want to visit vertices in the opposite 
-    direction and collect the minimum bi-component ID 
-    (i.e. earliest ancestor accessible from any descendants).
 
-    AP Pseudocode:
+    3) Write something about huffman codes here:
 
-    time = 0
-    visited[i] = false for all i
-    GetArticulationPoints(u)
-        visited[u] = true
-        u.st = time++
-        u.low = u.st    //keeps track of highest ancestor reachable from any descendants
-        dfsChild = 0    //needed because if no child then removing this node doesn't decompose graph
-        for each ni in adj[i]
-            if not visited[ni]
-                GetArticulationPoints(ni)
-                ++dfsChild
-                parents[ni] = u
-                u.low = Min(u.low, ni.low)  //while coming back up, get the lowest reachable ancestor from descendants
-            else if ni <> parent[u] //while going down, note down the back edges
-                u.low = Min(u.low, ni.st)
+        https://courses.csail.mit.edu/6.897/spring03/scribe_notes/L13/lecture13.pdf
+        and arithmetic codes, etc
 
-        //For dfs root node, we can't mark it as articulation point because 
-        //disconnecting it may not decompose graph. So we have extra check just for root node.
-        if (u.low = u.st and dfsChild > 0 and parent[u] != null) or (parent[u] = null and dfsChild > 1)
-            Output u as articulation point
-            Output edges of u with v.low >= u.low as bridges
-            Output u.low as bicomponent ID
+        Given a list of character and the frequencies they appear. Construct a Huffman Tree to encode all character.
 
-2.4) CUT VERTEX AKA ARTICULATION POINT finding:
-        u --> The vertex to be visited next 
-        visited[] --> keeps tract of visited vertices 
-        disc[] --> Stores discovery times of visited vertices 
-        parent[] --> Stores parent vertices in DFS tree 
-        ap[] --> Store articulation points
+        For more details of building the Huffman Tree and how to use it to encode and decode, please take a look at this article.
 
-        def AP(self): 
-            visited = [False] * (self.V) 
-            disc = [float("Inf")] * (self.V) 
-            low = [float("Inf")] * (self.V) 
-            parent = [-1] * (self.V) 
-            ap = [False] * (self.V) #To store articulation points 
-    
-            # Call the recursive helper function 
-            # to find articulation points 
-            # in DFS tree rooted with vertex 'i' 
-            for i in range(self.V): 
-                if visited[i] == False: 
-                    self.APUtil(i, visited, ap, parent, low, disc) 
-    
-            for index, value in enumerate (ap): 
-                if value == True: print index, 
+        In terms of writing the code to build the Huffman Tree, one solution I have is use a min heap to store Node objects, each Node 
+        object contains a character and its frequency, then every time poll the two lowest frequency Node objects from the min heap and 
+        create the sum Node, offer the sum Node back to the min heap, repeat this process till we only have one Node in the heap, and that 
+        will be the root node of the Huffman Tree. Eventually all the character nodes will become the leaves.
 
-        def APUtil(self,u, visited, ap, parent, low, disc): 
-            #Count of children in current node  
-            children = 0
-    
-            # Mark the current node as visited and print it 
-            visited[u]= True
-    
-            # Initialize discovery time and low value 
-            disc[u] = self.Time 
-            low[u] = self.Time 
-            self.Time += 1
-    
-            #Recur for all the vertices adjacent to this vertex 
-            for v in self.graph[u]: 
-                # If v is not visited yet, then make it a child of u 
-                # in DFS tree and recur for it 
-                if visited[v] == False : 
-                    parent[v] = u 
-                    children += 1
-                    self.APUtil(v, visited, ap, parent, low, disc) 
-    
-                    # Check if the subtree rooted with v has a connection to 
-                    # one of the ancestors of u 
-                    low[u] = min(low[u], low[v]) 
-    
-                    # u is an articulation point in following cases 
-                    # (1) u is root of DFS tree and has two or more chilren. 
-                    if parent[u] == -1 and children > 1: 
-                        ap[u] = True
-    
-                    #(2) If u is not root and low value of one of its child is more 
-                    # than discovery value of u. 
-                    if parent[u] != -1 and low[v] >= disc[u]: 
-                        ap[u] = True    
-                        
-                    # Update low value of u for parent function calls     
-                elif v != parent[u]:  # found backedge!
-                    low[u] = min(low[u], disc[v]) 
+        Encoding and decoding are pretty straightforward, just like how we traverse a tree to find a leaf with certain value, the only thing
+        is we use 0 and 1 to indicate whether we are traversing left or right direction.
 
 
-2.5) CUT EDGE AKA BRIDGE finding. 
-    
-    '''A recursive function that finds and prints bridges 
-    using DFS traversal 
-    low[w] is the lowest vertex reachable in a subtree rooted at w
+    4) Convert  some problems to multiplication and turn them into logs for djikstras such as 2sigmas currency exchange?
 
-    u --> The vertex to be visited next 
-    visited[] --> keeps tract of visited vertices 
-    disc[] --> Stores discovery times of visited vertices 
-    parent[] --> Stores parent vertices in DFS tree'''
-    def bridge(self): 
-   
-        # Mark all the vertices as not visited and Initialize parent and visited,  
-        # and ap(articulation point) arrays 
-        visited = [False] * (self.V) 
-        disc = [float("Inf")] * (self.V) 
-        low = [float("Inf")] * (self.V) 
-        parent = [-1] * (self.V) 
-  
-        # Call the recursive helper function to find bridges 
-        # in DFS tree rooted with vertex 'i' 
-        for i in range(self.V): 
-            if visited[i] == False: 
-                self.bridgeUtil(i, visited, parent, low, disc)
 
-    def bridgeUtil(self,u, visited, parent, low, disc): 
-  
-        # Mark the current node as visited and print it 
-        visited[u]= True
-  
-        # Initialize discovery time and low value 
-        disc[u] = self.Time 
-        low[u] = self.Time 
-        self.Time += 1
-  
-        #Recur for all the vertices adjacent to this vertex 
-        for v in self.graph[u]: 
-            # If v is not visited yet, then make it a child of u 
-            # in DFS tree and recur for it 
-            if visited[v] == False : 
-                parent[v] = u 
-                self.bridgeUtil(v, visited, parent, low, disc) 
-  
-                # Check if the subtree rooted with v has a connection to 
-                # one of the ancestors of u 
-                # this value will become smaller if v has a backedge that goes to an 
-                # ancestor of u
-                low[u] = min(low[u], low[v]) 
-  
-  
-                ''' If the lowest vertex reachable from subtree 
-                under v is below u in DFS tree, then u-v is 
-                a bridge'''
-                if low[v] > disc[u]: 
-                    print ("%d %d" %(u,v)) 
-      
-                      
-            elif v != parent[u]: # Update low value of u for parent function calls. 
-                low[u] = min(low[u], disc[v]) 
 
-2.55) MATRIX Problems Tips:
-      Try reversing. Try transposing. Try circular sorting. 
-      Flipping on x axis or y axis is just reversing. 
+    5) LeetCode 711 - Number of Distinct Islands II
 
-      MATRIX ROTATION:
-        HARMAN SOLN:
+    https://protegejj.gitbooks.io/algorithm-practice/content/711-number-of-distinct-islands-ii.html
+    Given a non-empty 2D arraygridof 0's and 1's, an island is a group of1's (representing land) connected 4-directionally (horizontal or vertical.) You may assume all four edges of the grid are surrounded by water.
+
+    Count the number of distinct islands. An island is considered to be the same as another if they have the same shape, or have the same shape after 
+    rotation (90, 180, or 270 degrees only) or reflection (left/right direction or up/down direction).
+
+
+    -> dfs to find all islands
+    -> ok now we need to encode the island!
+
+    
+    -> Find top left coordinate of shape, then subtract all coordiantes by top left coordinate to get it in a picture frame
+    -> width and height of picture frame??
+        -> keep track of top most coordinate, leftmost, rightmost, bottom most. 
+        -> leftmost - rightmost + 1= width
+        -> bttom - top + 1 = height
+         012 
+         111 0
+           1 1
+           1 2 
+
+        3 by 3!
+
+
+    -> get its width and height, and put it in an array
+    
+    -> then rotate array and insert into map, and check
+    -> (Memorize rotation code again)
 
-        def rotate(self, matrix):
-            n = len(matrix)
-            N = len(matrix)
-            indexN = N - 1
-            
-            for d in range(n//2):
-                swaps_to_do_this_layer = len(matrix) - 2*d - 1
-                # Swap everything except the last element. that is 
-                # automatically swapped on the first swap in the loop
-                for i in range( swaps_to_do_this_layer ):              
-                    # CONSIDER D AS THE BOUNDARY (with the help of indexN) AND 
-                    # I AS THE OFFSET TO THE ELEMENTS WITHIN BOUNDARY
-                    # I should only be offsetting one side, either a row, or a column
-                    
-                    northR, northC = d, i+d
-                    eastR, eastC = i + d, indexN - d
-                    southR, southC = indexN - d, indexN - d - i
-                    westR, westC = indexN - d - i, d
-                    
-                    matrix[northR][northC], matrix[eastR][eastC], matrix[southR][southC], matrix[westR][westC] =\
-                        matrix[westR][westC], matrix[northR][northC], matrix[eastR][eastC], matrix[southR][southC]
         SMARTER WAY:
         def rotate(self, matrix):
             n = len(matrix)
@@ -7652,4493 +13818,4960 @@ THESE ARE HARMAN'S PERSONAL SET OF PARADIGMS/ INTERVIEW NOTES:
                         row[j], row[~j] = row[~j], row[j]
 
 
-2.57) To find the root nodes in a directed graph (NOT DAG):
-      Reverse graph and find nodes with 0 children.
-      However, there may not be root nodes!
+SPIRAL MATRIX GOOD SOLN:
 
-2.575) REMEMBER CYCLE DETECING ON DIRECTED GRAPH ALWAYS NEEDS AT LEAST 3 COLORS!!!
-     WHILE ON UNDIRECTED YOU COULD JUST USE A VISTED SET. (OR FOR DIRECTED,
-     JUST REMEMBER TO POP THE PROCESSED ELEMENT FROM THE VISITED PATH, SO THAT A 
-     DIFFERENT DIRECTED PATH CAN VISIT THE PROCESSED ELEMENT)
-     
+    Let us use coordinate (x, y) and direction of movement (dx, dy). Each time when we reach point outside 
+    matrix we rotate. How we can rotate? We can either create array of rotations in advance or we can use the trick 
+    dx, dy = -dy, dx. Also how we understand it is time to rotate? We will write already visited elements with *, so 
+    when we see * or we go outside the grid, it is time to rotate.
 
+    Complexity
+    It is O(mn) both for time and space.
 
-2.58) Cycle finding in directed graph and undirected graph is 
-      completely different! Memorize details of each way. 
 
-    Directed graph cycle finding: Course Schedule (LC):
-    There are a total of n courses you have to take, 
-    labeled from 0 to n-1.
+    class Solution:
+        def spiralOrder(self, matrix):
+            n, m = len(matrix[0]), len(matrix)
+            x, y, dx, dy = 0, 0, 1, 0
+            ans = []
+            for _ in range(m*n):
+                if not 0 <= x+dx < n or not 0 <= y+dy < m or matrix[y+dy][x+dx] == "*":
+                    dx, dy = -dy, dx
+                    
+                ans.append(matrix[y][x])
+                matrix[y][x] = "*"
+                x, y = x + dx, y + dy
+            
+            return ans
 
-    Some courses may have prerequisites, for example 
-    to take course 0 you have to first take course 1, 
-    which is expressed as a pair: [0,1]
 
-    Given the total number of courses and a list of prerequisite 
-    pairs, is it possible for you to finish all courses?
-    
-    Method 1 COLORED DFS:
-        def canFinishWithColoredDFS(self, numCourses, prerequisites):        
-            g = defaultdict(set)
 
-            for req in prerequisites:
-                g[req[1]].add(req[0])
+MEMORY ALLOCATOR
+    I've been recently asked this question in the onsite interview:
+    You are required to design a memory allocation class for an bigArray, which will have below methods:
+
+    int bigArray[10000] -> Not necessarily int[], can be anything(Should not modify array)
+
+    int allocateSlice(int size){
+    // allocate a contiguous slice of length size in the array and return the starting index from where data can be stored
+    }
+
+    int freeSlice(int startIndex){
+    // de-allocate a contiguous slice starting at startIndex, with size it has been allocated earlier
+    }
+
+    I was able to come up with an approach but don't think it was scaleable and would pass all test cases!
+    Can you guys tell me your thoughts on possible solutions?
+
+    #Google #Design
+
+        Maintain a set of 'free' ranges in a set sorted by their length. The set will initially have only one value - [0, MAXSIZE - 1]. When you have to
+        allocate for size n, binary search for first range, then split it and store this operation in a hashmap. To free a slice, get the size from the hashmap 
+        and insert that range back into the set. Both operations take O(logn).
+
+        Write so we use a treemap to contain sizes pointing to ranges
+        
+        when we free, we will have to find if that range toouches another range, merge it, and then put it into tree map right?
+
+
+    Top k most frequenet element with TREE MAP/BST
+
+        The total time complexity is O(n + klogn)
+
+        class Solution {
+        public:
+            vector<int> topKFrequent(vector<int>& nums, int k) {
+                unordered_map<int, int> valToCnt;
+                for (auto it: nums) 
+                    valToCnt[it]++;
+                
+                map<int, vector<int>> cntToVal;
+                for (auto it: valToCnt) 
+                    cntToVal[-it.second].push_back(it.first);
+                
+                vector<int> ans; 
+                for (auto it: cntToVal) {
+                    for (auto itB: it.second) {
+                        ans.push_back(itB);
+                        k--;
+                        if (!k) return ans;
+                    }
+                }
+                return ans;
+            }
+        };
+
+
+
+
+
+    Snapchat Phone Screen
+
+        Question - Design a class/method AddAndGetTopK to add a number and get top K frequent elements.
+        Eg - k = 3
+        4
+        4,5
+        4,5,4 => 4,5
+        4,5,4,6 => 4,5,6
+        4,5,4,6,5 => 4,5,6
+        4,5,4,6,5,7 => 4,5,6
+        4,5,4,6,5,7,7 => 4,5,7
+
+        I suggessted a BST solution with O(logn) insertion time and O(logn) time for getting top K elements, by maintaining the count of nodes below every node.
+
+        Any other solutions?
+
+
+        freq -> val BST. 
+        
+        OK add a number
+        val -> freq hashmap
+        then also update in freq->val map 
+
+        Ok but how do we do top k?
+
+        can also use pq, and get rid of dirty elements. 
+
+
+    ENUMERATING ALL TOPOLOGICAL SORTS (DATAVISOR)
+        Enumerate all possible topological sorts,
+        dont just give me one topological sort!!
+
+    Word finder:
+
+        We are given a list of words that have both 'simple' and 'compound' words in them. Write an algorithm that 
+        prints out a list of words without the compound words that are made up of the simple words.
+
+        Input: chat, ever, snapchat, snap, salesperson, per, person, sales, son, whatsoever, what so.
+        Output should be: chat, ever, snap, per, sales, son, what, so
+ 
+        The idea . First we have to sort words by length. Then generate trie and put the words in it. Check in the trie if some word is compound.
+
+
+    Given an R x C grid of letters "P", "F", and ".", you have one person "P" and his friends "F".
+    The person will go visit all his friends and can walk over the empty spaces to visit his friends.
+    He visits a friend when he walks onto the friend's square.
+    He can walk over his friends.
+    Find the length of the shortest path for him to visit all his friends.
+
+    "..P..",
+    "F...F",
+    "FF.FF"
+    The answer is 9. Can someone please help solving this question?
+
+        Answer:
+        Create MST using the friends node. (Kruskal Algo) -
+        Find shortest distance to any of the friends starting from P. (BFS )
+        Ans = Cost of MST (part1) + shortest distance(part-2)
+
+    Word Search 2 Snap:
+
+        class TrieNode():
+            def __init__(self):
+                self.children = collections.defaultdict(TrieNode)
+                self.isWord = False
             
-            def has_cycle_directed(node, g, colors):
-                colors[node] = "G" # Grey being processed
+        class Trie():
+            def __init__(self):
+                self.root = TrieNode()
+            
+            def insert(self, word):
+                node = self.root
+                for w in word:
+                    node = node.children[w]
+                node.isWord = True
+            
+            def search(self, word):
+                node = self.root
+                for w in word:
+                    node = node.children.get(w)
+                    if not node:
+                        return False
+                return node.isWord
+            
+        class Solution(object):
+            def findWords(self, board, words):
+                res = []
+                trie = Trie()
+                node = trie.root
+                for w in words:
+                    trie.insert(w)
+                for i in xrange(len(board)):
+                    for j in xrange(len(board[0])):
+                        self.dfs(board, node, i, j, "", res)
+                return res
+            
+            def dfs(self, board, node, i, j, path, res):
+                if node.isWord:
+                    res.append(path)
+                    node.isWord = False
+                if i < 0 or i >= len(board) or j < 0 or j >= len(board[0]):
+                    return 
+                tmp = board[i][j]
+                node = node.children.get(tmp)
+                if not node:
+                    return 
+                board[i][j] = "#"
+                self.dfs(board, node, i+1, j, path+tmp, res)
+                self.dfs(board, node, i-1, j, path+tmp, res)
+                self.dfs(board, node, i, j-1, path+tmp, res)
+                self.dfs(board, node, i, j+1, path+tmp, res)
+                board[i][j] = tmp
+
+
+    Coding questions:
+        Problem 1
+
+        Custom:
+            Given an R x C grid of letters "P", "F", and ".", you have one person "P" and his friends "F".
+            The person will go visit all his friends and can walk over the empty spaces to visit his friends. 
+            He visits a friend when he walks onto the friend's square.
+            He can walk over his friends.
+            Find the length of the shortest path for him to visit all his friends.
+
+            "..P..",
+            "F...F",
+            "FF.FF"
+            
+            
+            The answer is 9.
+
+            This is a graph problem. You need to compute the distance between each person or friend, 
+            then find the size of the minimum spanning tree. Use a union find.
+
+            Worth coding this??
+
+
+    Subclassing + LRUCache but  each key has a cost instead of 1 for capiacty:
+        from collections import OrderedDict
+
+        class SCLRUCache(OrderedDict):
+            def __init__(self, max_cost: int):
+                self.curr_cost = 0
+                self.max_cost = max_cost
+            
+            def add(self, key, value, cost: int):
+                self[key] = (value, cost)
+                self.curr_cost += cost
+                while self.curr_cost > self.max_cost:
+                    _, removed_cost = self.popitem(last = False)
+                    self.curr_cost -= removed_cost
+                    
+            def read(self, key):
+                if key not in self:
+                    return - 1
+
+                self.move_to_end(key)
+                value, _ = self[key]
+                return value
+
+    241. Different Ways to Add Parentheses
+
+        Given a string expression of numbers and operators, return all possible results from computing all the different possible ways to group numbers and operators. You may return the answer in any order.
+
+        
+
+        Example 1:
+
+        Input: expression = "2-1-1"
+        Output: [0,2]
+        Explanation:
+        ((2-1)-1) = 0 
+        (2-(1-1)) = 2
+        Example 2:
+
+        Input: expression = "2*3-4*5"
+        Output: [-34,-14,-10,-10,10]
+        Explanation:
+        (2*(3-(4*5))) = -34 
+        ((2*3)-(4*5)) = -14 
+        ((2*(3-4))*5) = -10 
+        (2*((3-4)*5)) = -10 
+        (((2*3)-4)*5) = 10
+        
+
+        Constraints:
+
+        1 <= expression.length <= 20
+        expression consists of digits and the operator '+', '-', and '*'.
+        All the integer values in the input expression are in the range [0, 99].
+
+
+            class Solution:
+                def diffWaysToCompute(self, expression: str) -> List[int]:
+                    
+                    if ('+' not in expression) and ('-' not in expression) and ('*' not in expression):
+                        return [int(expression)]
+                    
+                    res = []
+                    
+                    for i, v in enumerate(expression):
+                        if v == '+' or v == '-' or v == '*':
+                            left_res = self.diffWaysToCompute(expression[:i])
+                            right_res = self.diffWaysToCompute(expression[i + 1:])
+                            for left_i, left_v in enumerate(left_res):
+                                for right_i, right_v in enumerate(right_res):
+                                    if v == '+':
+                                        res.append(left_v + right_v)
+                                    elif v == '-':
+                                        res.append(left_v - right_v)
+                                    else:
+                                        res.append(left_v * right_v)
+                    return res
+
+            MEMO SOLN
+
+            class Solution:
+                def diffWaysToCompute(self, expression: str) -> List[int]:
+                    self.memo = defaultdict(list)
+                    return self.diffWaysToComputeUtil(expression)
+                    
+                    
+                def diffWaysToComputeUtil(self, expression: str) -> List[int]:
+                    if expression in self.memo:
+                        return self.memo[expression]
+                    
+                    if ('+' not in expression) and ('-' not in expression) and ('*' not in expression):
+                        return [int(expression)]
+                    
+                    res = []
+                    
+                    for i, v in enumerate(expression):
+                        if v == '+' or v == '-' or v == '*':
+                            left_res = self.diffWaysToComputeUtil(expression[:i])
+                            right_res = self.diffWaysToComputeUtil(expression[i + 1:])
+                            for left_i, left_v in enumerate(left_res):
+                                for right_i, right_v in enumerate(right_res):
+                                    if v == '+':
+                                        res.append(left_v + right_v)
+                                    elif v == '-':
+                                        res.append(left_v - right_v)
+                                    else:
+                                        res.append(left_v * right_v)
+                    self.memo[expression] = res
+                    return res
+
+
+
+
+    Quick Select impl: Get Top K most frequent elemetns:
+
+        from collections import Counter
+        class Solution:
+            def topKFrequent(self, nums: List[int], k: int) -> List[int]:
+                count = Counter(nums)
+                unique = list(count.keys())
                 
-                for c in g[node]:
-                    if colors.get(c) is None and has_cycle_directed(c, g, colors):
-                        return True
-                    elif colors.get(c) == "G":
-                        # We are processing this node but we looped back around somehow
-                        # so cycle
-                        return True
-                    else: 
-                        # The node we are processing has already been processed. 
-                        continue  
-                colors[node] = "B" # Black
+                def partition(left, right, pivot_index) -> int:
+                    pivot_frequency = count[unique[pivot_index]]
+                    # 1. move pivot to end
+                    unique[pivot_index], unique[right] = unique[right], unique[pivot_index]  
+                    
+                    # 2. move all less frequent elements to the left
+                    store_index = left
+                    for i in range(left, right):
+                        if count[unique[i]] < pivot_frequency:
+                            unique[store_index], unique[i] = unique[i], unique[store_index]
+                            store_index += 1
+
+                    # 3. move pivot to its final place
+                    unique[right], unique[store_index] = unique[store_index], unique[right]  
+                    
+                    return store_index
+                
+                def quickselect(left, right, k_smallest) -> None:
+                    """
+                    Sort a list within left..right till kth less frequent element
+                    takes its place. 
+                    """
+                    # base case: the list contains only one element
+                    if left == right: 
+                        return
+                    
+                    # select a random pivot_index
+                    pivot_index = random.randint(left, right)     
+                                    
+                    # find the pivot position in a sorted list   
+                    pivot_index = partition(left, right, pivot_index)
+                    
+                    # if the pivot is in its final sorted position
+                    if k_smallest == pivot_index:
+                        return 
+                    # go left
+                    elif k_smallest < pivot_index:
+                        quickselect(left, pivot_index - 1, k_smallest)
+                    # go right
+                    else:
+                        quickselect(pivot_index + 1, right, k_smallest)
+                
+                n = len(unique) 
+                # kth top frequent element is (n - k)th less frequent.
+                # Do a partial sort: from less frequent to the most frequent, till
+                # (n - k)th less frequent element takes its place (n - k) in a sorted array. 
+                # All element on the left are less frequent.
+                # All the elements on the right are more frequent.  
+                quickselect(0, n - 1, n - k)
+                # Return top k frequent elements
+                return unique[n - k:]
+
+    Circular sort:
+
+        Given an array of integers, return true or false if the numbers in the array go from 0... (N - 1) 
+        where N is the length of the array
+
+        Linear time, constant space is a requirement
+
+        example:
+        [0,1,2,3,4] = true;
+        [4,2,1,0,3] = true;
+        [0,1,5,2,4] = false;
+
+
+
+    Valid Number DFA SOLN:
+        class Solution(object):
+        def isNumber(self, s):
+            """
+            :type s: str
+            :rtype: bool
+            """
+            #define a DFA
+            state = [{}, 
+                    {'blank': 1, 'sign': 2, 'digit':3, '.':4}, 
+                    {'digit':3, '.':4},
+                    {'digit':3, '.':5, 'e':6, 'blank':9},
+                    {'digit':5},
+                    {'digit':5, 'e':6, 'blank':9},
+                    {'sign':7, 'digit':8},
+                    {'digit':8},
+                    {'digit':8, 'blank':9},
+                    {'blank':9}]
+            currentState = 1
+            for c in s:
+                if c >= '0' and c <= '9':
+                    c = 'digit'
+                if c == ' ':
+                    c = 'blank'
+                if c in ['+', '-']:
+                    c = 'sign'
+                if c not in state[currentState].keys():
+                    return False
+                currentState = state[currentState][c]
+            if currentState not in [3,5,8,9]:
                 return False
-            
-            colors = {}  # None -> white, Black -> Done, Grey -> Processing 
-            for i in range(numCourses):
-                # process each forest seperately
-                # print("DFS ON", i)
-                if(colors.get(i) is None and has_cycle_directed(i, g, colors)):
-                    print("COLORS ARE, ", colors)
-                    return False     
             return True
 
-    METHOD 2 BFS + TOPOSORT WITH INORDER OUTORDER:
-        def canFinish(self, numCourses, prerequisites):
+    Word Search 2: Find all words on the board:
+        https://leetcode.com/problems/word-search-ii/discuss/59790/Python-dfs-solution-(directly-use-Trie-implemented).
+        @caikehe Great solution, but no need to implement Trie.search() since the search is essentially done by dfs.
 
-            g = defaultdict(set)
-            inorder_count = defaultdict(int)    
-            # Init
-            for c in range(numCourses):
-                inorder_count[c] = 0
-                
-            for req in prerequisites:
-                g[req[1]].add(req[0])
-                inorder_count[req[0]] += 1
+
+        class TrieNode():
+            def __init__(self):
+                self.children = collections.defaultdict(TrieNode)
+                self.isWord = False
             
-            print("inorder count")
+        class Trie():
+            def __init__(self):
+                self.root = TrieNode()
             
-            root_nodes = [k for (k,v) in  inorder_count.items() if v == 0]
-            print("root nodes", root_nodes)
+            def insert(self, word):
+                node = self.root
+                for w in word:
+                    node = node.children[w]
+                node.isWord = True
             
-            print("G", g)
-            print("Inorder count", inorder_count)
+            def search(self, word):
+                node = self.root
+                for w in word:
+                    node = node.children.get(w)
+                    if not node:
+                        return False
+                return node.isWord
             
-            d = deque(root_nodes)
-            visited = set()
-            while d:
-                node = d.popleft()
-                
-                visited.add(node)
-                
-                children = g[node]
-                for c in children:
-                    inorder_count[c] -= 1
-                    if(inorder_count[c] == 0):
-                        d.append(c)
-                               
-            # If you cant visit all nodes from root nodes, then there is a cycle 
-            # in directed graph.      
-            return len(visited) == numCourses
+        class Solution(object):
+            def findWords(self, board, words):
+                res = []
+                trie = Trie()
+                node = trie.root
+                for w in words:
+                    trie.insert(w)
+                for i in xrange(len(board)):
+                    for j in xrange(len(board[0])):
+                        self.dfs(board, node, i, j, "", res)
+                return res
+            
+            def dfs(self, board, node, i, j, path, res):
+                if node.isWord:
+                    res.append(path)
+                    node.isWord = False
+                if i < 0 or i >= len(board) or j < 0 or j >= len(board[0]):
+                    return 
+                tmp = board[i][j]
+                node = node.children.get(tmp)
+                if not node:
+                    return 
+                board[i][j] = "#"
+                self.dfs(board, node, i+1, j, path+tmp, res)
+                self.dfs(board, node, i-1, j, path+tmp, res)
+                self.dfs(board, node, i, j-1, path+tmp, res)
+                self.dfs(board, node, i, j+1, path+tmp, res)
+                board[i][j] = tmp
 
 
-2.59) Cycle finding in undirected graph: 
 
-        def undirected_has_cycle(G):
-            color = {v: WHITE for v in G}
-            cycle = False
+    Similar to HRT problem:
 
-            def visit(u, p):
-                nonlocal cycle
-                if cycle:
-                    return
+        There are some processes that need to be executed. Amount of a load that process causes on a server that runs it, is being represented by a single integer. Total load caused on a server is the sum of the loads of all the processes that run on that server. You have at your disposal two servers, on which mentioned processes can be run. Your goal is to distribute given processes between those two servers in the way that, absolute difference of their loads will be minimized.
 
-                color[u] = GREY
-                for v in G[u]:
-                    if color[v] == WHITE:
-                        visit(v, u)
-                    elif v != p and color[v] == GREY:
-                        cycle = True
-                color[u] = BLACK
+        Given an array of n integers, of which represents loads caused by successive processes, return the minimum absolute difference of server loads.
 
-            for s in G:
-                if color[s] == WHITE:
-                    visit(s, None)
-                    if cycle:
-                        return True
+        Example 1:
 
-            return cycle
+        Input: [1, 2, 3, 4, 5]
+        Output: 1
+        Explanation:
+        We can distribute the processes with loads [1, 2, 4] to the first server and [3, 5] to the second one,
+        so that their total loads will be 7 and 8, respectively, and the difference of their loads will be equal to 1.
 
 
+        Just do the HRT problem instead!
+        Dishes, friends,  ETC, minimize the unfairness!
 
-2.6) LRU Cache learnings and techniques=>
-    Circular Doubly linked lists are better than doubly linked lists if you set up dummy nodes
-    so you dont have to deal with edge cases regarding changing front and back pointers
-    -> With doubly linked lists and maps, You can remove any node in O(1) time as well as append to front and back in O(1) time 
-       which enables alot of efficiency
 
-    -> You can also use just an ordered map for this question to solve it fast!! 
-       (pop items and put them back in to bring them to the front technique to do LRU)
 
-    from collections import OrderedDict
-    class LRUCache:
+    K stack pops
 
-        def __init__(self, capacity: int):
-            self.max_capacity = capacity
-            self.lru_cache = OrderedDict()
-            
-        def get(self, key: int) -> int:
-            key = str(key)
-            if(key not in self.lru_cache):
-                return -1
-            value = self.lru_cache[key]
-            del self.lru_cache[key]
-            self.lru_cache[key] = value
-            return value
 
-        def put(self, key: int, value: int) -> None:
-            key = str(key)
-            if(key not in self.lru_cache):
-                if(len(self.lru_cache) < self.max_capacity):
-                    self.lru_cache[key] = value
-                else:
-                    # last=False signals you want to delete first instead
-                    # of last entry. 
-                    self.lru_cache.popitem(last=False)
-                    self.lru_cache[key] = value
+    Divide subset into equal partitions Subset sum into k partitions (linkedin): 
+
+
+###################################################################################
+##################################################################################
+
+[Python] Powerful Ultimate Binary Search Template. Solved many problems
+
+
+    Binary Search helps us reduce the search time from linear O(n) to logarithmic O(log n). 
+
+    >> Most Generalized Binary Search
+    Suppose we have a search space. It could be an array, a range, etc. 
+    
+    Usually it's sorted in ascending order. For most tasks, 
+    we can transform the requirement into the following generalized form:
+
+    Minimize k , s.t. condition(k) is True
+
+    The following code is the most generalized binary search template:
+
+    def binary_search(array) -> int:
+        def condition(value) -> bool:
+            pass
+
+        left, right = min(search_space), max(search_space) # could be [0, n], [1, n] etc. Depends on problem
+        while left < right:
+            mid = left + (right - left) // 2
+            if condition(mid):
+                right = mid
             else:
-                del self.lru_cache[key]
-                self.lru_cache[key] = value
+                left = mid + 1
+        return left
 
-    # WITH A DOUBLY LINKED CIRCULAR LIST:
-    class LRUCache:
-        def __init__(self, capacity):
-            self.capacity = capacity
-            self.dic = dict()
-            self.head = Node(0, 0)
-            self.tail = Node(0, 0)
-            self.head.next = self.tail
-            self.tail.prev = self.head
+    What's really nice of this template is that, for most of the binary search problems, 
+    we only need to modify three parts after copy-pasting this template, 
+    and never need to worry about corner cases and bugs in code any more:
 
-        def get(self, key):
-            if key in self.dic:
-                n = self.dic[key]
-                self._remove(n)
-                self._add(n)
-                return n.val
-            return -1
+    Correctly initialize the boundary variables left and right to specify search space. 
+    Only one rule: set up the boundary to include all possible elements;
+    Decide return value. Is it return left or return left - 1? 
+    Remember this: after exiting the while loop, left is the minimal k​ satisfying the condition function;
+    Design the condition function. This is the most difficult and most beautiful part. Needs lots of practice.
+    Below I'll show you guys how to apply this powerful template to many LeetCode problems.
 
-        def set(self, key, value):
-            if key in self.dic:
-                self._remove(self.dic[key])
-            n = Node(key, value)
-            self._add(n)
-            self.dic[key] = n
-            if len(self.dic) > self.capacity:
-                n = self.head.next
-                self._remove(n)
-                del self.dic[n.key]
 
-        def _remove(self, node):
-            p = node.prev
-            n = node.next
-            p.next = n
-            n.prev = p
+    Excellent work! Many people think sorted array is a must to apply 
+    binary search, which is not 100% correct. In some cases, there is no 
+    such array, or the array is not sorted, or the element are not even 
+    comparable! What makes binary search work is that there exists a function 
+    that can map elements in left half to True, and the other half to False, 
+    or vice versa. If we can find such a function, we can apply bs to find 
+    the boundary (lower_bound for example). For the interval notation, 
+    Professor E.W. Dijkstra favors left closed right open interval 
+    notation and explained why we benefit from this notation in his 
+    post which was published in 1982.
 
-        def _add(self, node):
-            p = self.tail.prev
-            p.next = node
-            self.tail.prev = node
-            node.prev = p
-            node.next = self.tail
+    In short, loop invariants help us design a loop and ensure the 
+    correctness of a loop in a formal way. ref1, ref2. For the binary search code, 
+    if we imagine the array expanded to infinity for both sides, then the loop 
+    invariants can phrased as:1) l<=r 2) elements in (-inf, l) are mapped to 
+    False by condition 3) elements in [r, +inf) are mapped to True by condition. 
+    These invariants are true before the loop, in each iteration of 
+    the loop, and after the loop. After the loop breaks, we know l ==r, 
+    from these invariants, we can conclude that elements in (-inf, l) are False, 
+    and those in [l, +inf) are true. Besides, to ensure a loop is 
+    correct, we also need to prove the loop break eventually. 
+    The proof is straight forward: at each iteration, the search 
+    range [l, r) shrinks by at least 1.
 
 
+    1.   First Bad Version [Easy]
+       You are a product manager and currently leading a team to develop a new 
+       product. Since each version is developed based on the previous version, 
+       all the versions after a bad version are also bad. Suppose you have n 
+       versions [1, 2, ..., n] and you want to find out the first bad one, which 
+       causes all the following ones to be bad. You are given an API bool 
+       isBadVersion(version) which will return whether version is bad.
 
-2.7) When you DFS/BACKTRACK, one way to reduce space usage, is using grid itself
-     as the visited set, and assigning and reverting it.  
-     Additionally, RETURN ASAP. PRUNE, PRUNE PRUNE. 
-     Do not aggregrate all the results then return.
-     NO UNNECESSARY SEARCHING. Look at Word Search in leet folder. 
+       Example:
 
-    Given a 2D board and a word, find if the word exists in the grid.
+       Given n = 5, and version = 4 is the first bad version.
 
-    class Solution:
-        def exist(self, board: List[List[str]], word: str) -> bool:
-        
-            def CheckLetter(row, col, cur_word):
-            #only the last letter remains
-                if len(cur_word) == 1:
-                    return self.Board[row][col] == cur_word[0]
-                else:
-                #mark the cur pos as explored -- None so that other can move here
-                    self.Board[row][col] = None
-                    if row+1<self.max_row and self.Board[row+1][col] == cur_word[1]:
-                        if CheckLetter(row+1, col, cur_word[1:]):
-                            return True
-                    if row-1>=0 and self.Board[row-1][col] == cur_word[1]:
-                        if CheckLetter(row-1, col, cur_word[1:]):
-                            return True
-                    if col+1<self.max_col and self.Board[row][col+1] == cur_word[1]:
-                        if CheckLetter(row, col+1, cur_word[1:]):
-                            return True
-                    if col-1>=0 and self.Board[row][col-1] == cur_word[1]:
-                        if CheckLetter(row, col-1, cur_word[1:]):
-                            return True
-                    #revert changes made
-                    self.Board[row][col] = cur_word[0]
-                    return False                  
-        
-            self.Board = board
-            self.max_row = len(board)
-            self.max_col = len(board[0])
-            if len(word)>self.max_row*self.max_col:
-                return False
-            for i in range(self.max_row):
-                for j in range(self.max_col):
-                    if self.Board[i][j] == word[0]:
-                        if CheckLetter(i, j, word):return True
-            return False
+       call isBadVersion(3) -> false
+       call isBadVersion(5) -> true
+       call isBadVersion(4) -> true
+
+       Then 4 is the first bad version. 
+       First, we initialize left = 1 and right = n to include all possible values. 
+       Then we notice that we don't even need to design the condition function. 
+       It's already given by the isBadVersion API. Finding the first bad version is 
+       equivalent to finding the minimal k satisfying isBadVersion(k) is True. 
+       Our template can fit in very nicely:
+
+       class Solution:
+           def firstBadVersion(self, n) -> int:
+               left, right = 1, n
+               while left < right:
+                   mid = left + (right - left) // 2
+                   if isBadVersion(mid):
+                       right = mid
+                   else:
+                       left = mid + 1
+               return left
 
 
-2.8) ROLLING HASH USAGE: 
-    Consider the string abcd and we have to find the hash values of 
-    substrings of this string having length 3 ,i.e., abc and bcd.
-    
-    For simplicity let us take 5 as the base but in actual scenarios we should mod it 
-    with a large prime number to avoid overflow.The highest 
-    power of base is calculated as (len-1) where len is length of substring.
+    2.  Sqrt(x) [Easy]
+       Implement int sqrt(int x). Compute and return the square root of x, 
+       where x is guaranteed to be a non-negative integer. Since the return type 
+       is an integer, the decimal digits are truncated and only the 
+       integer part of the result is returned.
 
-    H(abc) => a*(5^2) + b*(5^1) + c*(5^0) 
-    = 97*25 + 98*5 + 99*1 = 3014
+       Example:
 
-    H(bcd) => b*(5^2) + c*(5^1) + d*(5^0) 
-    = 98*25 + 99*5 + 100*1 = 3045
-    
-    So, we do not need to rehash the string again. Instead, we can subtract 
-    the hash code corresponding to the first character from 
-    the first hash value,multiply the result by the considered 
-    prime number and add the hash code corresponding to the next character to it.
-    
-    H(bcd)=(H(abc)-a*(5^2))*5 + d*(5^0)=(3014-97*25)*5 + 100*1 = 3045
+       Input: 4
+       Output: 2
+       Input: 8
+       Output: 2
+       Easy one. First we need to search for minimal k satisfying 
+       condition k^2 > x, then k - 1 is the answer to the question. 
+       We can easily come up with the solution. Notice that I set 
+       right = x + 1 instead of right = x to deal with special input 
+       cases like x = 0 and x = 1.
 
-    In general,the hash H can be defined as:-
+       def mySqrt(x: int) -> int:
+           left, right = 0, x + 1
+           while left < right:
+               mid = left + (right - left) // 2
+               if mid * mid > x:
+                   right = mid
+               else:
+                   left = mid + 1
+           return left - 1  # `left` is the minimum k value, `k - 1` is the answer
 
-    H=( c1a_{k-1} + c2a_{k-2} + c3a_{k-3}. . . . + cka_0 ) % m
-    
-    where a is a constant, c1,c2, ... ck are the input characters 
-    and m is a large prime number, since the probability of 
-    two random strings colliding is about ≈ 1/m.
 
-    Then, the hash value of next substring,Hnxt using rolling hash can be defined as:-
+    3.  Search Insert Position [Easy]
+       Given a sorted array and a target value, return the index if the 
+       target is found. If not, return the index where it would be if it were 
+       inserted in order. You may assume no duplicates in the array.
 
-    Hnxt=( ( H - c1ak-1 ) * a + ck+1a0 ) % m
+       Example:
 
-    // computes the hash value of the input string s
-    long long compute_hash(string s) {
-        const int p = 31;   // base 
-        const int m = 1e9 + 9; // large prime number
-        long long hash_value = 0;
-        long long p_pow = 1;
-        for (char c : s) {
-            hash_value = (hash_value + (c - 'a' + 1) * p_pow) % m;
-            p_pow = (p_pow * p) % m;  
-        }
-        return hash_value;
-    }
-    // finds the hash value of next substring given nxt as the ending character 
-    // and the previous substring prev 
-    long long rolling_hash(string prev,char nxt)
-    {
-        const int p = 31;
-        const int m = 1e9 + 9;
-        long long H=compute_hash(prev);
-        long long Hnxt=( ( H - pow(prev[0],prev.length()-1) ) * p + (int)nxt ) % m;
-        return Hnxt;
-    }
+       Input: [1,3,5,6], 5
+       Output: 2
+       Input: [1,3,5,6], 2
+       Output: 1
 
-    The various applications of Rolling Hash algorithm are:
+       Very classic application of binary search. We are looking for the 
+       minimal k value satisfying nums[k] >= target, and we can just 
+       copy-paste our template. Notice that our solution is correct regardless 
+       of whether the input array nums has duplicates. Also notice that the input 
+       target might be larger than all elements in nums and therefore 
+       needs to placed at the end of the array. 
+       That's why we should initialize right = len(nums) instead of right = len(nums) - 1.
 
-    Rabin-Karp algorithm for pattern matching in a string in O(n) time
-    Calculating the number of different substrings of a string in O(n2logn)
-    Calculating the number of palindromic substrings in a str
+       class Solution:
+           def searchInsert(self, nums: List[int], target: int) -> int:
+               left, right = 0, len(nums)
+               while left < right:
+                   mid = left + (right - left) // 2
+                   if nums[mid] >= target:
+                       right = mid
+                   else:
+                       left = mid + 1
+               return left
 
-    EXAMPLE:
+    >> Advanced Application
+    The above problems are quite easy to solve, because they 
+    already give us the array to be searched. We'd know that we should 
+    use binary search to solve them at first glance. However, more often 
+    are the situations where the search space and search target are not 
+    so readily available. Sometimes we won't even realize that the problem 
+    should be solved with binary search -- we might just turn to dynamic 
+    programming or DFS and get stuck for a very long time.
 
-    187. Repeated DNA Sequences
-    Write a function to find all the 10-letter-long sequences 
-    (substrings) that occur more than once in a DNA molecule.
+    As for the question "When can we use binary search?", my answer 
+    is that, If we can discover some kind of monotonicity, for example, 
+    if condition(k) is True then condition(k + 1) is True, 
+    then we can consider binary search.
 
-    Example:
 
-    Input: s = "AAAAACCCCCAAAAACCCCCCAAAAAGGGTTT"
+    1.    Capacity To Ship Packages Within D Days [Medium]
+        A conveyor belt has packages that must be shipped from 
+        one port to another within D days. The i-th package on the 
+        conveyor belt has a weight of weights[i]. Each day, 
+        we load the ship with packages on the conveyor belt 
+        (in the order given by weights). We may not load more 
+        weight than the maximum weight capacity of the ship.
 
-    Output: ["AAAAACCCCC", "CCCCCAAAAA"]
+        Return the least weight capacity of the ship that 
+        will result in all the packages on the conveyor 
+        belt being shipped within D days.
 
-    def findRepeatedDnaSequences(self, s):
-        # We can use rolling hash to effeciently 
-        # compute hash values of the pattern
-        # hsh as counter for hash value => string
-        hsh = {}
-        def cal_hsh(string):
-            assert(len(string) == 10)
-            hsh_val = 0
-            for i in range(10):
-                hsh_val += ord(string[i]) * 7**i
-            return hsh_val    
-        def update_hsh(prev_val, drop_idx, add_idx):
-            return (prev_val - ord(s[drop_idx]))//7 + ord(s[add_idx]) * 7 ** 9
+        Example :
+
+        Input: weights = [1,2,3,4,5,6,7,8,9,10], D = 5
+        Output: 15
+        Explanation: 
+        A ship capacity of 15 is the minimum to ship 
+            all the packages in 5 days like this:
+        1st day: 1, 2, 3, 4, 5
+        2nd day: 6, 7
+        3rd day: 8
+        4th day: 9
+        5th day: 10
+
+        Note that the cargo must be shipped in the order given, 
+        so using a ship of capacity 14 and splitting 
+        the packages into parts like (2, 3, 4, 5), 
+        (1, 6, 7), (8), (9), (10) is not allowed.
         
-        n = len(s)
-        if n < 10: return []
-        hsh_val = cal_hsh(s[:10])
-        hsh[hsh_val] = s[:10]
-        ret = set()
-        # Notice this is n-9 since we want the last substring of length 10
-        for i in range(1, n-9):
-            hsh_val = update_hsh(hsh_val, i-1, i+9)
-            if hsh_val in hsh:
-                ret.add(s[i:i+10])
-            else:
-                hsh[hsh_val] = s[i:i+10]
-        return list(ret)
+        SOLN:
+        Start with a high capacity that works -> then keep reducing it until 
+        we are at an integer that causes D to go from viable -> not viable
+        Since thats the linear search solution -> Try binary
+        
+        Try total sum -> then half sum -> then quarter sum -> and keep going 
+        until D == 5
+        But how do verify a particular weight -> In O(N) by running it through array?
+        We should be able to do faster by doing a type of DP rite? idk.
 
-    
-3) 0-1 BFS
-    we can use BFS to solve the SSSP (single-source shortest path) 
-    problem in O(|E|), if the weights of each edge is either 0 or 1.
 
-    append new vertices at the beginning if the corresponding edge 
-    has weight 0, i.e. if d[u] = d[v], or at the end if the edge 
-    has weight 1, i.e. if d[u]=d[v]+1. This way the queue still remains sorted at all time.
+        Binary search probably would not come to our mind when we first meet 
+        this problem. We might automatically treat weights as search space and 
+        then realize we've entered a dead end after wasting lots of time. 
+        In fact, we are looking for the minimal one among all feasible capacities. 
+        We dig out the monotonicity of this problem: if we can successfully 
+        ship all packages within D days with capacity m, then we can definitely 
+        ship them all with any capacity larger than m. Now we can design a 
+        condition function, let's call it feasible, given an input capacity, 
+        it returns whether it's possible to ship all packages within D days. 
+        This can run in a greedy way: if there's still room for the current 
+        package, we put this package onto the conveyor belt, otherwise we 
+        wait for the next day to place this package. If the total days 
+        needed exceeds D, we return False, otherwise we return True.
 
-    vector<int> d(n, INF);
-    d[s] = 0;
-    deque<int> q;
-    q.push_front(s);
-    while (!q.empty()) {
-        int v = q.front();
-        q.pop_front();
-        for (auto edge : adj[v]) {
-            int u = edge.first;
-            int w = edge.second;
-            if (d[v] + w < d[u]) {
-                d[u] = d[v] + w;
-                if (w == 1)
-                    q.push_back(u);
-                else
-                    q.push_front(u);
-            }
-        }
-    }
+        Next, we need to initialize our boundary correctly. Obviously 
+        capacity should be at least max(weights), otherwise the conveyor 
+        belt couldn't ship the heaviest package. On the other hand, capacity 
+        need not be more thansum(weights), because then we can 
+        ship all packages in just one day.
 
-    Dial's algorithm
-    We can extend this even further if we allow the weights of the edges to be even bigger. 
-    If every edge in the graph has a weight ≤k, than the distances of vertices 
-    in the queue will differ by at most k from the distance of v to the source. 
-    So we can keep k+1 buckets for the vertices in the queue, and
-    whenever the bucket corresponding to the smallest distance gets 
-    empty, we make a cyclic shift to get the bucket with the next higher 
-    distance. This extension is called Dial's algorithm.
+        Now we've got all we need to apply our binary search template:
+
+        def shipWithinDays(weights: List[int], D: int) -> int:
+            def feasible(capacity) -> bool:
+                days = 1
+                total = 0
+                for weight in weights:
+                    total += weight
+                    if total > capacity:  # too heavy, wait for the next day
+                        total = weight
+                        days += 1
+                        if days > D:  # cannot ship within D days
+                            return False
+                return True
+
+            left, right = max(weights), sum(weights)
+            while left < right:
+                mid = left + (right - left) // 2
+                if feasible(mid):
+                    right = mid
+                else:
+                    left = mid + 1
+            return left
 
 
+    2.   Split Array Largest Sum [Hard]
+        Given an array which consists of non-negative integers and an 
+        integer m, you can split the array into m non-empty continuous 
+        subarrays. Write an algorithm to minimize the largest sum 
+        among these m subarrays.
 
-4) To do things inplace, such as inplace quick sort, or even binary search, 
-    it is best to operate on index values in your recursion 
-    instead of slicing and joining arrays.
-    Always operate on the pointers for efficiency purposes.
+        Input:
+        nums = [7,2,5,10,8]
+        m = 2
 
-5) If you need to keep track of a list of values instead of just 1 values 
-    such as a list of maxes, instead of 1 max, 
-    and pair off them off, use an ordered dictionary! 
-    They will keep these values ordered for pairing purposes. 
-    pushing and poping an element in an ordered map brings it to the front. 
+        Output:
+        18
 
-6)  If you need to do range searches, you need a range tree. 
-    if you dont have time to get a range tree, or a kd tree 
-    use binary searching as the substitute!
+        Explanation:
+        There are four ways to split nums into two subarrays. 
+        The best way is to split it into [7,2,5] and [10,8], 
+        where the largest sum among the two subarrays is only 18.
+        
+        Are these problems like rotated DP? or binsearch on DP?
+        How are we avoiding doing DP?
 
+        def answer(nums, m):
 
-7) if the problem is unsorted, try sorting and if you need to keeping 
-    track of indexes, use reverse index map, to do computations. 
+            def viable(nums, allowedSum):
+                # there is always 1 section
+                sections = 1
+                curr = 0
 
-7.5) If the problem is already sorted, try binary search. 
+                for i in nums:
+                    # curr += i
+                    if curr + i  > allowedSum:
+                        sections += 1
+                        curr = i 
+                        if sections > m:
+                            return False
+                
 
-8) Do preprocessing work before you start solving problem to improve efficiency
+                return True
+            
+            # do binsearch 
+            i, j = max(nums), sum(nums)
+            while i < j:
+                mid = i  + (j-i)//2
 
-9) Use Counter in python to create a multiset. 
+                if viable(nums, mid):
+                    j = mid
+                else:
+                    i = mid + 1
 
-10) Use dynamic programming for optimal substructure, subsequence questions
-    -> Top down is easier to reason because you just memoize solutions youve seen before. 
-    -> Check for optimal substructure ( A given problems has Optimal Substructure Property 
-                                       if optimal solution of the given problem can be obtained 
-                                       by using optimal solutions of its subproblems.)
-    
-    -> Check of overlapping solutions. Make problems overlap by processing it in a certian way!!! Look at directionality!!! 
-        (DP cant help binary search because no overlapping)
+            return i
 
-    -> TO DO IT: Define Subproblems. Dynamic programming algorithms usually involve a recurrence involving
-            some quantity OPT(k₁, …, kₙ) over one or more variables (usually, these variables
-            represent the size of the problem along some dimension). Define what this quantity represents
-            and what the parameters mean. This might take the form “OPT(k) is the maximum
-            number of people that can be covered by the first k cell towers” or “OPT(u, v, i) is the
-            length of the shortest path from u to v of length at most i.”
-            • Write a Recurrence. Now that you've defined your subproblems, you will need to write
-            out a recurrence relation that defines OPT(k₁, …, kₙ) in terms of some number of subproblems.
-            Make sure that when you do this you include your base cases.
+        If you take a close look, you would probably see how similar 
+        this problem is with LC 1011 above. Similarly, we can design a 
+        feasible function: given an input threshold, then decide if we can 
+        split the array into several subarrays such that every subarray-sum 
+        is less than or equal to threshold. In this way, we discover the 
+        monotonicity of the problem: if feasible(m) is True, then all inputs 
+        larger than m can satisfy feasible function. You can see that the 
+        solution code is exactly the same as LC 1011.
+        Their soln:
+        
+        def splitArray(nums: List[int], m: int) -> int:        
+            def feasible(threshold) -> bool:
+                count = 1
+                total = 0
+                for num in nums:
+                    total += num
+                    if total > threshold:
+                        total = num
+                        count += 1
+                        if count > m:
+                            return False
+                return True
 
-    -> The other key property is that there
-            should be only a polynomial number of different subproblems. These two properties together allow
-            us to build the optimal solution to the final problem from optimal solutions to subproblems.
-            In the top-down view of dynamic programming, the first property above corresponds to being
-            able to write down a recursive procedure for the problem we want to solve. The second property
-            corresponds to making sure that this recursive procedure makes only a polynomial number of
-            different recursive calls. In particular, one can often notice this second property by examining
-            the arguments to the recursive procedure: e.g., if there are only two integer arguments that range
-            between 1 and n, then there can be at most n^2 different recursive calls.
-            Sometimes you need to do a little work on the problem to get the optimal-subproblem-solution
-            property. For instance, suppose we are trying to find paths between locations in a city, and some
-            intersections have no-left-turn rules (this is particulatly bad in San Francisco). Then, just because
-            the fastest way from A to B goes through intersection C, it doesn’t necessarily use the fastest way
-            to C because you might need to be coming into C in the correct direction. In fact, the right way
-            to model that problem as a graph is not to have one node per intersection, but rather to have one
-            node per <Intersection, direction> pair. That way you recover the property you need.
+            left, right = max(nums), sum(nums)
+            while left < right:
+                mid = left + (right - left) // 2
+                if feasible(mid):
+                    right = mid     
+                else:
+                    left = mid + 1
+            return left
+    
+    For split array largest sum here is the dp soln:
 
+        class Solution(object):
+            def splitArray(self, nums, m):
+                """
+                :type nums: List[int]
+                :type m: int
+                :rtype: int
+                """
+                if not nums or not m or len(nums) < m:
+                    return
+                
+                n = len(nums)
+                presum = [0] * (n + 1)
+                for i in range(n):
+                    presum[i + 1] = presum[i] + nums[i]
+                
+                f = [float("inf")] * (n + 1)
+                f[0] = 0
+                
+                for j in range(m):
+                    for i in range(n, 0, -1): # must be from n to 1, otherwise results will be wrong
+                        for k in range(j - 1, i):
+                            f[i] = min(f[i], max(f[k], presum[i] - presum[k]))
+                
+                return f[n]
 
-10.5) DP Construction:
-        DP problems typically show up at optimization or counting problems 
-        (or have an optimization/counting component). Look for words like 
-        "number of ways", "minimum", "maximum", "shortest", "longest", etc.
 
-        Start by writing your inputs. Identify which inputs are variable and which are constant.
 
-        Now write your output. You output will be whatever you are optimizing or 
-        counting. Because of this, the output might not match exactly what you
-        are solving for (if counting / optimizing is only a component of the problem).
+    3.   Koko Eating Bananas [Medium]
+        Koko loves to eat bananas. There are N piles of bananas, 
+        the i-th pile has piles[i] bananas. The guards have gone and 
+        will come back in H hours. Koko can decide her bananas-per-hour 
+        eating speed of K. Each hour, she chooses some pile of bananas, 
+        and eats K bananas from that pile. If the pile has less than K 
+        bananas, she eats all of them instead, and won't eat any more 
+        bananas during this hour.
 
-        Write a recurrence using your output as the function, your inputs
-        as inputs to the function, and recursive calls in the function body. 
-        The recursive calls will represent the "choices" that you can make, 
-        so that means you'll have one recursive call per "choice". (You are usually optimizing 
-        over choices are counting different types of choices). Think of ways to split up 
-        your input space into smaller components. The type of input will dictate how this 
-        might look. Array/string inputs usually peel one or two elements from the front 
-        or back of the array and recurse on the rest of the array. Binary tree inputs 
-        usually peel the root off and recurse on the two subtrees. Matrix inputs 
-        usually peel an element off and recurse in both directions (up or down and right or left).
+        Koko likes to eat slowly, but still wants to finish eating 
+        all the bananas before the guards come back. Return the minimum 
+        integer K such that she can eat all the bananas within H hours.
 
-        Come up with base case(s) for the recurrence. When you make the recursive calls, 
-        you decrease the problem size by a certain amount, x. You will probably need about x base cases.
+        Example :
 
-        Write your code. I recommend top-down for interviews since you 
-        don't have to worry about solving subproblems in the right order. 
-        Your cache will have one dimension per non-constant input.
+        Input: piles = [3,6,7,11], H = 8
+        Output: 4
+        Input: piles = [30,11,23,4,20], H = 5
+        Output: 30
+        Input: piles = [30,11,23,4,20], H = 6
+        Output: 23
 
-        After writing code, think about whether bottom-up is possible 
-        (can you come up with an ordering of subproblems where smaller 
-        subproblems are visited before larger subproblems?). If so, you 
-        can decide whether it is possible to reduce space complexity by 
-        discarding old answers to subproblems. If it's possible to reduce 
-        space, mention it in the interview (and explain). You probably won't 
-        have to code it. If you have time, feel free to code it bottom-up.
+        Very similar to LC 1011 and LC 410 mentioned above. 
+        Let's design a feasible function, given an input speed, 
+        determine whether Koko can finish all bananas within H hours 
+        with hourly eating speed speed. Obviously, the lower bound 
+        of the search space is 1, and upper bound is max(piles), 
+        because Koko can only choose one pile of bananas to eat every hour.
 
-10.7) Memorize 0-1 Knapsack and strategy
-      and space efficiency strategy:
-    
-    -> LEARN HOW TO USE A PARENTS {} MAP TO REVISIT THE OPTIMIZED DP STATES!
-        -> And return the optimized solution
-    -> Learn how to seperate concerns when creating DP GRIDS. 
-    -> LEARN how to space optimize with PREV/NEXT Rolling optimizer,
-        -> Learn how to also JUST have PREV without Next space optimization
-           by being smart about how you iterate over data
+        def minEatingSpeed(piles: List[int], H: int) -> int:
+            def feasible(speed) -> bool:
+                # return sum(math.ceil(pile / speed) for pile in piles) <= H  # slower        
+                return sum((pile - 1) // speed + 1 for pile in piles) <= H  # faster
 
-    # n is number of items. 
-    def knapSack(W, wt, val, n): 
-        K = [[0 for x in range(W + 1)] for x in range(n + 1)] 
-    
-        # Build table K[][] in bottom up manner 
-        for i in range(n + 1): 
-            for w in range(W + 1): 
-                if i == 0 or w == 0: 
-                    K[i][w] = 0
-                elif wt[i-1] <= w: 
-                    K[i][w] = max(val[i-1] + K[i-1][w-wt[i-1]],  K[i-1][w]) 
-                else: 
-                    K[i][w] = K[i-1][w] 
+            left, right = 1, max(piles)
+            while left < right:
+                mid = left  + (right - left) // 2
+                if feasible(mid):
+                    right = mid
+                else:
+                    left = mid + 1
+            return left
     
-        return K[n][W] 
+    4.    Minimum Number of Days to Make m Bouquets [Medium]
+          
+        Given an integer array bloomDay, an integer m and an integer k. 
+        We need to make m bouquets. To make a bouquet, you need to use 
+        k adjacent flowers from the garden. The garden consists of n flowers, 
+        the ith flower will bloom in the bloomDay[i] and then can be 
+        used in exactly one bouquet. Return the minimum number of 
+        days you need to wait to be able to make m bouquets from the garden. 
+        If it is impossible to make m bouquets return -1.
+        Examples:
+        Input: bloomDay = [1,10,3,10,2], m = 3, k = 1
+        Output: 3
+        Explanation: Let's see what happened in the first three days. 
+        x means flower bloomed and _ means flower didn't bloom in the garden.
+        We need 3 bouquets each should contain 1 flower.
+        After day 1: [x, _, _, _, _]   // we can only make one bouquet.
+        After day 2: [x, _, _, _, x]   // we can only make two bouquets.
+        After day 3: [x, _, x, _, x]   // we can make 3 bouquets. The answer is 3.
+        
+        Input: bloomDay = [1,10,3,10,2], m = 3, k = 2
+        Output: -1
+        Explanation: We need 3 bouquets each has 2 flowers, 
+        that means we need 6 flowers. We only have 5 flowers 
+        so it is impossible to get the needed bouquets and we return -1.
+        
+        You can either enumerate all k length intervals, and m of them. 
+        Which may be hard?
+        Or we create a viable function and feed in an argument that is binary searched. 
+        ...
+        Algo:
+        Check if its viable first, if theres enough flowers. 
+        Viable function -> specify max time to wait. 
+        Which is between min(Array) and max(Array) inclusive. 
+        Then create interval -> it cant accept values that are bigger, 
+        otherwise create new interval -> if you werent able to create atleast m, then 
+        not viable. 
+        Binary search to find first viable?
+        Now that we've solved three advanced problems above, 
+        this one should be pretty easy to do. The monotonicity 
+        of this problem is very clear: if we can make m bouquets 
+        after waiting for d days, then we can definitely finish 
+        that as well if we wait for more than d days.
 
-    # SPACE EFFICIENT
-    You can reduce the 2d array to a 1d array saving the values for the current iteration. 
-    For this to work, we have to iterate capacity (inner for-loop) in the 
-    opposite direction so we that we don't use the values that 
-    were updated in the same iteration 
+        def minDays(bloomDay: List[int], m: int, k: int) -> int:
+            def feasible(days) -> bool:
+                bonquets, flowers = 0, 0
+                for bloom in bloomDay:
+                    if bloom > days:
+                        flowers = 0
+                    else:
+                        bonquets += (flowers + 1) // k
+                        flowers = (flowers + 1) % k
+                return bonquets >= m
 
-    TO REMEMBER HOW TO DO BOTTOM PROBLEM, FOR DP REMEMBER THAT YOU ARE FILLING 
-    A 2D GRID. HOW SHOULD THE GRID BE FILLED WITH PENCIL AND PAPER? 
-    THATS HOW YOU FIGURE IT OUT 
-    (aka what are the entries in the map if you did topdown?)
-    
-    from collections import namedtuple
+            if len(bloomDay) < m * k:
+                return -1
+            left, right = 1, max(bloomDay)
+            while left < right:
+                mid = left + (right - left) // 2
+                if feasible(mid):
+                    right = mid
+                else:
+                    left = mid + 1
+            return left
+                    
 
-    def knapsack(capacity, items):
-        # A DP array for the best-value that could be achieved for each weight.
-        best_value = [0] * (capacity + 1)
-        # The previous item used to achieve the best-value for each weight.
-        previous_item = [None] * (capacity + 1)
-        for item in items:
-            for w in range(capacity, item.weight - 1, -1):
-                value = best_value[w - item.weight] + item.value
-                if value > best_value[w]:
-                    best_value[w] = value
-                    previous_item[w] = item
 
-        cur_weight = capacity
-        taken = []
-        while cur_weight > 0:
-            taken.append(previous_item[cur_weight])
-            cur_weight -= previous_item[cur_weight].weight
+    5.   Kth Smallest Number in Multiplication Table [Hard]
+        Nearly every one have used the Multiplication Table. 
+        But could you find out the k-th smallest number quickly 
+        from the multiplication table? Given the height m and the 
+        length n of a m * n Multiplication Table, and a positive 
+        integer k, you need to return the k-th smallest number in this table.
 
-        return best_value[capacity], taken
+        Example :
 
+        Input: m = 3, n = 3, k = 5
+        Output: 3
+        Explanation: 
+        The Multiplication Table:
+        1	2	3
+        2	4	6
+        3	6	9
 
-1)  Know how to write BFS with a deque, and DFS explicitely with a list. 
-    Keep tracking of function arguments in tuple for list. 
+        The 5-th smallest number is 3 (1, 2, 2, 3, 3).
 
-2)  If you need a priority queue, use heapq. Need it for djikistras. 
-    Djikstras is general BFS for graphs with different sized edges. 
 
-12.5) Know expand around center to find/count palindroms in a string:
-    class Solution(object):
-        def countSubstrings(self, s):
-            # Find all even and odd substrings. 
-            '''
-            THis is also known as the expand around center solution.        
-            '''
-            
-            i = 0
-            count = 0
-            for i in range(len(s)):            
-                left = i
-                right = i
-                
-                # Count odd palins
-                def extend(left, right, s):
-                    count = 0
-                    while True:
-                        if left < 0 or right >= len(s) or s[left] != s[right]:
-                            break   
-                        count += 1
-                        left = left - 1
-                        right = right + 1
-                    return count
-                
-                count += extend(left, right, s)
-                count += extend(left, right+1, s)
+            5th smallest. Can we do a quick select? 
+            so partition, then look for value in left or right partion 
+            -> worst case O(n^2) -> best case O(n)
             
-            return count
         
+        For Kth-Smallest problems like this, what comes to our mind 
+        first is Heap. Usually we can maintain a Min-Heap and just 
+        pop the top of the Heap for k times. However, that doesn't 
+        work out in this problem. We don't have every single number in 
+        the entire Multiplication Table, instead, we only have the height 
+        and the length of the table. If we are to apply Heap method, 
+        we need to explicitly calculate these m * n values and save 
+        them to a heap. The time complexity and space complexity of this 
+        process are both O(mn), which is quite inefficient. This is 
+        when binary search comes in. Remember we say that designing condition 
+        function is the most difficult part? In order to find the k-th smallest 
+        value in the table, we can design an enough function, given an input num, 
+        determine whether there're at least k values less than or 
+        equal to num. The minimal num satisfying enough function is the 
+        answer we're looking for. Recall that the key to binary search 
+        is discovering monotonicity. In this problem, if num satisfies 
+        enough, then of course any value larger than num can satisfy. 
+        This monotonicity is the fundament of our binary search algorithm.
 
-13) TOPO SORT -> if you dont know which node to start this from, start from any node.
-                    topo sort will still figure out the sorting. keep visited set. 
-                    
-                    result = deque()
-                    def topo_sort(node, visited):
+        Let's consider search space. Obviously the lower bound should be 1, 
+        and the upper bound should be the largest value in the Multiplication 
+        Table, which is m * n, then we have search space [1, m * n]. The 
+        overwhelming advantage of binary search solution to heap solution 
+        is that it doesn't need to explicitly calculate all numbers in that 
+        table, all it needs is just picking up one value out of the 
+        search space and apply enough function to this value, to determine 
+        should we keep the left half or the right half of the search 
+        space. In this way, binary search solution only requires constant 
+        space complexity, much better than heap solution.
 
-                        visited.add(node)
-                        children = g[node]
-                        
-                        for c in children:
-                            if(c in visited):
-                                continue
+        Next let's consider how to implement enough function. 
+        It can be observed that every row in the Multiplication Table 
+        is just multiples of its index. For example, all numbers in 
+        3rd row [3,6,9,12,15...] are multiples of 3. Therefore, 
+        we can just go row by row to count the total number of entries 
+        less than or equal to input num. Following is the complete solution.
+        (Could probably binary search it form each row? 
+        nah cause we still have to check
+        each row, so speed benefit is trumped by that.)
 
-                            topo_sort(c, visited)
-                        result.appendleft(node)
-                    
-                    for node in g.keys():
-                        if node not in visited:
-                            topo_sort(node, visited)
+        def findKthNumber(m: int, n: int, k: int) -> int:
+            def enough(num) -> bool:
+                count = 0
+                for val in range(1, m + 1):  # count row by row
+                    add = min(num // val, n)
+                    if add == 0:  # early exit
+                        break
+                    count += add
+                return count >= k                
 
+            left, right = 1, n * m
+            while left < right:
+                mid = left + (right - left) // 2
+                if enough(mid):
+                    right = mid
+                else:
+                    left = mid + 1
+            return left 
+                
+    6. Find K-th Smallest Pair Distance [Hard]
+       Given an integer array, return the k-th smallest distance 
+       among all the pairs. The distance of a pair (A, B) is 
+       defined as the absolute difference between A and B.
 
+       Example :
 
-14) Use stacks/queues to take advantage of push/pop structure in problems 
-    such as parentheses problems. Or valid expression problems.
+       Input:
+       nums = [1,3,1]
+       k = 1
+       Output: 0 
+       Explanation:
+       Following are all the pairs. The 1st smallest 
+        distance pair is (1,1), and its distance is 0.
+       (1,3) -> 2
+       (1,1) -> 0
+       (3,1) -> 2
 
-15) When you have a problem and it gives you a Binary search tree, 
-    make sure to exploit that structure and not treat it as a normal
-    binary tree!!!
+       Ok so sort it, [1,1,3]
+       -> now 1,1 1,3 1,3 -> 0, 2, 2
+       Number of pairs is 3 x 2  _ _ <- using space theory. 
+       Lets binary search the space. 
+       min -> difference between 1st and 2nd pair.
+           -> largest diff -> 1st and last pair
 
+        Enough function 
+        
+        -> Use 2 pointers and check when the difference 
+        is too much 
+        keep first ptr on left most, then increment right
+        when difference gets too big, then start reducing first ptr?
 
-16) Diviide and conquer
+        Very similar to LC 668 above, both are about finding Kth-Smallest. Just like LC 668, 
+        We can design an enough function, given an input distance, determine whether 
+        there're at least k pairs whose distances are less than or 
+        equal to distance. We can sort the input array and use two pointers 
+        (fast pointer and slow pointer, pointed at a pair) to scan it. 
+        Both pointers go from leftmost end. If the current pair pointed 
+        at has a distance less than or equal to distance, all pairs between 
+        these pointers are valid (since the array is already sorted), we move 
+        forward the fast pointer. Otherwise, we move forward the slow pointer. 
+        By the time both pointers reach the rightmost end, we finish our 
+        scan and see if total counts exceed k. Here is the implementation:
 
-17) Greedy algorithms => requires smart way of thinking about things
+        ENOUGH FUNCTION IS O(N) DO YOU KNOW WHY!
+        MEMORIZE IT!!! SLIDING WINDOW, 
+        It is O(N). the possible function is a classic sliding windowing solution, 
+        left and right would always increment in each outer loop iteration. 
+        So time complexity is O(2N) = O(N).
 
-18) Bit magic -> Entire section done in math notes.
+        [1,3,6,10,15, END]
+         ^         ^
+        Lets say dist is 11 so ptrs end up like above. 
+        Count is 4-0-1 = 3 pairs
+        
+        [1,3,6,10,15,END]
+           ^       ^
+        Lets say dist is 11 so ptrs end up like above. 
+        Count is 4-1-1 = 2 pairs          
+
+        [1,3,6,10,15,END]
+             ^       ^
+
+        Lets say dist is 11 so ptrs end up like above. 
+        Count is 5-2-1 = 2 pairs    
+
+        def enough(distance) -> bool:  # two pointers
+            count, i, j = 0, 0, 0
+            while i < n or j < n:
+                while j < n and nums[j] - nums[i] <= distance:  # move fast pointer
+                    j += 1
+                count += j - i - 1  # count pairs
+                i += 1  # move slow pointer
+            return count >= k
+        
+        Obviously, our search space should be [0, max(nums) - min(nums)]. 
+        Now we are ready to copy-paste our template:
 
-19) Dynamic programming with bitmasking
+        def smallestDistancePair(nums: List[int], k: int) -> int:
+            nums.sort()
+            n = len(nums)
+            left, right = 0, nums[-1] - nums[0]
+            while left < right:
+                mid = left + (right - left) // 2
+                if enough(mid):
+                    right = mid
+                else:
+                    left = mid + 1
+            return left
+                
+        ANOTHER IMPLEMENTATION:
 
-20) GRIDS THOUGHT PROCESS AND DP:
-    When you do DP bottom up think of GRIDS. How many dimensions are your grid?
-    How would you fill a grid if you were to do it by pencil? Which direction?
-    Think about top down case -> HOW DOES THE MAP FILL UP. OK HOW SHOULD the GRID FILL UP
-    Whats the base cases in the GRID? 
-    Whats the recurrence relation?
-    What locations need to be filled in GRID before other spots. 
+        class Solution(object):
+            def smallestDistancePair(self, nums, k):
+                def possible(guess):
+                    #Is there k or more pairs with distance <= guess?
+                    count = left = 0
+                    for right, x in enumerate(nums):
+                        while x - nums[left] > guess:
+                            left += 1
+                        count += right - left
+                    return count >= k
 
-21) 4. Merge Intervals
-        The Merge Intervals pattern is an efficient technique to deal with 
-        overlapping intervals. In a lot of problems involving intervals, you 
-        either need to find overlapping intervals or merge intervals if they overlap. 
-        The pattern works like this:
-        Given two intervals (‘a’ and ‘b’), there will be six different ways the 
-        two intervals can relate to each other:
-         => a consumes b, b consumes a, b after a, a after b, b after a no overlap, a after b no overlap
+                nums.sort()
+                lo = 0
+                hi = nums[-1] - nums[0]
+                while lo < hi:
+                    mi = (lo + hi) / 2
+                    if possible(mi):
+                        hi = mi
+                    else:
+                        lo = mi + 1
+                return lo
+        
+    7.    Ugly Number III [Medium]
+       Write a program to find the n-th ugly number. 
+       Ugly numbers are positive integers which are 
+       divisible by a or b or c.
 
-        How do you identify when to use the Merge Intervals pattern?
-            If you’re asked to produce a list with only mutually exclusive intervals
-            If you hear the term “overlapping intervals”.
-        Merge interval problem patterns:
-            Intervals Intersection (medium)
-            Maximum CPU Load (hard)
+       Example :
 
+       Input: n = 3, a = 2, b = 3, c = 5
+       Output: 4
+       Explanation: The ugly numbers are 2, 3, 4, 5, 6, 8, 9, 10... The 3rd is 4.
+       Input: n = 4, a = 2, b = 3, c = 4
+       Output: 6
+       Explanation: The ugly numbers are 2, 3, 4, 6, 8, 9, 10, 12... The 4th is 6.
 
-22) Cyclic Sort: 
-        This pattern describes an interesting 
-        approach to deal with problems involving arrays containing
-        numbers in a given range. The Cyclic Sort pattern iterates over the array 
-        one number at a time, and if the current number you are iterating is not 
-        at the correct index, you swap it with the number at its correct index. You could 
-        try placing the number in its correct index, but this will produce a complexity 
-        of O(n^2) which is not optimal, hence the Cyclic Sort pattern.
+        Nothing special. Still finding the Kth-Smallest. 
+        We need to design an enough function, given an input num, 
+        determine whether there are at least n ugly numbers less than or equal to num. Since a might be a multiple of b or c, or the other way round, 
+        we need the help of greatest common divisor to avoid counting duplicate numbers.
 
-        How do I identify this pattern?
-        They will be problems involving a sorted array with numbers in a given range
-        If the problem asks you to find the: 
-        -> missing/duplicate/smallest number in an sorted/rotated array
-           
-        We one by one consider all cycles. We first consider the cycle that 
-        includes first element. We find correct position of first element, 
-        place it at its correct position, say j. We consider old value of arr[j] 
-        and find its correct position, we keep doing this till all elements of current 
-        cycle are placed at correct position, i.e., we don’t come back to cycle starting point.
-    
-        Problems featuring cyclic sort pattern:
-        Find the Missing Number (easy)
-        Find the Smallest Missing Positive Number (medium)
+        def nthUglyNumber(n: int, a: int, b: int, c: int) -> int:
+            def enough(num) -> bool:
+                // Triple set addition!
+                total = mid//a + mid//b + mid//c - mid//ab - mid//ac - mid//bc + mid//abc
+                return total >= n
 
-22.5) CYCLIC SORT EXAMPLE:
+            ab = a * b // math.gcd(a, b) # LCM
+            ac = a * c // math.gcd(a, c) # LCM
+            bc = b * c // math.gcd(b, c) # LCM
+            abc = a * bc // math.gcd(a, bc)
+            left, right = 1, 10 ** 10
+            while left < right:
+                mid = left + (right - left) // 2
+                if enough(mid):
+                    right = mid
+                else:
+                    left = mid + 1
+            return left
 
-    class Solution(object):
-        def rotate(self, nums, k):
-            
-            start = 0
-            val = nums[start]
-            
-            i = start
-            N = len(nums)
-            swaps = 0
-            
-            while True:
-                pivot = i + k
-                pivot %= N
-                
-                temp = nums[pivot]
-                nums[pivot] = val
-                val = temp
-                i = pivot
-                
-                swaps += 1
-                if(swaps == N):
-                    return 
-                if pivot == start:
-                    i = start + 1             
-                    val = nums[start + 1]
-                    start += 1        
-            return nums
-            
-    Another Solution:
-    def solution(A, K):
-        N = len(A)
-        
-        if N == 0:
-            return []
-        
-        i = 0
-        nxtVal = A[0]
-        swaps = 0
-        lastLoc = 0
 
-        while True:
-            A[(i + K) % N], nxtVal = nxtVal, A[(i + K) % N]
-            i = (i + K) % N
-            
-            swaps += 1
-            if swaps == N:
-                break 
-            if i == lastLoc:
-                lastLoc += 1
-                i += 1
-                nxtVal = A[i]
-                # did we do all swaps?
-        return A
+    8.    Find the Smallest Divisor Given a Threshold [Medium]
+       Given an array of integers nums and an integer threshold, 
+       we will choose a positive integer divisor and divide all 
+       the array by it and sum the result of the division. Find 
+       the smallest divisor such that the result mentioned above 
+       is less than or equal to threshold.
 
+       Each result of division is rounded to the nearest integer 
+       greater than or equal to that element. (For example: 7/3 = 3 
+       and 10/2 = 5). It is guaranteed that there will be an answer.
 
+       Example :
 
+       Input: nums = [1,2,5,9], threshold = 6
+       Output: 5
+       Explanation: We can get a sum to 17 (1+2+5+9) if the divisor is 1. 
+       If the divisor is 4 we can get a sum to 7 (1+1+2+3) and 
+       if the divisor is 5 the sum will be 5 (1+1+1+2). 
 
-22.6) Know in-place reverse linked list (MEMORIZE)
-        # Function to reverse the linked list 
-            def reverse(self): 
-                prev = None
-                current = self.head 
-                while(current is not None): 
-                    next = current.next
-                    current.next = prev 
-                    prev = current 
-                    current = next
-                self.head = prev 
-        
-        Reverse a Sub-list (medium)
-        Reverse every K-element Sub-list (medium)
 
-22.7) Find the start of a loop in a linked list:
+       After so many problems introduced above, this one 
+       should be a piece of cake. We don't even need to bother 
+       to design a condition function, because the problem has 
+       already told us explicitly what condition we need to satisfy.
 
-       Consider the following linked list, where E is the cylce entry and X, the crossing point of fast and slow.
-        H: distance from head to cycle entry E
-        D: distance from E to X
-        L: cycle length
-                          _____
-                         /     \
-        head_____H______E       \
-                        \       /
-                         X_____/   
-        
-    
-        If fast and slow both start at head, when fast catches slow, slow has traveled H+D and fast 2(H+D). 
-        Assume fast has traveled n loops in the cycle, we have:
-        2H + 2D = H + D + L  -->  H + D = nL  --> H = nL - D
-        Thus if two pointers start from head and X, respectively, one first reaches E, the other also reaches E. 
-        In my solution, since fast starts at head.next, we need to move slow one step forward in the beginning of part 2
+       def smallestDivisor(nums: List[int], threshold: int) -> int:
+           def condition(divisor) -> bool:
+               return sum((num - 1) // divisor + 1 for num in nums) <= threshold
 
-        Algorithm
-        Use two references slow, fast, initialized to the head
-        Increment slow and fast until they meet
-        fast is incremented twice as fast as slow
-        If fast.next is None, we do not have a circular list
-        When slow and fast meet, move slow to the head
-        Increment slow and fast one node at a time until they meet
-        Where they meet is the start of the loop
+           left, right = 1, max(nums)
+           while left < right:
+               mid = left + (right - left) // 2
+               if condition(mid):
+                   right = mid
+               else:
+                   left = mid + 1
+           return left
 
-        class MyLinkedList(LinkedList):
+    Other examples:
+        c) Given an integer 1 <= n <= 10^5 and integer 'm'. The task is to tell the max step we can reach starting from 1, 
+        if at every step 'x', our 'm' reduces by pow(x, 2). And we can not move ahead if m becomes 0.
 
-            def find_loop_start(self):
-                if self.head is None or self.head.next is None:
-                    return None
-                slow = self.head
-                fast = self.head
-                while fast.next is not None:
-                    slow = slow.next
-                    fast = fast.next.next
-                    if fast is None:
-                        return None
-                    if slow == fast:
-                        break
-                slow = self.head
-                while slow != fast:
-                    slow = slow.next
-                    fast = fast.next
-                    if fast is None:
-                        return None
-                return slow
+        Example:
 
-22.8) Find kth to last element of linked list
+        Input: n = 10^5, m = 10
+        Output: 3
+        Explaination: m at every step: 
+        1 : 10 - 1 = 9 -> move ahead
+        2 : 9 - 4 = 5 -> move ahead
+        3 : 5 - 9 = -4 -> return;
+        Approach:
 
-        Algorithm
-        Setup two pointers, fast and slow
-        Give fast a headstart, incrementing it once if k = 1, twice if k = 2, ...
-        Increment both pointers until fast reaches the end
-        Return the value of slow
+        Gave a linear approach but the interviewer wasn't happy with the O(n) time complexity and asled me optimize it. 
+        With the help of a couple of hints, I came with a binary search solution which reduced the time complexity to O(log(n)). 
+        After which, I managed to further optimize it to a O(log(sqrt(m)) solution.
 
+        -> Can solve with sum of geometric series formula actually right??
 
+        2^n - 1 > m
+        2^n > m + 1
+        n > log(m+1)?
 
-1)  TREE DFS:
-    Decide whether to process the current node now (pre-order), 
-    or between processing two children (in-order) 
-    or after processing both children (post-order).
-    Make two recursive calls for both the children 
-    of the current node to process them.
-    -> You can also just use Tree DFS to process in bfs order
 
-23.5) 2 STACKS == QUEUE TECHNIQUE!
-      push onto one, if you pop and empty, 
-      dump first one into second one!
+    a) You are given a function f(x, y) you don't know what it does internally,
+    However, you know that it is a increasing function based on the values of x and y 
+    ie, f(0, 0) < f(0, 1) and f(1, 0) < f(2, 0) and so on..
 
-24) TWO HEAPS TECHNIQUE!!!
+        Now,
+        You are given an int z , You need to figure out minimum values for x and y such 
+        that value of z can be obtained, You may assume all x, y, z > 0
 
-        In many problems, we are given a set of elements such that we can divide them
-        into two parts. To solve the problem, we are interested in knowing 
-        the smallest element in one part and the biggest element in the other 
-        part. This pattern is an efficient approach to solve such problems.
+        My Answer is to use binary search on the range 0 - z for both x and y.
 
-        This pattern uses two heaps; A Min Heap to find the smallest element 
-        and a Max Heap to find the biggest element. The pattern works by 
-        storing the first half of numbers in a Max Heap, this is because 
-        you want to find the largest number in the first half. You then 
-        store the second half of numbers in a Min Heap, as you want to 
-        find the smallest number in the second half. At any time, the 
-        median of the current list of numbers can be calculated from 
-        the top element of the two heaps.
 
-        Ways to identify the Two Heaps pattern:
-        Useful in situations like Priority Queue, Scheduling
-        If the problem states that you need to find the 
-        -> smallest/largest/median elements of a set
-        Sometimes, useful in problems featuring a binary tree data structure
-        Problems featuring
-        -> Find the Median of a Number Stream (medium)
 
 
-25) BFS CREATION OF SUBSETS! (instead of dfs choose/dont choose strat. 
-    Can this strat also be used to do TOP DOWN DP with BFS ?)
 
-    A huge number of coding interview problems involve 
-    dealing with Permutations and Combinations of a 
-    given set of elements. The pattern Subsets describes 
-    an efficient Breadth First Search (BFS) approach to 
-    handle all these problems.
+###################################################################################
+###################################################################################
 
-    The pattern looks like this:
-    Given a set of [1, 5, 3]
-    Start with an empty set: [[]]
-    Add the first number (1) to all the existing subsets to create new subsets: [[], [1]];
-    Add the second number (5) to all the existing subsets: [[], [1], [5], [1,5]];
-    Add the third number (3) to all the existing subsets: [[], [1], [5], [1,5], [3], [1,3], [5,3], [1,5,3]].
+BINARY SEARCH DIFFERENT TEMPLATES AND THEIR USE CASES!!!!!!
 
-    Problems featuring Subsets pattern:
-    Subsets With Duplicates (easy)
-    String Permutations by changing case (medium)
+Tip
+Personally,
+If I want find the index, I always use while (left < right)
+If I may return the index during the search, I'll use while (left <= right)
 
-26) Modified Binary Search  
-        First, find the middle of start and end. 
-        An easy way to find the middle would be: 
-        middle = (start + end) / 2.
-        
-        But this has a good chance of producing an integer overflow 
-        so it’s recommended that you represent the middle as: 
-        middle = start + (end — start) / 2
 
-        Problems featuring the Modified Binary Search pattern:
-        Order-agnostic Binary Search (easy)
-        Search in a Sorted Infinite Array (medium)
+I like you tip, summary of 2 most frequently used binary search templates.
+one is return index during the search:
 
-27) Top K elements
-        -> CAN BE SOLVED IN O(N) WITH BUCKET SORT, AND QUICK SELECT. CHECK IT OUT
-        -> TOP K MOST FREQUENT ELEMENTS QUESTION TO SEE THIS. 
+while lo <= hi:
+  mid = (lo+hi)/2
+  if nums[mid] == target:
+    return mid
+  if nums[mid] > target:
+    hi = mid-1
+  else:
+    lo = mid+1
+return -1
 
-        Any problem that asks us to find the top/smallest/frequent ‘K’ 
-        elements among a given set falls under this pattern.
+Another more frequently used binary search template is for searching lowest 
+element satisfy function(i) == True (the array should satisfy function(x) == False 
+for 0 to i-1, and function(x) == True for i to n-1, and it is up to the question to 
+define the function, like in the find peak element problem, function(x) can be nums[x] < nums[x+1] ), 
+there are 2 ways to write it:
 
-        The best data structure to keep track of ‘K’ elements is Heap. 
-        This pattern will make use of the Heap to solve multiple 
-        problems dealing with ‘K’ elements at a time from 
-        a set of given elements. The pattern looks like this:
+while lo <= hi:
+  mid = (lo+hi)/2
+  if function(mid):
+    hi = mid-1
+  else:
+    lo = mid+1
+return lo
 
-        Insert ‘K’ elements into the min-heap or max-heap based on the problem.
+or
 
-        Iterate through the remaining numbers and if you find one that is 
-        larger than what you have in the heap, 
-        then remove that number and insert the larger one.
+while lo <  hi:
+  mid = (lo+hi)/2
+  if function(mid):
+    hi = mid
+  else:
+    lo = mid+1
+return lo
 
-        There is no need for a sorting algorithm because the heap will keep track of the elements for you.
-        How to identify the Top ‘K’ Elements pattern:
-        If you’re asked to find the top/smallest/frequent ‘K’ elements of a given set
-        If you’re asked to sort an array to find an exact element
-        Problems featuring Top ‘K’ Elements pattern:
-        Top ‘K’ Numbers (easy)
-        Top ‘K’ Frequent Numbers (medium)
+No matter which one you use, just be careful about updating the hi and lo, which 
+could easily lead to infinite loop. Some binary question is searching a floating 
+number and normally the question will give you a precision, in which case you 
+don't need to worry too much about the infinite loop but your while 
+condition will become something like "while lo+1e-7<hi"
 
-        # Top K Frequent Elements
 
-        class Solution(object):
-            def topKFrequent(self, nums, k):
-                """
-                :type nums: List[int]
-                :type k: int
-                :rtype: List[int]
-                """
+For people who are wondering about the section of the post,
 
-                num_of_items_to_return = k
-                m = collections.defaultdict(int)
-                
-                for i in nums:
-                    m[i] += 1
+"If I want find the index, I always use while (left < right)
+If I may return the index during the search, I'll use while (left <= right)"
 
-                pq = [] # heapq
-                counter = itertools.count()
-                
-                # entry_finder = {} Used for deleting other elements in heapq!
-                
-                for k, v in m.items():
-                
-                    if len(pq) < num_of_items_to_return:
-                        count = next(counter)
-                        i = [v, count, k] #[priority, count, task]
-                        heappush(pq, i)
-                    else:
-                        top =  pq[0][0] # get priority
-                        print("TOP IS", top)
+Let's use the array a = [1,2,3] as an example, where we're searching for key = 3
 
-                        if v > top:
-                            _ = heappop(pq)
-                            
-                            
-                            count = next(counter)
-                            i = [v, count, k] #[priority, count, task]
-                            
-                            heappush(pq, i)
-                            
-                return map(lambda x: x[-1], pq)
+If we know the index definitely exists, then we use while l < r
 
+We first search 2, notice that 2 < key. So we set l = res = mid+1. 
+We break the loop since l == r and return res. Because res is the 
+only possible answer left, and since we know the index exists, we just return that.
 
-28) K way Merge:
+Now if we don't know if the index exists, then we set l = mid+1 and 
+only set res if a[mid] == key. We still have to check the final 
+possibility, because we don't know whether or not that index contains the key.
 
-K-way Merge helps you solve problems that involve a set of sorted arrays.
 
-        Whenever you’re given ‘K’ sorted arrays, you can use a
-        Heap to efficiently perform a sorted traversal of all 
-        the elements of all arrays. You can push the smallest 
-        element of each array in a Min Heap to get the overall minimum. 
-        After getting the overall minimum, push the next element 
-        from the same array to the heap. Then, repeat this process 
-        to make a sorted traversal of all elements.
+###################################################################################
+##################################################################################
 
-        The pattern looks like this:
-        Insert the first element of each array in a Min Heap.
-        After this, take out the smallest (top) element from the heap and add it to the merged list.
-        After removing the smallest element from the heap, insert the next element of the same list into the heap.
-        Repeat steps 2 and 3 to populate the merged list in sorted order.
-        How to identify the K-way Merge pattern:
-        The problem will feature sorted arrays, lists, or a matrix
-        If the problem asks you to merge sorted lists, find the smallest element in a sorted list.
-        Problems featuring the K-way Merge pattern:
-        Merge K Sorted Lists (medium)
-        K Pairs with Largest Sums (Hard)
+Binary Search Ultimate Handbook:
 
-29) Questions you can solve with XOR can also probably be done with other operators such as +, -, *, /. Make
-    sure you check for integer overflow. thats why xor method is always better.
 
-29.5)  You are given an array A of n - 2 integers 
-    which are in the range between 1 and n. All numbers 
-    appear exactly once, except two numbers, which are 
-    missing. Find these two missing numbers.
+    What is binary search?
+    Normally, to find the target in a group, such as an array of numbers, the worst case scenario is we need to go 
+    through every single element (O(n)). However, when these elements are sorted, we are able to take the privilege 
+    of this extra information to bring down the search time to O(log n), that is if we have 100 elements, 
+    the worst case scenario would be 10 searches. That is a huge performance improvement.
 
-    Ok so go through range of numbers between 1 and n.
-    XOR all those numbers,
-    ex:
+    The Gif below demonstrates the power of binary search.
 
-    def soln(ans):
-        val = 0
-        for i in range(0, N):
-            val ^= (i+1)
+    https://assets.leetcode.com/static_assets/posts/1EYkSkQaoduFBhpCVx7nyEA.gif
 
-        # then xor with ever number in ans. 
-        for i in A:
-            val ^= i
+    The reason behind this huge performance increase is because for each search iterations, 
+    we are able to cut the elements we will be looking at in half. Fewer elements to look at = faster search time. 
+    And this all comes from the simple fact that in a sorted list, everything to the right of n will be greater or equal to it, and vice versa.
 
-        # ok now val is   a ^ b where both a and b are different 
-        # how to extract a, and b?
-        '''
+    Before we look at the abstract ideas of binary search, let's see the code first:
 
-        you could run  a ^ b and try to xor it with 
-        a number between 1 and n -> the result would be the other number, 
-        b. 
+        var search = function(nums, target) {
+            let lo = 0, hi = nums.length-1;
+            while (lo < hi) {
+                let mid = lo + Math.floor((hi-lo+1)/2);
+                if (target < nums[mid]) {
+                    hi = mid - 1
+                } else {
+                    lo = mid; 
+                }
+            }
+            return nums[lo]==target?lo:-1;
+        };
 
-        then check if the other number is between 1 and N and if it is,
-        keep it. -> could you also check if the a and b you found is 
-        also the same as the sum of the 2 missing numbers, which you can 
-        get by subtracting N(n+1)/2 - sum(A). 
-        so if it passes both tests then its more likely to be that rite!!
-        but could 2 seperate 'a, 'b pairs still pass both sum and xor test?
-        
-        ABOVE SOLUTION IS HACKY!!
-        '''
+    The fundamental idea
 
-        BETTER SOLUTION: 
-        # ok now val is   a ^ b where both a and b are different 
-        # how to extract a, and b?
-        '''
-        well if the value is 10001. 
+    1. lo & hi
+    We define two variables, let's call them lo and hi . They will store array indexes and they work 
+    like a boundary such that we will only be looking at elements inside the boundary.
+    Normally, we would want initialize the boundary to be the entire array.
 
-        The 0 means they were both either 0 bit, or both 1 bit.
-        if its 1, then either the a has a 1 bit and b has 0 bit or 
-        vice versa. 
+    let lo = 0, hi = nums.length-1;
 
-        Partitioning based on inspecting u ^ v
-        Luckily, we can figure out what to do by using what we 
-        already stated earlier. Let’s think about this:
+    2. mid
+    The mid variable indicates the middle element within the boundary. It separates our boundary into 2 parts. 
+    Remember how I said binary search works by keep cutting the elements in half, the mid element works like a 
+    traffic police, it indicates us which side do we want to cut our boundary to.
 
-        If the two bits XOR takes as input are the same, the result is 0, otherwise it is 1.
+    Note when an array has even number of elements, it's your decision to use either the left mid (lower mid) or the right mid (upper mid)
 
-        If we analyze the individual bits in u ^ v, then every 0 means that the 
-        bit had the same value in both u and v. Every 1 means that the bits differed.
+    let mid = lo + Math.floor((hi - lo) / 2); // left/lower mid
 
-        Using this, we find the first 1 in u ^ v, i.e. the first position i where u and v 
-        have to differ. Then we partition A as well as the numbers from 1 to n according to that bit.
-        We end up with two partitions, each of which contains two sets:
+    let mid = lo + Math.floor((hi - lo + 1) / 2); // right/upper mid
+
+    3. Comparing the target to mid
+    By comparing our target to mid, we can identify which side of the boundary does the target belong. 
+    For example, If our target is greater than mid, this means it must exist in the right of mid . In this case, 
+    there is no reason to even keep a record of all the numbers to its left. And this is the fundamental 
+    mechanics of binary search - keep shrinking the boundary.
+
+    if (target < nums[mid]) {
+        hi = mid - 1
+    } else {
+        lo = mid; 
+    }
+
+
+    4. Keep the loop going
+    Lastly, we use a while loop to keep the search going:
+
+    while (lo < hi) { ... }
+    The while loop only exits when lo == hi, which means there's only one element left. And if we implemented 
+    everything correctly, that only element should be our answer(assume if the target is in the array).
+
+    The pattern
+    It may seem like binary search is such a simple idea, but when you look closely in the code, we are 
+    making some serious decisions that can completely change the behavior of our code.
+    These decisions include:
+
+    Do I use left or right mid?
+    Do I use < or <= , > or >=?
+    How much do I shrink the boundary? is it mid or mid - 1 or even mid + 1 ?
+    ...
+    And just by messing up one of these decisions, either because you don't 
+    understand it completely or by mistake, it's going to break your code.
+    To solve these decision problems, I use the following set of rules to always keep me away from trouble, 
+    most importantly, it makes my code more consistent and predictable in all edge cases.
 
-        Partition 0
-        The set of all values from 1 to n where the i-th bit is 0
-        The set of all values from A where the i-th bit is 0
-        Partition 1
-        The set of all values from 1 to n where the i-th bit is 1
-        The set of all values from A where the i-th bit is 1
-        Since u and v differ in position i, we know that they have to be in different partitions.
+    1. Choice of lo and hi, aka the boundary
+    Normally, we set the initial boundary to the number of elements in the array
 
-        Reducing the problem
-        Next, we can use another insight described earlier:
+    let lo = 0, hi = nums.length - 1;
+    But this is not always the case.
+    We need to remember: the boundary is the range of elements we will be searching from.
+    The initial boundary should include ALL the elements, meaning all the possible answers should be included. 
+    Binary search can be applied to none array problems, such as Math, and this statement is still valid.
 
-        While we worked on integers from 1 to n so far, this is not required. In fact, the 
-        previous algorithm works in any situation where there is (1) some set of potential 
-        elements and (2) a set of elements actually appearing. The sets may only differ 
-        in the one missing (or duplicated) element.
+    For example, In LeetCode 35, the question asks us to find an index to insert into the array.
+    It is possible that we insert after the last element of the array, thus the complete range of boundary becomes
 
-        These two sets correspond exactly to the sets we have in each partition. 
-        We can thus search for u by applying this idea to one of the partitions 
-        and finding the missing element, and then find v by applying it to the other partition.
+    let lo = 0, hi = nums.length;
 
-        This is actually a pretty nice way of solving it: We effectively 
-        reduce this new problem to the more general version of the problem we solved earlier.
 
+    2. Calculate mid
+    Calculating mid can result in overflow when the numbers are extremely big. I ll demonstrate a few ways of calculating mid from the worst to the best.
 
+    let mid = Math.floor((lo + hi) / 2) // worst, very easy to overflow
 
+    let mid = lo + Math.floor((hi - lo) / 2) // much better, but still possible
 
-1)  Use loop invarients when doing 2 pointer solutions, greedy solutions, etc. to think about, and help
-    interviewer realize that your solution works!!!
+    let mid = (lo + hi) >>> 1 // the best, but hard to understand
+    When we are dealing with even elements, it is our choice to pick the left mid or the right mid , 
+    and as I ll be explaining in a later section, a bad choice will lead to an infinity loop.
 
-2)  Derieive mathematical relationships between numbers in array, and solve for a solution. Since
-    there was a mathematical relationship, xor can prolly be used for speedup. 
-    For instance: Find the element that appears once
+    let mid = lo + Math.floor((hi - lo) / 2) // left/lower mid
 
-        Given an array where every element occurs three times, except one element which occurs only once. 
+    let mid = lo + Math.floor((hi - lo + 1) / 2) // right/upper mid
+    
+    
+    3. How do we shrink boundary
+    I always try to keep the logic as simple as possible, that is a single pair of if...else. 
+    But what kind of logic are we using here? My rule of thumb is always use a logic that you can exclude mid.
+    Let's see an example:
+
+    if (target < nums[mid]) {
+        hi = mid - 1
+    } else {
+        lo = mid; 
+    }
 
-        Soln: Add each number once and multiply the sum by 3, we will get thrice the sum of each 
-        element of the array. Store it as thrice_sum. Subtract the sum of the whole array 
-        from the thrice_sum and divide the result by 2. The number we get is the required 
-        number (which appears once in the array).
-        How do we add each number once though? we cant use a set. 
-        XOr? wtf?
+    Here, if the target is less than mid, there's no way mid will be our answer, and we can 
+    exclude it very confidently using hi = mid - 1. Otherwise, mid still has the 
+    potential to be the target, thus we include it in the boundary lo = mid.
+    On the other hand, we can rewrite the logic as:
 
-3)  DP is like traversing a DAG. it can have a parents array, dist, and visited set. SOmetimes you need to backtrack
-    to retrieve parents so remember how to do that!!!!. 
+    if (target > nums[mid]) {
+        lo = mid + 1; // mid is excluded
+    } else {
+        hi = mid; // mid is included
+    }
+    
+    
+    4. while loop
+    To keep the logic simple, I always use
 
-4)  Do bidirectional BFS search if you know S and T and you are finding the path! 
-    (i think its good for early termination in case there is no path)
+    while(lo < hi) { ... }
+    Why? Because this way, the only condition the loop exits is lo == hi. I 
+    know they will be pointing to the same element, and I know that element always exists.
 
-5)  For linked list questions, draw it out. Dont think about it. Then figur eout how you are rearranging the ptrs.
-    and how many new variables you need. ALSO USE DUMMY POINTERS to not deal with modifying head pointer case. 
+    5. Avoid infinity loop
+    Remember I said a bad choice of left or right mid will lead to an infinity loop? Let's tackle this down.
+    Example:
 
+    let mid = lo + ((hi - lo) / 2); // Bad! We should use right/upper mid!
 
-6)  Linear Algorithms:
-    Bracket Matching => Use stack
-    Postfix Calculator and Conversion
-        Prefix calculator => 2 + 6 * 3 => this needs binary tree to do i think! with extra mem
-        Prefix: + 2 * 6 3, * + 2 6 3
-        Postfix: 2 6 3 * +, 2 6 + 3 *
-        We can evaluate postfix in O(n). Push elements in stack. when you see operator, 
-        pop 2 elements right, do compute, put back into stack.
+    if (target < nums[mid]) {
+        hi = mid - 1
+    } else {
+        lo = mid; 
+    }
 
-    (Static) selection problem
-        Given unchanged array of n elements. can we find kth smallest element of A in O(n). yeah prlly
-        A = {2, 8, 7, 1, 5, 4, 6, 3} 
-        4th smallest is 4. 
-        4 solutions: 
-        sort and get k-1 element O(nlogn)
-        Do heap-select USING MIN HEAP. create min heap of given n element and call extractMin() k times.
-            O(n + kLogn) => because heapify is O(n)
-        Method 3 (Using Max-Heap)
-            We can also use Max Heap for finding the k’th smallest element. Following is algorithm.
-            1) Build a Max-Heap MH of the first k elements (arr[0] to arr[k-1]) of the given array. O(k)
+    Now, imagine when there are only 2 elements left in the boundary. If the logic fell into the 
+    else statement, since we are using the left/lower mid, it's simply not doing anything. It just keeps shrinking itself to itself, and the program got stuck.
+    We have to keep in mind that, the choice of mid and our shrinking logic has to work together 
+    in a way that every time, at least 1 element is excluded.
 
-            2) For each element, after the k’th element (arr[k] to arr[n-1]), compare it with root of MH.
-            ……a) If the element is less than the root then make it root and call heapify for MH
-            ……b) Else ignore it.
-            // The step 2 is O((n-k)*logk)
+    let mid = lo + ((hi - lo + 1) / 2); // Bad! We should use left/lower mid!
 
-            1) Finally, root of the MH is the kth smallest element.
+    if (target > nums[mid]) {
+        lo = mid + 1; // mid is excluded
+    } else {
+        hi = mid; // mid is included
+    }
+    
+    So when your binary search is stuck, think of the situation when there are only 2 elements left. Did the boundary shrink correctly?
 
-            Time complexity of this solution is O(k + (n-k)*Logk)
+    TD;DR
+    My rule of thumb when it comes to binary search:
 
-        METHOD 4(BEST METHOD QUICK SELECT): -> DO MEDIAN OF MEDIANS TO GET O(N) NOT WORST AVERAGE CASE? worst time!!!
-           The idea is, not to do complete quicksort, but stop at the point where pivot itself is k’th         
-            smallest element. Also, not to recur for both left and right sides of pivot, 
-            but recur for one of them according to the position of pivot. The worst case time          
-            complexity of this method is O(n^2), but it works in O(n) on average.
+    Include ALL possible answers when initialize lo & hi
+    Don't overflow the mid calculation
+    Shrink boundary using a logic that will exclude mid
+    Avoid infinity loop by picking the correct mid and shrinking logic
+    Always think of the case when there are 2 elements left
+    Because this problem is a failrly easy, the implementions may be pretty straight forward and you may 
+    wonder why do I need so many rules. However, binary search problems can get much much more complex, and without 
+    consistent rules, it's very hard to write predictable code. In the end, I would say 
+    everybody has their own style of binary serach, find the style that works for you!
 
-    Sorting in linear time
-        Given array, each int between [0, 100] can we sort in O(n). yeah counting sort.
-        What if given arry has range of 32 bit unsigned ints [0, 2^32 -1] => radix sort
 
-    Sliding window
-        -> Given an array of n elements, can we find a smallest sub-array size so that the sum of the sub-array is greater 
-        than or equal to a constant S in O(n)
-        
-        2 pointers both start at index 0. move end pointer 
-        to right until you have S. then keep that as current_min_running_length_of_subarray.
-        move start pointer to right to remove elements, then fix by extending end pointer if sum falls below S. 
-        get new subarrays and update current_min_running_length_of_subarray. 
+#######################################
+COOL NOTES PART 0.85: DYNAMIC PROGRAMMING PATTERNS, ILLUSTRATIONS, AND EXAMPLES: 
 
+https://leetcode.com/discuss/study-guide/1200320/Thief-with-a-knapsack-a-series-of-crimes
 
 
+    One of the classical problems of dynamic programming is the 0/1 knapsack problem. The thief has a knapsack of given 
+    capacity, and he wishes to maximize the profit with the available valuables. What should he do?
 
-7)  Heapify is cool. Python heapify implementation that is O(N) implemented below: 
-    UNDERSTAND IT.
-        # Single slash is simple division in python. 2 slashes is floor division in python
-        # only the root of the heap actually has depth log2(len(a)). Down at the nodes one above a leaf - 
-        # where half the nodes live - a leaf is hit on the first inner-loop iteration.
+    Though it would be weird if he starts implementing DP at the crime scene. But anyways.
+    Keep track of the maximum profit he can achieve up to a certain weight, and decide whether to pick the next object or not. Here is a simple code for the same.
 
-        def heapify(A):
-            for root in xrange(len(A)//2-1, -1, -1):
-                rootVal = A[root]
-                child = 2*root + 1
-                while child < len(A):
-                    # we pick the smaller child to sort?
-                    # makes sense because the smaller child is the one
-                    # that has to fight with the parent in a min heap.
-                    if child+1 < len(A) and A[child] > A[child+1]:
-                        child += 1
-                    if rootVal <= A[child]:
-                        break
-                    A[child], A[(child-1)//2] = A[(child-1)//2], A[child]
-                    child = child *2 + 1
+    Capacity of Knapsack: W (given)
+    Objective: Maximize profit.
 
-8)  Understand counting sort, radix sort.
-        Counting sort is a linear time sorting algorithm that sort in O(n+k) 
-        time when elements are in range from 1 to k.        
-        What if the elements are in range from 1 to n2? 
-        We can’t use counting sort because counting sort will take O(n2) which is worse 
-        than comparison based sorting algorithms. Can we sort such an array in linear time?
-        Radix Sort is the answer. The idea of Radix Sort is to do digit by digit 
-        sort starting from least significant digit to most significant digit. 
-        Radix sort uses counting sort as a subroutine to sort.
-        Look at section below for impls.
+        int dp[W + 1] = {0};
+        for (int i=0; i<n; ++i)
+            for (int j=W; j>=weight[i]; --j)
+                dp[j] = max(dp[j], value[i]+ dp[j - weight[i]]);
+        return dp[W];
 
+        dp[j] if he will not pick the ith object, otherwise value[i]+ dp[j - weight[i]]
 
-9)  To do post order traversal or inorder traversal 
-    on a binary tree iteratively (or doing any dfs, where you want to vist root node last). 
-    you need to USE A FLAG!! (LOOK at morris traversal for cool funs!)
 
-        def postorderTraversal(self, root):
-            traversal, stack = [], [(root, False)]
-            while stack:
-                node, visited = stack.pop()
-                if node:
-                    if visited:
-                        # add to result if visited
-                        traversal.append(node.val)
-                    else:
-                        # post-order
-                        stack.append((node, True))
-                        stack.append((node.right, False))
-                        stack.append((node.left, False))
 
-            return traversal
+    UPD: Why the inner loop is decremental in the above code?
+    Consider this scenario; your knapsack has a capacity of 10kg, the current item i weighs 4kg. You are in the inner loop, and you start updating your dp states. You will update dp[4] as you can put this item over the 0kg item (i.e., empty), next you update dp[5], and so on. Now you reached dp[8], you will look behind and say that we can update this using dp[4], as the weight constraint allows you to. But here's the catch, you had already put the 4kg item on the state dp[4], so in essence, you are double-counting the item. This can be easily solved using a reverse loop as you'll update dp[8] with dp[4], which hadn't considered the 4kg item. A similar concept you'll encounter in the subset sum problems, but in problems like coin change which has an infinite supply of each item, an incremental for-loop is used.
 
-        def inorderTraversal(self, root):
-            result, stack = [], [(root, False)]
 
-            while stack:
-                cur, visited = stack.pop()
-                if cur:
-                    if visited:
-                        result.append(cur.val)
-                    else:
-                        stack.append((cur.right, False))
-                        stack.append((cur, True))
-                        stack.append((cur.left, False))
 
-            return result
-        
-        def preorderTraversal(self, root):
-            ret = []
-            stack = [root]
-            while stack:
-                node = stack.pop()
-                if node:
-                    ret.append(node.val)
-                    stack.append(node.right)
-                    stack.append(node.left)
-            return ret
+    Now, let's see how our thief with his knapsack will commit a series of crimes at LeetCode.
+    LC416. Partition equal subset sum
 
+    Can an array of positive integers be partitioned into two subsets, such that their sums are equal?
+    Can our thief pick a subset such that the sum of the subset is half the sum of the whole array?
 
-10) When you need to keep a set of running values such as mins, and prev mins, 
-    you can keep all the runnign mins in a datastructre and as your algorithm traverses the datastructure, 
-    update the datastructure for the running value as well in the same way to maintaing consistency!
-    For instance, min stack: 
-    Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.
+    Capacity of Knapsack: Half the sum of the given array.
+    Objective: Achieve a total sum exact as the capacity.
 
-    push(x) -- Push element x onto stack.
-    pop() -- Removes the element on top of the stack.
-    top() -- Get the top element.
-    getMin() -- Retrieve the minimum element in the stack.
+        vector<bool> dp(sum+1, false);
+        dp[0] = true; 
+        for (auto num : nums)
+            for (int i=sum; i>0; --i)
+                if (i >= num) dp[i] = dp[i-num] or dp[i];
+        return dp[sum];
+        dp[i] if the number is not included in the subset, else dp[i-num].
+        Handle one edge case :)
 
-    have 2 stacks, one for the actual stack, and another that simulates the same operations to 
-    maintain the running min.
+    In LC416 the 'sum' in the code is actually sum/2 ..right? -> Yes
 
 
-11) In some questions you can 
-    do DFS or BFS from a root node to a specific 
-    child node and you end up traversing a tree, 
-    either the DFS tree or BFS Tree. 
-    HOWEVER, AS AN O(1) space optimization, you might be able 
-    to go backward from the child node to the root node,
-    and only end up traversing a path rather than a tree!
-    Go up the tree for SPEED. 
+    LC474. Ones and Zeroes
 
+    Given an array of binary strings strs and two integers m and n. Return the size of the largest subset 
+    of strs such that there are at most m 0's and n 1's in the subset.
+    Can our thief pick up at most m 0's and n 1's?
 
-40.1) Can create queue with 2 stacks
+    Capacity of Knapsack: Limitless
+    Objective: Pick up at most m 0's and 1 n's
 
+        vector<vector<int>> dp(M+1, vector<int>(N+1, 0));
+        for (auto s : strs) {
+            int zero = zeros(s); // a function to count zeroes in a string
+            int one = ones(s); // a function to count ones in a string
+            for (int i=M; i>=zero; --i)
+                for (int j=N; j>=one; --j)
+                    dp[i][j] = max(dp[i][j], 1 + dp[i-zero][j-one]); 
+        }
+        return dp[M][N];
+        dp[i][j] if the string is not chosen, else dp[i-zero][j-one]
 
-40.2) Heap
-    -> Given a node k, easy to compute indices for
-        parent and children
-        - Parent Node: floor(k/2)
-        - Children: 2k, 2k+1
-    You must refer to the definition of a Binary Heap:
 
-        A Binary heap is by definition a complete binary tree ,that is, all levels of the       
-        tree, 
-        except possibly the last one (deepest) are fully filled, and, if the last     
-        level of the tree is not complete, the nodes of that level are filled from left to        
-        right.
+    LC343. Integer Break
+
+        Capacity of Knapsack: n
+        Objective: Maximize the product of chosen smaller integers
+
+        vector<int> dp(n+1, 0);
+        dp[0] = 1;
+        for (int i=1; i<n; ++i)
+            for (int j=i; j<=n; ++j)
+                dp[j] = max(dp[j], dp[j-i]*i);
+        return dp[n];
         
-        It is by definition that it is never unbalanced. The maximum difference in balance      
-        of the two subtrees is 1, when the last level is partially filled with nodes only       
-        in the left subtree.
+        dp[j] if the number is not included in the product. dp[j-i]*i if the number is included, 
+        multiply with the previous suitable state.
+
+    Unbound knapsack
+    In this class of problems, every available item type is present in infinite 
+    quantity. Iterate over the choices, and put it any number of combinations you wish.
+
+    LC518. Coin Change 2
+    Given an array of coins and an integer representing a total amount. Return the 
+    number of combinations that make up that amount. If impossible, return 0. Each coin is in present infinite quantity.
+    The order will not matter in this problem. e.g.
+
+    To achieve a sum of 5 using [1,2,5]
+    5 = 5
+    5 = 2+2+1 // other permutations like (2,1,2) are not included
+    5 = 2+1+1+1
+    5 = 1+1+1+1+1
+    result is 4 ways
+    Can our thief pick a total sum equal to the target?
+
+    Capacity of Knapsack: target
+    Objective: Count the number of ways to achieve the target
+
+    vector<int> dp(amount+1, 0);
+    dp[0] = 1;
+    for (auto coin : coins)
+        for (int i=1; i<=amount; i++)
+            if (coin <= i) dp[i] += dp[i-coin];
+    return dp[amount];
+
+    Since every coin can be put in any combination, iterate over coins, and fill every achievable target. 
+    This will prevent the recounting of the permutations. Why? Because the definition of our state dp[i] is 
+    the number of ways to achieve a sum i using all coins. If we'll first iterate over the sum and next on the coins, 
+    we'll include all three permutations viz. (1,2,2), (2,1,2), and (2,2,1) in the solution. 
+    Because we are adding dp[i-coin] every time we find a suitable candidate. Alternatively, you 
+    can use a 2D dp, where the state dp[i][j], will be the number of ways to get sum j using first i coins. 
+    This approach will be independent of the priority of the for-loops.
+
+    LC377. Combination Sum IV
+    Given an array of distinct integers and a target, return the number of possible combinations that add up to the target.
+
+    In this problem, the order matters, unlike Coin Change 2. So, iterate over the target, 
+    then the coins (in this case numbers). Else use a 2D dp.
+
+    vector<unsigned int> dp(target+1, 0);
+    dp[0] = 1;
+    for (int i=1; i<= target; ++i)
+        for (auto n : nums)
+            if (i >= n) dp[i] += dp[i - n];
+    return dp[target];
+    For every problem, pick one example and dry run the code to fill the states.
+
+    In question LC377. Combination Sum IV solution's those who are confused why we are iterating over the
+    target then nums=> because before moving to next target previous state of targets should be complete
+    and in the case of Coin change 2 all previous coin state should be complete to get the desired dp result
 
-    -> To insert node: (running time O(lgn)) (SIFT UP)
-    1) make a new node at last level as far left as possible. 
-    2) if node breaks heap property, swap with its parent node. 
-    3) new node moves up tree. repeat 1) to 3) until all conflicts resolved.
+###################################################################################
+###################################################################################
+COOL NOTES PART 0.90: DYNAMIC PROGRAMMING PATTERNS, ILLUSTRATIONS, AND EXAMPLES: 
 
-    -> Deleting root node: (SIFT DOWN)
-    1) Remove the root, and bring the last node (rightmost node 
-    in the last leve) to the root. 
-    2) If the root breaks the heap property, look at its children
-    and swap it with the larger one. 
-    3) Repeat 2 until all conflicts resolved
+    Patterns
+    Minimum (Maximum) Path to Reach a Target
+    Distinct Ways
+    Merging Intervals
+    DP on Strings
+    Decision Making
+
+    Minimum (Maximum) Path to Reach a Target
+    Statement
+    Given a target find minimum (maximum) cost / path / sum to reach the target.
 
+    Approach
+    Choose minimum (maximum) path among all possible paths 
+    before the current state, then add value for the current state.
 
-41) FORD FULKERSON ALGORITHM PYTHON (MAX FLOW MIN CUT):
-    class Graph: 
-    
-        def __init__(self,graph): 
-            self.graph = graph # residual graph 
-            self. ROW = len(graph)             
+    routes[i] = min(routes[i-1], routes[i-2], ... , routes[i-k]) + cost[i]
+    Generate optimal solutions for all values in the target and return the value for the target.
+
+    for (int i = 1; i <= target; ++i) {
+        for (int j = 0; j < ways.size(); ++j) {
+            if (ways[j] <= i) {
+                dp[i] = min(dp[i], dp[i - ways[j]] + cost / path / sum) ;
+            }
+        }
+    }
+    return dp[target]
+
+    Similar Problems
+
+    1.   Min Cost Climbing Stairs Easy
+    for (int i = 2; i <= n; ++i) {
+        dp[i] = min(dp[i-1], dp[i-2]) + (i == n ? 0 : cost[i]);
+    }
+    return dp[n]
     
-        '''Returns true if there is a path from source 's' to sink 't' in 
-        residual graph. Also fills parent[] to store the path '''
-        def BFS(self,s, t, parent): 
+    1.  Minimum Path Sum Medium
+    for (int i = 1; i < n; ++i) {
+        for (int j = 1; j < m; ++j) {
+            grid[i][j] = min(grid[i-1][j], grid[i][j-1]) + grid[i][j];
+        }
+    }
+    return grid[n-1][m-1]
     
-            # Mark all the vertices as not visited 
-            visited =[False]*(self.ROW) 
-            queue=[] 
-            queue.append(s) 
-            visited[s] = True
+    1.   Coin Change Medium
+    for (int j = 1; j <= amount; ++j) {
+        for (int i = 0; i < coins.size(); ++i) {
+            if (coins[i] <= j) {
+                dp[j] = min(dp[j], dp[j - coins[i]] + 1);
+            }
+        }
+    }
+
+    1.   Minimum Falling Path Sum Medium
+    2.   Minimum Cost For Tickets Medium
+    3.   2 Keys Keyboard Medium
+    4.   Perfect Squares Medium
+    5.   Last Stone Weight II Medium
+    6.   Triangle Medium
+    7.   Ones and Zeroes Medium
+    8.   Maximal Square Medium
+    9.   Coin Change Medium
+    10.  Tiling a Rectangle with the Fewest Squares Hard
+    11.  Dungeon Game Hard
+    12.  Minimum Number of Refueling Stops Hard
+
+    Distinct Ways
+    Statement
+    Given a target find a number of distinct ways to reach the target.
 
-            while queue: 
-    
-                #Dequeue a vertex from queue and print it 
-                u = queue.pop(0) 
-            
-                # Get all adjacent vertices of the dequeued vertex u 
-                # If a adjacent has not been visited, then mark it 
-                # visited and enqueue it 
-                for ind, val in enumerate(self.graph[u]): 
-                    if visited[ind] == False and val > 0 : 
-                        queue.append(ind) 
-                        visited[ind] = True
-                        parent[ind] = u 
+    Approach
+    Sum all possible ways to reach the current state.
 
-            return True if visited[t] else False
-                      
-        # Returns tne maximum flow from s to t in the given graph 
-        def FordFulkerson(self, source, sink): 
-    
-            # This array is filled by BFS and to store path 
-            parent = [-1]*(self.ROW) 
-    
-            max_flow = 0 # There is no flow initially 
-    
-            # Augment the flow while there is path from source to sink 
-            while self.BFS(source, sink, parent) : 
-    
-                # Find minimum residual capacity of the edges along the 
-                # path filled by BFS. Or we can say find the maximum flow 
-                # through the path found. 
-                path_flow = float("Inf") 
-                s = sink 
+    routes[i] = routes[i-1] + routes[i-2], ... , + routes[i-k]
+    Generate sum for all values in the target and return the value for the target.
 
-                # Get the limiting flow in the path. Traverse parents array to get path
-                while(s !=  source): 
-                    path_flow = min (path_flow, self.graph[parent[s]][s]) 
-                    s = parent[s] 
-    
-                # Add path flow to overall flow 
-                max_flow +=  path_flow 
-    
-                # update residual capacities of the edges and reverse edges along the path 
-                v = sink 
-                while(v !=  source): 
-                    u = parent[v] 
-                    self.graph[u][v] -= path_flow 
-                    self.graph[v][u] += path_flow 
-                    v = parent[v] 
+    for (int i = 1; i <= target; ++i) {
+        for (int j = 0; j < ways.size(); ++j) {
+            if (ways[j] <= i) {
+                dp[i] += dp[i - ways[j]];
+            }
+        }
+    }
+    return dp[target]
     
-            return max_flow 
+    Similar Problems
+    1.  Climbing Stairs easy
+    for (int stair = 2; stair <= n; ++stair) {
+        for (int step = 1; step <= 2; ++step) {
+            dp[stair] += dp[stair-step];   
+        }
+    }
 
-    graph = [[0, 16, 13, 0, 0, 0], 
-            [0, 0, 10, 12, 0, 0], 
-            [0, 4, 0, 0, 14, 0], 
-            [0, 0, 9, 0, 0, 20], 
-            [0, 0, 0, 7, 0, 4], 
-            [0, 0, 0, 0, 0, 0]]    
-    g = Graph(graph) 
-    source = 0; sink = 5
-    print ("The maximum possible flow is %d " % g.FordFulkerson(source, sink)) 
-  
-    Output:
-    The maximum possible flow is 23
+    1.  Unique Paths Medium
+    for (int i = 1; i < m; ++i) {
+        for (int j = 1; j < n; ++j) {
+            dp[i][j] = dp[i][j-1] + dp[i-1][j];
+        }
+    }
 
-42) Bipartite matching problem: (Max flow 1)
-    n students. d dorms. Each student wants to live in one of 
-    the dorms of his choice. 
-    Each dorm can accomodate at most one student. 
+    1.    Number of Dice Rolls With Target Sum Medium
 
-    Problem: Find an assignment that maximizes the number of 
-    students who get a housing.
-    
-    Add source and sink. 
-    make edges between students and dorms. 
-    all edges weight are 1
-    S-> all students -> all dorms -> T
+        You have d dice, and each die has 
+        f faces numbered 1, 2, ..., f.
 
-    Find the max-flow. Then find the optimal assignment from the chosen
-    edges. 
+        Return the number of possible ways (out of f^d total ways) modulo 10^9 + 7 
+        to roll the dice so the sum of the face up numbers equals target.
+        Example 1:
+        Input: d = 1, f = 6, target = 3
+        Output: 1
+        Explanation: 
+        You throw one die with 6 faces.  There is only one way to get a sum of 3.
+        
+        Example 2:
+        Input: d = 2, f = 6, target = 7
+        Output: 6
+        Explanation: 
+        You throw two dice, each with 6 faces.  There are 6 ways to get a sum of 7:
+        1+6, 2+5, 3+4, 4+3, 5+2, 6+1.
 
-    If dorm j can accomodate cj students -> make edge with capacity
-    cj from dorm j to the sink.
-    
-43) Decomposing a DAG into nonintersecting paths:
-    -> Split each vertex v into vleft and vright
-    -> For each edge u->v in the DAG, make an edge from uleft to vright
+        harman analysis:
+        OPT[d][target] = WAYS TO GET THAT AMOUNT WITH THAT NUMBER OF DICE RIGHT? [right?]
+        OPT[d][target] += OPT[d-1][target - ways[i]]
+        Can optimize out d because weonly use the previous d ever!
+        But the answer has to use all dice so has to be OPT[D][TARGET]
 
-44) Min Cost Max Flow:
-    A varient of max-flow problem. Each edge has capacity c(e) and
-    cost cost(e). You have to pay cost(e) amount of money per unit 
-    flow per unit flow flowing through e
-    -> Problem: Find the max flow that has the minimum total cost.
-    -> Simple algo (Slow):
-        Repeat following:
-            Take the residual graph
-            Find a negative cost cycle using Bellman Ford
-                -> If there is none, finish. 
-            Circulate flow through the cycle to decrease the total cost,
-            until one of the edges is saturated.
-                -> Total amount of flow doesnt change .
+    ways = listOf()
+    for (int rep = 1; rep <= d; ++rep) {
+        vector<int> new_ways(target+1);
+        for (int already = 0; already <= target; ++already) {
+            for (int pipe = 1; pipe <= f; ++pipe) {
+                if (already - pipe >= 0) {
+                    new_ways[already] += ways[already - pipe];
+                    new_ways[already] %= mod;
+                }
+            }
+        }
+        ways = new_ways;
+    }
 
-47) Union Find Structure
-    -> Used to store disjoint sets
-    -> Can support 2 types of operations efficienty:
-    - Find(x) returns the "representative" of the set that x belongs. 
-    - Union(x, y): merges 2 sets that contain x and y
 
-    Both operations can be done in (essentially) constant time
-    Main idea: represent each set by a rooted tree
-        -> Every node maintains a link to its parent
-        -> A root node is "representative" of the corresponding set.
-    
-    Find(x) => follow the links from x until a node points itself. 
-        -> This is O(N). DO PATH COMPRESSION.
-        -> Makes tree shallower every time Find() is called. 
-        -> After Find(x) returns the root, backtrack to x and reroute
-            all the links to the root. 
+    Note
 
-    Union(x, y) => run Find(x) and Find(y) to find the 
-            corresponding root nodes and direct one to the other
+    Some questions point out the number of repetitions, 
+    in that case, add one more loop to simulate every repetition.
 
-    Union By rank:  
-        always attaches the shorter tree to the root of the 
-        taller tree. Thus, the resulting tree 
-        is no taller than the originals unless they were of equal height, 
-        in which case the resulting tree is taller by one node.
+    1.   Knight Probability in Chessboard Medium
+    2.   Target Sum Medium
+    3.   Combination Sum IV Medium
+    4.   Knight Dialer Medium
+    5.   Dice Roll Simulation Medium
+    6.   Partition Equal Subset Sum Medium
+    7.   Soup Servings Medium
+    8.   Domino and Tromino Tiling Medium
+    9.   Minimum Swaps To Make Sequences Increasing
+    10.  Number of Longest Increasing Subsequence Medium
+    11.  Unique Paths II Medium
+    12.  Out of Boundary Paths Medium
+    13.  Number of Ways to Stay in the Same Place After Some Steps Hard
+    14.  Count Vowels Permutation Hard
 
-        To implement union by rank, each element is associated with a rank. 
-        Initially a set has one element and a rank of zero. If two sets are 
-        unioned and have the same rank, the resulting set's rank is one larger; 
-        otherwise, if two sets are unioned and have different ranks, the resulting
-        set's rank is the larger of the two. Ranks are used instead of height or 
-        depth because path compression will change the trees' heights over time.
+    Merging Intervals
+    Statement
+    Given a set of numbers find an optimal solution 
+    for a problem considering the current number 
+    and the best you can get from the left and right sides.
 
-    PSEUDOCODE:
-    function MakeSet(x)
-        if x is not already present:
-            add x to the disjoint-set tree
-            x.parent := x
-            x.rank   := 0
-            x.size   := 1
+    Approach
+    Find all optimal solutions for every interval 
+    and return the best possible answer.
 
-    function Find(x)
-        if x.parent != x
-            x.parent := Find(x.parent)
-        return x.parent
+    // from i to j
+    dp[i][j] = dp[i][k] + result[k] + dp[k+1][j]
+    Get the best from the left and right sides and add a solution for the current position.
 
-    function Union(x, y)
-        xRoot := Find(x)
-        yRoot := Find(y)
-    
-        // x and y are already in the same set
-        if xRoot == yRoot            
-            return
-    
-        // x and y are not in same set, so we merge them
-        if xRoot.rank < yRoot.rank
-            xRoot, yRoot := yRoot, xRoot // swap xRoot and yRoot
+    for(int l = 1; l<n; l++) {
+        for(int i = 0; i<n-l; i++) {
+            int j = i+l;
+            for(int k = i; k<j; k++) {
+                dp[i][j] = max(dp[i][j], dp[i][k] + result[k] + dp[k+1][j]);
+            }
+        }
+    }
+    return dp[0][n-1]
     
-        // merge yRoot into xRoot
-        yRoot.parent := xRoot
-        if xRoot.rank == yRoot.rank:
-            xRoot.rank := xRoot.rank + 1
     
+    Similar Problems
+    1.    Minimum Cost Tree From Leaf Values Medium
 
 
-48) Applications of Union Find:
-    keep track of the connected components of an undirected graph. 
-    This model can then be used to determine whether 
-    two vertices belong to the same component, 
-    or whether adding an edge between them would result in a cycle. 
-    DETECT CYCLE IN UNDIRECTED GRAPH:
-    
-        # A utility function to find the subset of an element i 
-        def find_parent(self, parent,i): 
-            if parent[i] == -1: 
-                return i 
-            if parent[i]!= -1: 
-                return self.find_parent(parent,parent[i]) 
-    
-        # A utility function to do union of two subsets 
-        def union(self,parent,x,y): 
-            x_set = self.find_parent(parent, x) 
-            y_set = self.find_parent(parent, y) 
-            parent[x_set] = y_set 
+    Given an array arr of positive integers, 
+    consider all binary trees that can be possibly constructed
+    from the arr:
 
-        # The main function to check whether a given graph 
-        # contains cycle or not 
-        def isCyclic(self): 
+    Each node has either 0 or 2 children;                               
+    The values of arr correspond to the values of each 
+    leaf in an in-order traversal of the tree.  
+    The value of each non-leaf node is equal to the 
+    product of the largest leaf value 
+    in its left and right subtree respectively.
+    Among all possible binary trees considered, return the 
+    smallest possible sum of the values of each non-leaf node.  
+    It is guaranteed this sum fits into a 32-bit integer.
+
+    A node is a leaf if and only if it has zero children.
+
+    Top Down:
+    class Solution:
+        def mctFromLeafValues(self, arr: List[int]) -> int:
+            return self.helper(arr, 0, len(arr) - 1, {})
             
-            # Allocate memory for creating V subsets and 
-            # Initialize all subsets as single element sets 
-            parent = [-1]*(self.V) 
-    
-            # Iterate through all edges of graph, find subset of both 
-            # vertices of every edge, if both subsets are same, then 
-            # there is cycle in graph. 
-            for i in self.graph: 
-                for j in self.graph[i]: 
-                    x = self.find_parent(parent, i)  
-                    y = self.find_parent(parent, j) 
-                    if x == y: 
-                        return True
-                    self.union(parent,x,y) 
+        def helper(self, arr, l, r, cache):
+            if (l, r) in cache:
+                return cache[(l, r)]
+            if l >= r:
+                return 0
+            
+            res = float('inf')
+            for i in range(l, r):
+                rootVal = max(arr[l:i+1]) * max(arr[i+1:r+1])
+                res = min(res, rootVal + self.helper(arr, l, i, cache) + self.helper(arr, i + 1, r, cache))
+            
+            cache[(l, r)] = res
+            return res
 
+    Bottom Up:
+    class Solution:
+        def mctFromLeafValues(self, arr: List[int]) -> int:
+            n = len(arr)
+            dp = [[float('inf') for _ in range(n)] for _ in range(n)]
+            for i in range(n):
+                dp[i][i] = 0
+            
+            for l in range(2, n + 1):
+                for i in range(n - l + 1):
+                    j = i + l - 1
+                    for k in range(i, j):
+                        rootVal = max(arr[i:k+1]) * max(arr[k+1:j+1])
+                        dp[i][j] = min(dp[i][j], rootVal + dp[i][k] + dp[k + 1][j])
+            return dp[0][n - 1]
 
-49) Detect negative cycles with Bellman Ford:
 
-    1) Initialize distances from source to all vertices as infinite and distance to source itself as 0. 
-    Create an array dist[] of size |V| with all values as infinite except dist[src] where src is source vertex.
+    for (int l = 1; l < n; ++l) {
+        for (int i = 0; i < n - l; ++i) {
+            int j = i + l;
+            dp[i][j] = INT_MAX;
+            for (int k = i; k < j; ++k) {
+                dp[i][j] = min(dp[i][j], dp[i][k] + dp[k+1][j] + maxs[i][k] * maxs[k+1][j]);
+            }
+        }
+    }
 
-    2) This step calculates shortest distances. Do following |V|-1 times where |V| is the number of vertices in given graph.
-    …..a) Do following for each edge u-v
-    ………………If dist[v] > dist[u] + weight of edge uv, then update dist[v]
-    ………………….dist[v] = dist[u] + weight of edge uv
+    Greedy Sol:
+    The greedy approach is to find the smallest value in the array, 
+    use it and its smaller neighbor to build a non-leaf node, then we can safely delete 
+    it from the array since it has a smaller value than its neightbor so it will never be 
+    used again. Repeat this process until there is only one node left in the array 
+    (which means we cannot build a new level any more)
 
-    3) This step reports if there is a negative weight cycle in graph. Do following for each edge u-v
-    ……If dist[v] > dist[u] + weight of edge uv, then “Graph contains negative weight cycle”
+    class Solution:
+        def mctFromLeafValues(self, A):
+            res = 0
+            while len(A) > 1:
+                i = A.index(min(A))
+                res += min(A[i - 1:i] + A[i + 1:i + 2]) * A.pop(i)
+            return res
 
-    The idea of step 3 is, step 2 guarantees shortest distances if graph doesn’t 
-    contain negative weight cycle. If we iterate through all edges one more 
-    time and get a shorter path for any vertex, then 
-    there is a negative weight cycle.
+    Solution 2: Stack Soluton
+    we decompose a hard problem into reasonable easy one:
+    Just find the next greater element in the array, on the left and one right.
+    Refer to the problem 503. Next Greater Element II
+
+    lee215's O(N) solution
+    The second solution removes the less of pair arr[i] and arr[i + 1] which has minimum product during each iteration.
+    Now we think about it, each iteration actually removes a local minimum value.
+    For elements arr[i - 1], arr[i] and arr[i + 1] where arr[i] is the local minium.
+    The product added to final result is arr[i] * min(arr[i - 1], arr[i + 1])
+    The problem can be translated into removing all local minium values while 
+    finding the first greater element on the left and on the right.
+    A stack based solution from previous problems can be applied as lee215 mentioned in his post.
+
+    Time O(N) for one pass
+    Space O(N) for stack in the worst cases
+    def mctFromLeafValues(self, A):
+        res = 0
+        stack = [float('inf')]
+        for a in A:
+            while stack[-1] <= a:
+                mid = stack.pop()
+                res += mid * min(stack[-1], a)
+            stack.append(a)
+        while len(stack) > 2:
+            res += stack.pop() * stack[-1]
+        return res
 
-52) Flattening a multilevel doubly linked list using a stack:
-        def flatten(self, head):
-            if not head:
-                return
-            
-            dummy = Node(0,None,head,None)     
-            stack = []
-            stack.append(head)
-            prev = dummy
-            
-            while stack:
-                root = stack.pop()
+    1.  Unique Binary Search Trees Medium
+    2.    Minimum Score Triangulation of Polygon Medium
+    3.   Remove Boxes Medium
+    4.    Minimum Cost to Merge Stones Medium
+    5.   Burst Balloons Hard
+    6.   Guess Number Higher or Lower II Medium
 
-                root.prev = prev
-                prev.next = root
-                
-                if root.next:
-                    stack.append(root.next)
-                    root.next = None
-                if root.child:
-                    stack.append(root.child)
-                    root.child = None
-                prev = root        
-                
-            # disengage dummy node
-            dummy.next.prev = None
-            return dummy.next
+    DP on Strings
+    General problem statement for this pattern 
+    can vary but most of the time you are given 
+    two strings where lengths of those strings are not big
 
+    Statement
+    Given two strings s1 and s2, return some result.
 
-53) The art of segment trees and monoqueues:
-    PLEASE REVIEW SEGMENT TREES IN DATA STRUCTURES NOTES!!
+    Approach
+    Most of the problems on this pattern requires 
+    a solution that can be accepted in O(n^2) complexity.
 
-    Previously we saw segment trees.
-    That data structure was able to answer the question
+    // i - indexing string s1
+    // j - indexing string s2
+    for (int i = 1; i <= n; ++i) {
+        for (int j = 1; j <= m; ++j) {
+            if (s1[i-1] == s2[j-1]) {
+                dp[i][j] = /*code*/;
+            } else {
+                dp[i][j] = /*code*/;
+            }
+        }
+    }
 
-    reduce(lambda x,y: operator(x,y), arr[i:j], default)
-    and we were able to answer it in O(\log(j - i)) time. 
-    Moreover, construction of this data structure only took O(n) time. 
-    Moreover, it was very generic as operator and 
-    default could assume be any values.
+    If you are given one string s the approach may little vary
 
-    This obviously had a lot of power, but we can use something a lot 
-    simpler if we want to answer easier problems. 
-    Suppose instead, we wanted to ask the question
+    for (int l = 1; l < n; ++l) {
+        for (int i = 0; i < n-l; ++i) {
+            int j = i + l;
+            if (s[i] == s[j]) {
+                dp[i][j] = /*code*/;
+            } else {
+                dp[i][j] = /*code*/;
+            }
+        }
+    }
 
-    reduce(lambda x,y: operator(x,y), arr[i:i + L])
-    with the caveat that operator(x,y) will return 
-    either x or y and that L remains fixed.
+    1.    Longest Common Subsequence Medium
 
-    Some examples of this is to find the minimum of some 
-    fixed length range, or the maximum in some fixed length range.
+        Let the input sequences be X[0..m-1] and Y[0..n-1] of lengths m and n respectively.
+        And let L(X[0..m-1], Y[0..n-1]) be the length of LCS of the two sequences X and Y. 
+        Following is the recursive definition of L(X[0..m-1], Y[0..n-1]).
 
-    Introducing, the Monotonic Queue, with the handy name Monoqueue.
+        If last characters of both sequences match (or X[m-1] == Y[n-1]) then 
+        L(X[0..m-1], Y[0..n-1]) = 1 + L(X[0..m-2], Y[0..n-2])
 
-    The code for this guy is pretty self explanatory, but the basic idea 
-    is to maintain a sliding window that sweeps across. 
-    Moreover, the contents of the Monoqueue are sorted 
-    with respect to the comparator Operator, so to 
-    find the “best” in a range one only need look at the front.
+        If last characters of both sequences do not match (or X[m-1] != Y[n-1]) then 
+        L(X[0..m-1], Y[0..n-1]) = MAX ( L(X[0..m-2], Y[0..n-1]), L(X[0..m-1], Y[0..n-2]) )
 
-    from collections import deque
-    class Monoqueue:
-        def __init__(self, operator):
-            self.q = deque()
-            self.op = operator
-        
-        def get_best(self):
-            if not self.q:
-                return None
-            return self.q[0][0]
-        
-        '''
+    for (int i = 1; i <= n; ++i) {
+        for (int j = 1; j <= m; ++j) {
+            if (text1[i-1] == text2[j-1]) {
+                dp[i][j] = dp[i-1][j-1] + 1;
+            } else {
+                dp[i][j] = max(dp[i-1][j], dp[i][j-1]);
+            }
+        }
+    }
 
-        if q has elements, look at back of queue. 
-        pop the elements off that cannot be best possible (i think? WTF??)
-        Ok sure. What the count does is it shows the range for which 
-        it is the best possible value. once you exit the range, remove the front
-        of the queue, and go to the next best, which will be the best for a certain sized window
-        before another thing is the best. 
-        So we keep track of the bests at each step only, and keep the best even if we "pop" because
-        its located a lil to the right, of the thing you popped on the main stream. 
-        '''
-        def push(self, val):
-            count = 0
-            while self.q and self.op(val, self.q[-1][0]):
-                count += 1 + self.q[-1][1]
-                self.q.pop()
-            self.q.append([val, count])
-        '''
-        Pop front. only if count is == 0.
-        Otherwise, decrement the count. Why is the count important?
-        I guess the count keeps track of the range you are sliding across
-        so if you pop it, and slide to the right, its still THE BEST POSSIBLE VALUE 
-        (because the best possible value is located somewhere a lil to the right), 
-        because it was not actually popped. just some garbage element on the main list 
-        was popped. 
-        '''
-        def pop(self):
-            if not self.q:
-                return None
-            if self.q[0][1] > 0:
-                self.q[0][1] -= 1
-            else:
-                self.q.popleft()
+    
+    1.   Palindromic Substrings Medium
+    for (int l = 1; l < n; ++l) {
+        for (int i = 0; i < n-l; ++i) {
+            int j = i + l;
+            if (s[i] == s[j] && dp[i+1][j-1] == j-i-1) {
+                dp[i][j] = dp[i+1][j-1] + 2;
+            } else {
+                dp[i][j] = 0;
+            }
+        }
+    }
 
-54) Boyer moore voting algortihm:
-    given an array of n elements, tell me if there is an 
-    element that appears more than n/2 times.
+    1.  Longest Palindromic Subsequence Medium
+    2.  Shortest Common Supersequence Medium
+    3.  Edit Distance Hard
+    4.  Distinct Subsequences Hard
+    5.  Minimum ASCII Delete Sum for Two Strings Medium
+    6.  Longest Palindromic Substring Medium
 
-    Obviously this has a huge amount of uses.
+    Decision Making
+    The general problem statement for this pattern is 
+    for the given situation decide whether to use or 
+    not to use the current state. So, the 
+    problem requires you to make a decision at a current state.
 
-    The trivial solution would be to sort the array in O(n * log(n)) time and then
+    Statement
+    Given a set of values find an answer with an 
+    option to choose or ignore the current value.
 
-    Boyer Moore Algorithm
-    This will require two passes, the first to find a 
-    possible candidate, and the second to verify that 
-    it is a candidate. The second part is 
-    trivial so we will not focus on it. The first sweep
-    however is a little bit more tricky.
+    Approach
+    If you decide to choose the current value use the 
+    previous result where the value was ignored; 
+    vice-versa, if you decide to ignore the 
+    current value use previous result where value was used.
 
-    We initialize a count to 0. Then as we proceed in the list, 
-    if the count is 0, we make the current value being
-    looked at the candidate. If the value we’re looking at 
-    is the candidate, then we increment the count by 1, 
-    otherwise we decrement the count.
+    // i - indexing a set of values
+    // j - options to ignore j values
+    for (int i = 1; i < n; ++i) {
+        for (int j = 1; j <= k; ++j) {
+            dp[i][j] = max({dp[i][j], dp[i-1][j] + arr[i], dp[i-1][j-1]}); //keep it
+            dp[i][j-1] = max({dp[i][j-1], dp[i-1][j-1] + arr[i], arr[i]}); //ignore it?
+        }
+    }
 
-    Distributed Boyer-Moore
-    Determine how many cores/processors you have, and call it t. 
-    Now, split your array into t positions and run Boyer-Moore 
-    on each of these sections. You will get a candidate 
-    and a count from each of these sections. Now, 
-    recursively run Boyer-Moore on the list of 
-    [candidate1 * count1] + [candidate2 * count2] … . Pretty cool right!
+    1.   House Robber Easy
 
-    Generalization
-    The generalized problem is given a list, 
-    find all elements of the list that occur more 
-    than n/k times. We simply have to carry 
-    the proof from the last case over and it applies directly.
+    You are a professional robber planning to rob houses along a street. 
+    Each house has a certain amount of money stashed, the only constraint 
+    stopping you from robbing each of them is that adjacent houses have security 
+    systems connected and it will automatically contact the police if two 
+    adjacent houses were broken into on the same night.
 
-    Have a set of possible candidates, and have an associated count with them.
+    Given an integer array nums representing the amount of money of each house, 
+    return the maximum amount of money you can rob tonight without alerting the police.
 
-    Iterate through the list, and if the item is in 
-    the dictionary, increment the count. If not and 
-    the number of elements in the dictionary is less 
-    than k, then just add it to the dictionary with count 1. 
-    Otherwise, decrement all the counters by 1, and delete 
-    any candidates with a counter 1.
+    for (int i = 1; i < n; ++i) {
+        dp[i][1] = max(dp[i-1][0] + nums[i], dp[i-1][1]);
+        dp[i][0] = dp[i-1][1];
+    }
+    
+    1.   Best Time to Buy and Sell Stock Easy
+    2.   Best Time to Buy and Sell Stock with Transaction Fee Medium
+    3.   Best Time to Buy and Sell Stock with Cooldown Medium
+    4.   Best Time to Buy and Sell Stock III Hard
+    5.   Best Time to Buy and Sell Stock IV Hard
 
-55)    Common problems solved using DP on broken profile include:
+###########################################################################################
+############################################################################################
+COOL NOTES 0.95 CODEFORCES DP 1
 
-        finding number of ways to fully fill an area 
-        (e.g. chessboard/grid) with some figures (e.g. dominoes)
-        finding a way to fill an area with minimum number of figures
-        finding a partial fill with minimum number of unfilled space (or cells, in case of grid)
-        finding a partial fill with the minimum number of figures, such that no more figures can be added
-        Problem "Parquet"
-        
-        Problem description. Given a grid of size N×M. 
-        Find number of ways to 
-        fill the grid with figures of size 2×1 (no cell 
-        should be left unfilled, 
-        and figures should not overlap each other).
+    MEMOIZATION VS FORWARD STYLE DP VS BACKWARD STYLE DP AND RECOVERING THE DP SOLUTION
 
-        Let the DP state be: dp[i,mask], where i=1,…N and mask=0,…2^(M)−1.
+    Memoization vs DP:
 
-        i respresents number of rows in the current grid, and mask is the state of 
-        last row of current grid. If j-th bit of mask is 0 then the corresponding 
-        cell is filled, otherwise it is unfilled.
+    The memoization approach does not spend time on unnecessary states — 
+    it is a lazy algorithm. Only the states which influence the 
+    final answer are processed. Here are the pros and cons of memoization 
+    over 
+    DP: 1[+]. Sometimes easier to code. 
+    2[+]. Does not require to specify order on states explicitly. 
+    3[+]. Processes only necessary states. 
+    4[-]. Works only in the backward-style DP. 
+    5[-]. Works a bit slower than DP (by constant).
 
-        Clearly, the answer to the problem will be dp[N,0].
+    Forward vs backward DP style
+    backward style. The schema is: iterate through all the states 
+    and for each of them calculate the result by looking backward 
+    and using the already known DP results of previous states. 
+    This style can also be called recurrent since it uses recurrent 
+    equations directly for calculation. The relations for backward-style 
+    DP are obtained by examining the best solution for the state 
+    and trying to decompose it to lesser states. 
+    (YOU HAVE SEEN BACKWARD STYLE PLENTY OF TIMES!)
 
-        We will be building the DP state by iterating over each i=1,⋯N 
-        and each mask=0,…2^(M)−1, and for each mask we will be only transitioning forward, 
-        that is, we will be adding figures to the current grid.
-        
-        int n, m;
-        vector < vector<long long> > dp;
-        void calc (int x = 0, int y = 0, int mask = 0, int next_mask = 0)
-        {
-            if (x == n)
-                return;
-            if (y >= m)
-                dp[x+1][next_mask] += d[x][mask];
-            else
-            {
-                int my_mask = 1 << y;
-                if (mask & my_mask)
-                    calc (x, y+1, mask, next_mask);
-                else
-                {
-                    calc (x, y+1, mask, next_mask | my_mask);
-                    if (y+1 < m && ! (mask & my_mask) && ! (mask & (my_mask << 1)))
-                        calc (x, y+2, mask, next_mask);
-                }
-            }
-        }
+    There is also forward-style DP. Surprisingly it is often more 
+    convenient to use. The paradigm of this style is to iterate 
+    through all the DP states and from each state perform some transitions 
+    leading forward to other states. Each transition modifies the currently 
+    stored result for some unprocessed states. When the state is considered, 
+    its result is already determined completely. The forward formulation does 
+    not use recurrent equations, so it is more complex to prove the correctness 
+    of solution strictly mathematically. The recurrent relations used in forward-style 
+    DP are obtained by considering one partial solution for the state and trying to 
+    continue it to larger states. To perform forward-style DP it is necessary to 
+    fill the DP results with neutral values before starting the calculation
+    
+    Problem 1:
+    Given a list of n coins, their weights W1, W2, ..., Wn; and the total sum S. 
+    Find the minimum number of coins the overall weight of which is 
+    S (we can use as many coins of each type as we want)
 
+    FOWARD STYLE DP (IT USES RELAXTION LIKE DJIKSTRA/BELLMAN FORD):
 
-        int main()
-        {
-            cin >> n >> m;
+    The first example will be combinatoric coins problem. 
+    Suppose that you have a partial solution with P overall weight. 
+    Then you can add arbitrary coin with weight Wi and get overall weight P+Wi. 
+    So you get a transition from state (P) to state (P+Wi). When 
+    this transition is considered, the result for state (P) is added to 
+    the result of state (P+Wi) which means that all the ways to get P weight 
+    can be continued to the ways to get P+Wi weight by adding i-th coin. 
+    Here is the code.
 
-            dp.resize (n+1, vector<long long> (1<<m));
-            dp[0][0] = 1;
-            for (int x=0; x<n; ++x)
-                for (int mask=0; mask<(1<<m); ++mask)
-                    calc (x, 0, mask, 0);
+    /* Recurrent relations (transitions) of DP:
+    {k[0] = 1;
+    {(P)->k ===> (P+Wi)->nk    add k to nk
+    */
+    //res array is automatically filled with zeroes
+    res[0] = 1;                                 //DP base is the same
+    for (int p = 0; p<s; p++)                   //iterate through DP states
+        for (int i = 0; i<n; i++) {               //iterate through coin to add
+            int np = p + wgt[i];                    //the new state is (np)
+            if (np > s) continue;                   //so the transition is (p) ==> (np)
+            res[np] += res[p];                      //add the DP result of (p) to DP result of (np)
+        }
+    int answer = res[s];                        //problem answer is the same
 
-            cout << dp[n][0];
+    PROBLEM 2: LCS
+    The second example is longest common subsequence problem. 
+    It is of maximization-type, so we have to fill the results array 
+    with negative infinities before calculation. The DP base is state (0,0)->0 
+    which represents the pair of empty prefixes. When we consider partial 
+    solution (i,j)->L we try to continue it by three ways: 
+    1. Add the next letter of first word to the prefix, do not change subsequence. 
+    2. Add the next letter of the second word to the prefix, do not change subsequence. 
+    3. Only if the next letters of words are the same: add next letter 
+        to both prefixes and include it in the subsequence. 
+    
+    For each transition we perform so-called relaxation of the larger DP state result. 
+    We look at the currently stored value in that state: if it is 
+    worse that the proposed one, then it is replaced with the proposed one, 
+    otherwise it is not changed. The implementation code and compact 
+    representation of DP relations are given below.
+
+    /* Recurrent relations (transitions) of DP:
+    {L[0,0] = 0;
+    |          /> (i+1,j)->relax(L)
+    {(i,j)->L ==> (i,j+1)->relax(L)
+                \> (i+1,j+1)->relax(L+1)  (only if next symbols are equal)
+    */
+    void relax(int &a, int b) {                   //relaxation routine
+    if (a < b) a = b;
+    }
+    
+    memset(lcs, -63, sizeof(lcs));              //fill the DP results array with negative infinity
+    lcs[0][0] = 0;                              //set DP base: (0,0)->0
+    for (int i = 0; i<=n1; i++)
+        for (int j = 0; j<=n2; j++) {             //iterate through all states
+            int tres = lcs[i][j];
+            // Improve the next states from the current state, and what we see rn. 
+            // Djikstra relax style!
+            relax(lcs[i+1][j], tres);               //try transition of type 1
+            relax(lcs[i][j+1], tres);               //try transition of type 2
+            if (str1[i] == str2[j])                 //and if next symbols are the same
+                relax(lcs[i+1][j+1], tres + 1);       //then try transition of type 3
         }
+    int answer = lcs[n1][n2];
 
+    Recovering the best solution for optimization problems
 
-#############################################################################
-###################################################33
+    DP finds only the goal function value itself. 
+    It does not pr
+    There are two ways to get the solution path.
+    METHOD 1: REVERSE DP
+    The first way is to recalculate the DP from the end to the start. 
+    First we choose the final state (f) we want to trace the path from. 
+    Then we process the (f) state just like we did it in the DP: 
+    iterate through all the variants to get it. Each variant originates 
+    in a previous state (p). If the variant produces the result equal 
+    to DP result of state (f), then the variant if possible. There is 
+    always at least one possible variant to produce the DP result for 
+    the state, though there can be many of them. If the variant 
+    originating from (p) state is possible, then there is at least 
+    one best solution path going through state (p). Therefore we can
+    move to state (p) and search the path from starting state to 
+    state (p) now. We can end path tracing when we reach the starting state.
 
-Cool Notes Part 0.5: Sliding Window with a deque
-        -> In this question you learn about the difference between useless elements, 
-           and useful elements.
-           How to use a deque to maintain the useful elemenets as you run through the arry
-           Operating on the indexes of an array instead of the actual elements (pointers!)
-           Always try to realized how to discern useless and useful elements when sliding your window,
-           and how to keep track of them and maintain them
-           (In this case, every iteration we cull bad elements!)
+    METHOD 2: BACKLINKS
 
-        -> Sliding Window Maximum (Maximum of all subarrays of size k)
-           Given an array and an integer k, find the maximum for each 
-           and every contiguous subarray of size k. O(N) algorithm
+    Another way is to store back-links along with the DP result. 
+    For each state (s) we save the parameters of the previous state (u) 
+    that was continued. When we perform a transition (u) ==> (s) which 
+    produces better result than the currently stored in (s) then we set 
+    the back-link to (s) to the state (u). To trace the DP solution path 
+    we need simply to repeatedly move to back-linked state until the 
+    starting state is met. Note that you can store any additional 
+    info about the way the DP result was obtained to simplify 
+    solution reconstruction.
 
-           We create a Deque, Qi of capacity k, that stores only useful elements 
-           of current window of k elements. An element is useful if it is in current window 
-           and is greater than all other elements on left side of it in current window. 
-           We process all array elements one by one and maintain Qi to contain 
-           useful elements of current window and these useful elements are 
-           maintained in sorted order. The element at front of the Qi is 
-           the largest and element at rear of Qi is the smallest of current window. 
-           Time Complexity: O(n). It seems more than O(n) at first look. 
-           If we take a closer look, we can observe that every element of 
-           array is added and removed at most once. 
-           So there are total 2n operations.
-          
-            def printMax(arr, n, k): 
-                
-                """ Create a Double Ended Queue, Qi that  
-                will store indexes of array elements.  
-                The queue will store indexes of useful  
-                elements in every window and it will 
-                maintain decreasing order of values from 
-                front to rear in Qi, i.e., arr[Qi.front[]] 
-                to arr[Qi.rear()] are sorted in decreasing 
-                order"""
-                Qi = deque() 
-                
-                # Process first k (or first window)  
-                # elements of array 
-                for i in range(k): 
-                    
-                    # For every element, the previous  
-                    # smaller elements are useless 
-                    # so remove them from Qi 
-                    while Qi and arr[i] >= arr[Qi[-1]] : 
-                        Qi.pop() 
-                    
-                    # Add new element at rear of queue 
-                    Qi.append(i); 
-                    # We are storing the indexes for the biggest elements!
-                
-                # Qi contains the biggest elements in the first k so:
-                # k -> [1, 4, 6, 3, 5] (5 elements)
-                # Qi -> [2, 5] (useful elements -> 
-                #              the indexes for elements that can become a maximum)
-                # element at front of queue is maximum, in this case, it is 6 (index is 2)
+    Use first method if memory is a problem. Otherwise use method 2. 
+
+    EXAMPLE OF RECOVERING THE SOLUTION PATH:
+
+    /* Consider the input data: S=11, n=3, W = {1,3,5}
+    The DP results + back-links table is:
+    P  = 0 |1 |2 |3 |4 |5 |6 |7 |8 |9 |10|11
+    -------+--+--+--+--+--+--+--+--+--+--+--
+    mink = 0 |1 |2 |1 |2 |1 |2 |3 |2 |3 |2 |3
+    prev = ? |S0|S1|S0|S1|S0|S1|S2|S3|S4|S5|S6
+    item = ? |I0|I0|I1|I1|I2|I2|I2|I2|I2|I2|I2
+    */
+    
+    int mink[MAXW];                       //the DP result array
+    int prev[MAXW], item[MAXW];           //prev  -  array for back-links to previous state
+    int k;                                //item  -  stores the last item index
+    int sol[MAXW];                        //sol[0,1,2,...,k-1] would be the desired solution
+    
+    memset(mink, 63, sizeof(mink));     //fill the DP results with positive infinity
+    mink[0] = 0;                        //set DP base (0)->0
+    for (int p = 0; p<s; p++)           //iterate through all states
+        for (int i = 0; i<n; i++) {       //try to add one item
+        int np = p + wgt[i];            //from (P)->k we get
+        int nres = mink[p] + 1;         //to (P+Wi)->k+1
+        if (mink[np] > nres) {          //DP results relaxation
+            mink[np] = nres;              //in case of success
+            prev[np] = p;                 //save the previous state
+            item[np] = i;                 //and the used last item
+        }
+        }
+    
+    int answer = mink[s];
+    int cp = s;                         //start from current state S
+    while (cp != 0) {                   //until current state is zero
+        int pp = prev[cp];                //get the previous state from back-link
+        sol[k++] = item[cp];              //add the known item to solution array
+        cp = pp;                          //move to the previous state
+    }
+####################3
+cOOL NOTES 0.99
 
-                # Process rest of the elements, i.e.  
-                # from arr[k] to arr[n-1] 
-                for i in range(k, n): 
-                    
-                    # The element at the front of the 
-                    # queue is the largest element of 
-                    # previous window, so print it 
-                    print(str(arr[Qi[0]]) + " ", end = "") 
-                    
-                    # Remove our really good candidates which are  
-                    # out of window now. SO SAD!! 
-                    # out of window elements are in the front of the queue. 
-                    # indexes are increasing like above -> 2 -> 5
-                    # its i-k because we want to shift our removal range to start at index 0 
-                    # and go up to n-k for the last window.
-                    while Qi and Qi[0] <= i-k: 
-                        
-                        # remove from front of deque 
-                        Qi.popleft()  
-                    
-                    # Remove all elements smaller than 
-                    # the currently being added element  
-                    # (Remove useless elements) 
-                    # we can do this because the element we are adding will always
-                    # be a candidate for the sliding window in the next iteration, 
-                    # and a better candidate, than the  "useless" elements in the sliding
-                    # window
-                    while Qi and arr[i] >= arr[Qi[-1]] : 
-                        Qi.pop() 
-                    
-                    # Add current element at the rear of Qi 
-                    Qi.append(i) 
-                
-                # Print the maximum element of last window 
-                print(str(arr[Qi[0]])) 
+2D default dict 
+
+do this:
+
+        opt = defaultdict(lambda: defaultdict(int))
+
+###########################################################################################
+############################################################################################
+COOL NOTES 0.98 CODEFORCES DP 2 
+    OPTIMIZING DP
+
+    TSP:
+    "Given a list of cities and the distances between each pair of cities, what 
+    is the shortest possible route that visits each city exactly once and returns to the origin city?"
+
+    -> Consolidate equivalent states
         
-        -> YOU CAN ALSO ANSWER THIS QUESTION WITH A SEGMENT TREE. 
+        Consider TSP problem as an example. The bruteforce recursive 
+        solution searches over all simple paths from city 0 recursively. 
+        State of this solution is any simple path which starts from city 0. 
+        In this way a state domain is defined and the recursive relations 
+        for them are obvious. But then we can notice that states (0,A,B,L) 
+        and (0,B,A,L) are equivalent. It does not matter in what order the 
+        internal cities were visited — only the set of visited cities and the 
+        last city matter. It means that our state domain is redundant, so let's 
+        merge the groups of equivalent states. We will get state domain (S,L)->R 
+        where S is set of visited states, L is the last city in the path and R is the 
+        minimal possible length of such path. The recursive solution with O((N-1)!) 
+        states is turned into DP over subsets with O(2^N*N) states.
 
-        OTHER TAKEAWAYS:
-        This queue is a monoqueue
-        What does Monoqueue do here:
+    -> Prune impossible states
+        The state is impossible if its result is always equal to 
+        zero(combinatorial) / infinity(minimization). Deleting such a state is a 
+        good idea since it does not change problem answer for sure. 
+        The impossible states can come from several sources:
+       
+       1. Explicit parameter dependence. The state domain is (A,B) and we know that for all 
+          possible states B = f(A) where f is some function (usually analytic and simple). In 
+          such a case B parameter means some unnecessary information and can be deleted from 
+          state description. The state domain will be just (A). If we ever need parameter B to 
+          perform a transition, we can calculate it as f(A). As the result the size of 
+          state domain is decreased dramatically.
 
-        It has three basic options:
-        push: push an element into the queue; O (1) (amortized)
-        pop: pop an element out of the queue; O(1) (pop = remove, it can't report this element)
-        max: report the max element in queue;O(1)
+       2. Implicit parameter dependence. This case is worse. We have state domain (A,B) 
+          where A represents some parameters and we know that for any possible state f(A,B) = 0. 
+          In other words, for each possible state some property holds. The best idea is of course 
+          to express one of parameters as explicitly dependent on the others. Then we can go to 
+          case 1 and be happy=) Also if we know that B is either f1(A) or f2(A) or f3(A) or ... or fk(A) 
+          then we can change state domain from (A,B) to (A,i) where i=1..k is a number of equation 
+          B variant. If nothing helps, we can always use approach 4.
 
-        It takes only O(n) time to process a N-size sliding window minimum/maximum problem.
-        Note: different from a priority queue (which takes O(nlogk) to solve this problem), 
-        it doesn't pop the max element: It pops the first element (in original order) in queue.
+       3. Inequalities on parameters. The common way to exploit inequalities 
+          for parameters is to set tight loop bounds. For example, if state domain 
+          is (i,j) and i<j then we can write for(i=0;i<N;i++) for(j=i+1;j<N;j++) 
+          or for(j=0;j<N;j++) for(i=0;i<j;i++). In this case we avoid processing impossible 
+          states and average speedup is x(2). If there are k parameters which are 
+          non-decreasing, speedup will raise to x(k!).
 
-###################################################################################
-##################################################################################
+       4. No-thinking ways. Even if it is difficult to determine 
+           which states are impossible, the fact of their existence 
+           itself can be exploited. There are several ways:
 
-[Python] Powerful Ultimate Binary Search Template. Solved many problems
+            A. Discard impossible states and do not process them. Just add 
+            something like "if (res[i][j]==0) continue;" inside loop which iterates over 
+            DP states and you are done. This optimization should be always used because 
+            overhead is tiny but speedup can be substantial. It does not decrease size of 
+            state domain but saves time from state processing.
 
+            B. Use recursive search with memoization. It will behave very similar to DP 
+            but will process only possible states. The decision to use it must be made before 
+            coding starts because the code differs from DP code a lot.
 
-    Binary Search helps us reduce the search time from linear O(n) to logarithmic O(log n). 
+            C. Store state results in a map. This way impossible states do not eat memory and time at all. 
+            Unfortunately, you'll have to pay a lot of time complexity for this technique: O(log(N)) with 
+            ordered map and slow O(1) with unordered map. And a big part of code must 
+            be rewritten to implement it.>
 
-    >> Most Generalized Binary Search
-    Suppose we have a search space. It could be an array, a range, etc. 
-    
-    Usually it's sorted in ascending order. For most tasks, 
-    we can transform the requirement into the following generalized form:
+    -> Store results only for two layers of DP state domain
 
-    Minimize k , s.t. condition(k) is True
+        The usual case is when result for state (i,A) is dependent only on 
+        results for states (i-1,*). In such a DP only two neighbouring layers 
+        can be stored in memory. Results for each layer are discarded after 
+        the next one is calculated. The memory is then reused for the next layer and so on.
 
-    The following code is the most generalized binary search template:
 
-    def binary_search(array) -> int:
-        def condition(value) -> bool:
-            pass
+        Memory contains two layers only. One of them is current layer and another one is previous layer 
+        (in case of forward DP one layer is current and another is next). After current layer is fully processed, 
+        layers are swapped. There is no need to swap their contents, just swap their pointers/references. 
+        Perhaps the easiest approach is to always store even-numbered layers in one memory buffer(index 0) 
+        and odd-numbered layers in another buffer(index 1). To rewrite complete and working 
+        DP solution to use this optimization you need to do only: 
+        1. In DP results array definition, change the first size of array to two. 
+        2. Change indexation [i] to [i&1] in all accesses to this array. (i&1 is equal to i modulo 2). 
+        3. In forward DP clear the next layer contents immediately after loop over layer 
+              index i. Here is the code example of layered forward-style minimization DP: 
+              
+              int res[2][MAXK]; //note that first dimension is only 2 
+              for (int i = 0; i<N; i++) 
+              { 
+                  memset(res[(i+1)&1], 63, sizeof(res[0])); //clear the contents of next layer (set to infinity) 
+                  for (int j = 0; j<=K; j++) { //iterate through all states as usual 
+                    int ni = i + 1; //layer index of transition destination is fixed 
+                    int nj, nres = DPTransition(res[i&1][j], ???); //get additional parameters and results somehow 
+                    if (res[ni&1][nj] > nres) //relax destination result 
+                        res[ni&1][nj] = nres; //note &1 in first index 
+                  } 
+            }
 
-        left, right = min(search_space), max(search_space) # could be [0, n], [1, n] etc. Depends on problem
-        while left < right:
-            mid = left + (right - left) // 2
-            if condition(mid):
-                right = mid
-            else:
-                left = mid + 1
-        return left
+        This technique reduces memory requirement in O(N) times which is 
+        often necessary to achieve desired space complexity. If sizeof(res) 
+        reduces to no more than several megabytes, then speed performance 
+        can increase due to cache-friendly memory accesses.
 
-    What's really nice of this template is that, for most of the binary search problems, 
-    we only need to modify three parts after copy-pasting this template, 
-    and never need to worry about corner cases and bugs in code any more:
+        Sometimes you have to store more than two layers. If DP transition relations 
+        use not more that k subsequent layers, then you can store only k layers in memory. 
+        Use modulo k operation to get the array index 
+        for certain layer just like &1 is used in the example.
 
-    Correctly initialize the boundary variables left and right to specify search space. 
-    Only one rule: set up the boundary to include all possible elements;
-    Decide return value. Is it return left or return left - 1? 
-    Remember this: after exiting the while loop, left is the minimal k​ satisfying the condition function;
-    Design the condition function. This is the most difficult and most beautiful part. Needs lots of practice.
-    Below I'll show you guys how to apply this powerful template to many LeetCode problems.
+        There is one problem though. In optimization problem there is no simple way 
+        to recover the path(solution) of DP. You will get the goal function of best solution, 
+        but you won't get the solution itself. To recover solution in usual 
+        way you have to store all the intermediate results.
 
+        There is a general trick which allows to recover path 
+        without storing all the DP results. The path can be recovered using divide and conquer method. 
+        Divide layers into approximately two halves and choose the middle layer with index m in 
+        between. Now expand the result of DP from (i,A)->R to (i,A)->R,mA where mA is the "middle state". 
+        It is value of additional parameter A of the state that lies both on the path and in the middle layer. 
+        Now let's see the following: 
+        1. After DP is over, problem answer is determined as minimal result in final layer (with certain properties maybe). 
+        2. Let this result be R,mA. Then (m,mA) is the state in the middle of the path we want to recover.
+        3. The results mA can be calculated via DP. Now we know the final and the middle states of the desired path. 
+        4. Divide layers into two halves and launch the same DP for each part recursively. 
+        5. Choose final state as answer for the right half and middle state as answer for the left half. 
+        6. Retrieve two states in the middle of these halves and continue recursively.
+        7.  This technique requires additional O(log(N)) time complexity because result for each layer 
+        8.  is recalculated approximately log(N) times.
+        9.  If some additional DP parameter is monotonous (for each transition (i,A) — (i+1,B) inequality A<=B holds) 
+            then domain of this parameter can also be divided into two halves by the middle point. 
+            In such a case asymptotic time complexity does not increase at all.
 
-    Excellent work! Many people think sorted array is a must to apply 
-    binary search, which is not 100% correct. In some cases, there is no 
-    such array, or the array is not sorted, or the element are not even 
-    comparable! What makes binary search work is that there exists a function 
-    that can map elements in left half to True, and the other half to False, 
-    or vice versa. If we can find such a function, we can apply bs to find 
-    the boundary (lower_bound for example). For the interval notation, 
-    Professor E.W. Dijkstra favors left closed right open interval 
-    notation and explained why we benefit from this notation in his 
-    post which was published in 1982.
 
-    In short, loop invariants help us design a loop and ensure the 
-    correctness of a loop in a formal way. ref1, ref2. For the binary search code, 
-    if we imagine the array expanded to infinity for both sides, then the loop 
-    invariants can phrased as:1) l<=r 2) elements in (-inf, l) are mapped to 
-    False by condition 3) elements in [r, +inf) are mapped to True by condition. 
-    These invariants are true before the loop, in each iteration of 
-    the loop, and after the loop. After the loop breaks, we know l ==r, 
-    from these invariants, we can conclude that elements in (-inf, l) are False, 
-    and those in [l, +inf) are true. Besides, to ensure a loop is 
-    correct, we also need to prove the loop break eventually. 
-    The proof is straight forward: at each iteration, the search 
-    range [l, r) shrinks by at least 1.
+    -> Precalculate
 
+        Often DP solution can benefit from precalculating something. 
+        Very often the precalculation is simple DP itself.
 
-    1.   First Bad Version [Easy]
-       You are a product manager and currently leading a team to develop a new 
-       product. Since each version is developed based on the previous version, 
-       all the versions after a bad version are also bad. Suppose you have n 
-       versions [1, 2, ..., n] and you want to find out the first bad one, which 
-       causes all the following ones to be bad. You are given an API bool 
-       isBadVersion(version) which will return whether version is bad.
+        A lot of combinatorial problems require precalculation of binomial coefficients. 
+        You can precalculate prefix sums of an array so that you can calculate sum of 
+        elements in segment in O(1) time. Sometimes it is beneficial to 
+        precalculate first k powers of a number.
 
-       Example:
+        Although the term precalculation refers to the calculations which are going 
+        before the DP, a very similar thing can be done in the DP process. 
+        For example, if you have state domain (a,b)->R you may find it useful to create 
+        another domain (a,k)->S where S is sum of all R(a,b) with b<k. 
+        It is not precisely precalculation since it expands the DP state domain, 
+        but it serves the same goal: spend some additional 
+        time for the ability to perform a particular operation quickly.>
 
-       Given n = 5, and version = 4 is the first bad version.
+    -> Rotate the optimization problem (ROTATION TECHNIQUE DONE IN ConnectTheCities.py in Competition folder)
 
-       call isBadVersion(3) -> false
-       call isBadVersion(5) -> true
-       call isBadVersion(4) -> true
+        There is a DP solution with state domain (W,A)->R for maximization problem, 
+        where W is weight of partial solution, A is some additional parameter 
+        and R is maximal value of partial solution that can be achieved. 
+        The simple problem unbounded knapsack problem will serve as an example for DP rotation.
 
-       Then 4 is the first bad version. 
-       First, we initialize left = 1 and right = n to include all possible values. 
-       Then we notice that we don't even need to design the condition function. 
-       It's already given by the isBadVersion API. Finding the first bad version is 
-       equivalent to finding the minimal k satisfying isBadVersion(k) is True. 
-       Our template can fit in very nicely:
+        Let's place additional requirement on the DP: if we increase weight W of partial 
+        solution without changing other parameters including result the solution worsens. 
+        Worsens means that the solution with increased weight can be discarded if the initial 
+        solution is present because the initial solution leads to better problem answer 
+        than the modified one. Notice that the similar statement must true for result R in 
+        any DP: if we increase the result R of partial solution the solution improves. 
+        In case of knapsack problem the requirement is true: we have some partial solution; 
+        if another solution has more weight and less value, then it is surely worse t
+        han the current one and it is not necessary to process it any further. 
+        The requirement may be different in sense of sign (minimum/maximum. worsens/improves).
 
-       class Solution:
-           def firstBadVersion(self, n) -> int:
-               left, right = 1, n
-               while left < right:
-                   mid = left + (right - left) // 2
-                   if isBadVersion(mid):
-                       right = mid
-                   else:
-                       left = mid + 1
-               return left
+        This property allows us to state another "rotated" DP: (R,A)->W where R is the value of partial solution, 
+        A is the same additional parameter, and W is the minimal possible weight for such a partial solution. 
+        In case of knapsack we try to take items of exactly R overall value with the least overall 
+        weight possible. The transition for rotated DP is performed the same way. 
+        The answer for the problem is obtained as usual: iterate through all 
+        states (R,A)->W with desired property and choose solution with maximal value.
 
+        To understand the name of the trick better imagine a grid on the plane 
+        with coordinates (W,R) where W is row index and R is column index. 
+        As we see, the DP stores only the result for rightmost(max-index) cell in each row. 
+        The rotated DP will store only the uppermost(min-index) cell in each column. 
+        Note the DP rotation will be incorrect if the requirement stated above does not hold.
 
-    2.  Sqrt(x) [Easy]
-       Implement int sqrt(int x). Compute and return the square root of x, 
-       where x is guaranteed to be a non-negative integer. Since the return type 
-       is an integer, the decimal digits are truncated and only the 
-       integer part of the result is returned.
+        The rotation is useful only if the range of possible values R is much less than the 
+        range of possible weights W. The state domain will take O(RA) memory instead of O(WA) 
+        which can help sometimes. For example consider the 0-1 knapsack problem with arbitrary 
+        positive real weights and values. DP is not directly applicable in this case. 
+        But rotated DP can be used to create fully polynomial approximation scheme which 
+        can approximate the correct answer with relative error not more than arbitrary threshold. 
+        The idea is to divide all values by small eps and round to the nearest integer. 
+        Then solve DP with state domain (k,R)->W where k is number of already processed items, 
+        R is overall integer value of items and W is minimal possible overall weight. Note that 
+        you cannot round weights in knapsack problem because the optimal solution you obtain 
+        this way can violate the knapsack size constraint.
 
-       Example:
+    -> Calculate matrix power by squaring
 
-       Input: 4
-       Output: 2
-       Input: 8
-       Output: 2
-       Easy one. First we need to search for minimal k satisfying 
-       condition k^2 > x, then k - 1 is the answer to the question. 
-       We can easily come up with the solution. Notice that I set 
-       right = x + 1 instead of right = x to deal with special input 
-       cases like x = 0 and x = 1.
+        This technique deals with layered combinatorial DP solution with transition independent 
+        of layer index. Two-layered DP has state domain (i,A)->R and recurrent rules 
+        in form R(i+1,A) = sum(R(i,B)*C(B)) over all B parameter values. It is important that 
+        recurrent rules does not depend on the layer index.
 
-       def mySqrt(x: int) -> int:
-           left, right = 0, x + 1
-           while left < right:
-               mid = left + (right - left) // 2
-               if mid * mid > x:
-                   right = mid
-               else:
-                   left = mid + 1
-           return left - 1  # `left` is the minimum k value, `k - 1` is the answer
+        Let's create a vector V(i) = (R(i,A1), R(i,A2), ..., R(i,Ak)) where Aj iterates through 
+        all possible values of A parameter. This vector contains all the results on i-th layer. 
+        Then the transition rule can be formulated as matrix multiplication: V(i+1) = M * V(i) 
+        where M is transition matrix. The answer for the problem is usually determined by the 
+        results of last layer, so we need to calculate V(N) = M^N * V(0).
 
+        The DP solution is to get V(0) and then multiply it by M matrix N times. It requires 
+        O(N * A^2) time complexity, or more precisely it requires O(N * Z) time where Z is 
+        number of non-zero elements of matrix M. Instead of one-by-one matrix multiplication, 
+        exponentiation by squaring can be used. It calculates M^N using O(log(N)) matrix multiplications. 
+        After the matrix power is available, we multiply vector V(0) by it and instantly get the results 
+        for last layer. The overall time complexity is O(A^3 * log(N)). This trick is necessary when A is 
+        rather small (say 200) and N is very large (say 10^9).
 
-    3.  Search Insert Position [Easy]
-       Given a sorted array and a target value, return the index if the 
-       target is found. If not, return the index where it would be if it were 
-       inserted in order. You may assume no duplicates in the array.
+    -> Use complex data structures and algorithms
 
-       Example:
+        Sometimes tough DP solutions can be accelerated by using complex acceleration 
+        structures or algorithms. Binary search, segment trees (range minimum/sum query), 
+        binary search tree (map) are good at accelerating particular operations. If you 
+        are desperate at inventing DP solution of Div1 1000 problem with 
+        proper time complexity, it may be a good idea to recall these things.
 
-       Input: [1,3,5,6], 5
-       Output: 2
-       Input: [1,3,5,6], 2
-       Output: 1
+        For example, longest increasing subsequence problem DP solution can be accelerated to 
+        O(N log(N)) with dynamic range minimum query data structure 
+        or with binary search depending on the chosen state domain.
 
-       Very classic application of binary search. We are looking for the 
-       minimal k value satisfying nums[k] >= target, and we can just 
-       copy-paste our template. Notice that our solution is correct regardless 
-       of whether the input array nums has duplicates. Also notice that the input 
-       target might be larger than all elements in nums and therefore 
-       needs to placed at the end of the array. 
-       That's why we should initialize right = len(nums) instead of right = len(nums) - 1.
+#######################################################################################################
+#######################################################################################################
 
-       class Solution:
-           def searchInsert(self, nums: List[int], target: int) -> int:
-               left, right = 0, len(nums)
-               while left < right:
-                   mid = left + (right - left) // 2
-                   if nums[mid] >= target:
-                       right = mid
-                   else:
-                       left = mid + 1
-               return left
+CODEFORCES DP 3 - STATE TRANSITIONS, AND STATES, AND RECURRENT RELATIONSHIPS
 
-    >> Advanced Application
-    The above problems are quite easy to solve, because they 
-    already give us the array to be searched. We'd know that we should 
-    use binary search to solve them at first glance. However, more often 
-    are the situations where the search space and search target are not 
-    so readily available. Sometimes we won't even realize that the problem 
-    should be solved with binary search -- we might just turn to dynamic 
-    programming or DFS and get stuck for a very long time.
+-> Overview 
+    Solution Code of DP solution usually contains an array representing 
+    subresults on the state domain. For example, classic knapsack problem solution will be like (FORWARD DP):
 
-    As for the question "When can we use binary search?", my answer 
-    is that, If we can discover some kind of monotonicity, for example, 
-    if condition(k) is True then condition(k + 1) is True, 
-    then we can consider binary search.
+    int maxcost[items+1][space+1];
+    memset(maxcost, -63, sizeof(maxcost));   //fill with negative infinity
+    maxcost[0][0] = 0;                       //base of DP
+    for (int i = 0; i<items; i++)            //iterations over states in proper order
+        for (int j = 0; j<=space; j++) {
+        int mc = maxcost[i][j];              //we handle two types forward transitions
+        int ni, nj, nmc;                     //from state (i,j)->mc to state (ni,nj)->nmc
+    
+        ni = i + 1;                          //forward transition: do not add i-th item
+        nj = j;
+        nmc = mc;      
+        if (maxcost[ni][nj] < nmc)           //relaxing result for new state
+            maxcost[ni][nj] = nmc;
+    
+        ni = i + 1;                          //forward transition: add i-th item
+        nj = j + size[i];
+        nmc = mc + cost[i];
+        if (nj <= space && maxcost[ni][nj] < nmc)
+            maxcost[ni][nj] = nmc;
+        }
+    int answer = -1000000000;                //getting answer from state results
+    for (j = 0; j<=space; j++)
+        if (maxcost[items][j] > answer)
+        answer = maxcost[items][j];
+    return answer;
 
+    Here (i,j) is state of DP with result equal to maxcost[i][j]. 
+    The result here means the maximal cost of items we can get by taking some of first i items with 
+    overall size of exactly j. So the set of (i,j) pairs and concept of maxcost[i][j] here 
+    comprise a state domain. The forward transition is adding or not adding the i-th item to 
+    the set of items we have already chosen.
 
-    1.    Capacity To Ship Packages Within D Days [Medium]
-        A conveyor belt has packages that must be shipped from 
-        one port to another within D days. The i-th package on the 
-        conveyor belt has a weight of weights[i]. Each day, 
-        we load the ship with packages on the conveyor belt 
-        (in the order given by weights). We may not load more 
-        weight than the maximum weight capacity of the ship.
+    The order of iterations through all DP states is important. The code above 
+    iterates through states with pairs (i,j) sorted lexicographically. It is correct 
+    since any transition goes from set (i,*) to set (i+1,*), so we see that i is increasing 
+    by one. Speaking in backward (recurrent) style, the result for each state (i,j) directly 
+    depends only on the results for the states (i-1,*).
 
-        Return the least weight capacity of the ship that 
-        will result in all the packages on the conveyor 
-        belt being shipped within D days.
+    To determine order or iteration through states we have to define order on state domain. 
+    We say that state (i1,j1) is greater than state (i2,j2) if (i1,j1) directly or indirectly 
+    (i.e. through several other states) depends on (i2,j2). This is definition of order on the 
+    state domain used. In DP solution any state must be considered after all the lesser states. 
+    Else the solution would give incorrect result.
 
-        Example :
+-> Multidimensional array 
+    The knapsack DP solution described above is an example of multidimensional array state domain (with 2 
+    dimensions). A lot of other problems have similar state domains. Generally 
+    speaking, in this category states are represented by k   parameters: (i1, i2, i3, ..., ik). 
+    So in the code we define a multidimensional array for state results like: 
+    int Result[N1][N2][N3]...    [Nk]. Of course there are some transition rules 
+    (recurrent relations). These rules themselves can be complex, but the order of states   
+    is usually simple.
 
-        Input: weights = [1,2,3,4,5,6,7,8,9,10], D = 5
-        Output: 15
-        Explanation: 
-        A ship capacity of 15 is the minimum to ship 
-            all the packages in 5 days like this:
-        1st day: 1, 2, 3, 4, 5
-        2nd day: 6, 7
-        3rd day: 8
-        4th day: 9
-        5th day: 10
+    In most cases the states can be iterated through in lexicographical order. 
+    To do this you have to ensure that if I = (i1, i2, i3, ...,  ik) directly 
+    depends on J = (j1, j2, j3, ..., jk) then I is lexicographically greater that J. 
+    This can be achieved by permuting  parameters (like using (j,i) instead of (i,j)) 
+    or reversing them. But it is usually easier to change the order and direction of nested   
+    loops. Here is general code of lexicographical traversion:
 
-        Note that the cargo must be shipped in the order given, 
-        so using a ship of capacity 14 and splitting 
-        the packages into parts like (2, 3, 4, 5), 
-        (1, 6, 7), (8), (9), (10) is not allowed.
-        
-        SOLN:
-        Start with a high capacity that works -> then keep reducing it until 
-        we are at an integer that causes D to go from viable -> not viable
-        Since thats the linear search solution -> Try binary
-        
-        Try total sum -> then half sum -> then quarter sum -> and keep going 
-        until D == 5
-        But how do verify a particular weight -> In O(N) by running it through array?
-        We should be able to do faster by doing a type of DP rite? idk.
+      for (int i1 = 0; i1<N1; i1++)
+        for (int i2 = 0; i2<N2; i2++)
+          ...
+            for (int ik = 0; ik<Nk; ik++) {
+              //get some states (j1, j2, j3, ..., jk) -> jres by performing transitions
+              //and handle them
+            }
+    Note: changing order of DP parameters in array and order of nested loops 
+    can noticably affect performance on modern computers due to    
+    CPU cache behavior.
 
+    This type of state domain is the easiest to understand and implement, that's why 
+    most DP tutorials show problems of this type. But it   is not the most 
+    frequently used type of state domain in SRMs. DP over subsets is much more popular.
 
-        Binary search probably would not come to our mind when we first meet 
-        this problem. We might automatically treat weights as search space and 
-        then realize we've entered a dead end after wasting lots of time. 
-        In fact, we are looking for the minimal one among all feasible capacities. 
-        We dig out the monotonicity of this problem: if we can successfully 
-        ship all packages within D days with capacity m, then we can definitely 
-        ship them all with any capacity larger than m. Now we can design a 
-        condition function, let's call it feasible, given an input capacity, 
-        it returns whether it's possible to ship all packages within D days. 
-        This can run in a greedy way: if there's still room for the current 
-        package, we put this package onto the conveyor belt, otherwise we 
-        wait for the next day to place this package. If the total days 
-        needed exceeds D, we return False, otherwise we return True.
+->  Subsets of a given set (IMPORTANT!)
 
-        Next, we need to initialize our boundary correctly. Obviously 
-        capacity should be at least max(weights), otherwise the conveyor 
-        belt couldn't ship the heaviest package. On the other hand, capacity 
-        need not be more thansum(weights), because then we can 
-        ship all packages in just one day.
+    The problems of this type has some set X. The number of elements in this set is small: 
+    less than 20. The idea of DP solution is to  consider all subsets of X as 
+    state domain. Often there are additional parameters. So generally we 
+    have state domain in form (s,a) where  s is a subset of X and "a" represents additional parameters.
 
-        Now we've got all we need to apply our binary search template:
+    Consider TSP problem as an example. The set of cities X={0, 1, 2, ..., N-1} 
+    is used here. State domain will have two parameters: s and  a. 
+    The state (s,a)->R means that R is the shortest path from city 0 to 
+    city "a" which goes through all the vertices from subset s    
+    exactly once. The transition is simply adding one city v to the 
+    end of path: (s,a)->R turns into (s+{v},v)->R + M[a,v]. Here M[i,j] 
+    is     distance between i-th and j-th city. Any hamiltonian cycle is a 
+    path which goes through each vertex exactly once plus the edge which    
+    closes the cycle, so the answer for TSP problem can be computed as min(R[X,a]+M[a,0]) among all vertices "a".
 
-        def shipWithinDays(weights: List[int], D: int) -> int:
-            def feasible(capacity) -> bool:
-                days = 1
-                total = 0
-                for weight in weights:
-                    total += weight
-                    if total > capacity:  # too heavy, wait for the next day
-                        total = weight
-                        days += 1
-                        if days > D:  # cannot ship within D days
-                            return False
-                return True
+    It is very convenient to encode subsets with binary numbers. 
+    Look recipe "Representing sets with bitfields" for detailed explanation.
 
-            left, right = max(weights), sum(weights)
-            while left < right:
-                mid = left + (right - left) // 2
-                if feasible(mid):
-                    right = mid
-                else:
-                    left = mid + 1
-            return left
+    The state domain of DP over subsets is usually ordered by set 
+    inclusion. Each forward transition adds some elements to the current  
+    subset, but does not subtract any. So result for each state (s,a) depends 
+    only on the results of states (t,b) where t is subset of s.    
+    If state domain is ordered like this, then we can iterate through subsets 
+    in lexicographical order of binary masks. Since subsets are  
+    usually represented with binary integers, we can iterate through 
+    all subsets by iterating through all integers from 0 to 2^N — 1. For    
+    example in TSP problem solution looks like:
+    So the subset will always be computed before you compute a superset!
+    0, 0001, 0010, 0011, 0100, 0101, 0110, 0111, 1000
 
+      int res[1<<N][N];
+      memset(res, 63, sizeof(res));       //filling results with positive infinity
+      res[1<<0][0] = 0;                   //DP base
+    
+      for (int s = 0; s < (1<<N); s++)    //iterating through all subsets in lexicographical order
+        for (int a = 0; a < N; a++) {
+          int r = res[s][a];
+          for (int v = 0; v < N; v++) {   //looking through all transitions (cities to visit next)
+            if (s & (1<<v)) continue;     //we cannot visit cities that are already visited
+            int ns = s | (1<<v);          //perform transition
+            int na = v;
+            int nr = r + matr[a][v];      //by adding edge (a &mdash; v) distance
+            if (res[ns][na] > nr)         //relax result for state (ns,na) with nr
+              res[ns][na] = nr;
+          }
+        }
+      int answer = 1000000000;            //get TSP answer
+      for (int a = 0; a < N; a++)
+        answer = min(answer, res[(1<<N)-1][a] + matr[a][0]);
 
-    2.   Split Array Largest Sum [Hard]
-        Given an array which consists of non-negative integers and an 
-        integer m, you can split the array into m non-empty continuous 
-        subarrays. Write an algorithm to minimize the largest sum 
-        among these m subarrays.
+    Often in DP over subsets you have to iterate through all subsets or 
+    supersets of a given set s. The bruteforce implementation will  
+    require O(4^N) time for the whole DP, but it can be easily optimized to 
+    take O(3^N). Please read recipe "Iterating Over All Subsets of a Set".
 
-        Input:
-        nums = [7,2,5,10,8]
-        m = 2
 
-        Output:
-        18
+-> Substrings of a given string
 
-        Explanation:
-        There are four ways to split nums into two subarrays. 
-        The best way is to split it into [7,2,5] and [10,8], 
-        where the largest sum among the two subarrays is only 18.
-        
-        Are these problems like rotated DP? or binsearch on DP?
-        How are we avoiding doing DP?
+    There is a fixed string or a fixed segment. According to the problem 
+    definition, it can be broken into two pieces, then each of pieces  
+    can be again divided into two pieces and so forth until we get unit-length strings. 
+    And by doing this we need to achieve some goal.
 
-        def answer(nums, m):
+    Classical example of DP over substrings is context-free grammar parsing algorithm. 
+    Problems which involve putting parentheses to    
+    arithmetic expression and problems that ask to optimize the overall 
+    cost of recursive breaking are often solved by DP over substrings.     
+    In this case there are two special parameters L and R which represent indices of left 
+    and right borders of a given substring. There can     
+    be some additional parameters, we denote them as "a". So each 
+    state is defined by (L,R,a). To calculate answer for each state, 
+    all the  ways to divide substring into two pieces are considered. 
+    Because of it, states must be iterated through in order or non-decreasing   
+    length. Here is the scheme of DP over substrings (without additional parameters):
 
-            def viable(nums, allowedSum):
-                # there is always 1 section
-                sections = 1
-                curr = 0
+      res[N+1][N+1];                          //first: L, second: R
+      for (int s = 0; s<=N; s++)              //iterate size(length) of substring
+        for (int L = 0; L+s<=N; L++) {        //iterate left border index
+          int R = L + s;                      //right border index is clear
+          if (s <= 1) {                       
+            res[L][R] = DPBase(L, R);         //base of DP &mdash; no division
+            continue;
+          }
+          tres = ???;                          
+          for (int M = L+1; M<=R-1; M++)      //iterate through all divisions
+            tres = DPInduction(tres, res[L][M], res[M][R]);
+          res[L][R] = tres;
+        }
+      answer = DPAnswer(res[0][N]);
 
-                for i in nums:
-                    # curr += i
-                    if curr + i  > allowedSum:
-                        sections += 1
-                        curr = i 
-                        if sections > m:
-                            return False
-                
+-> Subtrees(vertices) of a given rooted tree
 
-                return True
-            
-            # do binsearch 
-            i, j = max(nums), sum(nums)
-            while i < j:
-                mid = i  + (j-i)//2
+    The problem involves a rooted tree. Sometimes a graph is given 
+    and its DFS search tree is used. Some sort of result can be calculated   
+    for each subtree. Since each subtree is uniquely identified by its root, 
+    we can treat DP over subtrees as DP over vertices. The result    
+    for each non-leaf vertex is determined by the results of its immediate children.
 
-                if viable(nums, mid):
-                    j = mid
-                else:
-                    i = mid + 1
+    The DP over subtree has a state domain in form (v,a) where v is a root of 
+    subtree and "a" may be some additional parameters. states are     
+    ordered naturally be tree order on vertices. Therefore the easiest way to 
+    iterate through states in correct order is to launch DFS from     
+    the root of tree. When DFS exits from a vertex, its result must 
+    be finally computed and stored in global memory. 
+    The code generally     looks like:
 
-            return i
+      bool vis[N];                                  //visited mark for DFS
+      res[N];                                       //DP result array
+    
+      void DFS(int v) {                             //visit v-rooted subtree recursively
+        vis[v] = true;                              //mark vertex as visited
+        res[v] = ???;                               //initial result, which is final result in case v is leaf
+        for (int i = 0; i<nbr[v].size(); i++) {     //iterate through all sons s
+          int s = nbr[v][i];                        
+          if (!vis[s]) {                            //if vertex is not visited yet, then it's a son in DFS tree
+            DFS(s);                                 //visit it recursively
+            res[v] = DPInduction(res[v], res[s]);   //recalculate result for current vertex
+          }
+        }
+      }
+      ...
+      memset(vis, false, sizeof(vis));              //mark all vertices as not visited
+      DFS(0);                                       //run DFS from the root = vertex 0
+      answer = DPAnswer(res[0]);                    //get problem answer from result of root
 
-        If you take a close look, you would probably see how similar 
-        this problem is with LC 1011 above. Similarly, we can design a 
-        feasible function: given an input threshold, then decide if we can 
-        split the array into several subarrays such that every subarray-sum 
-        is less than or equal to threshold. In this way, we discover the 
-        monotonicity of the problem: if feasible(m) is True, then all inputs 
-        larger than m can satisfy feasible function. You can see that the 
-        solution code is exactly the same as LC 1011.
-        Their soln:
-        
-        def splitArray(nums: List[int], m: int) -> int:        
-            def feasible(threshold) -> bool:
-                count = 1
-                total = 0
-                for num in nums:
-                    total += num
-                    if total > threshold:
-                        total = num
-                        count += 1
-                        if count > m:
-                            return False
-                return True
+    Sometimes the graph of problem is not connected (e.g. a forest). 
+    In this case run a series of DFS over the whole graph. The results for     
+    roots of individual trees are then combined in some way. 
+    Usually simple summation/maximum or a simple formula is enough 
+    but in tough cases this "merging problem" can turn out to require 
+    another DP solution.
 
-            left, right = max(nums), sum(nums)
-            while left < right:
-                mid = left + (right - left) // 2
-                if feasible(mid):
-                    right = mid     
-                else:
-                    left = mid + 1
-            return left
+    The DPInduction is very simple in case when there are no additional parameters. 
+    But very often state domain includes the additional     
+    parameters and becomes complicated. DPInduction turns out to be 
+    another(internal) DP in this case. Its state domain is (k,a) where k is     
+    number of sons of vertex considered so far and "a" is additional info. 
+    Be careful about the storage of results of this internal DP. 
+    If  you are solving optimization problem and you are required to 
+    recover the solution (not only answer) then you have to save results of     
+    this DP for solution recovering. In this case you'll have an array 
+    globalres[v,a] and an array internalres[v,k,a]. Topcoder problems    r
+    arely require solution, so storage of internal DP results is not necessary. 
+    It is easier not to store them globally. In the code below    
+    internal results for a vertex are initialized after all the sons 
+    are traversed recursively and are discarded after DFS exits a vertex.     
+    This case is represented in the code below:
+
+      bool vis[N];
+      gres[N][A];
+      intres[N+1][A];
+    
+      void DFS(int v) {
+        vis[v] = true;
+    
+        vector<int> sons;
+        for (int i = 0; i<nbr[v].size(); i++) {    //first pass: visit all sons and store their indices
+          int s = nbr[v][i];
+          if (!vis[s]) {
+            DFS(s);
+            sons.push_back(s);
+          }
+        }
+    
+        int SK = sons.size();                      //clear the internal results array
+        for (int k = 0; k<=SK; k++)
+          memset(intres[k], ?, sizeof(intres[k]));
     
+        for (int a = 0; a<A; a++)                  //second pass: run internal DP over array of sons
+          intres[0][a] = InternalDPBase(v, a);
+        for (int k = 0; k<SK; k++)                 //k = number of sons considered so far
+          for (int a = 0; a<A; a++)                //a = additional parameter for them
+            for (int b = 0; b<A; b++) {            //b = additional parameter for the son being added
+              int na = DPTransition(v, a, b);
+              int nres = DPInduction(intres[k][a], gres[sons[k]][b]);
+              intres[k+1][na] = DPMerge(intres[k+1][na], nres);
+            }
+        for (int a = 0; a<A; a++)                  //copy answer of internal DP to result for vertex
+          gres[v][a] = intres[SK][a];
+      }
+      ...
+      memset(vis, false, sizeof(vis));              //series of DFS
+      for (int v = 0; v<N; v++) if (!vis[v]) {
+        DFS(v);
+        ???                                         //handle results for connected component
+      }
+      ???                                           //get the answer in some way
 
-    3.   Koko Eating Bananas [Medium]
-        Koko loves to eat bananas. There are N piles of bananas, 
-        the i-th pile has piles[i] bananas. The guards have gone and 
-        will come back in H hours. Koko can decide her bananas-per-hour 
-        eating speed of K. Each hour, she chooses some pile of bananas, 
-        and eats K bananas from that pile. If the pile has less than K 
-        bananas, she eats all of them instead, and won't eat any more 
-        bananas during this hour.
+    It is very important to understand how time/space complexity is calculated 
+    for DP over subtrees. For example, the code just above   
+    requires O(N*A^2) time. Though dumb analysis says it 
+    is O(N^2*A^2): {N vertices} x {SK<=N sons for each} x A x A. 
+    Let Ki denote number    of sons of vertex i. Though each Ki may 
+    be as large as N-1, their sum is always equal to N-1 in a rooted tree. 
+    This fact is the key to     
+    further analysis. Suppose that DFS code for i-th vertex runs in not 
+    more than Ki*t time. Since DFS is applied only once to each vertex,     
+    the overall time will be TC(N) = sum(Ki*t) <= N*t. Consider t=A^2 for the case 
+    above and you'll get O(N*A^2) time complexity. To    benefit from this acceleration, 
+    be sure not to iterate through all vertices of graph in DFS. For example above, 
+    running memset for the     whole intres array in DFS will raise the time complexity. 
+    Time of individual DFS run will become O(N*A + Ki*A^2) instead of O(Ki*A^2).  
+    The overall time complexity will become O(N^2*A + N*A^2) which is great regress 
+    in case if A is much smaller that N. Using the same  approach you may achieve 
+    O(N*A) space complexity in case you are asked to recover solution. We have already 
+    said that to recover     solution you have to store globally the array 
+    internalres[v,k,a]. If you allocate memory for this array dynamically, then 
+    you can   ignore completely states with k>Ki. Since the sum of all Ki is N, 
+    you will get O(N*A) space.
 
-        Koko likes to eat slowly, but still wants to finish eating 
-        all the bananas before the guards come back. Return the minimum 
-        integer K such that she can eat all the bananas within H hours.
+-> Layer count + layer profile
 
-        Example :
+    This is the toughest type of DP state domain. It is usually used in 
+    tiling or covering problems on special graphs. The classic examples     
+    are: calculate number of ways to tile the rectangular board with dominoes 
+    (certain cells cannot be used); or put as many chess figures  
+    on the chessboard as you can so that they do not hit each other 
+    (again, some cells may be restricted).
 
-        Input: piles = [3,6,7,11], H = 8
-        Output: 4
-        Input: piles = [30,11,23,4,20], H = 5
-        Output: 30
-        Input: piles = [30,11,23,4,20], H = 6
-        Output: 23
+    Generally speaking, all these problems can be solved with DP over subsets 
+    (use set of all cells of board). DP with profiles is an   
+    optimization which exploits special structure in this set. The board we have 
+    to cover/tile is represented as an array of layers. We try   
+    to consider layers one by one and store partial solutions after each layer. 
+    In simple rectangular board case layer is one row of the  board. 
+    The profile is a subset of cells in current row which are already tiled.
 
-        Very similar to LC 1011 and LC 410 mentioned above. 
-        Let's design a feasible function, given an input speed, 
-        determine whether Koko can finish all bananas within H hours 
-        with hourly eating speed speed. Obviously, the lower bound 
-        of the search space is 1, and upper bound is max(piles), 
-        because Koko can only choose one pile of bananas to eat every hour.
+    The state domain has form (k,p) where k is number of fully processed layers 
+    and p is so-called profile of solution. Profile is the  necessary information 
+    about solution in layers that are not fully processed yet. 
+    The transitions go from (k,p) to (k+1,q) where q is     
+    some new profile. The number of transitions for each state is usually large, 
+    so they all are iterated through by recursive search,  
+    sometimes with pruning. The search has to find all the ways to 
+    increase the partial solution up to the next layer.
 
-        def minEatingSpeed(piles: List[int], H: int) -> int:
-            def feasible(speed) -> bool:
-                # return sum(math.ceil(pile / speed) for pile in piles) <= H  # slower        
-                return sum((pile - 1) // speed + 1 for pile in piles) <= H  # faster
+    The example code below calculates the number of way to fully 
+    cover empty cells on the given rectangular board with dominoes.
 
-            left, right = 1, max(piles)
-            while left < right:
-                mid = left  + (right - left) // 2
-                if feasible(mid):
-                    right = mid
-                else:
-                    left = mid + 1
-            return left
+    int res[M+1][1<<N];                     
+                                            //k = number of fully tiled rows               
+    int k, p, q;                            //p = profile of k-th row = subset of tiled cells
+    bool get(int i) {                       //q = profile of the next row (in search)        
+      return matr[k][i] == '#'              
+          || (p & (1<<i));                  //check whether i-th cell in current row is not free
+    }
+    void Search(int i) {                    //i = number of processed cells in current row
+      if (i == N) {
+        add(res[k+1][q], res[k][p]);        //the current row processed, make transition
+        return;
+      }
     
-    4.    Minimum Number of Days to Make m Bouquets [Medium]
-          
-        Given an integer array bloomDay, an integer m and an integer k. 
-        We need to make m bouquets. To make a bouquet, you need to use 
-        k adjacent flowers from the garden. The garden consists of n flowers, 
-        the ith flower will bloom in the bloomDay[i] and then can be 
-        used in exactly one bouquet. Return the minimum number of 
-        days you need to wait to be able to make m bouquets from the garden. 
-        If it is impossible to make m bouquets return -1.
-        Examples:
-        Input: bloomDay = [1,10,3,10,2], m = 3, k = 1
-        Output: 3
-        Explanation: Let's see what happened in the first three days. 
-        x means flower bloomed and _ means flower didn't bloom in the garden.
-        We need 3 bouquets each should contain 1 flower.
-        After day 1: [x, _, _, _, _]   // we can only make one bouquet.
-        After day 2: [x, _, _, _, x]   // we can only make two bouquets.
-        After day 3: [x, _, x, _, x]   // we can make 3 bouquets. The answer is 3.
-        
-        Input: bloomDay = [1,10,3,10,2], m = 3, k = 2
-        Output: -1
-        Explanation: We need 3 bouquets each has 2 flowers, 
-        that means we need 6 flowers. We only have 5 flowers 
-        so it is impossible to get the needed bouquets and we return -1.
-        
-        You can either enumerate all k length intervals, and m of them. 
-        Which may be hard?
-        Or we create a viable function and feed in an argument that is binary searched. 
-        ...
-        Algo:
-        Check if its viable first, if theres enough flowers. 
-        Viable function -> specify max time to wait. 
-        Which is between min(Array) and max(Array) inclusive. 
-        Then create interval -> it cant accept values that are bigger, 
-        otherwise create new interval -> if you werent able to create atleast m, then 
-        not viable. 
-        Binary search to find first viable?
-        Now that we've solved three advanced problems above, 
-        this one should be pretty easy to do. The monotonicity 
-        of this problem is very clear: if we can make m bouquets 
-        after waiting for d days, then we can definitely finish 
-        that as well if we wait for more than d days.
+      if (get(i)) {                         //if current cell is not free, skip it
+        Search(i+1);
+        return;
+      }
+    
+      if (i+1<N && !get(i+1))               //try putting (k,i)-(k,i+1) domino
+        Search(i+2);
+    
+      if (k+1<M && matr[k+1][i] != '#') {   //try putting (k,i)-(k+1,i) domino
+        q ^= (1<<i);     // PUT IT IN       //note that the profile of next row is changed
+        Search(i+1);
+        q ^= (1<<i);   // TAKE IT OUT OF "NEXT" ROW
+      }
+    }
+    ...
+    res[0][0] = 1;                          //base of DP
+    for (k = 0; k<M; k++)                   //iterate over number of processed layers
+      for (p = 0; p<(1<<N); p++) {          //iterate over profiles
+        q = 0;                              //initialize the new profile
+        Search(0);                          //start the search for all transitions
+      }
+    int answer = res[M][0];                 //all rows covered with empty profile = answer
 
-        def minDays(bloomDay: List[int], m: int, k: int) -> int:
-            def feasible(days) -> bool:
-                bonquets, flowers = 0, 0
-                for bloom in bloomDay:
-                    if bloom > days:
-                        flowers = 0
-                    else:
-                        bonquets += (flowers + 1) // k
-                        flowers = (flowers + 1) % k
-                return bonquets >= m
+    The asymptotic time complexity is not easy to calculate exactly. 
+    Since search for i performs one call to i+1 and one call to i+2, the   
+    complexity of individual search is not more than N-th Fibonacci number = fib(N). 
+    Moreover, if profile p has only F free cells it will     
+    require O(fib(F)) time due to pruning. If we sum C(N,F) fib(F) for all F we'll 
+    get something like (1+phi)^N, where phi is golden ratio.  
+    The overall time complexity is O(M * (1+phi)^N). Empirically it is even lower.
 
-            if len(bloomDay) < m * k:
-                return -1
-            left, right = 1, max(bloomDay)
-            while left < right:
-                mid = left + (right - left) // 2
-                if feasible(mid):
-                    right = mid
-                else:
-                    left = mid + 1
-            return left
-                    
+    The code is not optimal. Almost all DP over profiles should use "storing two layers" 
+    space optimization. Look "Optimizing DP solution"  recipe. Moreover DP over 
+    broken profiles can be used. In this DP state domain (k,p,i) is used, 
+    where i is number of processed cells in   a row. No recursive search is 
+    launched since it is converted to the part of DP. The time 
+    complexity is even lower with this solution.
+
+    The hard DP over profiles examples can include extensions like: 
+    1. Profile consists of more than one layer. 
+       For example to cover the    grid with three-length tiles you need to store 
+       two layers in the profile. 
+    2. Profile has complex structure. For example to find optimal    
+       in some sense hamiltonian cycle on the rectangular board you have 
+       to use matched parentheses strings as profiles. 
+    3. Distinct profile  structure. Set of profiles may be different for each layer. 
+       You can store profiles in map in this case.
 
+DONE READING -> GO TO COMPETITIVE/PROBLEMS to see all the usages of above techniques. 
+https://codeforces.com/blog/entry/43256
 
-    5.   Kth Smallest Number in Multiplication Table [Hard]
-        Nearly every one have used the Multiplication Table. 
-        But could you find out the k-th smallest number quickly 
-        from the multiplication table? Given the height m and the 
-        length n of a m * n Multiplication Table, and a positive 
-        integer k, you need to return the k-th smallest number in this table.
+#####################################################################################################################
+#####################################################################################################################
 
-        Example :
+COOL NOTES PART 1: DYNAMIC PROGRAMMING RECURRENCES EXAMPLES: 
+(In the code ->  &mdash; means minus sign. The html was parsed wrong)
+(For dp, define subproblem, then recurrence, then base cases, then implement)
 
-        Input: m = 3, n = 3, k = 5
-        Output: 3
-        Explanation: 
-        The Multiplication Table:
-        1	2	3
-        2	4	6
-        3	6	9
+1) Given n, find number of diff ways to write n as sum of 1, 3, 4
+    Let Dn be the number of ways to write n as the sum of 1, 3, 4
+    Recurrence: well n = x1 + x2 + ... + xm. If xm = 1, other terms sum to n-1
+    Sums that end with xm=1 is Dn-1
+
+    Recurrence => Dn = Dn-1 + Dn-3 + Dn-4
+    Solve base cases D0 = 1, Dn = 0 for all negative n. 
+    Code:    
+    D[0] = D[1] = D[2] = 1; D[3] = 2;
+    for(i = 4; i <= n; i++)
+        D[i] = D[i-1] + D[i-3] + D[i-4]
 
-        The 5-th smallest number is 3 (1, 2, 2, 3, 3).
 
+2) Given 2 strings x and y. Find Longest common subsequence. 
+    Let Dij be the length of LCS of x1...i, y1...j
+    D[i,j] = D[i-1,j-1] + 1 if xi = yj
+    D[i,j] = max{D[i-1, j], D[i, j-1]}  otherwise
 
-            5th smallest. Can we do a quick select? 
-            so partition, then look for value in left or right partion 
-            -> worst case O(n^2) -> best case O(n)
-            
-        
-        For Kth-Smallest problems like this, what comes to our mind 
-        first is Heap. Usually we can maintain a Min-Heap and just 
-        pop the top of the Heap for k times. However, that doesn't 
-        work out in this problem. We don't have every single number in 
-        the entire Multiplication Table, instead, we only have the height 
-        and the length of the table. If we are to apply Heap method, 
-        we need to explicitly calculate these m * n values and save 
-        them to a heap. The time complexity and space complexity of this 
-        process are both O(mn), which is quite inefficient. This is 
-        when binary search comes in. Remember we say that designing condition 
-        function is the most difficult part? In order to find the k-th smallest 
-        value in the table, we can design an enough function, given an input num, 
-        determine whether there're at least k values less than or 
-        equal to num. The minimal num satisfying enough function is the 
-        answer we're looking for. Recall that the key to binary search 
-        is discovering monotonicity. In this problem, if num satisfies 
-        enough, then of course any value larger than num can satisfy. 
-        This monotonicity is the fundament of our binary search algorithm.
+    Find and solve base cases(In top down, this is the base case for the recursion): 
+    D[i, 0] = D[0, j] = 0
+    D[0, all the js] = 0
+    D[all the is, 0] = 0
+    When implementing remember to look at your base cases and 
+    understand you have to start with those and build up!
+    Helps you figure out directionality!
 
-        Let's consider search space. Obviously the lower bound should be 1, 
-        and the upper bound should be the largest value in the Multiplication 
-        Table, which is m * n, then we have search space [1, m * n]. The 
-        overwhelming advantage of binary search solution to heap solution 
-        is that it doesn't need to explicitly calculate all numbers in that 
-        table, all it needs is just picking up one value out of the 
-        search space and apply enough function to this value, to determine 
-        should we keep the left half or the right half of the search 
-        space. In this way, binary search solution only requires constant 
-        space complexity, much better than heap solution.
+    def lcs(X , Y): 
+        # find the length of the strings 
+        m = len(X) 
+        n = len(Y) 
+    
+        # declaring the array for storing the dp values 
+        L = [[None]*(n+1) for i in xrange(m+1)] 
+    
+        """Following steps build L[m+1][n+1] in bottom up fashion 
+        Note: L[i][j] contains length of LCS of X[0..i-1] 
+        and Y[0..j-1]"""
+        for i in range(m+1): 
+            for j in range(n+1): 
+                if i == 0 or j == 0 : 
+                    L[i][j] = 0
+                elif X[i-1] == Y[j-1]: 
+                    L[i][j] = L[i-1][j-1]+1
+                else: 
+                    L[i][j] = max(L[i-1][j] , L[i][j-1]) 
+    
+        # L[m][n] contains the length of LCS of X[0..n-1] & Y[0..m-1] 
+        return L[m][n] 
 
-        Next let's consider how to implement enough function. 
-        It can be observed that every row in the Multiplication Table 
-        is just multiples of its index. For example, all numbers in 
-        3rd row [3,6,9,12,15...] are multiples of 3. Therefore, 
-        we can just go row by row to count the total number of entries 
-        less than or equal to input num. Following is the complete solution.
-        (Could probably binary search it form each row? 
-        nah cause we still have to check
-        each row, so speed benefit is trumped by that.)
+    
+3) Interval DP (IMPORTANT!)
+    Given a string x = x1..n, find the min number of chars that need to be inserted to make it a palindrome. 
+    Let D[i, j] be the min number of char that need to be inserted to make xi..j into a palindrome
 
-        def findKthNumber(m: int, n: int, k: int) -> int:
-            def enough(num) -> bool:
-                count = 0
-                for val in range(1, m + 1):  # count row by row
-                    add = min(num // val, n)
-                    if add == 0:  # early exit
-                        break
-                    count += add
-                return count >= k                
+    Consider shortest palindrome y1..k containing xi..j. Either y1 = xi or yk = xj.
+    y[2..k-1] is then an optimal solution for x[i+1..j] or x[i..j-1] or x[i+1..j-1]
+    Recurrence:
 
-            left, right = 1, n * m
-            while left < right:
-                mid = left + (right - left) // 2
-                if enough(mid):
-                    right = mid
-                else:
-                    left = mid + 1
-            return left 
-                
-    6.   Find K-th Smallest Pair Distance [Hard]
-       Given an integer array, return the k-th smallest distance 
-       among all the pairs. The distance of a pair (A, B) is 
-       defined as the absolute difference between A and B.
+    Dij = 1 + min(D[i+1, j], D[i, j-1]) if xi != xj
+    Dij  = D[i+1,j-1] if xi=xj  otherwise   
+    
+    Base Case: 
+    D[i,i] = D[i, i-1] = 0 for all i
+    
+    Solution subproblem is D[1, n] => i = 1, j = n
 
-       Example :
+    Directionality is hard here:
+    //fill in base cases here
+    for(t = 2, t<= n; t++):
+        for(i = 1, j =t, j <= n; ++i, ++j):
+            //fill in D[i][j] here
 
-       Input:
-       nums = [1,3,1]
-       k = 1
-       Output: 0 
-       Explanation:
-       Following are all the pairs. The 1st smallest 
-        distance pair is (1,1), and its distance is 0.
-       (1,3) -> 2
-       (1,1) -> 0
-       (3,1) -> 2
+    => We used t to fill in table correctly! This is interval DP! 
+    => This is the correct directionality. DIRECTIONALITY IS BASED ON YOUR BASE CASESE!!!
+    => A good way to figure out how to fill up table is just to write out example D[i][j] and figure
+        out how you are filling them up with your base cases.
+    
+	// Recursive Approach
+	int f(string s, int i, int j, vector<vector<int>>& dp) {
+        if(i >= j)
+            return 0;
+        if(dp[i][j] != -1)
+            return dp[i][j];
+        if(s[i] == s[j])
+            return dp[i][j] = f(s, i + 1, j - 1, dp);
+        int op1 = 1 + f(s, i + 1, j, dp);
+        int op2 = 1 + f(s, i, j - 1, dp);
+        return dp[i][j] = min(op1, op2); 
+    }
 
-       Ok so sort it, [1,1,3]
-       -> now 1,1 1,3 1,3 -> 0, 2, 2
-       Number of pairs is 3 x 2  _ _ <- using space theory. 
-       Lets binary search the space. 
-       min -> difference between 1st and 2nd pair.
-           -> largest diff -> 1st and last pair
+      int minInsertions(string s) {
+        vector<vector<int>> dp(s.size(), vector<int>(s.size(), 1e6));
+        int n = s.size();
+        for(int i = 0; i < n; i++)
+            dp[i][i] = 0;
+        for(int len = 1; len <= n; len++) {
+            for(int i = 0; i + len < n; i++) {
+                dp[i][i] = 0;
+                int j = i + len;
+                if(s[i] == s[j]) {
+                    if(len == 1)
+                        dp[i][j] = 0;
+                    else
+                        dp[i][j] = dp[i + 1][j - 1];
+                }
+                else {
+                    dp[i][j] = min(1 + dp[i + 1][j], 1 + dp[i][j - 1]);
+                }
+            }
+        }
+        return dp[0][n - 1];
+   }
+   
 
-        Enough function 
-        
-        -> Use 2 pointers and check when the difference 
-        is too much 
-        keep first ptr on left most, then increment right
-        when difference gets too big, then start reducing first ptr?
 
-        Very similar to LC 668 above, both are about finding Kth-Smallest. Just like LC 668, 
-        We can design an enough function, given an input distance, determine whether 
-        there're at least k pairs whose distances are less than or 
-        equal to distance. We can sort the input array and use two pointers 
-        (fast pointer and slow pointer, pointed at a pair) to scan it. 
-        Both pointers go from leftmost end. If the current pair pointed 
-        at has a distance less than or equal to distance, all pairs between 
-        these pointers are valid (since the array is already sorted), we move 
-        forward the fast pointer. Otherwise, we move forward the slow pointer. 
-        By the time both pointers reach the rightmost end, we finish our 
-        scan and see if total counts exceed k. Here is the implementation:
+    Solution 2:
+    Reverse x to get x-reversed.
+    The answer is n - L where L is the length of the LCS of x and x-reversed
 
-        ENOUGH FUNCTION IS O(N) DO YOU KNOW WHY!
-        MEMORIZE IT!!! SLIDING WINDOW, 
-        It is O(N). the possible function is a classic sliding windowing solution, 
-        left and right would always increment in each outer loop iteration. 
-        So time complexity is O(2N) = O(N).
+    Intuition
+    Split the string s into to two parts,
+    and we try to make them symmetrical by adding letters.
 
-        [1,3,6,10,15, END]
-         ^         ^
-        Lets say dist is 11 so ptrs end up like above. 
-        Count is 4-0-1 = 3 pairs
-        
-        [1,3,6,10,15,END]
-           ^       ^
-        Lets say dist is 11 so ptrs end up like above. 
-        Count is 4-1-1 = 2 pairs          
+    The more common symmetrical subsequence they have,
+    the less letters we need to add.
 
-        [1,3,6,10,15,END]
-             ^       ^
+    Now we change the problem to find the length of longest common sequence.
+    This is a typical dynamic problem.
 
-        Lets say dist is 11 so ptrs end up like above. 
-        Count is 5-2-1 = 2 pairs    
+4) Subset DP => requires bitmasking!
+    Given a weighted graph with n nodes, find the shortest path that visits every node exactly once (TSP)
+    
+    D[S, v] the length of optimal path that visits every node in the set S exactly once and ends at v. 
+    there are n2^n subproblems
+    Answer is min{v in V such that D[V, v]} where V is the given set of nodes. 
 
-        def enough(distance) -> bool:  # two pointers
-            count, i, j = 0, 0, 0
-            while i < n or j < n:
-                while j < n and nums[j] - nums[i] <= distance:  # move fast pointer
-                    j += 1
-                count += j - i - 1  # count pairs
-                i += 1  # move slow pointer
-            return count >= k
-        
-        Obviously, our search space should be [0, max(nums) - min(nums)]. 
-        Now we are ready to copy-paste our template:
+    Base Case: 
+    For each node v, D[{v}, v] = 0
+    Recurrence:
+    consider TSP path. Right before arivign at v, the path comes from some u in S - {v}, and that subpath
+    has to be the optimal one that covers S- {v} ending at u.
+    Just try all possible candidates for u
 
-        def smallestDistancePair(nums: List[int], k: int) -> int:
-            nums.sort()
-            n = len(nums)
-            left, right = 0, nums[-1] - nums[0]
-            while left < right:
-                mid = left + (right - left) // 2
-                if enough(mid):
-                    right = mid
-                else:
-                    left = mid + 1
-            return left
-                
-        ANOTHER IMPLEMENTATION:
+    D[S, v] = min[u in S - {v}] (D[S-{v}][u] + cost(u, v) )
 
-        class Solution(object):
-            def smallestDistancePair(self, nums, k):
-                def possible(guess):
-                    #Is there k or more pairs with distance <= guess?
-                    count = left = 0
-                    for right, x in enumerate(nums):
-                        while x - nums[left] > guess:
-                            left += 1
-                        count += right - left
-                    return count >= k
+    Use integer to represet set. 19 = 010011 represents set {0, 1, 4}
+    Union of two sets x and y: x | y
+    Set intersection: x & y
+    Symmetic difference: x ^ y
+    singleton set {i}: 1 << i
+    Membership test: x & (1 << i) != 0
 
-                nums.sort()
-                lo = 0
-                hi = nums[-1] - nums[0]
-                while lo < hi:
-                    mi = (lo + hi) / 2
-                    if possible(mi):
-                        hi = mi
-                    else:
-                        lo = mi + 1
-                return lo
-        
-    7.    Ugly Number III [Medium]
-       Write a program to find the n-th ugly number. 
-       Ugly numbers are positive integers which are 
-       divisible by a or b or c.
+#######################################
+##########################################
+
+COOL Notes PART 1.5: DP with bitmasking example: 
+    Problem
+    Your task will be to calculate number of different assignments of n different 
+    topics to n students such that everybody gets exactly one topic he likes.
+    1 means the student likes the subject. 0 means they dont.
 
-       Example :
+    Solution:
+        Defining the DP state
+        So, we can define our DP state with two variables, 
+        'k' and 'B' as :
 
-       Input: n = 3, a = 2, b = 3, c = 5
-       Output: 4
-       Explanation: The ugly numbers are 2, 3, 4, 5, 6, 8, 9, 10... The 3rd is 4.
-       Input: n = 4, a = 2, b = 3, c = 4
-       Output: 6
-       Explanation: The ugly numbers are 2, 3, 4, 6, 8, 9, 10, 12... The 4th is 6.
+        DP(k,B) = Total no. of possible arrangements of 
+        students 0 to k choosing subset of subjects as per bitmask B.
 
-        Nothing special. Still finding the Kth-Smallest. 
-        We need to design an enough function, given an input num, 
-        determine whether there are at least n ugly numbers less than or equal to num. Since a might be a multiple of b or c, or the other way round, 
-        we need the help of greatest common divisor to avoid counting duplicate numbers.
+        Time for some optimization. The best way to optimize a DP solution is to 
+        reduce its "dimension", i.e, reduce the no. of state variables. 
+        In or case, we can see that k = No. of set bits in B. So, k 
+        can be easily calculated from B and hence not a part of our DP states anymore.
 
-        def nthUglyNumber(n: int, a: int, b: int, c: int) -> int:
-            def enough(num) -> bool:
-                // Triple set addition!
-                total = mid//a + mid//b + mid//c - mid//ab - mid//ac - mid//bc + mid//abc
-                return total >= n
+        The new DP state is :
 
-            ab = a * b // math.gcd(a, b) # LCM
-            ac = a * c // math.gcd(a, c) # LCM
-            bc = b * c // math.gcd(b, c) # LCM
-            abc = a * bc // math.gcd(a, bc)
-            left, right = 1, 10 ** 10
-            while left < right:
-                mid = left + (right - left) // 2
-                if enough(mid):
-                    right = mid
-                else:
-                    left = mid + 1
-            return left
+        DP(B) = Total no. of possible arrangements of students 
+        0 to k assigning subjects as per bitmask B.
 
+        where k = count set bits of B
+        The base case should be DP(0) = 1 , as there is 
+        exactly 1 way to arrange 0 students and 0 subjects.
 
-    8.    Find the Smallest Divisor Given a Threshold [Medium]
-       Given an array of integers nums and an integer threshold, 
-       we will choose a positive integer divisor and divide all 
-       the array by it and sum the result of the division. Find 
-       the smallest divisor such that the result mentioned above 
-       is less than or equal to threshold.
+        For a state B , we can define the recurrence relation as follows :
 
-       Each result of division is rounded to the nearest integer 
-       greater than or equal to that element. (For example: 7/3 = 3 
-       and 10/2 = 5). It is guaranteed that there will be an answer.
+        where k = number of set bits in B,
 
-       Example :
+            DP(B) = for each i'th set bit in B, 
+            check  whether k'th student likes i'th subject. 
+            if true, DP(B) += DP(unset i'th bit from B)
 
-       Input: nums = [1,2,5,9], threshold = 6
-       Output: 5
-       Explanation: We can get a sum to 17 (1+2+5+9) if the divisor is 1. 
-       If the divisor is 4 we can get a sum to 7 (1+1+2+3) and 
-       if the divisor is 5 the sum will be 5 (1+1+1+2). 
+        basically, for any arrangement, we remove 
+        one bit at a time and add up the resulting 
+        state if it satisfies the "liking" criteria. 
+        For example :
 
+        DP(1011) = DP(0011) + DP(1001) + DP(1010)
 
-       After so many problems introduced above, this one 
-       should be a piece of cake. We don't even need to bother 
-       to design a condition function, because the problem has 
-       already told us explicitly what condition we need to satisfy.
+        (assuming 3rd student likes 1st, 3rd and 
+        4th subjects. If he didn't like any of 
+        those, then those disliked states wouldn't be added)
 
-       def smallestDivisor(nums: List[int], threshold: int) -> int:
-           def condition(divisor) -> bool:
-               return sum((num - 1) // divisor + 1 for num in nums) <= threshold
+        logically, this can be explained as follows :
 
-           left, right = 1, max(nums)
-           while left < right:
-               mid = left + (right - left) // 2
-               if condition(mid):
-                   right = mid
-               else:
-                   left = mid + 1
-           return left
+        for a DP state 1011, the 3rd student can be assigned 
+        to either 1st,3rd or 4th subject. Now, if the student 
+        was assigned to 1st subject, then the number of ways to 
+        assign the previous students is given by DP(0011). 
+        Similarly, if 3rd student gets 3rd subject, we 
+        add DP(1001), and for 4th subject we add DP(1010).
 
-###################################################################################
-###################################################################################
+        Implementation
+        in practice, we create a single dimensional array of 
+        size 1<<20 (i.e. 2^20) . Let it be called DP[ ].
+        First, set DP[0] = 1 ;
+        then , run a loop from 1 to (1<<n)-1 (i.e. (2^n)-1) to generate all possible bitmasks
+        for each index of the loop, apply the recurrence relation as discussed above
+        finally, DP[(1<<n)-1] gives the answer.
 
-BINARY SEARCH DIFFERENT TEMPLATES AND THEIR USE CASES!!!!!!
+        //base case
+	    dp[0] = 1;
+      
+        //recurrence relation implemented
+        for (int j = 1; j < (1 << n) ; j++) {
+            int idx = Integer.bitCount(j);
+            for (int k = 0; k < n; k++) {
+                if (likes[idx-1][k] == false || (j & (1 << k)) == 0)
+                    continue;
+                dp[j] += dp[(j & ~(1 << k))];
+            }
+        }
+        
+        //final answer
+        System.out.println(dp[(1 << n) -1]);
 
-Tip
-Personally,
-If I want find the index, I always use while (left < right)
-If I may return the index during the search, I'll use while (left <= right)
+#######################################################
+#######################################################
 
+COOL Notes PART 1.7:
 
-I like you tip, summary of 2 most frequently used binary search templates.
-one is return index during the search:
+    Sorted Lists Python Intro:
+    (A btree with high load factor instead of a binary tree)
+    295. Find Median from Data Stream
 
-while lo <= hi:
-  mid = (lo+hi)/2
-  if nums[mid] == target:
-    return mid
-  if nums[mid] > target:
-    hi = mid-1
-  else:
-    lo = mid+1
-return -1
+        The median is the middle value in an ordered integer list. If the size of the list is even, there is 
+        no middle value and the median is the mean of the two middle values.
 
-Another more frequently used binary search template is for searching lowest 
-element satisfy function(i) == True (the array should satisfy function(x) == False 
-for 0 to i-1, and function(x) == True for i to n-1, and it is up to the question to 
-define the function, like in the find peak element problem, function(x) can be nums[x] < nums[x+1] ), 
-there are 2 ways to write it:
+        For example, for arr = [2,3,4], the median is 3.
+        For example, for arr = [2,3], the median is (2 + 3) / 2 = 2.5.
+        Implement the MedianFinder class:
 
-while lo <= hi:
-  mid = (lo+hi)/2
-  if function(mid):
-    hi = mid-1
-  else:
-    lo = mid+1
-return lo
+        MedianFinder() initializes the MedianFinder object.
+        void addNum(int num) adds the integer num from the data stream to the data structure.
+        double findMedian() returns the median of all elements so far. Answers within 10-5 of the actual answer will be accepted.
 
-or
 
-while lo <  hi:
-  mid = (lo+hi)/2
-  if function(mid):
-    hi = mid
-  else:
-    lo = mid+1
-return lo
+    Usual soln is -> 2 heaps.
 
-No matter which one you use, just be careful about updating the hi and lo, which 
-could easily lead to infinite loop. Some binary question is searching a floating 
-number and normally the question will give you a precision, in which case you 
-don't need to worry too much about the infinite loop but your while 
-condition will become something like "while lo+1e-7<hi"
+    Another type of soln: BSTs:
+    find size of bst, then search for it? we can look for 
+    particular keys but how do we find the nth element (besides quick select)
+    
+    search for N//2
+    
+    from sortedcontainers import SortedList
+    class MedianFinder:
+        def __init__(self):
+            self.srr = SortedList()  # SortedList has insert O(log(n)) can hold duplicates and remains sorted upon insertion.
+            self.n = 0
+        def addNum(self, x: int) -> None:
+            self.srr.add(x)
+            self.n += 1
+        def findMedian(self) -> float:
+            if self.n%2==1:
+                return self.srr[self.n//2]  # Access element O(1)
+            else:
+                return (self.srr[self.n//2]+self.srr[self.n//2-1])/2
+    
+    Lets try it on 
+        315. Count of Smaller Numbers After Self
 
+        You are given an integer array nums and you have to return a new counts array. 
+        The counts array has the property where counts[i] is the number of smaller 
+        elements to the right of nums[i].
 
-For people who are wondering about the section of the post,
 
-"If I want find the index, I always use while (left < right)
-If I may return the index during the search, I'll use while (left <= right)"
+        from sortedcontainers import SortedList
 
-Let's use the array a = [1,2,3] as an example, where we're searching for key = 3
+        class Solution:
+            def countSmaller(self, nums: List[int]) -> List[int]:
+                n = len(nums)
+                ans = [0] * n
+                sortedList = SortedList()
+                for i in range(n - 1, -1, -1):
+                    index = sortedList.bisect_left(nums[i])
+                    ans[i] = index
+                    sortedList.add(nums[i])
+                return ans
+        Complexity:
 
-If we know the index definitely exists, then we use while l < r
+        Time: O(NlogN)
+        Space: O(N)
 
-We first search 2, notice that 2 < key. So we set l = res = mid+1. 
-We break the loop since l == r and return res. Because res is the 
-only possible answer left, and since we know the index exists, we just return that.
+    Click to see SortedList behind the scene!
+    SortedList implementation: https://github.com/grantjenks/python-sortedcontainers/blob/master/sortedcontainers/sortedlist.py.
 
-Now if we don't know if the index exists, then we set l = mid+1 and 
-only set res if a[mid] == key. We still have to check the final 
-possibility, because we don't know whether or not that index contains the key.
+    Basically, it divides a big problem into smaller sub problems and store sorted elements into sublists, each sublist stores 
+    up to loadFactor=1000 elements by default. There are 2 main internal variables:
+        _lists: store list of sublists, each sublist stores elements in sorted order. 
+                When the size of the sublist grows very big which is greater than 2*loadFactor, it will split into 2 smaller sublists.
+        _maxes: store maximum of each sublists.
 
+    When we do bisect_left, bisect_right or add in SortedList. It does binary search in _maxes to find the 
+            index of corresponding sublist. Then call bisect_left, bisect_right or insort in that sublist.
 
+    There are 3 basic operations, which all cost O(logN) in time complexity:
 
+    bisect_left(val): find index to be inserted in the left side. For example: sortedList = [1, 3, 3, 4], 
+        then arr.bisect_left(3) = 1, arr.bisect_left(2) = 1, arr.bisect_left(4) = 3
+    bisect_right(val): find index to be inserted in the right side. For example: sortedList = [1, 3, 3, 4], 
+        then arr.bisect_right(3) = 3, arr.bisect_right(2) = 1, arr.bisect_right(4) = 4
+    add(val): allow to add value into our SortedList.
+    
+    Then we just simply iteterate array from right to left, use bisect_left(val) to found left insert 
+        index and its index is also a number of elements less than val.
 
 
+    (count-of-smaller-numbers-after-self - leetcode)
+    from sortedcontainers import SortedList
 
-###################################################################################
-###################################################################################
-COOL NOTES PART 0.90: DYNAMIC PROGRAMMING PATTERNS, ILLUSTRATIONS, AND EXAMPLES: 
+    class Solution:
+        def countSmaller(self, nums):
+            SList, ans = SortedList(), []
+            for num in nums[::-1]:
+                ind = SortedList.bisect_left(SList, num)
+                ans.append(ind)
+                SList.add(num)
+                
+            return ans[::-1]
 
-    Patterns
-    Minimum (Maximum) Path to Reach a Target
-    Distinct Ways
-    Merging Intervals
-    DP on Strings
-    Decision Making
 
-    Minimum (Maximum) Path to Reach a Target
-    Statement
-    Given a target find minimum (maximum) cost / path / sum to reach the target.
 
-    Approach
-    Choose minimum (maximum) path among all possible paths 
-    before the current state, then add value for the current state.
+#######################################################
+#######################################################
 
-    routes[i] = min(routes[i-1], routes[i-2], ... , routes[i-k]) + cost[i]
-    Generate optimal solutions for all values in the target and return the value for the target.
+COOL NOTES 1.8: DIVIDE AND CONQUER AND MODIFIED MERGE SORT STRATEGIES!!!
++ BSTS, SORTEDLISTS, SEGMENT TREES, FENWICK TREES QQUICK INTRO! PART 1
+    Merge Sort Modification TO SOLVE PROBLEMS!!
 
-    for (int i = 1; i <= target; ++i) {
-        for (int j = 0; j < ways.size(); ++j) {
-            if (ways[j] <= i) {
-                dp[i] = min(dp[i], dp[i - ways[j]] + cost / path / sum) ;
-            }
-        }
-    }
-    return dp[target]
 
-    Similar Problems
+        MergeSort(arr[], l,  r)
+        If r > l
+            1. Find the middle point to divide the array into two halves:  
+                    middle m = l+ (r-l)/2
+            2. Call mergeSort for first half:   
+                    Call mergeSort(arr, l, m)
+            3. Call mergeSort for second half:
+                    Call mergeSort(arr, m+1, r)
+            4. Merge the two halves sorted in step 2 and 3:
+                    Call merge(arr, l, m, r)
 
-    1.   Min Cost Climbing Stairs Easy
-    for (int i = 2; i <= n; ++i) {
-        dp[i] = min(dp[i-1], dp[i-2]) + (i == n ? 0 : cost[i]);
-    }
-    return dp[n]
-    
-    1.  Minimum Path Sum Medium
-    for (int i = 1; i < n; ++i) {
-        for (int j = 1; j < m; ++j) {
-            grid[i][j] = min(grid[i-1][j], grid[i][j-1]) + grid[i][j];
-        }
-    }
-    return grid[n-1][m-1]
-    
-    1.   Coin Change Medium
-    for (int j = 1; j <= amount; ++j) {
-        for (int i = 0; i < coins.size(); ++i) {
-            if (coins[i] <= j) {
-                dp[j] = min(dp[j], dp[j - coins[i]] + 1);
-            }
-        }
-    }
 
-    1.   Minimum Falling Path Sum Medium
-    2.   Minimum Cost For Tickets Medium
-    3.   2 Keys Keyboard Medium
-    4.   Perfect Squares Medium
-    5.    Last Stone Weight II Medium
-    6.   Triangle Medium
-    7.   Ones and Zeroes Medium
-    8.   Maximal Square Medium
-    9.   Coin Change Medium
-    10.   Tiling a Rectangle with the Fewest Squares Hard
-    11.  Dungeon Game Hard
-    12.  Minimum Number of Refueling Stops Hard
 
-    Distinct Ways
-    Statement
-    Given a target find a number of distinct ways to reach the target.
+        Some of the applications of merge sort:-
+        1.Given an integer array nums, return the number of good pairs in the array.
+        A good pair is a pair (i, j) where 0 <= i < j < nums.length and nums[i] > nums[j].
 
-    Approach
-    Sum all possible ways to reach the current state.
+        [1,3,2,4,0]
 
-    routes[i] = routes[i-1] + routes[i-2], ... , + routes[i-k]
-    Generate sum for all values in the target and return the value for the target.
 
-    for (int i = 1; i <= target; ++i) {
-        for (int j = 0; j < ways.size(); ++j) {
-            if (ways[j] <= i) {
-                dp[i] += dp[i - ways[j]];
+        -> merge sort
+        1 3 2 merge 4 0
+        0 1 2       3 4 
+
+        Approach1:- brute force :- take two nested loop and iterate from 0 to nums.size and check the condition 
+        nums[i]>nums[j].If the condition satisfies then increment the count .
+
+        int goodPair(vector<int>&nums)
+        {
+            int count=0;
+            for(int i=0;i<nums.size();i++)
+            {
+                    for(int j=i+1;j<nums.size();j++)
+                        {
+                                if(nums[i]>nums[j])
+                                        {
+                                            count++;
+                                        }
+                            }
             }
+            return count;
         }
-    }
-    return dp[target]
-    
-    Similar Problems
-    1.  Climbing Stairs easy
-    for (int stair = 2; stair <= n; ++stair) {
-        for (int step = 1; step <= 2; ++step) {
-            dp[stair] += dp[stair-step];   
-        }
-    }
 
-    1.  Unique Paths Medium
-    for (int i = 1; i < m; ++i) {
-        for (int j = 1; j < n; ++j) {
-            dp[i][j] = dp[i][j-1] + dp[i-1][j];
-        }
-    }
+        Now its time complexity is O(n2).
 
-    1.    Number of Dice Rolls With Target Sum Medium
+        Can we optimise?? If yes then how??
+        Hint:- use Merge sort
 
-        You have d dice, and each die has 
-        f faces numbered 1, 2, ..., f.
+        First divide the array and at the time of merging just apply the condition and check .If the condition satisfies ,increment count.
 
-        Return the number of possible ways (out of f^d total ways) modulo 10^9 + 7 
-        to roll the dice so the sum of the face up numbers equals target.
-        Example 1:
-        Input: d = 1, f = 6, target = 3
-        Output: 1
-        Explanation: 
-        You throw one die with 6 faces.  There is only one way to get a sum of 3.
+        int goodPairs(vector<int>& nums) {
+                ret = 0;
+                mergeSort(nums, 0, nums.size()-1);
+                return ret;
+            }
         
-        Example 2:
-        Input: d = 2, f = 6, target = 7
-        Output: 6
-        Explanation: 
-        You throw two dice, each with 6 faces.  There are 6 ways to get a sum of 7:
-        1+6, 2+5, 3+4, 4+3, 5+2, 6+1.
-
-    for (int rep = 1; rep <= d; ++rep) {
-        vector<int> new_ways(target+1);
-        for (int already = 0; already <= target; ++already) {
-            for (int pipe = 1; pipe <= f; ++pipe) {
-                if (already - pipe >= 0) {
-                    new_ways[already] += ways[already - pipe];
-                    new_ways[already] %= mod;
+            void mergeSort(vector<int>& nums, int left, int right) {
+                if (right <= left) {
+                    return;
                 }
+                int middle = left + (right - left)/2;
+                mergeSort(nums, left, middle);
+                mergeSort(nums,middle+1, right);
+        
+                //count elements
+                int count = 0;
+                for (int l = left, r = middle+1; l <= middle;) {
+                    if (r > right || nums[l] <= nums[r]) {
+                        l++;
+                        ret += count;
+                    } else {
+                        r++;
+                        count++;
+                    }
+                }
+                
+                //sort
+                sort(nums.begin()+left, nums.begin()+right + 1);   
             }
-        }
-        ways = new_ways;
-    }
 
 
-    Note
-
-    Some questions point out the number of repetitions, 
-    in that case, add one more loop to simulate every repetition.
 
-    1.   Knight Probability in Chessboard Medium
-    2.   Target Sum Medium
-    3.   Combination Sum IV Medium
-    4.   Knight Dialer Medium
-    5.    Dice Roll Simulation Medium
-    6.   Partition Equal Subset Sum Medium
-    7.   Soup Servings Medium
-    8.   Domino and Tromino Tiling Medium
-    9.   Minimum Swaps To Make Sequences Increasing
-    10.  Number of Longest Increasing Subsequence Medium
-    11. Unique Paths II Medium
-    12.  Out of Boundary Paths Medium
-    13.   Number of Ways to Stay in the Same Place After Some Steps Hard
-    14.   Count Vowels Permutation Hard
+        Similar problem:-1.https://leetcode.com/problems/reverse-pairs/
+        2.https://leetcode.com/problems/count-of-smaller-numbers-after-self/
 
-    Merging Intervals
-    Statement
-    Given a set of numbers find an optimal solution 
-    for a problem considering the current number 
-    and the best you can get from the left and right sides.
+        Second type of use of merge sort:-
+        1.merging of sorted arrays
+        2.merging of sorted list
 
-    Approach
-    Find all optimal solutions for every interval 
-    and return the best possible answer.
+        **Similar problem:--https://leetcode.com/problems/merge-k-sorted-lists/
+        2.https://leetcode.com/problems/sort-list/
+        **
 
-    // from i to j
-    dp[i][j] = dp[i][k] + result[k] + dp[k+1][j]
-    Get the best from the left and right sides and add a solution for the current position.
 
-    for(int l = 1; l<n; l++) {
-        for(int i = 0; i<n-l; i++) {
-            int j = i+l;
-            for(int k = i; k<j; k++) {
-                dp[i][j] = max(dp[i][j], dp[i][k] + result[k] + dp[k+1][j]);
-            }
-        }
-    }
-    return dp[0][n-1]
     
-    
-    Similar Problems
-    1.    Minimum Cost Tree From Leaf Values Medium
+    The C++ merge sort template for pairs 'i', 'j' problem:
+        // [l, r) is the interval to be sorted
+        int sort_count(iterator l, iterator r) {
+            if (r - l <= 1) return; 
+            // step 1. find the middle
+            iterator m = l + (r - l) / 2;
+            // step 2. sort left and right subarray
+            int count = sort_count(l, m) + sort_count(m, r);
+            /* step 3. write your code here for counting the pairs (i, j).*/
+                    
+            // step 4. call inplace_merge to merge
+            inplace_merge(l, m, r);
+            return count;
+        }
 
+        C++ provides built-ins for merge sort including:
 
-    Given an array arr of positive integers, 
-    consider all binary trees that can be possibly constructed
-    from the arr:
+        merge(l1.begin(), l1.end(), l2.begin(), l2.end(), result.begin()); which stores the merged array in result
+        inplace_merge(l.begin(), l.middle, l.end()) where array [begin, middle) is merged with array [middle, end)
 
-    Each node has either 0 or 2 children;                               
-    The values of arr correspond to the values of each 
-    leaf in an in-order traversal of the tree.  
-    The value of each non-leaf node is equal to the 
-    product of the largest leaf value 
-    in its left and right subtree respectively.
-    Among all possible binary trees considered, return the 
-    smallest possible sum of the values of each non-leaf node.  
-    It is guaranteed this sum fits into a 32-bit integer.
+        LeetCode 315. Count of Smaller Numbers After Self. Return the number of js such that i < j and nums[j] < nums[i].
 
-    for (int l = 1; l < n; ++l) {
-        for (int i = 0; i < n - l; ++i) {
-            int j = i + l;
-            dp[i][j] = INT_MAX;
-            for (int k = i; k < j; ++k) {
-                dp[i][j] = min(dp[i][j], dp[i][k] + dp[k+1][j] + maxs[i][k] * maxs[k+1][j]);
+            #define iterator vector<vector<int>>::iterator
+            void sort_count(iterator l, iterator r, vector<int>& count) {
+                if (r - l <= 1) return;
+                iterator m = l + (r - l) / 2;
+                sort_count(l, m, count);
+                sort_count(m, r, count);
+                for (iterator i = l, j = m; i < m; i++) {
+                    while (j < r && (*i)[0] > (*j)[0]) j++;
+                    count[(*i)[1]] += j - m; // add the number of valid "j"s to the indices of *i
+                }
+                inplace_merge(l, m, r);
+            }
+            vector<int> countSmaller(vector<int>& nums) {
+                vector<vector<int>> hold;
+                int n = nums.size();
+                for (int i = 0; i < n; ++i) hold.push_back(vector<int>({nums[i], i})); // "zip" the nums with their indices
+                vector<int> count(n, 0);
+                sort_count(hold.begin(), hold.end(), count);
+                return count;
             }
-        }
-    }
 
-    1.  Unique Binary Search Trees Medium
-    2.    Minimum Score Triangulation of Polygon Medium
-    3.   Remove Boxes Medium
-    4.    Minimum Cost to Merge Stones Medium
-    5.   Burst Balloons Hard
-    6.   Guess Number Higher or Lower II Medium
 
-    DP on Strings
-    General problem statement for this pattern 
-    can vary but most of the time you are given 
-    two strings where lengths of those strings are not big
+    Continued Merge Sort Strategy Theory:
+        493. Reverse Pairs
 
-    Statement
-    Given two strings s1 and s2, return some result.
+        Given an integer array nums, return the number of reverse pairs in the array.
+        A reverse pair is a pair (i, j) where 0 <= i < j < nums.length and nums[i] > 2 * nums[j].
 
-    Approach
-    Most of the problems on this pattern requires 
-    a solution that can be accepted in O(n^2) complexity.
+        Input: nums = [1,3,2,3,1]
+        Output: 2
+        ----
 
-    // i - indexing string s1
-    // j - indexing string s2
-    for (int i = 1; i <= n; ++i) {
-        for (int j = 1; j <= m; ++j) {
-            if (s1[i-1] == s2[j-1]) {
-                dp[i][j] = /*code*/;
-            } else {
-                dp[i][j] = /*code*/;
-            }
-        }
-    }
 
-    If you are given one string s the approach may little vary
+        It looks like a host of solutions are out there (BST-based, BIT-based, Merge-sort-based). 
+        Here I'd like to focus on the general principles behind these solutions and its possible
+        application to a number of similar problems.
 
-    for (int l = 1; l < n; ++l) {
-        for (int i = 0; i < n-l; ++i) {
-            int j = i + l;
-            if (s[i] == s[j]) {
-                dp[i][j] = /*code*/;
-            } else {
-                dp[i][j] = /*code*/;
+        The fundamental idea is very simple: break down the array and solve for the subproblems.
+
+
+        SLOW O(n^2) python soln: BISECT:
+
+        def reversePairs(self, nums: List[int]) -> int:
+            res = 0
+            sorted_values = []
+            for j in range(len(nums)):
+                i = bisect.bisect_right(sorted_values, 2 * nums[j])
+                res += (j - i)
+                bisect.insort(sorted_values, nums[j])
+            return res
+
+
+        BST soln 1:
+ 
+            1. BST-based solution
+
+            we will define the tree node as follows, where val is the node value and cnt is the total number of elements 
+            in the subtree rooted at current node that are greater than or equal to val:
+
+            class Node {
+                int val, cnt;
+                Node left, right;
+                    
+                Node(int val) {
+                    this.val = val;
+                    this.cnt = 1;
+                }
             }
-        }
-    }
 
-    1.    Longest Common Subsequence Medium
-    for (int i = 1; i <= n; ++i) {
-        for (int j = 1; j <= m; ++j) {
-            if (text1[i-1] == text2[j-1]) {
-                dp[i][j] = dp[i-1][j-1] + 1;
-            } else {
-                dp[i][j] = max(dp[i-1][j], dp[i][j-1]);
+            The searching and insertion operations can be done as follows:
+
+            private int search(Node root, long val) {
+                if (root == null) {
+                    return 0;
+                } else if (val == root.val) {
+                    return root.cnt;
+                } else if (val < root.val) {
+                    return root.cnt + search(root.left, val);
+                } else {
+                    return search(root.right, val);
+                }
             }
-        }
-    }
 
-    
-    1.   Palindromic Substrings Medium
-    for (int l = 1; l < n; ++l) {
-        for (int i = 0; i < n-l; ++i) {
-            int j = i + l;
-            if (s[i] == s[j] && dp[i+1][j-1] == j-i-1) {
-                dp[i][j] = dp[i+1][j-1] + 2;
-            } else {
-                dp[i][j] = 0;
+            private Node insert(Node root, int val) {
+                if (root == null) {
+                    root = new Node(val);
+                } else if (val == root.val) {
+                    root.cnt++;
+                } else if (val < root.val) {
+                    root.left = insert(root.left, val);
+                } else {
+                    root.cnt++;
+                    root.right = insert(root.right, val);
+                }
+                
+                return root;
             }
-        }
-    }
+            
+            Note: this homemade BST is not self-balanced and the time complexity can go as bad as O(n^2) 
+            (in fact you will get TLE if you copy and paste the solution here). To guarantee O(nlogn) performance, 
+            use one of the self-balanced BST's (e.g. Red-black tree, AVL tree, etc.).
 
-    1.   Longest Palindromic Subsequence Medium
-    2.    Shortest Common Supersequence Medium
-    3.  Edit Distance Hard
-    4.   Distinct Subsequences Hard
-    5.   Minimum ASCII Delete Sum for Two Strings Medium
-    6. Longest Palindromic Substring Medium
+            public int reversePairs(int[] nums) {
+                int res = 0;
+                Node root = null;
+                    
+                for (int ele : nums) {
+                    res += search(root, 2L * ele + 1);
+                    root = insert(root, ele);
+                }
+                
+                return res;
+            }    
 
-    Decision Making
-    The general problem statement for this pattern is 
-    forgiven situation decide whether to use or 
-    not to use the current state. So, the 
-    problem requires you to make a decision at a current state.
+        BST soln 2:
+            KEEP TRACK NODES GREATER THAN OR EQUAL TO YOU!
 
-    Statement
-    Given a set of values find an answer with an 
-    option to choose or ignore the current value.
 
-    Approach
-    If you decide to choose the current value use the 
-    previous result where the value was ignored; 
-    vice-versa, if you decide to ignore the 
-    current value use previous result where value was used.
+            class Node:
+                def __init__(self, val):
+                    self.val = val
+                    self.ge_cnt = 0
+                    self.left = None
+                    self.right = None
 
-    // i - indexing a set of values
-    // j - options to ignore j values
-    for (int i = 1; i < n; ++i) {
-        for (int j = 1; j <= k; ++j) {
-            dp[i][j] = max({dp[i][j], dp[i-1][j] + arr[i], dp[i-1][j-1]});
-            dp[i][j-1] = max({dp[i][j-1], dp[i-1][j-1] + arr[i], arr[i]});
-        }
-    }
+            class Solution:
+                def reversePairs(self, nums: List[int]) -> int:
+                    if not nums:
+                        return 0
+                    
+                    root = None
+                    ans = 0
+                    cp_nums = nums.copy()
+                    cp_nums.sort()
+                    root = self.bst(cp_nums, 0, len(nums) - 1)
+                    
+                    for num in nums:
+                        ans += self.search(root, 2 * num + 1)
+                        root = self.update(root, num)
+                    
+                    return ans
 
-    1.   House Robber Easy
+                def search(self, root, val):
+                    if not root:
+                        return 0
+                    
+                    if root.val < val:
+                        ans = self.search(root.right, val)
+                    elif root.val > val:
+                        ans = self.search(root.left, val) + root.ge_cnt
+                    else:
+                        ans = root.ge_cnt
+                    
+                    return ans
+                
+                def update(self, root, val):
+                    if root.val == val:
+                        root.ge_cnt += 1
+                    elif root.val < val:
+                        root.ge_cnt += 1
+                        self.update(root.right, val)
+                    else:
+                        self.update(root.left, val)
+                    return root
+                
+                def bst(self, nums, l, r):
+                    if l > r:
+                        return None
+                    m = l + (r - l) // 2
+                    root = Node(nums[m])
+                    root.left = self.bst(nums, l, m - 1)
+                    root.right = self.bst(nums, m + 1, r)
+                    return root
+  
 
-    for (int i = 1; i < n; ++i) {
-        dp[i][1] = max(dp[i-1][0] + nums[i], dp[i-1][1]);
-        dp[i][0] = dp[i-1][1];
-    }
-    
-    1.   Best Time to Buy and Sell Stock Easy
-    2.   Best Time to Buy and Sell Stock with Transaction Fee Medium
-    3.   Best Time to Buy and Sell Stock with Cooldown Medium
-    4.   Best Time to Buy and Sell Stock III Hard
-    5.   Best Time to Buy and Sell Stock IV Hard
+        MERGE SORT SOLN1 :
 
-###########################################################################################
-############################################################################################
-COOL NOTES 0.95 CODEFORCES DP 1
+            MergeSort solution
 
-    MEMOIZATION VS FORWARD STYLE DP VS BACKWARD STYLE DP AND RECOVERING THE DP SOLUTION
+            class Solution(object):
+                def reversePairs(self, nums):
+                    if not nums:
+                        return 0
+                    
+                    return self.mergesort(nums)[1]
+                
+                
+                def mergesort(self, nums):
+                    if len(nums) <= 1:
+                        return nums, 0
+                    m = len(nums)//2
+                    left, countl = self.mergesort(nums[:m])
+                    right, countr = self.mergesort(nums[m:])
+                    count = countl + countr
+                    for r in right:
+                        temp = len(left) - bisect.bisect(left, 2*r)
+                        if temp == 0:
+                            break
+                        count += temp
+                    
+                    return sorted(left+right), count   
 
-    Memoization vs DP:
+        Merge Sort soln2:
 
-    The memoization approach does not spend time on unnecessary states — 
-    it is a lazy algorithm. Only the states which influence the 
-    final answer are processed. Here are the pros and cons of memoization 
-    over 
-    DP: 1[+]. Sometimes easier to code. 
-    2[+]. Does not require to specify order on states explicitly. 
-    3[+]. Processes only necessary states. 
-    4[-]. Works only in the backward-style DP. 
-    5[-]. Works a bit slower than DP (by constant).
+            # O(nlogn)
+            def countSmaller(self, nums: List[int]) -> List[int]:
+                nums = nums[::-1]
+                nums = [(n,i) for i,n in enumerate(nums)]
+                res = [0]*len(nums)
+                
+                def mergesort(l,r):
+                    if l == r:
+                        return 
+                    mid = (l+r)//2
+                    mergesort(l,mid)
+                    mergesort(mid+1,r)
+                    
+                    i = l
+                    # O(n)
+                    for j in range(mid+1,r+1):
+                        while i < mid+1 and nums[i][0] < nums[j][0]:
+                            i += 1
+                        res[nums[j][1]] += i-l
+                    
+                    # nums[l:r+1] = sorted(nums[l:r+1]) The TC of this line is nlogn, 
+                    # I think you need to use merge to replace this line
+                    nums[l:r+1] = sorted(nums[l:r+1])
 
-    Forward vs backward DP style
-    backward style. The schema is: iterate through all the states 
-    and for each of them calculate the result by looking backward 
-    and using the already known DP results of previous states. 
-    This style can also be called recurrent since it uses recurrent 
-    equations directly for calculation. The relations for backward-style 
-    DP are obtained by examining the best solution for the state 
-    and trying to decompose it to lesser states. 
-    (YOU HAVE SEEN BACKWARD STYLE PLENTY OF TIMES!)
+                    
+                mergesort(0,len(nums)-1) if nums else None
 
-    There is also forward-style DP. Surprisingly it is often more 
-    convenient to use. The paradigm of this style is to iterate 
-    through all the DP states and from each state perform some transitions 
-    leading forward to other states. Each transition modifies the currently 
-    stored result for some unprocessed states. When the state is considered, 
-    its result is already determined completely. The forward formulation does 
-    not use recurrent equations, so it is more complex to prove the correctness 
-    of solution strictly mathematically. The recurrent relations used in forward-style 
-    DP are obtained by considering one partial solution for the state and trying to 
-    continue it to larger states. To perform forward-style DP it is necessary to 
-    fill the DP results with neutral values before starting the calculation
-    
-    Problem 1:
-    Given a list of n coins, their weights W1, W2, ..., Wn; and the total sum S. 
-    Find the minimum number of coins the overall weight of which is 
-    S (we can use as many coins of each type as we want)
+                return res[::-1]           
 
-    FOWARD STYLE DP (IT USES RELAXTION LIKE DJIKSTRA/BELLMAN FORD):
 
-    The first example will be combinatoric coins problem. 
-    Suppose that you have a partial solution with P overall weight. 
-    Then you can add arbitrary coin with weight Wi and get overall weight P+Wi. 
-    So you get a transition from state (P) to state (P+Wi). When 
-    this transition is considered, the result for state (P) is added to 
-    the result of state (P+Wi) which means that all the ways to get P weight 
-    can be continued to the ways to get P+Wi weight by adding i-th coin. 
-    Here is the code.
 
-    /* Recurrent relations (transitions) of DP:
-    {k[0] = 1;
-    {(P)->k ===> (P+Wi)->nk    add k to nk
-    */
-    //res array is automatically filled with zeroes
-    res[0] = 1;                                 //DP base is the same
-    for (int p = 0; p<s; p++)                   //iterate through DP states
-        for (int i = 0; i<n; i++) {               //iterate through coin to add
-        int np = p + wgt[i];                    //the new state is (np)
-        if (np > s) continue;                   //so the transition is (p) ==> (np)
-        res[np] += res[p];                      //add the DP result of (p) to DP result of (np)
-        }
-    int answer = res[s];                        //problem answer is the same
+####################################################
+#####################################################
 
-    PROBLEM 2: LCS
-    The second example is longest common subsequence problem. 
-    It is of maximization-type, so we have to fill the results array 
-    with negative infinities before calculation. The DP base is state (0,0)->0 
-    which represents the pair of empty prefixes. When we consider partial 
-    solution (i,j)->L we try to continue it by three ways: 
-    1. Add the next letter of first word to the prefix, do not change subsequence. 
-    2. Add the next letter of the second word to the prefix, do not change subsequence. 
-    3. Only if the next letters of words are the same: add next letter 
-        to both prefixes and include it in the subsequence. 
-    
-    For each transition we perform so-called relaxation of the larger DP state result. 
-    We look at the currently stored value in that state: if it is 
-    worse that the proposed one, then it is replaced with the proposed one, 
-    otherwise it is not changed. The implementation code and compact 
-    representation of DP relations are given below.
+COOL NOTES 1.8: MODIFIED MERGE SORT STRATEGIES!!!
++ BSTS, SORTEDLISTS, SEGMENT TREES, FENWICK TREES QQUICK INTRO! PART 2
 
-    /* Recurrent relations (transitions) of DP:
-    {L[0,0] = 0;
-    |          /> (i+1,j)->relax(L)
-    {(i,j)->L ==> (i,j+1)->relax(L)
-                \> (i+1,j+1)->relax(L+1)  (only if next symbols are equal)
-    */
-    void relax(int &a, int b) {                   //relaxation routine
-    if (a < b) a = b;
-    }
-    
-    memset(lcs, -63, sizeof(lcs));              //fill the DP results array with negative infinity
-    lcs[0][0] = 0;                              //set DP base: (0,0)->0
-    for (int i = 0; i<=n1; i++)
-        for (int j = 0; j<=n2; j++) {             //iterate through all states
-        int tres = lcs[i][j];
-        // Improve the next states from the current state, and what we see rn. 
-        // Djikstra relax style!
-        relax(lcs[i+1][j], tres);               //try transition of type 1
-        relax(lcs[i][j+1], tres);               //try transition of type 2
-        if (str1[i] == str2[j])                 //and if next symbols are the same
-            relax(lcs[i+1][j+1], tres + 1);       //then try transition of type 3
-        }
-    int answer = lcs[n1][n2];
+        BIT TREE SOLN (count-of-smaller-numbers-after-self)
+            First get rank, the smallest number will be rank 1, the second smallest will be rank 2...
+            With this rank info binary indexed tree can be used to count smaller numbers as we scan from right to left.
 
-    Recovering the best solution for optimization problems
+            The quantity i & -i reveals the last non-zero bit in the binary representation of the integer i.
 
-    DP finds only the goal function value itself. 
-    It does not produce the best solution along 
-    with the numerical answer. 
+            def countSmaller(self, nums):
+                rank, N, res = {val: i + 1 for i, val in enumerate(sorted(nums))}, len(nums), []
+                BITree = [0] * (N + 1)
+                
+                def update(i):
+                    while i <= N:
+                        BITree[i] += 1
+                        i += (i & -i)
+
+                def getSum(i):
+                    s = 0
+                    while i:
+                        s += BITree[i]
+                        i -= (i & -i)
+                    return s
+                
+                for x in reversed(nums):
+                    res.append(getSum(rank[x] - 1))
+                    update(rank[x])
+                return res[::-1]
 
-    There are two ways to get the solution path.
-    METHOD 1: REVERSE DP
-    The first way is to recalculate the DP from the end to the start. 
-    First we choose the final state (f) we want to trace the path from. 
-    Then we process the (f) state just like we did it in the DP: 
-    iterate through all the variants to get it. Each variant originates 
-    in a previous state (p). If the variant produces the result equal 
-    to DP result of state (f), then the variant if possible. There is 
-    always at least one possible variant to produce the DP result for 
-    the state, though there can be many of them. If the variant 
-    originating from (p) state is possible, then there is at least 
-    one best solution path going through state (p). Therefore we can
-    move to state (p) and search the path from starting state to 
-    state (p) now. We can end path tracing when we reach the starting state.
 
-    METHOD 2: BACKLINKS
+        BIT TREE SOLN (493. Reverse Pairs):
+            For BIT, the searching and insertion operations are:
 
-    Another way is to store back-links along with the DP result. 
-    For each state (s) we save the parameters of the previous state (u) 
-    that was continued. When we perform a transition (u) ==> (s) which 
-    produces better result than the currently stored in (s) then we set 
-    the back-link to (s) to the state (u). To trace the DP solution path 
-    we need simply to repeatedly move to back-linked state until the 
-    starting state is met. Note that you can store any additional 
-    info about the way the DP result was obtained to simplify 
-    solution reconstruction.
+            private int search(int[] bit, int i) {
+                int sum = 0;
+                
+                while (i < bit.length) {
+                    sum += bit[i];
+                    i += i & -i;
+                }
 
-    Use first method if memory is a problem. Otherwise use method 2. 
+                return sum;
+            }
 
-    EXAMPLE OF RECOVERING THE SOLUTION PATH:
+            private void insert(int[] bit, int i) {
+                while (i > 0) {
+                    bit[i] += 1;
+                    i -= i & -i;
+                }
+            }
 
-    /* Consider the input data: S=11, n=3, W = {1,3,5}
-    The DP results + back-links table is:
-    P  = 0 |1 |2 |3 |4 |5 |6 |7 |8 |9 |10|11
-    -------+--+--+--+--+--+--+--+--+--+--+--
-    mink = 0 |1 |2 |1 |2 |1 |2 |3 |2 |3 |2 |3
-    prev = ? |S0|S1|S0|S1|S0|S1|S2|S3|S4|S5|S6
-    item = ? |I0|I0|I1|I1|I2|I2|I2|I2|I2|I2|I2
-    */
-    
-    int mink[MAXW];                       //the DP result array
-    int prev[MAXW], item[MAXW];           //prev  -  array for back-links to previous state
-    int k;                                //item  -  stores the last item index
-    int sol[MAXW];                        //sol[0,1,2,...,k-1] would be the desired solution
-    
-    memset(mink, 63, sizeof(mink));     //fill the DP results with positive infinity
-    mink[0] = 0;                        //set DP base (0)->0
-    for (int p = 0; p<s; p++)           //iterate through all states
-        for (int i = 0; i<n; i++) {       //try to add one item
-        int np = p + wgt[i];            //from (P)->k we get
-        int nres = mink[p] + 1;         //to (P+Wi)->k+1
-        if (mink[np] > nres) {          //DP results relaxation
-            mink[np] = nres;              //in case of success
-            prev[np] = p;                 //save the previous state
-            item[np] = i;                 //and the used last item
-        }
-        }
-    
-    int answer = mink[s];
-    int cp = s;                         //start from current state S
-    while (cp != 0) {                   //until current state is zero
-        int pp = prev[cp];                //get the previous state from back-link
-        sol[k++] = item[cp];              //add the known item to solution array
-        cp = pp;                          //move to the previous state
-    }
 
+            And the main program, where again we will search for all elements greater than twice of current element
+            while insert the element itself into the BIT. For each element, the "index" function will return 
+            its index in the BIT. Unlike the BST-based solution, this is guaranteed to run at O(nlogn).
 
-###########################################################################################
-############################################################################################
-COOL NOTES 0.98 CODEFORCES DP 2 
-    OPTIMIZING DP
+            public int reversePairs(int[] nums) {
+                int res = 0;
+                int[] copy = Arrays.copyOf(nums, nums.length);
+                int[] bit = new int[copy.length + 1];
+                
+                Arrays.sort(copy);
+                
+                for (int ele : nums) {
+                    res += search(bit, index(copy, 2L * ele + 1));
+                    insert(bit, index(copy, ele));
+                }
+                
+                return res;
+            }
 
-    -> Consolidate equivalent states
+            private int index(int[] arr, long val) {
+                int l = 0, r = arr.length - 1, m = 0;
+                    
+                while (l <= r) {
+                    m = l + ((r - l) >> 1);
+                        
+                    if (arr[m] >= val) {
+                        r = m - 1;
+                    } else {
+                        l = m + 1;
+                    }
+                }
+                
+                return l + 1;
+            }
 
-        Consider TSP problem as an example. The bruteforce recursive 
-        solution searches over all simple paths from city 0 recursively. 
-        State of this solution is any simple path which starts from city 0. 
-        In this way a state domain is defined and the recursive relations 
-        for them are obvious. But then we can notice that states (0,A,B,L) 
-        and (0,B,A,L) are equivalent. It does not matter in what order the 
-        internal cities were visited — only the set of visited cities and the 
-        last city matter. It means that our state domain is redundant, so let's 
-        merge the groups of equivalent states. We will get state domain (S,L)->R 
-        where S is set of visited states, L is the last city in the path and R is the 
-        minimal possible length of such path. The recursive solution with O((N-1)!) 
-        states is turned into DP over subsets with O(2^N*N) states.
 
-    -> Prune impossible states
-        The state is impossible if its result is always equal to 
-        zero(combinatorial) / infinity(minimization). Deleting such a state is a 
-        good idea since it does not change problem answer for sure. 
-        The impossible states can come from several sources:
-       
-       1. Explicit parameter dependence. The state domain is (A,B) and we know that for all 
-          possible states B = f(A) where f is some function (usually analytic and simple). In 
-          such a case B parameter means some unnecessary information and can be deleted from 
-          state description. The state domain will be just (A). If we ever need parameter B to 
-          perform a transition, we can calculate it as f(A). As the result the size of 
-          state domain is decreased dramatically.
+            More explanation for the BIT-based solution:
 
-       2. Implicit parameter dependence. This case is worse. We have state domain (A,B) 
-          where A represents some parameters and we know that for any possible state f(A,B) = 0. 
-          In other words, for each possible state some property holds. The best idea is of course 
-          to express one of parameters as explicitly dependent on the others. Then we can go to 
-          case 1 and be happy=) Also if we know that B is either f1(A) or f2(A) or f3(A) or ... or fk(A) 
-          then we can change state domain from (A,B) to (A,i) where i=1..k is a number of equation 
-          B variant. If nothing helps, we can always use approach 4.
+            We want the elements to be sorted so there is a sorted version of the input array which is copy.
 
-       3. Inequalities on parameters. The common way to exploit inequalities 
-          for parameters is to set tight loop bounds. For example, if state domain 
-          is (i,j) and i<j then we can write for(i=0;i<N;i++) for(j=i+1;j<N;j++) 
-          or for(j=0;j<N;j++) for(i=0;i<j;i++). In this case we avoid processing impossible 
-          states and average speedup is x(2). If there are k parameters which are 
-          non-decreasing, speedup will raise to x(k!).
+            The bit is built upon this sorted array. Its length is one greater than that of the copy array to account for the root.
 
-       4. No-thinking ways. Even if it is difficult to determine 
-           which states are impossible, the fact of their existence 
-           itself can be exploited. There are several ways:
+            Initially the bit is empty and we start doing a sequential scan of the input array. For each element being scanned,
+            we first search the bit to find all elements greater than twice of it and add the result to res. 
+            We then insert the element itself into the bit for future search.
 
-            A. Discard impossible states and do not process them. Just add 
-            something like "if (res[i][j]==0) continue;" inside loop which iterates over 
-            DP states and you are done. This optimization should be always used because 
-            overhead is tiny but speedup can be substantial. It does not decrease size of 
-            state domain but saves time from state processing.
+            Note that conventionally searching of the bit involves traversing towards the root from some index of the bit, 
+            which will yield a predefined running total of the copy array up to the corresponding index. For insertion, the 
+            traversing direction will be opposite and go from some index towards the end of the bit array.
 
-            B. Use recursive search with memoization. It will behave very similar to DP 
-            but will process only possible states. The decision to use it must be made before 
-            coding starts because the code differs from DP code a lot.
+            For each scanned element of the input array, its searching index will be given by the 
+            index of the first element in the copy array that is greater than twice of it (shifted up by 1 
+            to account for the root), while its insertion index will be the index of the first element in the 
+            copy array that is no less than itself (again shifted up by 1). This is what the index function is for.
 
-            C. Store state results in a map. This way impossible states do not eat memory and time at all. 
-            Unfortunately, you'll have to pay a lot of time complexity for this technique: O(log(N)) with 
-            ordered map and slow O(1) with unordered map. And a big part of code must 
-            be rewritten to implement it.>
+            For our case, the running total is simply the number of elements encountered during the traversal process. 
+            If we stick to the convention above, the running total will be the number of elements smaller than the one 
+            at the given index, since the copy array is sorted in ascending order. However, we'd actually like to find 
+            the number of elements greater than some value (i.e., twice of the element being scanned), therefore we need 
+            to flip the convention. This is what you see inside the search and insert functions: the former traversing 
+            towards the end of the bit while the latter towards the root.
 
-    -> Store results only for two layers of DP state domain
 
-        The usual case is when result for state (i,A) is dependent only on 
-        results for states (i-1,*). In such a DP only two neighbouring layers 
-        can be stored in memory. Results for each layer are discarded after 
-        the next one is calculated. The memory is then reused for the next layer and so on.
+    IS THIS A FAST WAY TO MAKE A SEGMENT TREE SOLN??
+        (For count-of-smaller-numbers-after-self)
+        class SegmentTreeNode:
+            def __init__(self, low, high):
+                self.low = low
+                self.high = high
+                self.left = None
+                self.right = None
+                self.cnt = 0
+                
+        class Solution: 
+            def _build(self, left, right):
+                root = SegmentTreeNode(self.nums[left], self.nums[right])
+                if left == right:
+                    return root
+                
+                mid = (left+right)//2
+                root.left = self._build(left, mid)
+                root.right = self._build(mid+1, right)
+                return root
+            
+            def _update(self, root, val):
+                if not root:
+                    return 
+                if root.low <= val <= root.high:
+                    root.cnt += 1
+                    self._update(root.left, val)
+                    self._update(root.right, val)
+                    
+            def _query(self, root, lower, upper):
+                if lower <= root.low and root.high <= upper:
+                    return root.cnt
+                if upper < root.low or root.high < lower:
+                    return 0
+                return self._query(root.left, lower, upper) + self._query(root.right, lower, upper)
+            
+            # O(nlogn)
+            def countSmaller(self, nums: List[int]) -> List[int]:
+                nums = nums[::-1]
+                self.nums = sorted(list(set(nums)))
+                root = self._build(0, len(self.nums)-1)  if nums else None
+                
+                res = []
+                for n in nums:
+                    res.append(self._query(root,float('-inf'),n-1)) 
+                    self._update(root, n)
+                return res[::-1]
 
 
-        Memory contains two layers only. One of them is current layer and another one is previous layer 
-        (in case of forward DP one layer is current and another is next). After current layer is fully processed, 
-        layers are swapped. There is no need to swap their contents, just swap their pointers/references. 
-        Perhaps the easiest approach is to always store even-numbered layers in one memory buffer(index 0) 
-        and odd-numbered layers in another buffer(index 1). To rewrite complete and working 
-        DP solution to use this optimization you need to do only: 
-        1. In DP results array definition, change the first size of array to two. 
-        2. Change indexation [i] to [i&1] in all accesses to this array. (i&1 is equal to i modulo 2). 
-        3. In forward DP clear the next layer contents immediately after loop over layer 
-              index i. Here is the code example of layered forward-style minimization DP: 
-              int res[2][MAXK]; //note that first dimension is only 2 
-              for (int i = 0; i<N; i++) 
-              { 
-                  memset(res[(i+1)&1], 63, sizeof(res[0])); //clear the contents of next layer (set to infinity) 
-                  for (int j = 0; j<=K; j++) { //iterate through all states as usual 
-                    int ni = i + 1; //layer index of transition destination is fixed 
-                    int nj, nres = DPTransition(res[i&1][j], ???); //get additional parameters and results somehow 
-                    if (res[ni&1][nj] > nres) //relax destination result 
-                        res[ni&1][nj] = nres; //note &1 in first index 
-                  } 
-            }
 
-        This technique reduces memory requirement in O(N) times which is 
-        often necessary to achieve desired space complexity. If sizeof(res) 
-        reduces to no more than several megabytes, then speed performance 
-        can increase due to cache-friendly memory accesses.
 
-        Sometimes you have to store more than two layers. If DP transition relations 
-        use not more that k subsequent layers, then you can store only k layers in memory. 
-        Use modulo k operation to get the array index 
-        for certain layer just like &1 is used in the example.
 
-        There is one problem though. In optimization problem there is no simple way 
-        to recover the path(solution) of DP. You will get the goal function of best solution, 
-        but you won't get the solution itself. To recover solution in usual 
-        way you have to store all the intermediate results.
+    SEGMENT TREE SOLN 2:
+
+
+        class SegmentTreeNode(object):
+            def __init__(self, val, start, end):
+                self.val = val
+                self.start = start
+                self.end = end
+                self.children = []
+
+
+        class SegmentTree(object):
+            def __init__(self, n):
+                self.root = self.build(0, n - 1)
 
-        There is a general trick which allows to recover path 
-        without storing all the DP results. The path can be recovered using divide and conquer method. 
-        Divide layers into approximately two halves and choose the middle layer with index m in 
-        between. Now expand the result of DP from (i,A)->R to (i,A)->R,mA where mA is the "middle state". 
-        It is value of additional parameter A of the state that lies both on the path and in the middle layer. 
-        Now let's see the following: 
-        1. After DP is over, problem answer is determined as minimal result in final layer (with certain properties maybe). 
-        2. Let this result be R,mA. Then (m,mA) is the state in the middle of the path we want to recover.
-        3. The results mA can be calculated via DP. Now we know the final and the middle states of the desired path. 
-        4. Divide layers into two halves and launch the same DP for each part recursively. 
-        5. Choose final state as answer for the right half and middle state as answer for the left half. 
-        6. Retrieve two states in the middle of these halves and continue recursively.
-        7.  This technique requires additional O(log(N)) time complexity because result for each layer 
-        8.  is recalculated approximately log(N) times.
-        9.  If some additional DP parameter is monotonous (for each transition (i,A) — (i+1,B) inequality A<=B holds) 
-            then domain of this parameter can also be divided into two halves by the middle point. 
-            In such a case asymptotic time complexity does not increase at all.
+            def build(self, start, end):
+                if start > end:
+                    return
 
+                root = SegmentTreeNode(0, start, end)
+                if start == end:
+                    return root
 
-    -> Precalculate
+                mid = (start + end) / 2
+                root.children.append(self.build(start, mid))
+                root.children.append(self.build(mid + 1, end))
+                return root
 
-        Often DP solution can benefit from precalculating something. 
-        Very often the precalculation is simple DP itself.
+            def update(self, i, val, root=None):
+                root = root or self.root
+                if i < root.start or i > root.end:
+                    return root.val
 
-        A lot of combinatorial problems require precalculation of binomial coefficients. 
-        You can precalculate prefix sums of an array so that you can calculate sum of 
-        elements in segment in O(1) time. Sometimes it is beneficial to 
-        precalculate first k powers of a number.
+                if i == root.start == root.end:
+                    root.val += val
+                    return root.val
 
-        Although the term precalculation refers to the calculations which are going 
-        before the DP, a very similar thing can be done in the DP process. 
-        For example, if you have state domain (a,b)->R you may find it useful to create 
-        another domain (a,k)->S where S is sum of all R(a,b) with b<k. 
-        It is not precisely precalculation since it expands the DP state domain, 
-        but it serves the same goal: spend some additional 
-        time for the ability to perform a particular operation quickly.>
+                root.val = sum([self.update(i, val, c) for c in root.children])
+                return root.val
 
-    -> Rotate the optimization problem (ROTATION TECHNIQUE DONE IN ConnectTheCities.py in Competition folder)
+            def sum(self, start, end, root=None):
+                root = root or self.root
+                if end < root.start or start > root.end:
+                    return 0
 
+                if start <= root.start and end >= root.end:
+                    return root.val
 
-        There is a DP solution with state domain (W,A)->R for maximization problem, 
-        where W is weight of partial solution, A is some additional parameter 
-        and R is maximal value of partial solution that can be achieved. 
-        The simple problem unbounded knapsack problem will serve as an example for DP rotation.
+                return sum([self.sum(start, end, c) for c in root.children])
 
-        Let's place additional requirement on the DP: if we increase weight W of partial 
-        solution without changing other parameters including result the solution worsens. 
-        Worsens means that the solution with increased weight can be discarded if the initial 
-        solution is present because the initial solution leads to better problem answer 
-        than the modified one. Notice that the similar statement must true for result R in 
-        any DP: if we increase the result R of partial solution the solution improves. 
-        In case of knapsack problem the requirement is true: we have some partial solution; 
-        if another solution has more weight and less value, then it is surely worse t
-        han the current one and it is not necessary to process it any further. 
-        The requirement may be different in sense of sign (minimum/maximum. worsens/improves).
 
-        This property allows us to state another "rotated" DP: (R,A)->W where R is the value of partial solution, 
-        A is the same additional parameter, and W is the minimal possible weight for such a partial solution. 
-        In case of knapsack we try to take items of exactly R overall value with the least overall 
-        weight possible. The transition for rotated DP is performed the same way. 
-        The answer for the problem is obtained as usual: iterate through all 
-        states (R,A)->W with desired property and choose solution with maximal value.
+        class Solution(object):
+            def countSmaller(self, nums):
+                ordering = {v: i for i, v in enumerate(sorted(set(nums)))}
+
+                tree = SegmentTree(len(ordering))
+                results = []
+                for i in reversed(range(len(nums))):
+                    results.append(tree.sum(0, ordering[nums[i]] - 1))
+                    tree.update(ordering[nums[i]], 1)
+                return results[::-1]
+            
 
-        To understand the name of the trick better imagine a grid on the plane 
-        with coordinates (W,R) where W is row index and R is column index. 
-        As we see, the DP stores only the result for rightmost(max-index) cell in each row. 
-        The rotated DP will store only the uppermost(min-index) cell in each column. 
-        Note the DP rotation will be incorrect if the requirement stated above does not hold.
+    BIT TREE SOLN 2:
 
-        The rotation is useful only if the range of possible values R is much less than the 
-        range of possible weights W. The state domain will take O(RA) memory instead of O(WA) 
-        which can help sometimes. For example consider the 0-1 knapsack problem with arbitrary 
-        positive real weights and values. DP is not directly applicable in this case. 
-        But rotated DP can be used to create fully polynomial approximation scheme which 
-        can approximate the correct answer with relative error not more than arbitrary threshold. 
-        The idea is to divide all values by small eps and round to the nearest integer. 
-        Then solve DP with state domain (k,R)->W where k is number of already processed items, 
-        R is overall integer value of items and W is minimal possible overall weight. Note that 
-        you cannot round weights in knapsack problem because the optimal solution you obtain 
-        this way can violate the knapsack size constraint.
+        class BinaryIndexedTree(object):
+            def __init__(self, n):
+                self.sums = [0] * (n + 1)
 
-    -> Calculate matrix power by squaring
+            def update(self, i, val):
+                while i < len(self.sums):
+                    self.sums[i] += 1
+                    i += i & -i
 
-        This technique deals with layered combinatorial DP solution with transition independent 
-        of layer index. Two-layered DP has state domain (i,A)->R and recurrent rules 
-        in form R(i+1,A) = sum(R(i,B)*C(B)) over all B parameter values. It is important that 
-        recurrent rules does not depend on the layer index.
+            def sum(self, i):
+                r = 0
+                while i > 0:
+                    r += self.sums[i]
+                    i -= i & -i
+                return r
 
-        Let's create a vector V(i) = (R(i,A1), R(i,A2), ..., R(i,Ak)) where Aj iterates through 
-        all possible values of A parameter. This vector contains all the results on i-th layer. 
-        Then the transition rule can be formulated as matrix multiplication: V(i+1) = M * V(i) 
-        where M is transition matrix. The answer for the problem is usually determined by the 
-        results of last layer, so we need to calculate V(N) = M^N * V(0).
 
-        The DP solution is to get V(0) and then multiply it by M matrix N times. It requires 
-        O(N * A^2) time complexity, or more precisely it requires O(N * Z) time where Z is 
-        number of non-zero elements of matrix M. Instead of one-by-one matrix multiplication, 
-        exponentiation by squaring can be used. It calculates M^N using O(log(N)) matrix multiplications. 
-        After the matrix power is available, we multiply vector V(0) by it and instantly get the results 
-        for last layer. The overall time complexity is O(A^3 * log(N)). This trick is necessary when A is 
-        rather small (say 200) and N is very large (say 10^9).
+        class Solution(object):
+            def countSmaller(self, nums):
+                hashTable = {v: i for i, v in enumerate(sorted(set(nums)))}
 
-    -> Use complex data structures and algorithms
+                tree, r = BinaryIndexedTree(len(hashTable)), []
+                for i in xrange(len(nums) - 1, -1, -1):
+                    r.append(tree.sum(hashTable[nums[i]]))
+                    tree.update(hashTable[nums[i]] + 1, 1)
+                return r[::-1]
 
-        Sometimes tough DP solutions can be accelerated by using complex acceleration 
-        structures or algorithms. Binary search, segment trees (range minimum/sum query), 
-        binary search tree (map) are good at accelerating particular operations. If you 
-        are desperate at inventing DP solution of Div1 1000 problem with 
-        proper time complexity, it may be a good idea to recall these things.
 
-        For example, longest increasing subsequence problem DP solution can be accelerated to 
-        O(N log(N)) with dynamic range minimum query data structure 
-        or with binary search depending on the chosen state domain.
+    Reverse pairs another one:
 
-#######################################################################################################
-#######################################################################################################
+        class SegmentTreeNode(object):
+            def __init__(self, val, start, end):
+                self.val = val
+                self.start, self.end = start, end
+                self.left, self.right = None, None
 
-CODEFORCES DP 3 - STATE TRANSITIONS, AND STATES, AND RECURRENT RELATIONSHIPS
+        class SegmentTree(object):
+            def __init__(self, n):
+                self.root = self.buildTree(0, n-1)
 
--> Overview 
-    Solution Code of DP solution usually contains an array representing 
-    subresults on the state domain. For example, classic knapsack problem solution will be like (FORWARD DP):
+            def buildTree(self, start, end):
+                if start > end:
+                    return None
+                root = SegmentTreeNode(0, start, end)
+                if start == end:
+                    return root
+                mid = (start+end) / 2
+                root.left, root.right = self.buildTree(start, mid), self.buildTree(mid+1, end)
+                return root
+
+            def update(self, i, diff, root=None):
+                root = root or self.root
+                if i < root.start or i > root.end:
+                    return
+                root.val += diff
+                if i == root.start == root.end:
+                    return
+                self.update(i, diff, root.left)
+                self.update(i, diff, root.right)
 
-    int maxcost[items+1][space+1];
-    memset(maxcost, -63, sizeof(maxcost));   //fill with negative infinity
-    maxcost[0][0] = 0;                       //base of DP
-    for (int i = 0; i<items; i++)            //iterations over states in proper order
-        for (int j = 0; j<=space; j++) {
-        int mc = maxcost[i][j];              //we handle two types forward transitions
-        int ni, nj, nmc;                     //from state (i,j)->mc to state (ni,nj)->nmc
-    
-        ni = i + 1;                          //forward transition: do not add i-th item
-        nj = j;
-        nmc = mc;      
-        if (maxcost[ni][nj] < nmc)           //relaxing result for new state
-            maxcost[ni][nj] = nmc;
-    
-        ni = i + 1;                          //forward transition: add i-th item
-        nj = j + size[i];
-        nmc = mc + cost[i];
-        if (nj <= space && maxcost[ni][nj] < nmc)
-            maxcost[ni][nj] = nmc;
-        }
-    int answer = -1000000000;                //getting answer from state results
-    for (j = 0; j<=space; j++)
-        if (maxcost[items][j] > answer)
-        answer = maxcost[items][j];
-    return answer;
+            def sum(self, start, end, root=None):
+                root = root or self.root
+                if end < root.start or start > root.end:
+                    return 0
+                if start <= root.start and end >= root.end:
+                    return root.val
+                return self.sum(start, end, root.left) + self.sum(start, end, root.right)
+
+        class BinaryIndexTree(object):
+            def __init__(self, n):
+                self.sums = [0] * (n+1)
+
+            def update(self, i, val):
+                while i < len(self.sums):
+                    self.sums[i] += val
+                    i += i & -i
+
+            def sum(self, i):
+                res = 0
+                while i > 0:
+                    res += self.sums[i]
+                    i -= i & -i
+                return res
 
-    Here (i,j) is state of DP with result equal to maxcost[i][j]. 
-    The result here means the maximal cost of items we can get by taking some of first i items with 
-    overall size of exactly j. So the set of (i,j) pairs and concept of maxcost[i][j] here 
-    comprise a state domain. The forward transition is adding or not adding the i-th item to 
-    the set of items we have already chosen.
+        class Solution(object):
 
-    The order of iterations through all DP states is important. The code above 
-    iterates through states with pairs (i,j) sorted lexicographically. It is correct 
-    since any transition goes from set (i,*) to set (i+1,*), so we see that i is increasing 
-    by one. Speaking in backward (recurrent) style, the result for each state (i,j) directly 
-    depends only on the results for the states (i-1,*).
+            # The number we search may not be in the array
+            def greater_than(self, nums, x):
+                return bisect.bisect_right(nums, x)
 
-    To determine order or iteration through states we have to define order on state domain. 
-    We say that state (i1,j1) is greater than state (i2,j2) if (i1,j1) directly or indirectly 
-    (i.e. through several other states) depends on (i2,j2). This is definition of order on the 
-    state domain used. In DP solution any state must be considered after all the lesser states. 
-    Else the solution would give incorrect result.
+            # The number we search is in the array
+            def index(self, nums, x):
+                return bisect.bisect_left(nums, x)
+
+            def reversePairsSegmentTree(self, nums):
+                """
+                :type nums: List[int]
+                :rtype: int
+                """
+                seg_tree, res = SegmentTree(len(nums)), 0
+                sorted_nums = sorted(nums)
+                n = len(nums)
+                for i in xrange(0, n):
+                    gt = self.greater_than(sorted_nums, 2*nums[i])
+                    res += seg_tree.sum(gt, n-1)
+                    idx = self.index(sorted_nums, nums[i])
+                    seg_tree.update(idx, 1)
+                return res
+
+            def reversePairsBinaryIndexTree(self, nums):
+                """
+                :type nums: List[int]
+                :rtype: int
+                """
+                bi_tree, res = BinaryIndexTree(len(nums)), 0
+                sorted_nums = sorted(nums)
+                n = len(nums)
+                for i in xrange(0, len(nums)):
+                    gt = self.greater_than(sorted_nums, 2*nums[i])
+                    res += bi_tree.sum(n) - bi_tree.sum(gt)
+                    idx = self.index(sorted_nums, nums[i])
+                    bi_tree.update(idx+1, 1)
+                return res
+
+
+#######################################################
+#######################################################
+COOL NOTES PART -4: Graph Algorithms Part 1
+
+    Bellman Ford:
+
+        #Class to represent a graph 
+        class Graph: 
+        
+            def __init__(self,vertices): 
+                self.V= vertices #No. of vertices 
+                self.graph = [] # default dictionary to store graph 
+
+            # function to add an edge to graph 
+            def addEdge(self,u,v,w): 
+                self.graph.append([u, v, w]) 
+
+            # The main function that finds shortest distances from src to 
+            # all other vertices using Bellman-Ford algorithm.  The function 
+            # also detects negative weight cycle 
+            def BellmanFord(self, src): 
+        
+                # Step 1: Initialize distances from src to all other vertices 
+                # as INFINITE 
+                dist = [float("Inf")] * self.V 
+                dist[src] = 0 
+        
+        
+                # Step 2: Relax all edges |V| - 1 times. A simple shortest  
+                # path from src to any other vertex can have at-most |V| - 1  
+                # edges 
+                for i in range(self.V - 1): 
+                    # Update dist value and parent index of the adjacent vertices of 
+                    # the picked vertex. Consider only those vertices which are still in 
+                    # queue 
+                    for u, v, w in self.graph: 
+                        if dist[u] != float("Inf") and dist[u] + w < dist[v]: 
+                                dist[v] = dist[u] + w 
+        
+                # Step 3: check for negative-weight cycles.  The above step  
+                # guarantees shortest distances if graph doesn't contain  
+                # negative weight cycle.  If we get a shorter path, then there 
+                # is a cycle. 
+        
+                for u, v, w in self.graph: 
+                        if dist[u] != float("Inf") and dist[u] + w < dist[v]: 
+                                print "Graph contains negative weight cycle"
+                                return
+                                
+                # print all distance 
+                self.printArr(dist) 
+
+    Floyd Warshall:
+        We initialize the solution matrix same as 
+        the input graph matrix as a first step. 
+        Then we update the solution matrix by considering all 
+        vertices as an intermediate vertex. 
+        The idea is to one by one pick all vertices and updates all shortest 
+        paths which include the picked vertex as an intermediate vertex in the 
+        shortest path. When we pick vertex number k as an intermediate vertex, 
+        we already have considered vertices {0, 1, 2, .. k-1} as intermediate vertices. 
+
+        For every pair (i, j) of the source and destination 
+        vertices respectively, there are two possible cases.
+
+        1)  k is not an intermediate vertex in shortest path from i to j. 
+            We keep the value of dist[i][j] as it is.
+
+        2)  k is an intermediate vertex in shortest path from i to j. We update 
+            the value of dist[i][j] as dist[i][k] + dist[k][j] if dist[i][j] > dist[i][k] + dist[k][j]
+
+
+        # Solves all pair shortest path via Floyd Warshall Algorithm 
+        def floydWarshall(graph): 
+        
+            """ dist[][] will be the output matrix that will finally 
+                have the shortest distances between every pair of vertices """
+            """ initializing the solution matrix same as input graph matrix 
+            OR we can say that the initial values of shortest distances 
+            are based on shortest paths considering no  
+            intermediate vertices """
 
--> Multidimensional array 
-    The knapsack DP solution described above is an example of multidimensional array state domain (with 2 
-    dimensions). A lot of other problems have similar state domains. Generally 
-    speaking, in this category states are represented by k   parameters: (i1, i2, i3, ..., ik). 
-    So in the code we define a multidimensional array for state results like: 
-    int Result[N1][N2][N3]...    [Nk]. Of course there are some transition rules 
-    (recurrent relations). These rules themselves can be complex, but the order of states   
-    is usually simple.
+            dist = map(lambda i : map(lambda j : j , i) , graph) 
+            
+            """ Add all vertices one by one to the set of intermediate 
+            vertices. 
+            ---> Before start of an iteration, we have shortest distances 
+            between all pairs of vertices such that the shortest 
+            distances consider only the vertices in the set  
+            {0, 1, 2, .. k-1} as intermediate vertices. 
+            ----> After the end of a iteration, vertex no. k is 
+            added to the set of intermediate vertices and the  
+            set becomes {0, 1, 2, .. k} 
+            """
 
-    In most cases the states can be iterated through in lexicographical order. 
-    To do this you have to ensure that if I = (i1, i2, i3, ...,  ik) directly 
-    depends on J = (j1, j2, j3, ..., jk) then I is lexicographically greater that J. 
-    This can be achieved by permuting  parameters (like using (j,i) instead of (i,j)) 
-    or reversing them. But it is usually easier to change the order and direction of nested   
-    loops. Here is general code of lexicographical traversion:
+            for k in range(V): 
+        
+                # pick all vertices as source one by one 
+                for i in range(V): 
+        
+                    # Pick all vertices as destination for the 
+                    # above picked source 
+                    for j in range(V): 
+        
+                        # If vertex k is on the shortest path from  
+                        # i to j, then update the value of dist[i][j] 
+                        dist[i][j] = min(dist[i][j] , 
+                                        dist[i][k]+ dist[k][j] 
+                                        ) 
+            printSolution(dist)
+        
+        graph = [[0,5,INF,10], 
+                [INF,0,3,INF], 
+                [INF, INF, 0,   1], 
+                [INF, INF, INF, 0] 
+            ] 
 
-      for (int i1 = 0; i1<N1; i1++)
-        for (int i2 = 0; i2<N1; i2++)
-          ...
-            for (int ik = 0; ik<Nk; ik++) {
-              //get some states (j1, j2, j3, ..., jk) -> jres by performing transitions
-              //and handle them
-            }
-    Note: changing order of DP parameters in array and order of nested loops 
-    can noticably affect performance on modern computers due to    
-    CPU cache behavior.
+        # Print the solution 
+        floydWarshall(graph); 
+        Following matrix shows the shortest distances between every pair of vertices
+        0      5      8      9
+        INF      0      3      4
+        INF    INF      0      1
+        INF    INF    INF      0
 
-    This type of state domain is the easiest to understand and implement, that's why 
-    most DP tutorials show problems of this type. But it   is not the most 
-    frequently used type of state domain in SRMs. DP over subsets is much more popular.
+    DJIKSTRA:
 
-->  Subsets of a given set
+        from collections import defaultdict
+        from heapq import *
 
-    The problems of this type has some set X. The number of elements in this set is small: 
-    less than 20. The idea of DP solution is to  consider all subsets of X as 
-    state domain. Often there are additional parameters. So generally we 
-    have state domain in form (s,a) where  s is a subset of X and "a" represents additional parameters.
+        def dijkstra(edges, f, t):
+            g = defaultdict(list)
+            for l,r,c in edges:
+                g[l].append((c,r))
+            # better to use dist than a parent path
+            q, seen, mins = [(0,f,())], set(), {f: 0}
+            while q:
+                (cost,v1,path) = heappop(q)
+                if v1 not in seen:
+                    seen.add(v1)
+                    path = (v1, path)
+                    if v1 == t: return (cost, path)
 
-    Consider TSP problem as an example. The set of cities X={0, 1, 2, ..., N-1} 
-    is used here. State domain will have two parameters: s and  a. 
-    The state (s,a)->R means that R is the shortest path from city 0 to 
-    city "a" which goes through all the vertices from subset s    
-    exactly once. The transition is simply adding one city v to the 
-    end of path: (s,a)->R turns into (s+{v},v)->R + M[a,v]. Here M[i,j] 
-    is     distance between i-th and j-th city. Any hamiltonian cycle is a 
-    path which goes through each vertex exactly once plus the edge which    
-    closes the cycle, so the answer for TSP problem can be computed as min(R[X,a]+M[a,0]) among all vertices "a".
+                    for c, v2 in g.get(v1, ()):
+                        if v2 in seen: continue
+                        prev = mins.get(v2, None)
+                        next = cost + c
+                        if prev is None or next < prev:
+                            mins[v2] = next
+                            heappush(q, (next, v2, path)) # is this the change key op? - yes
+            return float("inf")
 
-    It is very convenient to encode subsets with binary numbers. 
-    Look recipe "Representing sets with bitfields" for detailed explanation.
+        if __name__ == "__main__":
+            edges = [
+                ("A", "B", 7),
+                ("A", "D", 5),
+                ("B", "C", 8),
+                ("B", "D", 9),
+                ("B", "E", 7),
+                ("C", "E", 5),
+                ("D", "E", 15),
+                ("D", "F", 6),
+                ("E", "F", 8),
+                ("E", "G", 9),
+                ("F", "G", 11)
+            ]
 
-    The state domain of DP over subsets is usually ordered by set 
-    inclusion. Each forward transition adds some elements to the current  
-    subset, but does not subtract any. So result for each state (s,a) depends 
-    only on the results of states (t,b) where t is subset of s.    
-    If state domain is ordered like this, then we can iterate through subsets 
-    in lexicographical order of binary masks. Since subsets are  
-    usually represented with binary integers, we can iterate through 
-    all subsets by iterating through all integers from 0 to 2^N — 1. For    
-    example in TSP problem solution looks like:
+            print "=== Dijkstra ==="
+            print edges
+            print "A -> E:"
+            print dijkstra(edges, "A", "E")
+            print "F -> G:"
+            print dijkstra(edges, "F", "G")
 
-      int res[1<<N][N];
-      memset(res, 63, sizeof(res));       //filling results with positive infinity
-      res[1<<0][0] = 0;                   //DP base
-    
-      for (int s = 0; s < (1<<N); s++)    //iterating through all subsets in lexicographical order
-        for (int a = 0; a < N; a++) {
-          int r = res[s][a];
-          for (int v = 0; v < N; v++) {   //looking through all transitions (cities to visit next)
-            if (s & (1<<v)) continue;     //we cannot visit cities that are already visited
-            int ns = s | (1<<v);          //perform transition
-            int na = v;
-            int nr = r + matr[a][v];      //by adding edge (a &mdash; v) distance
-            if (res[ns][na] > nr)         //relax result for state (ns,na) with nr
-              res[ns][na] = nr;
-          }
-        }
-      int answer = 1000000000;            //get TSP answer
-      for (int a = 0; a < N; a++)
-        answer = min(answer, res[(1<<N)-1][a] + matr[a][0]);
+#############################################################################
+#############################################################################
+COOL NOTES PART -2: HOW TO USE HEAP DICTIONARIES WITH DECREASE KEY USING HEAPQ!
 
-    Often in DP over subsets you have to iterate through all subsets or 
-    supersets of a given set s. The bruteforce implementation will  
-    require O(4^N) time for the whole DP, but it can be easily optimized to 
-    take O(3^N). Please read recipe "Iterating Over All Subsets of a Set".
+        -> Sort stability: how do you get two tasks with equal priorities 
+        to be returned in the order they were originally added?
 
+        -> In the future with Python 3, tuple comparison breaks for (priority, task) 
+        pairs if the priorities are equal and the tasks do not have a default comparison order.
 
--> Substrings of a given string
+        -> If the priority of a task changes, how do you 
+        move it to a new position in the heap?
 
-    There is a fixed string or a fixed segment. According to the problem 
-    definition, it can be broken into two pieces, then each of pieces  
-    can be again divided into two pieces and so forth until we get unit-length strings. 
-    And by doing this we need to achieve some goal.
+        -> Or if a pending task needs to be deleted, 
+        how do you find it and remove it from the queue?
 
-    Classical example of DP over substrings is context-free grammar parsing algorithm. 
-    Problems which involve putting parentheses to    
-    arithmetic expression and problems that ask to optimize the overall 
-    cost of recursive breaking are often solved by DP over substrings.     
-    In this case there are two special parameters L and R which represent indices of left 
-    and right borders of a given substring. There can     
-    be some additional parameters, we denote them as "a". So each 
-    state is defined by (L,R,a). To calculate answer for each state, 
-    all the  ways to divide substring into two pieces are considered. 
-    Because of it, states must be iterated through in order or non-decreasing   
-    length. Here is the scheme of DP over substrings (without additional parameters):
+        A solution to the first two challenges is to store entries as 3-element list 
+        including the priority, an entry count, and the task. The entry count serves 
+        as a tie-breaker so that two tasks with the same priority are returned 
+        in the order they were added. And since no two entry counts are the same, 
+        the tuple comparison will never attempt to directly compare two tasks.
 
-      res[N+1][N+1];                          //first: L, second: R
-      for (int s = 0; s<=N; s++)              //iterate size(length) of substring
-        for (int L = 0; L+s<=N; L++) {        //iterate left border index
-          int R = L + s;                      //right border index is clear
-          if (s <= 1) {                       
-            res[L][R] = DPBase(L, R);         //base of DP &mdash; no division
-            continue;
-          }
-          tres = ???;                          
-          for (int M = L+1; M<=R-1; M++)      //iterate through all divisions
-            tres = DPInduction(tres, res[L][M], res[M][R]);
-          res[L][R] = tres;
-        }
-      answer = DPAnswer(res[0][N]);
+        The remaining challenges revolve around finding a pending task and 
+        making changes to its priority or removing it entirely. 
+        Finding a task can be done with a dictionary pointing to an entry in the queue.
 
--> Subtrees(vertices) of a given rooted tree
+        Removing the entry or changing its priority is more difficult because 
+        it would break the heap structure invariants. So, a possible solution 
+        is to mark the existing entry as 
+        Removed and add a new entry with the revised priority:
 
-    The problem involves a rooted tree. Sometimes a graph is given 
-    and its DFS search tree is used. Some sort of result can be calculated   
-    for each subtree. Since each subtree is uniquely identified by its root, 
-    we can treat DP over subtrees as DP over vertices. The result    
-    for each non-leaf vertex is determined by the results of its immediate children.
+        pq = []                         # list of entries arranged in a heap
+        entry_finder = {}               # mapping of tasks to entries
+        REMOVED = '<removed-task>'      # placeholder for a removed task
+        counter = itertools.count()     # unique sequence count
 
-    The DP over subtree has a state domain in form (v,a) where v is a root of 
-    subtree and "a" may be some additional parameters. states are     
-    ordered naturally be tree order on vertices. Therefore the easiest way to 
-    iterate through states in correct order is to launch DFS from     
-    the root of tree. When DFS exits from a vertex, its result must 
-    be finally computed and stored in global memory. 
-    The code generally     looks like:
+        def add_task(task, priority=0):
+            'Add a new task or update the priority of an existing task'
+            if task in entry_finder:
+                remove_task(task)
+            count = next(counter)
+            entry = [priority, count, task]
+            entry_finder[task] = entry
+            heappush(pq, entry)
 
-      bool vis[N];                                  //visited mark for DFS
-      res[N];                                       //DP result array
-    
-      void DFS(int v) {                             //visit v-rooted subtree recursively
-        vis[v] = true;                              //mark vertex as visited
-        res[v] = ???;                               //initial result, which is final result in case v is leaf
-        for (int i = 0; i<nbr[v].size(); i++) {     //iterate through all sons s
-          int s = nbr[v][i];                        
-          if (!vis[s]) {                            //if vertex is not visited yet, then it's a son in DFS tree
-            DFS(s);                                 //visit it recursively
-            res[v] = DPInduction(res[v], res[s]);   //recalculate result for current vertex
-          }
-        }
-      }
-      ...
-      memset(vis, false, sizeof(vis));              //mark all vertices as not visited
-      DFS(0);                                       //run DFS from the root = vertex 0
-      answer = DPAnswer(res[0]);                    //get problem answer from result of root
+        def remove_task(task):
+            'Mark an existing task as REMOVED.  Raise KeyError if not found.'
+            entry = entry_finder.pop(task)
+            entry[-1] = REMOVED
+
+        def pop_task():
+            'Remove and return the lowest priority task. Raise KeyError if empty.'
+            while pq:
+                priority, count, task = heappop(pq)
+                if task is not REMOVED:
+                    del entry_finder[task]
+                    return task
+            raise KeyError('pop from an empty priority queue')
 
-    Sometimes the graph of problem is not connected (e.g. a forest). 
-    In this case run a series of DFS over the whole graph. The results for     
-    roots of individual trees are then combined in some way. 
-    Usually simple summation/maximum or a simple formula is enough 
-    but in tough cases this "merging problem" can turn out to require 
-    another DP solution.
+#################################################################################3
+#######################################################################################
+CREATE ONE FOR C++ BINARY TREE MAPS HERE:
 
-    The DPInduction is very simple in case when there are no additional parameters. 
-    But very often state domain includes the additional     
-    parameters and becomes complicated. DPInduction turns out to be 
-    another(internal) DP in this case. Its state domain is (k,a) where k is     
-    number of sons of vertex considered so far and "a" is additional info. 
-    Be careful about the storage of results of this internal DP. 
-    If  you are solving optimization problem and you are required to 
-    recover the solution (not only answer) then you have to save results of     
-    this DP for solution recovering. In this case you'll have an array 
-    globalres[v,a] and an array internalres[v,k,a]. Topcoder problems    r
-    arely require solution, so storage of internal DP results is not necessary. 
-    It is easier not to store them globally. In the code below    
-    internal results for a vertex are initialized after all the sons 
-    are traversed recursively and are discarded after DFS exits a vertex.     
-    This case is represented in the code below:
+############################
+##########################3
+Linked List Practice!
+
+    24. Swap Nodes in Pairs
+    Medium
+    Given a linked list, swap every two adjacent nodes and return its head. 
+    You must solve the problem without modifying the values in the list's nodes (i.e., only nodes themselves may be changed.)
 
-      bool vis[N];
-      gres[N][A];
-      intres[N+1][A];
-    
-      void DFS(int v) {
-        vis[v] = true;
-    
-        vector<int> sons;
-        for (int i = 0; i<nbr[v].size(); i++) {    //first pass: visit all sons and store their indices
-          int s = nbr[v][i];
-          if (!vis[s]) {
-            DFS(s);
-            sons.push_back(s);
-          }
-        }
-    
-        int SK = sons.size();                      //clear the internal results array
-        for (int k = 0; k<=SK; k++)
-          memset(intres[k], ?, sizeof(intres[k]));
     
-        for (int a = 0; a<A; a++)                  //second pass: run internal DP over array of sons
-          intres[0][a] = InternalDPBase(v, a);
-        for (int k = 0; k<SK; k++)                 //k = number of sons considered so far
-          for (int a = 0; a<A; a++)                //a = additional parameter for them
-            for (int b = 0; b<A; b++) {            //b = additional parameter for the son being added
-              int na = DPTransition(v, a, b);
-              int nres = DPInduction(intres[k][a], gres[sons[k]][b]);
-              intres[k+1][na] = DPMerge(intres[k+1][na], nres);
-            }
-        for (int a = 0; a<A; a++)                  //copy answer of internal DP to result for vertex
-          gres[v][a] = intres[SK][a];
-      }
-      ...
-      memset(vis, false, sizeof(vis));              //series of DFS
-      for (int v = 0; v<N; v++) if (!vis[v]) {
-        DFS(v);
-        ???                                         //handle results for connected component
-      }
-      ???                                           //get the answer in some way
+    Input: head = [1,2,3,4]
+    Output: [2,1,4,3]
+    Example 2:
 
-    It is very important to understand how time/space complexity is calculated 
-    for DP over subtrees. For example, the code just above   
-    requires O(N*A^2) time. Though dumb analysis says it 
-    is O(N^2*A^2): {N vertices} x {SK<=N sons for each} x A x A. 
-    Let Ki denote number    of sons of vertex i. Though each Ki may 
-    be as large as N-1, their sum is always equal to N-1 in a rooted tree. 
-    This fact is the key to     
-    further analysis. Suppose that DFS code for i-th vertex runs in not 
-    more than Ki*t time. Since DFS is applied only once to each vertex,     
-    the overall time will be TC(N) = sum(Ki*t) <= N*t. Consider t=A^2 for the case 
-    above and you'll get O(N*A^2) time complexity. To    benefit from this acceleration, 
-    be sure not to iterate through all vertices of graph in DFS. For example above, 
-    running memset for the     whole intres array in DFS will raise the time complexity. 
-    Time of individual DFS run will become O(N*A + Ki*A^2) instead of O(Ki*A^2).  
-    The overall time complexity will become O(N^2*A + N*A^2) which is great regress 
-    in case if A is much smaller that N. Using the same  approach you may achieve 
-    O(N*A) space complexity in case you are asked to recover solution. We have already 
-    said that to recover     solution you have to store globally the array 
-    internalres[v,k,a]. If you allocate memory for this array dynamically, then 
-    you can   ignore completely states with k>Ki. Since the sum of all Ki is N, 
-    you will get O(N*A) space.
+    Input: head = []
+    Output: []
+    Example 3:
 
--> Layer count + layer profile
+    Input: head = [1]
+    Output: [1]
 
-    This is the toughest type of DP state domain. It is usually used in 
-    tiling or covering problems on special graphs. The classic examples     
-    are: calculate number of ways to tile the rectangular board with dominoes 
-    (certain cells cannot be used); or put as many chess figures  
-    on the chessboard as you can so that they do not hit each other 
-    (again, some cells may be restricted).
 
-    Generally speaking, all these problems can be solved with DP over subsets 
-    (use set of all cells of board). DP with profiles is an   
-    optimization which exploits special structure in this set. The board we have 
-    to cover/tile is represented as an array of layers. We try   
-    to consider layers one by one and store partial solutions after each layer. 
-    In simple rectangular board case layer is one row of the  board. 
-    The profile is a subset of cells in current row which are already tiled.
+    My soln:
 
-    The state domain has form (k,p) where k is number of fully processed layers 
-    and p is so-called profile of solution. Profile is the  necessary information 
-    about solution in layers that are not fully processed yet. 
-    The transitions go from (k,p) to (k+1,q) where q is     
-    some new profile. The number of transitions for each state is usually large, 
-    so they all are iterated through by recursive search,  
-    sometimes with pruning. The search has to find all the ways to 
-    increase the partial solution up to the next layer.
+    class Solution:
+        def swapPairs(self, head: Optional[ListNode]) -> Optional[ListNode]:
+            # okkk
+            
+            dummy = ListNode()
+            temp = dummy
+            curr = head
+            
+            while curr is not None and curr.next is not None:
+                next_adj_pair = curr.next.next
+                nxt = curr.next
+                temp.next = nxt
+                nxt.next = curr
+                temp = curr
+                curr = next_adj_pair
+                
+            temp.next = curr
+            
+            
+            return dummy.next        
 
-    The example code below calculates the number of way to fully 
-    cover empty cells on the given rectangular board with dominoes.
 
-    int res[M+1][1<<N];                     
-                                            //k = number of fully tiled rows               
-    int k, p, q;                            //p = profile of k-th row = subset of tiled cells
-    bool get(int i) {                       //q = profile of the next row (in search)        
-      return matr[k][i] == '#'              
-          || (p & (1<<i));                  //check whether i-th cell in current row is not free
-    }
-    void Search(int i) {                    //i = number of processed cells in current row
-      if (i == N) {
-        add(res[k+1][q], res[k][p]);        //the current row processed, make transition
-        return;
-      }
-    
-      if (get(i)) {                         //if current cell is not free, skip it
-        Search(i+1);
-        return;
-      }
-    
-      if (i+1<N && !get(i+1))               //try putting (k,i)-(k,i+1) domino
-        Search(i+2);
-    
-      if (k+1<M && matr[k+1][i] != '#') {   //try putting (k,i)-(k+1,i) domino
-        q ^= (1<<i);                        //note that the profile of next row is changed
-        Search(i+1);
-        q ^= (1<<i);
-      }
-    }
-    ...
-    res[0][0] = 1;                          //base of DP
-    for (k = 0; k<M; k++)                   //iterate over number of processed layers
-      for (p = 0; p<(1<<N); p++) {          //iterate over profiles
-        q = 0;                              //initialize the new profile
-        Search(0);                          //start the search for all transitions
-      }
-    int answer = res[M][0];                 //all rows covered with empty profile = answer
 
-    The asymptotic time complexity is not easy to calculate exactly. 
-    Since search for i performs one call to i+1 and one call to i+2, the   
-    complexity of individual search is not more than N-th Fibonacci number = fib(N). 
-    Moreover, if profile p has only F free cells it will     
-    require O(fib(F)) time due to pruning. If we sum C(N,F) fib(F) for all F we'll 
-    get something like (1+phi)^N, where phi is golden ratio.  
-    The overall time complexity is O(M * (1+phi)^N). Empirically it is even lower.
 
-    The code is not optimal. Almost all DP over profiles should use "storing two layers" 
-    space optimization. Look "Optimizing DP solution"  recipe. Moreover DP over 
-    broken profiles can be used. In this DP state domain (k,p,i) is used, 
-    where i is number of processed cells in   a row. No recursive search is 
-    launched since it is converted to the part of DP. The time 
-    complexity is even lower with this solution.
+#################################################################################3
+#######################################################################################
+Cool Trie Code:
 
-    The hard DP over profiles examples can include extensions like: 
-    1. Profile consists of more than one layer. 
-       For example to cover the    grid with three-length tiles you need to store 
-       two layers in the profile. 
-    2. Profile has complex structure. For example to find optimal    
-       in some sense hamiltonian cycle on the rectangular board you have 
-       to use matched parentheses strings as profiles. 
-    3. Distinct profile  structure. Set of profiles may be different for each layer. 
-       You can store profiles in map in this case.
+    Given a dictionary of words (sorted lexicographically) and a prefix string, return all the words that start with the given prefix. @BigV
+    Couldnt you binary search the letters in the word?
 
-DONE READING -> GO TO COMPETITIVE/PROBLEMS to see all the usages of above techniques. 
-https://codeforces.com/blog/entry/43256
+    But i guess trie is faster regardless. 
+    Rabinkarp hash the word. 
+    hash the first 8 letters of every word and put in a map. get idx, then go left and right in array!
 
-#####################################################################################################################
-#####################################################################################################################
 
-COOL NOTES PART 1: DYNAMIC PROGRAMMING RECURRENCES EXAMPLES: 
-(In the code ->  &mdash; means minus sign. The html was parsed wrong)
-(For dp, define subproblem, then recurrence, then base cases, then implement)
 
-1) Given n, find number of diff ways to write n as sum of 1, 3, 4
-    Let Dn be the number of ways to write n as the sum of 1, 3, 4
-    Recurrence: well n = x1 + x2 + ... + xm. If xm = 1, other terms sum to n-1
-    Sums that end with xm=1 is Dn-1
+    from collections import defaultdict
 
-    Recurrence => Dn = Dn-1 + Dn-3 + Dn-4
-    Solve base cases D0 = 1, Dn = 0 for all negative n. 
-    Code:    
-    D[0] = D[1] = D[2] = 1; D[3] = 2;
-    for(i = 4; i <= n; i++)
-        D[i] = D[i-1] + D[i-3] + D[i-4]
+    class TrieNode: 
+        def __init__(self): 
+            self.ht = defaultdict(TrieNode) 
+            self.isEnd = False 
+    class Trie: 
+        def __init__(self): 
+            self.root = TrieNode() 
+        
+        def add_word(self, word): 
+            curr = self.root
+            for char in word: 
+                curr = curr.ht[char]
+            curr.isEnd = True 
+        
+        def startsWith(self, prefix, trieNode): 
+            rtn = [] 
+            
+            def dfs(currWord, currTrieNode): 
+                if currTrieNode.isEnd: 
+                    rtn.append(currWord)
+                    
+                for char, children in currTrieNode.ht.items(): 
+                    dfs(currWord+char, children) 
+                
+            dfs(prefix, trieNode)
+            return rtn 
+        
+    def get_prefix(prefix): 
+        example = ['a','abc','abs', 'b','bob']
+        trie = Trie()
+        
+        for word in example: 
+            trie.add_word(word)
+            
+        curr_root = trie.root
+        for char in prefix: 
+            curr_root = curr_root.ht[char]
+        
+        rtn = []
+        rtn.append(trie.startsWith(prefix, curr_root))
 
+        return rtn 
+        
+    print(get_prefix('ab'))
 
-2) Given 2 strings x and y. Find Longest common subsequence. 
-    Let Dij be the length of LCS of x1...i, y1...j
-    D[i,j] = D[i-1,j-1] + 1 if xi = yj
-    D[i,j] = max{D[i-1, j], D[i, j-1]}  otherwise
+#######################################
+##########################################
+RANDOM QUESTIONS & RESERVOIR SAMPLING:
 
-    Find and solve base cases(In top down, this is the base case for the recursion): 
-    D[i, 0] = D[0, j] = 0
-    D[0, all the js] = 0
-    D[all the is, 0] = 0
-    When implementing remember to look at your base cases and 
-    understand you have to start with those and build up!
-    Helps you figure out directionality!
+    Swap To Back Of Array O(1) Trick Random Questions
+    Q. Given an array, you have to write a function to select a random number from the array such that it has not appeared in the last K calls to this function.
 
-    def lcs(X , Y): 
-        # find the length of the strings 
-        m = len(X) 
-        n = len(Y) 
-    
-        # declaring the array for storing the dp values 
-        L = [[None]*(n+1) for i in xrange(m+1)] 
-    
-        """Following steps build L[m+1][n+1] in bottom up fashion 
-        Note: L[i][j] contains length of LCS of X[0..i-1] 
-        and Y[0..j-1]"""
-        for i in range(m+1): 
-            for j in range(n+1): 
-                if i == 0 or j == 0 : 
-                    L[i][j] = 0
-                elif X[i-1] == Y[j-1]: 
-                    L[i][j] = L[i-1][j-1]+1
-                else: 
-                    L[i][j] = max(L[i-1][j] , L[i][j-1]) 
-    
-        # L[m][n] contains the length of LCS of X[0..n-1] & Y[0..m-1] 
-        return L[m][n] 
+        Approach : Used a combination of deque and unordered_set to generate the random number in O(N) time. Further, the 
+        interviewer required an optimisation of O(1), used a vector to do so. The vector contains the unselected elements so far. 
+        As soon as an element is visited, swap the element with the last element in the vector & do a pop_back operation to get the answer in O(1).
+
+
+        Write a RandomGenerator class:
+
+        public class RandomGenerator {
+
+            public RandomGenerator(int n) {
+            }
+            
+            public int generate() {
+                // todo
+            }
+        }
+        The contructor will be passed an integer n. generate is supposed to return a random number between 0 to n, but it 
+        is not supposed to return a number that it has already returned. If possiblities are exhauted, return -1.
+
+    Construct your own RNG:
+        You are in charge of writing a software for a slot machine. On press of a button, the slot machine should output the roll of 2 dice.
+        constraints: Do not use the random library. Probability of the dice rolls should be equal.
+
+        Take the unix timestamp in long form. Mod that number by 36. The remainder can range from 0 to 35. You can map the remainder to 
+        36 possibilities that the 2 6-side dice throws can have in terms of value pairs.
+
+        Another way to enhance:
+        Choose a few prime numbers and put them in an array of length N. Take system time down the smallest unit possible. 
+        Take the Mod of the floor of that number divided by previous selected prime. Use the result to select a new prime. 
+        Multiply system time the prime, take Mod 36 as suggested by @vishnushiva
+
+        You can also create your own Linear congruential generator
 
-    
-3) Interval DP
-    Given a string x = x1..n, find the min number of chars that need to be inserted to make it a palindrome. 
-    Let D[i, j] be the min number of char that need to be inserted to make xi..j into a palindrome
+            var seed = 0
 
-    Consider shortest palindrome y1..k containing xi..j. Either y1 = xi or yk = xj.
-    y[2..k-1] is then an optimal solution for x[i+1..j] or x[i..j-1] or x[i+1..j-1]
-    Recurrence:
+            func random() -> Int {
+                seed = (seed * 1103515245 + 12345) % Int(Int32.max)
+                return seed
+            }
 
-    Dij = 1 + min(D[i+1, j], D[i, j-1]) if xi != xj
-    Dij  = D[i+1,j-1] if xi=xj  otherwise   
-    
-    Base Case: 
-    D[i,i] = D[i, i-1] = 0 for all i
-    
-    Solution subproblem is D[1, n] => i = 1, j = n
+    Google - Generate random (x, y) within an area
+        Given a rectangular on a 2D coordinate, write a function to return (x, y) pair so that the distribution of the return value is uniform within the rectangular.
+        Followup 1: What if you are given multiple non-overlapping rectangular areas? How to generate uniformly distributed (x, y) pair?
+        Followup 2: What if you are given an arbitrary shaped area?
 
-    Directionality is hard here:
-    //fill in base cases here
-    for(t = 2, t<= n; t++):
-        for(i = 1, j =t, j <= n; ++i, ++j):
-            //fill in D[i][j] here
+        In general, to uniformly randomly select a (x,y) from inside a rectangle, you can independently sample the x coordinate and the y coordinate. 
+        Note that the rectangle might not be aligned along the axes (i.e. could be at an angle), but one can always find linear transformations to 
+        transform the rectangle so that its axes are parallel to the X and Y axes.
+
+        First part: Choose random number between 0 and x. and Random number between 0 and y. Then return (x,y)
+            random.uniform(a, b) -> 
+            Return a random floating point number N such that a <= N <= b for a <= b and b <= N <= a for b < a.
+            The end-point value b may or may not be included in the range depending on floating-point 
+            rounding in the equation a + (b-a) * random()
+
+        Follow up 1: Have weigth of every rectangle. Choose a rectangle, based on weight of rectangle. Then in each rectange do above thing. 
+
+        Arbitrary shape -> grab a very THIN rectangle. 
+        grab height of shape.
+        Then find a slice based on height [0 and height]
+
+        Then for arbitrary shape, get all widths within the height. 
+        -> widths will be intervals!
+
+        Choose an interval based on lengths of interval as the weight.
+        Once in the interval, just do uniform [startOfInterva, endOfInterval] rng.  
 
-    => We used t to fill in table correctly! This is interval DP! 
-    => This is the correct directionality. DIRECTIONALITY IS BASED ON YOUR BASE CASESE!!!
-    => A good way to figure out how to fill up table is just to write out example D[i][j] and figure
-        out how you are filling them up with your base cases.
 
-    Solution 2:
-    Reverse x to get x-reversed.
-    The answer is n - L where L is the length of the LCS of x and x-reversed
-    
-4) Subset DP => requires bitmasking!
-    Given a weighted graph with n nodes, find the shortest path that visits every node exactly once (TSP)
     
-    D[S, v] the length of optimal path that visits every node in the set S exactly once and ends at v. 
-    there are n2^n subproblems
-    Answer is min{v in V such that D[V, v]} where V is the given set of nodes. 
+    Create unbiased random from biased random:
 
-    Base Case: 
-    For each node v, D[{v}, v] = 0
-    Recurrence:
-    consider TSP path. Right before arivign at v, the path comes from some u in S - {v}, and that subpath
-    has to be the optimal one that covers S- {v} ending at u.
-    Just try all possible candidates for u
+        Suppose that you want to output 0 with probability 1/2 and 1 with probability 1/2. 
+        You have a function BIASED-RANDOM that outputs 1 with probability p and 0 with probability 1-p 
+        where 0<p<1.Write a function UNBIASED-RANDOM that uses BIASED -RANDOM and outputs 1 and 0 with equal probability.
 
-    D[S, v] = min[u in S - {v}] (D[S-{v}][u] + cost(u, v) )
+        Ok so roll twice, 
+        Consider one side heads 0
+        consider on side tails 1 
+        Roll until heads, then roll until tails. 
+        hmm
+        Heads Prob -> (1-p)
+        Tails prob -> p
 
-    Use integer to represet set. 19 = 010011 represents set {0, 1, 4}
-    Union of two sets x and y: x | y
-    Set intersection: x & y
-    Symmetic difference: x ^ y
-    singleton set {i}: 1 << i
-    Membership test: x & (1 << i) != 0
+        (1-p) * p = p * (1-p)
+        
+        HH -> H
+        HT -> T
+        TH -> H
+        TT -> T
+        
+        ok roll twice. 
+        if you get 
+        HH, or TH -> heads
 
-#######################################
-##########################################
+        if you get 
+        TH or TT -> tails. 
 
-COOL Notes PART 1.5: DP with bitmasking example: 
-    Problem
-    Your task will be to calculate number of different assignments of n different 
-    topics to n students such that everybody gets exactly one topic he likes.
-    1 means the student likes the subject. 0 means they dont.
+        (1-p)(1-p) = 1-2p + p^2  [2 heads]
+        
+        p*p = p^2  [2 tails]
 
-    Solution:
-        Defining the DP state
-        So, we can define our DP state with two variables, 
-        'k' and 'B' as :
+        (1-p)*p = [HT]
+        p * (1-p) = [TH]
 
-        DP(k,B) = Total no. of possible arrangements of 
-        students 0 to k choosing subset of subjects as per bitmask B.
+        so if you get different results you can use that to create fair coin
+        TH -> H, HT -> T
+        other options you have to re-roll!!
+        
 
-        Time for some optimization. The best way to optimize a DP solution is to 
-        reduce its "dimension", i.e, reduce the no. of state variables. 
-        In or case, we can see that k = No. of set bits in B. So, k 
-        can be easily calculated from B and hence not a part of our DP states anymore.
+    Write a function to generate random numbers between given range (5 to 55 inclusive) using a given function "rand_0()" which returns whether '0' or '1'.
+        Generate 5?
+        Generate 11? 
+        multiply...
 
-        The new DP state is :
+        hmm
+        how bout we subtract 5 from each now its 
+        0 to 50 -> hb now..
 
-        DP(B) = Total no. of possible arrangements of students 
-        0 to k assigning subjects as per bitmask B.
+        generate 16 * 4 = 64 -> 
+        0 - 3 
+        0 - 15
+        ...
 
-        where k = count set bits of B
-        The base case should be DP(0) = 1 , as there is 
-        exactly 1 way to arrange 0 students and 0 subjects.
 
-        For a state B , we can define the recurrence relation as follows :
 
-        where k = number of set bits in B,
 
-            DP(B) = for each i'th set bit in B, 
-            check  whether k'th student likes i'th subject. 
-            if true, DP(B) += DP(unset i'th bit from B)
+    Reservoir sampling:
+        Main idea:
+            we have n items we need to pick random!
+            select the first item, 
+            ok now select the second item 1/2 prob
+            ok now take third item with 1/3 prob
+            ... 
+            select nth item with 1/n prob
 
-        basically, for any arrangement, we remove 
-        one bit at a time and add up the resulting 
-        state if it satisfies the "liking" criteria. 
-        For example :
+            Can iterate through array and then tell me what item you got!
+            3 items:
+            prob you kept first item is
+            1 * (1/2) * (2/3) = 1/3!!
 
-        DP(1011) = DP(0011) + DP(1001) + DP(1010)
+            prob kept second item:
 
-        (assuming 3rd student likes 1st, 3rd and 
-        4th subjects. If he didn't like any of 
-        those, then those disliked states wouldn't be added)
+            1 * 1/2 * 2/3 = 1/3!!
+            prb kept 3rd item 
+            is  whatever you have *  1/3
 
-        logically, this can be explained as follows :
 
-        for a DP state 1011, the 3rd student can be assigned 
-        to either 1st,3rd or 4th subject. Now, if the student 
-        was assigned to 1st subject, then the number of ways to 
-        assign the previous students is given by DP(0011). 
-        Similarly, if 3rd student gets 3rd subject, we 
-        add DP(1001), and for 4th subject we add DP(1010).
 
-        Implementation
-        in practice, we create a single dimensional array of 
-        size 1<<20 (i.e. 2^20) . Let it be called DP[ ].
-        First, set DP[0] = 1 ;
-        then , run a loop from 1 to (1<<n)-1 (i.e. (2^n)-1) to generate all possible bitmasks
-        for each index of the loop, apply the recurrence relation as discussed above
-        finally, DP[(1<<n)-1] gives the answer.
 
-        //base case
-	    dp[0] = 1;
-      
-        //recurrence relation implemented
-        for (int j = 1; j < (1 << n) ; j++) {
-            int idx = Integer.bitCount(j);
-            for (int k = 0; k < n; k++) {
-                if (likes[idx-1][k] == false || (j & (1 << k)) == 0)
-                    continue;
-                dp[j] += dp[(j & ~(1 << k))];
-            }
-        }
+        Facebook | Onsite | Generate random max index
+        Given an array of integers arr, randomly return an index of the maximum value seen by far.
+
+        Example:
+        Input: [11, 30, 2, 30, 30, 30, 6, 2, 62, 62]
+
+        Having iterated up to the at element index 5 (where the last 30 is), randomly give an index among [1, 3, 4, 5] which are indices of 30 - the max value by far. Each index should have a ¼ chance to get picked.
+
+        Having iterated through the entire array, randomly give an index between 8 and 9 which are indices of the max value 62.
+
+        ok 
         
-        //final answer
-        System.out.println(dp[(1 << n) -1]);
+        import random 
 
-#######################################
-##########################################
+        max = float("-inf")
+        maxIdx = -1
+        count = 0
 
-COOL NOTES 2: EXPRESSION PARSING PROBLEMS
+        for idx, i in enumerate(arr):
+            if (i > max):
+                max = i
+                maxIdx = idx
+                count = 1
+            elif(i == max):
+                count += 1
 
-    Reverse Polish notation
-        Parsing of simple expressions
-        Unary operators
-        Right-associativity
-        A string containing a mathematical expression containing numbers 
-        and various operators is given. We have to compute the value of it in O(n), 
-        where n is the length of the string.
+                if(random.randint(1, count) == 1):
+                    maxIdx = idx
+        return maxIdx
+ 
 
-        The algorithm discussed here translates an expression into the so-called 
-        reverse Polish notation (explicitly or implicitly), and evaluates this expression.
+    WEIGHTED reservoir sampling: 
+    
+        528. Random Pick with Weight
 
-        Reverse Polish notation
-        The reverse Polish notation is a form of writing mathematical expressions, 
-        in which the operators are located after their operands. 
-        
-        For example the following expression
-        a+b∗c∗d+(e−f)∗(g∗h+i)
+        You are given a 0-indexed array of positive integers w where w[i] describes the weight of the ith index.
 
-        can be written in reverse Polish notation in the following way:
-        abc∗d∗+ef−gh∗i+∗+
+        You need to implement the function pickIndex(), which randomly picks an index in the range [0, w.length - 1] 
+        (inclusive) and returns it. The probability of picking an index i is w[i] / sum(w).
 
-        The convenience of the reverse Polish notation is, that expressions 
-        in this form are very easy to evaluate in linear time. We use a stack, 
-        which is initially empty. We will iterate over the operands and operators 
-        of the expression in reverse Polish notation. If the current element is a number, 
-        then we put the value on top of the stack, if the current element is an 
-        operator, then we get the top two elements from the stack, perform the operation, 
-        and put the result back on top of the stack. In the end there will be 
-        exactly one element left in the stack, which will be the value of the expression.
+        For example, if w = [1, 3], the probability of picking index 0 is 1 / (1 + 3) = 0.25 (i.e., 25%), and the 
+        probability of picking index 1 is 3 / (1 + 3) = 0.75 (i.e., 75%).
+        
 
-        Obviously this simple evaluation runs in O(n) time.
+        Ok here is the weighted reservori sampling soln:
 
+            The algorithm by Pavlos Efraimidis and Paul Spirakis solves exactly this problem. The original paper with complete proofs 
+            is published with the title "Weighted random sampling with a reservoir" in Information Processing Letters 2006, 
+            but you can find a simple summary here.
 
+            The algorithm works as follows. First observe that another way to solve the unweighted reservoir sampling is to assign to 
+            each element a random id R between 0 and 1 and incrementally (say with a heap) keep track of the top k ids. Now let's look at 
+            weighted version, and let's say the i-th element has weight w_i. Then, we modify the algorithm by choosing the id of the i-th 
+            element to be R^(1/w_i) where R is again uniformly distributed in (0,1).
 
-    Parsing of simple expressions
+            Another article talking about this algorithm is this one by the Cloudera folks.
 
-        For the time being we only consider a 
-        simplified problem: we assume that all operators 
-        are binary (i.e. they take two arguments), and all are 
-        left-associative (if the priorities are equal, 
-        they get executed from left to right). Parentheses are allowed.
+            in other words ->
+                rng(0,1) = 0.5 ^ 1/2 = 0.7071?
 
-        We will set up two stacks: one for numbers, and one for operators 
-        and parentheses. Initially both stacks are empty. For the second 
-        stack we will maintain the condition that all operations are 
-        ordered by strict descending priority. If there are parenthesis on the stack, 
-        than each block of operators (corresponding to one pair of parenthesis) 
-        is ordered, and the entire stack is not necessarily ordered.
+    WEIGHTED RANDOM PICK INDEX with cumulative sums and bin search:
 
-        We will iterate over the characters of the expression from left to right. 
-        If the current character is a digit, then we put the value of 
-        this number on the stack. If the current character is an 
-        opening parenthesis, then we put it on the stack. If the current 
-        character is a closing parenthesis, the we execute all operators on the stack 
-        until we reach the opening bracket (in other words we perform all 
-        operations inside the parenthesis). Finally if the current character 
-        is an operator, then while the top of the stack has 
-        an operator with the same or higher priority, we will execute 
-        this operation, and put the new operation on the stack.
+        import random 
 
-        After we processed the entire string, some operators might 
-        still be in the stack, so we execute them.
+        class Solution:
 
-        Here is the implementation of this method for the four operators + − ∗ /:
+            def __init__(self, w: List[int]):
+                
+                self.cum_sum = []
+                self.s = 0
+                for i in w:
+                    self.s += i
+                    self.cum_sum.append(self.s)
+                
+            def pickIndex(self) -> int:
+                # pick index with between 0 and total sum-1
+                '''
+                [1,2,3,4]
+                
+                so we have
+                [1, 3, 6, 10]
+                pick # between 1 and 10
+                
+                1 -> first idx
+                2 -> second
+                3 -> second idx
+                4 -> third idx
+                aka binary search for right idx which is always equal to or bigger than you!
+                never take smaller one
+                '''    
+                
+                r = random.randint(1, self.s)
+                start = 0
+                end = len(self.cum_sum) - 1
+                
+                while start < end:
+                    mid = start + (end - start)//2
+                    # print("start, mid, end, val", start, mid, end, self.cum_sum[mid])         
+                    if self.cum_sum[mid] == r:
+                        # return that idx!
+                        return  mid
+                    elif r < self.cum_sum[mid]:
+                        end = mid
+                    else:
+                        start = mid+1 # end might be the element we need!
+                
+                # also just do return bisect.bisect_left(self.cum_sum, r)
 
-        bool delim(char c) {
-            return c == ' ';
-        }
+                return start            
+                
 
-        bool is_op(char c) {
-            return c == '+' || c == '-' || c == '*' || c == '/';
-        }
 
-        int priority (char op) {
-            if (op == '+' || op == '-')
-                return 1;
-            if (op == '*' || op == '/')
-                return 2;
-            return -1;
-        }
 
-        void process_op(stack<int>& st, char op) {
-            int r = st.top(); st.pop();
-            int l = st.top(); st.pop();
-            switch (op) {
-                case '+': st.push(l + r); break;
-                case '-': st.push(l - r); break;
-                case '*': st.push(l * r); break;
-                case '/': st.push(l / r); break;
-            }
-        }
+    WEIGHTED RANDOM PICK INDEX WITH ALIAS METHOD
+        O(1) INTELLIGENT ALIAS METHOD: (TODO WRITE NOTES ON THIS.)
+        https://leetcode.com/problems/random-pick-with-weight/discuss/671439/Python-Smart-O(1)-solution-with-detailed-explanation
 
-        int evaluate(string& s) {
-            stack<int> st;
-            stack<char> op;
-            for (int i = 0; i < (int)s.size(); i++) {
-                if (delim(s[i]))
-                    continue;
+        Probably you already aware of other solutions, which use linear search with O(n) complexity and binary search with O(log n) complexity. 
+        When I first time solved this problem, I thought, that O(log n) is the best complexity you can achieve, howerer it is not! You can 
+        achieve O(1) complexity of function pickIndex(), using smart mathematical trick: let me explain it on the example: 
+        w = [w1, w2, w3, w4] = [0.1, 0.2, 0.3, 0.4]. Let us create 4 boxes with size 1/n = 0.25 and distribute original weights into 
+        our boxes in such case, that there is no more than 2 parts in each box. For example we can distribute it like this:
 
-                if (s[i] == '(') {
-                    op.push('(');
-                } else if (s[i] == ')') {
-                    while (op.top() != '(') {
-                        process_op(st, op.top());
-                        op.pop();
-                    }
-                    op.pop();
-                } else if (is_op(s[i])) {
-                    char cur_op = s[i];
-                    while (!op.empty() && priority(op.top()) >= priority(cur_op)) {
-                        process_op(st, op.top());
-                        op.pop();
-                    }
-                    op.push(cur_op);
-                } else {
-                    int number = 0;
-                    while (i < (int)s.size() && isalnum(s[i]))
-                        number = number * 10 + s[i++] - '0';
-                    --i;
-                    st.push(number);
-                }
-            }
+        Box 1: 0.1 of w1 and 0.15 of w3
+        Box 2: 0.2 of w2 and 0.05 of w3
+        Box 3: 0.1 of w3 and 0.15 of w4
+        Box 4: 0.25 of w4
+        (if weights sum of weights is not equal to one, we normalize them first, dividing by sum of all weights).
 
-            while (!op.empty()) {
-                process_op(st, op.top());
-                op.pop();
-            }
-            return st.top();
-        }
 
-        Thus we learned how to calculate the value of an expression in O(n), 
-        at the same time we implicitly used the reverse Polish notation.
-        By slightly modifying the above implementation it is also possible 
-        to obtain the expression in reverse Polish notation in an explicit form.
+        this method has a name: https://en.wikipedia.org/wiki/Alias_method , here you can see it in more details.
 
-    Parsing of all expressions include unary and right associative expr: 
+        Sketch of proof
+        There is always a way to distribute weights like this, it can be proved by induction, there is always be one box with weight <=1/n and 
+        one with >=1/n, we take first box in full and add the rest weight from the second, so they fill the full box. Like we did for Box 1 in our 
+        example: we take 0.1 - full w1 and 0.15 from w3. After we did it we have w2: 0.2, w3: 0.15 and w4: 0.4, and again we have one box with >=1/4 and one box with <=1/4.
 
-        Unary operators
-            Now suppose that the expression also contains unary operators 
-            (operators that take one argument). The unary plus and 
-            unary minus are common examples of such operators.
+        Now, when we created all boxes, to generate our data we need to do 2 steps: first, to generate box number in O(1), because sizes of boxes are 
+        equal, and second, generate point uniformly inside this box to choose index. This is working, because of Law of total probability.
 
-            One of the differences in this case, is that we need to 
-            determine whether the current operator is a unary or a binary one.
+        Complexity. Time and space complexity of preprocessing is O(n), but we do it only once. Time and space for function pickIndex is just O(1): 
+        all we need to do is generate uniformly distributed random variable twice!
 
-            You can notice, that before an unary operator, there always is 
-            another operator or an opening parenthesis, or nothing at 
-            all (if it is at the very beginning of the expression). On the contrary 
-            before a binary operator there will always be an operand (number) 
-            or a closing parenthesis. Thus it is easy to flag 
-            whether the next operator can be unary or not.
+        Code is not the easiest one to follow, but so is the solution. First, I keep two dictionaries Dic_More and Dic_Less, where I distribute 
+        weights if they are more or less than 1/n. Then I Iterate over these dictionaries and choose one weight which is more than 1/n, another 
+        which is less, and update our weights. Finally when Dic_Less is empty, it means that 
+        we have only elements equal to 1/n and we put them all into separate boxes.
 
-            Additionally we need to execute a unary and a binary operator 
-            differently. And we need to chose the priority of a binary operator 
-            higher than all of the binary operations.
+        I keep boxes in the following way: self.Boxes is a list of tuples, with 3 numbers: index of first weight, index of second weight and split, 
+        for example for Box 1: 0.1 of w1 and 0.15 of w3, we keep (1, 3, 0.4). If we have only one weight in box, we keep its index.
 
-            In addition it should be noted, that some unary operators 
-            (e.g. unary plus and unary minus) are actually right-associative.
+            class Solution:
+            def __init__(self, w):
+                ep = 10e-5
+                self.N, summ = len(w), sum(w)
+                weights = [elem/summ for elem in w]
+                Dic_More, Dic_Less, self.Boxes = {}, {}, []
+                
+                for i in range(self.N):
+                    if weights[i] >= 1/self.N:
+                        Dic_More[i] = weights[i]
+                    else:
+                        Dic_Less[i] = weights[i]
+
+                while Dic_More and Dic_Less:
+                    t_1 = next(iter(Dic_More))
+                    t_2 = next(iter(Dic_Less))
+                    self.Boxes.append([t_2,t_1,Dic_Less[t_2]*self.N])
+
+                    Dic_More[t_1] -= (1/self.N - Dic_Less[t_2])
+                    if Dic_More[t_1] < 1/self.N - ep:
+                        Dic_Less[t_1] = Dic_More[t_1]
+                        Dic_More.pop(t_1)
+                    Dic_Less.pop(t_2)
+                
+                for key in Dic_More: self.Boxes.append([key])
 
-        Right-associativity
-            Right-associative means, that whenever the priorities are equal, 
-            the operators must be evaluated from right to left.
+            def pickIndex(self):
+                r = random.uniform(0, 1)
+                Box_num = int(r*self.N)
+                if len(self.Boxes[Box_num]) == 1:
+                    return self.Boxes[Box_num][0]
+                else:
+                    q = random.uniform(0, 1)
+                    if q < self.Boxes[Box_num][2]:
+                        return self.Boxes[Box_num][0]
+                    else:
+                        return self.Boxes[Box_num][1]
 
-            As noted above, unary operators are usually right-associative. 
-            Another example for an right-associative operator is the 
-            exponentiation operator (a∧b∧c is usually perceived as a^(b^c) and not as (a^b)^c.
 
-            What difference do we need to make in order to correctly handle 
-            right-associative operators? It turns out that the changes 
-            are very minimal. The only difference will be, if the priorities 
-            are equal we will postpone the execution of the right-associative operation.
+    Generate uniform random integer
 
-            The only line that needs to be replaced is
+    Problem: given function of rand3() which return uniformly random int number of [1,2,3], 
+    write a random function rand4(), which return uniformly random integer of [1,2,3,4]
 
-            while (!op.empty() && priority(op.top()) >= priority(cur_op))
+    How to test it?
+    As follow up, I was asked about how to test rand4() function, to verify it's truly random.
+    My thought is to run rand4() for 1K times, and collect the frequency of [1,2,3,4], and then run 
+    rand4() 10K times and collect frequency, then run rand4() 100K time ... 
+    to see if the frequency of each number between [1,2,3,4] converge to 25%.
 
-            with:
+    There is a scenario like 1,2,3,4,1,2,3,4,1,2,3,4 ... ... like round robin generation. 
+    it would pass the convergence test I mentioned above, but it's not uniformly random. 
+    So does any pattern that shows a deterministic pattern, like 1,2,3,4,4,3,2,1 ...
 
-            while (!op.empty() && (
-                    (left_assoc(cur_op) && priority(op.top()) >= priority(cur_op)) ||
-                    (!left_assoc(cur_op) && priority(op.top()) > priority(cur_op))
-                ))
+    Any idea about how to test rand4() is truely uniformly random?
 
-            where left_assoc is a function that decides if an 
-            operator is left_associative or not.
+    Soln:
+        Can you generate a list of numbers by re-rolling rand3() the LCM of 3 and 4 which is 12.
+        So role rand3 4 times, sum it, do mod 4 -> and tell me what you get.
+        ^ Does this work??
 
-        Here is an implementation for the binary 
-        operators + − ∗ / and the unary operators + and −.
+        Something about REJECTION SAMPLING is how you do it!!
 
-            bool delim(char c) {
-                return c == ' ';
-            }
+    Any idea about how to test rand4() is truely uniformly random?
 
-            bool is_op(char c) {
-                return c == '+' || c == '-' || c == '*' || c == '/';
-            }
+    There are probably better ways, but... you could run rand4 a million times, store the results in a 1MB file, 
+    and let a good compression program compress it. It should result in about 250KB. If there are easy patterns 
+    like your examples or if the distribution is significantly non-uniform, it will be significantly smaller.
 
-            bool is_unary(char c) {
-                return c == '+' || c=='-';
-            }
+    
+    https://leetcode.com/problems/implement-rand10-using-rand7/
 
-            int priority (char op) {
-                if (op < 0) // unary operator get highest priority
-                    return 3; // Negative operators are right associative.
-                if (op == '+' || op == '-')
-                    return 1;
-                if (op == '*' || op == '/')
-                    return 2;
-                return -1;
-            }
 
-            void process_op(stack<int>& st, char op) {
-                if (op < 0) {
-                    int l = st.top(); st.pop();
-                    switch (-op) { // Negative operators are right associative. 
-                        case '+': st.push(l); break;
-                        case '-': st.push(-l); break;
-                    }
-                } else {
-                    int r = st.top(); st.pop();
-                    int l = st.top(); st.pop();
-                    switch (op) {
-                        case '+': st.push(l + r); break;
-                        case '-': st.push(l - r); break;
-                        case '*': st.push(l * r); break;
-                        case '/': st.push(l / r); break;
-                    }
-                }
-            }
+    Given the API rand7() that generates a uniform random integer in the range [1, 7], 
+    write a function rand10() that generates a uniform random integer in the range [1, 10]. 
+    You can only call the API rand7(), and you shouldn't call any other API. Please do not use a language's built-in random API.
 
-            int evaluate(string& s) {
-                stack<int> st;
-                stack<char> op;
-                bool may_be_unary = true;
-                for (int i = 0; i < (int)s.size(); i++) {
-                    if (delim(s[i]))
-                        continue;
+    Each test case will have one internal argument n, the number of times that your implemented 
+    function rand10() will be called while testing. Note that this is not an argument passed to rand10().
+    Use REJECTION SAMPLING
 
-                    if (s[i] == '(') {
-                        op.push('(');
-                        may_be_unary = true;
-                    } else if (s[i] == ')') {
-                        while (op.top() != '(') {
-                            process_op(st, op.top());
-                            op.pop();
-                        }
-                        op.pop();
-                        may_be_unary = false;
-                    } else if (is_op(s[i])) {
-                        char cur_op = s[i];
-                        if (may_be_unary && is_unary(cur_op))
-                            cur_op = -cur_op;
-                        while (!op.empty() && (
-                                (cur_op >= 0 && priority(op.top()) >= priority(cur_op)) ||
-                                (cur_op < 0 && priority(op.top()) > priority(cur_op))
-                            )) {
-                            process_op(st, op.top());
-                            op.pop();
-                        }
-                        op.push(cur_op);
-                        may_be_unary = true;
-                    } else {
-                        int number = 0;
-                        while (i < (int)s.size() && isalnum(s[i]))
-                            number = number * 10 + s[i++] - '0';
-                        --i;
-                        st.push(number);
-                        may_be_unary = false;
-                    }
-                }
+    Intuition
 
-                while (!op.empty()) {
-                    process_op(st, op.top());
-                    op.pop();
-                }
-                return st.top();
+    What if you could generate a random integer in the range 1 to 49? How would you generate a random integer 
+    in the range of 1 to 10? What would you do if the generated number is in the desired range? What if it is not?
+
+    Algorithm
+
+    This solution is based upon Rejection Sampling. The main idea is when you generate a number in the desired range,
+    output that number immediately. If the number is out of the desired range, reject it and re-sample again. 
+    As each number in the desired range has the same probability of being chosen, a uniform distribution is produced.
+
+    Obviously, we have to run rand7() function at least twice, as there are not enough numbers in the range of 1 to 10. 
+    By running rand7() twice, we can get integers from 1 to 49 uniformly. Why?
+    -> because we can generate 2 indexes into an array!
+     1 2 3 4 5 6 7
+   1 1 2 3 4 5 6 7 
+   2 8 91011121314
+   3 ...
+   4
+   5
+   6
+   7
+    aka -> 7 * i + j = 7*6 + 7 == 49?
+    
+        class Solution {
+        public:
+            int rand10() {
+                int row, col, idx;
+                do {
+                    row = rand7();
+                    col = rand7();
+                    idx = col + (row - 1) * 7;
+                } while (idx > 40);
+                return 1 + (idx - 1) % 10;
             }
+        };  
+    
+    Why not return 1 + (idx % 10) for Approach 1?
+    -> 
 
+        Because we are using % operation here, we need to do a quick math trick.
 
+        idx is in range 1 2 3 4 5 6 7 8 9 10, if we do nothing, it'll become 1 2 3 4 5 6 7 8 9 "0" after using (% 10).
 
-#######################################################
-#######################################################
-COOL NOTES PART -4: Graph Algorithms
+        So we need to offset 1, to range 0 1 2 3 4 5 6 7 8 9 at first.
+        After using (% 10), then add 1 back.
 
-    Bellman Ford:
+        Now it is correctly in range 1 2 3 4 5 6 7 8 9 10 again.
 
-        #Class to represent a graph 
-        class Graph: 
-        
-            def __init__(self,vertices): 
-                self.V= vertices #No. of vertices 
-                self.graph = [] # default dictionary to store graph 
+        Approach 2: Utilizing out-of-range samples
+        Intuition
 
-            # function to add an edge to graph 
-            def addEdge(self,u,v,w): 
-                self.graph.append([u, v, w]) 
+        There are a total of 2.45 calls to rand7() on average when using approach 1. 
+        Can we do better? Glad that you asked. In fact, we are able to improve average 
+        number of calls to rand7() by about 10%.
 
-            # The main function that finds shortest distances from src to 
-            # all other vertices using Bellman-Ford algorithm.  The function 
-            # also detects negative weight cycle 
-            def BellmanFord(self, src): 
-        
-                # Step 1: Initialize distances from src to all other vertices 
-                # as INFINITE 
-                dist = [float("Inf")] * self.V 
-                dist[src] = 0 
-        
-        
-                # Step 2: Relax all edges |V| - 1 times. A simple shortest  
-                # path from src to any other vertex can have at-most |V| - 1  
-                # edges 
-                for i in range(self.V - 1): 
-                    # Update dist value and parent index of the adjacent vertices of 
-                    # the picked vertex. Consider only those vertices which are still in 
-                    # queue 
-                    for u, v, w in self.graph: 
-                        if dist[u] != float("Inf") and dist[u] + w < dist[v]: 
-                                dist[v] = dist[u] + w 
-        
-                # Step 3: check for negative-weight cycles.  The above step  
-                # guarantees shortest distances if graph doesn't contain  
-                # negative weight cycle.  If we get a shorter path, then there 
-                # is a cycle. 
-        
-                for u, v, w in self.graph: 
-                        if dist[u] != float("Inf") and dist[u] + w < dist[v]: 
-                                print "Graph contains negative weight cycle"
-                                return
-                                
-                # print all distance 
-                self.printArr(dist) 
+        The idea is that we should not throw away the out-of-range samples, but instead use them to 
+        increase our chances of finding an in-range sample on the successive call to rand7.
 
-    Floyd Warshall:
-        We initialize the solution matrix same as 
-        the input graph matrix as a first step. 
-        Then we update the solution matrix by considering all 
-        vertices as an intermediate vertex. 
-        The idea is to one by one pick all vertices and updates all shortest 
-        paths which include the picked vertex as an intermediate vertex in the 
-        shortest path. When we pick vertex number k as an intermediate vertex, 
-        we already have considered vertices {0, 1, 2, .. k-1} as intermediate vertices. 
+        Algorithm
 
-        For every pair (i, j) of the source and destination 
-        vertices respectively, there are two possible cases.
+        Start by generating a random integer in the range 1 to 49 using the aforementioned method. 
+        In the event that we could not generate a number in the desired range (1 to 40), it is equally 
+        likely that each number of 41 to 49 would be chosen. In other words, we are able to obtain integers 
+        in the range of 1 to 9 uniformly. Now, run rand7() again to obtain integers in the range of 1 to 63 uniformly. 
+        Apply rejection sampling where the desired range is 1 to 60. If the generated number is in the desired range (1 to 60), 
+        we return the number. If it is not (61 to 63), we at least obtain integers of 1 to 3 uniformly. Run rand7() again to 
+        obtain integers in the range of 1 to 21 uniformly. The desired range is 1 to 20, and in the unlikely event we 
+        get a 21, we reject it and repeat the entire process again.
 
-        1)  k is not an intermediate vertex in shortest path from i to j. 
-            We keep the value of dist[i][j] as it is.
+        class Solution {
+        public:
+            int rand10() {
+                int a, b, idx;
+                while (true) {
+                    a = rand7();
+                    b = rand7();
+                    idx = b + (a - 1) * 7;
+                    if (idx <= 40)
+                        return 1 + (idx - 1) % 10;
+                    a = idx - 40;
+                    b = rand7();
+                    // get uniform dist from 1 - 63
+                    idx = b + (a - 1) * 7;
+                    if (idx <= 60)
+                        return 1 + (idx - 1) % 10;
+                    a = idx - 60;
+                    b = rand7();
+                    // get uniform dist from 1 - 21
+                    idx = b + (a - 1) * 7;
+                    if (idx <= 20)
+                        return 1 + (idx - 1) % 10;
+                }
+            }
+        };
 
-        2)  k is an intermediate vertex in shortest path from i to j. We update 
-            the value of dist[i][j] as dist[i][k] + dist[k][j] if dist[i][j] > dist[i][k] + dist[k][j]
+        Complexity Analysis
 
+        Time Complexity: O(1)O(1) average, but O(\infty)O(∞) worst case.
 
-        # Solves all pair shortest path via Floyd Warshall Algorithm 
-        def floydWarshall(graph): 
-        
-            """ dist[][] will be the output matrix that will finally 
-                have the shortest distances between every pair of vertices """
-            """ initializing the solution matrix same as input graph matrix 
-            OR we can say that the initial values of shortest distances 
-            are based on shortest paths considering no  
-            intermediate vertices """
 
-            dist = map(lambda i : map(lambda j : j , i) , graph) 
-            
-            """ Add all vertices one by one to the set of intermediate 
-            vertices. 
-            ---> Before start of an iteration, we have shortest distances 
-            between all pairs of vertices such that the shortest 
-            distances consider only the vertices in the set  
-            {0, 1, 2, .. k-1} as intermediate vertices. 
-            ----> After the end of a iteration, vertex no. k is 
-            added to the set of intermediate vertices and the  
-            set becomes {0, 1, 2, .. k} 
-            """
 
-            for k in range(V): 
-        
-                # pick all vertices as source one by one 
-                for i in range(V): 
-        
-                    # Pick all vertices as destination for the 
-                    # above picked source 
-                    for j in range(V): 
-        
-                        # If vertex k is on the shortest path from  
-                        # i to j, then update the value of dist[i][j] 
-                        dist[i][j] = min(dist[i][j] , 
-                                        dist[i][k]+ dist[k][j] 
-                                        ) 
-            printSolution(dist)
-        
-        graph = [[0,5,INF,10], 
-                [INF,0,3,INF], 
-                [INF, INF, 0,   1], 
-                [INF, INF, INF, 0] 
-            ] 
 
-        # Print the solution 
-        floydWarshall(graph); 
-        Following matrix shows the shortest distances between every pair of vertices
-        0      5      8      9
-        INF      0      3      4
-        INF    INF      0      1
-        INF    INF    INF      0
 
-    DJIKSTRA:
+    710. Random Pick With Blacklist (HARD): (TODO: SOLVE BY YOURSELF!)
+        Hard
 
-        from collections import defaultdict
-        from heapq import *
+        You are given an integer n and an array of unique integers blacklist. Design an algorithm to pick a random integer in 
+        the range [0, n - 1] that is not in blacklist. Any integer that is in the mentioned range and not in blacklist should 
+        be equally likely to be returned.
 
-        def dijkstra(edges, f, t):
-            g = defaultdict(list)
-            for l,r,c in edges:
-                g[l].append((c,r))
+        Optimize your algorithm such that it minimizes the number of calls to the built-in random function of your language.
+
+        Implement the Solution class:
 
-            q, seen, mins = [(0,f,())], set(), {f: 0}
-            while q:
-                (cost,v1,path) = heappop(q)
-                if v1 not in seen:
-                    seen.add(v1)
-                    path = (v1, path)
-                    if v1 == t: return (cost, path)
+        Solution(int n, int[] blacklist) Initializes the object with the integer n and the blacklisted integers blacklist.
+        int pick() Returns a random integer in the range [0, n - 1] and not in blacklist.
+        
 
-                    for c, v2 in g.get(v1, ()):
-                        if v2 in seen: continue
-                        prev = mins.get(v2, None)
-                        next = cost + c
-                        if prev is None or next < prev:
-                            mins[v2] = next
-                            heappush(q, (next, v2, path))
+        Example 1:
 
-            return float("inf")
+        Input
+        ["Solution", "pick", "pick", "pick", "pick", "pick", "pick", "pick"]
+        [[7, [2, 3, 5]], [], [], [], [], [], [], []]
+        Output
+        [null, 0, 4, 1, 6, 1, 0, 4]
+
+        Explanation
+        Solution solution = new Solution(7, [2, 3, 5]);
+        solution.pick(); // return 0, any integer from [0,1,4,6] should be ok. Note that for every call of pick,
+                        // 0, 1, 4, and 6 must be equally likely to be returned (i.e., with probability 1/4).
+        solution.pick(); // return 4
+        solution.pick(); // return 1
+        solution.pick(); // return 6
+        solution.pick(); // return 1
+        solution.pick(); // return 0
+        solution.pick(); // return 4
 
-        if __name__ == "__main__":
-            edges = [
-                ("A", "B", 7),
-                ("A", "D", 5),
-                ("B", "C", 8),
-                ("B", "D", 9),
-                ("B", "E", 7),
-                ("C", "E", 5),
-                ("D", "E", 15),
-                ("D", "F", 6),
-                ("E", "F", 8),
-                ("E", "G", 9),
-                ("F", "G", 11)
-            ]
+        
+        Harman Soln 
+        Just swap blacklisted elements to end of an array initalized from size 0 to N:
+        Use 2 pointer to keep track of border of elements that are blacklisted on the right side,
+        left pointer indicates elements not in blacklist and between left and right are unprocessed elements!
+        move right until you are on non blaclist item, and move left until you find a blacklist item and swap with right!
 
-            print "=== Dijkstra ==="
-            print edges
-            print "A -> E:"
-            print dijkstra(edges, "A", "E")
-            print "F -> G:"
-            print dijkstra(edges, "F", "G")
+        Then choose betweel [0 to L - sizeOfBlacklist]
 
-#############################################################################
-#############################################################################
-COOL NOTES PART -2: HOW TO USE HEAP DICTIONARIES WITH DECREASE KEY USING HEAPQ!
+        Better soln is to have map initialized of size Blacklist and do following:
 
-        -> Sort stability: how do you get two tasks with equal priorities 
-        to be returned in the order they were originally added?
+        Treat the first N - |B| numbers as those we can pick from. Iterate through the blacklisted 
+        numbers and map each of them to to one of the remaining non-blacklisted |B| numbers
 
-        -> In the future with Python 3, tuple comparison breaks for (priority, task) 
-        pairs if the priorities are equal and the tasks do not have a default comparison order.
+        For picking, just pick a random uniform int in 0, N - |B|. If its not blacklisted, 
+        return the number. If it is, return the number that its mapped to
 
-        -> If the priority of a task changes, how do you 
-        move it to a new position in the heap?
+        import random
+
+        class Solution:
+            def __init__(self, N, blacklist):
+                blacklist = sorted(blacklist)
+                self.b = set(blacklist)
+                self.m = {}
+                self.length = N - len(blacklist)
+                j = 0
+                for i in range(self.length, N):
+                    if i not in self.b:
+                        self.m[blacklist[j]] = i
+                        j += 1
+
+            def pick(self):
+                i = random.randint(0, self.length - 1)
+                return self.m[i] if i in self.m else i    
 
-        -> Or if a pending task needs to be deleted, 
-        how do you find it and remove it from the queue?
 
-        A solution to the first two challenges is to store entries as 3-element list 
-        including the priority, an entry count, and the task. The entry count serves 
-        as a tie-breaker so that two tasks with the same priority are returned 
-        in the order they were added. And since no two entry counts are the same, 
-        the tuple comparison will never attempt to directly compare two tasks.
 
-        The remaining challenges revolve around finding a pending task and 
-        making changes to its priority or removing it entirely. 
-        Finding a task can be done with a dictionary pointing to an entry in the queue.
 
-        Removing the entry or changing its priority is more difficult because 
-        it would break the heap structure invariants. So, a possible solution 
-        is to mark the existing entry as 
-        Removed and add a new entry with the revised priority:
 
-        pq = []                         # list of entries arranged in a heap
-        entry_finder = {}               # mapping of tasks to entries
-        REMOVED = '<removed-task>'      # placeholder for a removed task
-        counter = itertools.count()     # unique sequence count
 
-        def add_task(task, priority=0):
-            'Add a new task or update the priority of an existing task'
-            if task in entry_finder:
-                remove_task(task)
-            count = next(counter)
-            entry = [priority, count, task]
-            entry_finder[task] = entry
-            heappush(pq, entry)
 
-        def remove_task(task):
-            'Mark an existing task as REMOVED.  Raise KeyError if not found.'
-            entry = entry_finder.pop(task)
-            entry[-1] = REMOVED
 
-        def pop_task():
-            'Remove and return the lowest priority task. Raise KeyError if empty.'
-            while pq:
-                priority, count, task = heappop(pq)
-                if task is not REMOVED:
-                    del entry_finder[task]
-                    return task
-            raise KeyError('pop from an empty priority queue')
 
 
 
